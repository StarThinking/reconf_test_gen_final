reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755415020-172.17.0.3-1597688084057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-f99da813-3ad1-4939-bf08-9bb5fe722f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-a6e2b15f-d631-414a-95a8-c6a734c55979,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-bbe7d58b-45ed-42ea-a5ad-508bc4b56510,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-b16e39bb-fb60-463a-9d77-ba4ce2c2d673,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e7560dc8-365b-4a52-9064-53e4c87ec4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-923f8dcb-f200-4755-93c8-8aadec5989da,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-9a9b0358-947b-4e07-b7ab-1e6892d78f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-fcac6ddc-f763-4e1a-b672-e4f0b0e0f780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755415020-172.17.0.3-1597688084057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-f99da813-3ad1-4939-bf08-9bb5fe722f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-a6e2b15f-d631-414a-95a8-c6a734c55979,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-bbe7d58b-45ed-42ea-a5ad-508bc4b56510,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-b16e39bb-fb60-463a-9d77-ba4ce2c2d673,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e7560dc8-365b-4a52-9064-53e4c87ec4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-923f8dcb-f200-4755-93c8-8aadec5989da,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-9a9b0358-947b-4e07-b7ab-1e6892d78f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-fcac6ddc-f763-4e1a-b672-e4f0b0e0f780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092584179-172.17.0.3-1597688461933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-0e995e8b-55b8-4c55-93c3-20276b61a237,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-465a4fbd-bcaf-47e8-8f49-526df6c48b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-05baeb95-b9b7-4691-841d-8854c244c328,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-fc636c7d-bcc3-4912-b33e-1fdf218b2b54,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-6ba2d15a-019e-42d5-8ec3-99439652aa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-7fee8300-c5ff-4d74-a6dd-088986ff7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-a9734ae1-a359-4bfe-ac0f-6eff3aa99a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-c722b31d-b8dc-4094-ac5c-24b53ce5dc1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092584179-172.17.0.3-1597688461933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-0e995e8b-55b8-4c55-93c3-20276b61a237,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-465a4fbd-bcaf-47e8-8f49-526df6c48b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-05baeb95-b9b7-4691-841d-8854c244c328,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-fc636c7d-bcc3-4912-b33e-1fdf218b2b54,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-6ba2d15a-019e-42d5-8ec3-99439652aa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-7fee8300-c5ff-4d74-a6dd-088986ff7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-a9734ae1-a359-4bfe-ac0f-6eff3aa99a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-c722b31d-b8dc-4094-ac5c-24b53ce5dc1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624484987-172.17.0.3-1597688755201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-4efd9c8d-4206-417f-851c-81fcbd03aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-ba818afd-edb3-4890-b006-fa90731b6258,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-7347738f-e452-4aab-9446-468d8a17bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-5ab7a72b-1b10-4026-9cc7-0c442ac9865c,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-e4b55227-dddb-4963-a7e8-510a60aa6486,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-48d523db-2d34-41e5-b557-cd0ea4b4b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-38ae87f5-667a-4dbe-a152-c7fe03068cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-4f683857-daf0-4848-9e48-8657ca32e1d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624484987-172.17.0.3-1597688755201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-4efd9c8d-4206-417f-851c-81fcbd03aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-ba818afd-edb3-4890-b006-fa90731b6258,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-7347738f-e452-4aab-9446-468d8a17bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-5ab7a72b-1b10-4026-9cc7-0c442ac9865c,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-e4b55227-dddb-4963-a7e8-510a60aa6486,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-48d523db-2d34-41e5-b557-cd0ea4b4b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-38ae87f5-667a-4dbe-a152-c7fe03068cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-4f683857-daf0-4848-9e48-8657ca32e1d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348682954-172.17.0.3-1597688997682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-98284100-ea52-44cc-b9de-ec4836ffef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-a0c94016-e0f4-478c-8b13-0508907ede19,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-e937115c-bfb2-42a2-9344-a7839c44b04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-78cd16e4-a43b-4d16-92c9-66312038dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-281eabc5-0cca-4675-b282-09f7ab877f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-5f7fff99-3a7e-4f4b-8134-02f6e1dcb08a,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-dda20532-b501-47c7-ac11-b88d2595b52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-8c4537be-1475-4530-9b27-6f0e78488a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348682954-172.17.0.3-1597688997682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-98284100-ea52-44cc-b9de-ec4836ffef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-a0c94016-e0f4-478c-8b13-0508907ede19,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-e937115c-bfb2-42a2-9344-a7839c44b04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-78cd16e4-a43b-4d16-92c9-66312038dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-281eabc5-0cca-4675-b282-09f7ab877f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-5f7fff99-3a7e-4f4b-8134-02f6e1dcb08a,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-dda20532-b501-47c7-ac11-b88d2595b52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-8c4537be-1475-4530-9b27-6f0e78488a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961983920-172.17.0.3-1597689138223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-bdb90613-466a-4ff0-a0c4-9aa22ebd70be,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-1807defa-f11e-493f-a5a8-6ddb86d05fed,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-1d043caa-2989-406f-8449-029f50113829,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-3ce9e552-62d1-4847-a6ed-3284add26efa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-dd36d3ec-a1cd-4068-a521-d64d061a15f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-27f05abc-90b7-4fe3-80a3-10f1b82ff2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-872966c9-0587-4490-85ee-c06796bdf525,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-517c2e8d-ef77-446b-ad46-d85dfd3081e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961983920-172.17.0.3-1597689138223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-bdb90613-466a-4ff0-a0c4-9aa22ebd70be,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-1807defa-f11e-493f-a5a8-6ddb86d05fed,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-1d043caa-2989-406f-8449-029f50113829,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-3ce9e552-62d1-4847-a6ed-3284add26efa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-dd36d3ec-a1cd-4068-a521-d64d061a15f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-27f05abc-90b7-4fe3-80a3-10f1b82ff2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-872966c9-0587-4490-85ee-c06796bdf525,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-517c2e8d-ef77-446b-ad46-d85dfd3081e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016026911-172.17.0.3-1597689294834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-e3914ba5-3f69-4062-9db6-fa1475955f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-f5bb0bf4-955b-48c7-8ebd-9fc3e807a7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-4f5857b0-fe98-49b2-92ad-ed6bbc24ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-29c21de2-ca08-4b82-81b8-a37ae5ea5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-59716882-3014-4563-b218-d100c5d3c072,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d7e02801-790c-47f3-a5de-045decd30193,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-474a8d19-7443-4bc8-8d37-69e7575a6707,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-cd79af9b-4604-42fc-ac50-a99ad105ec6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016026911-172.17.0.3-1597689294834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-e3914ba5-3f69-4062-9db6-fa1475955f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-f5bb0bf4-955b-48c7-8ebd-9fc3e807a7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-4f5857b0-fe98-49b2-92ad-ed6bbc24ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-29c21de2-ca08-4b82-81b8-a37ae5ea5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-59716882-3014-4563-b218-d100c5d3c072,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d7e02801-790c-47f3-a5de-045decd30193,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-474a8d19-7443-4bc8-8d37-69e7575a6707,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-cd79af9b-4604-42fc-ac50-a99ad105ec6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626840911-172.17.0.3-1597689769111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-fdfab1f8-488c-47f2-b5e6-d6c40b08db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-02653ab5-da59-448f-815d-82d3a8b9275b,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-a9b5fbb7-0d9f-4609-b15b-d694c1c1c291,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-aa1399a4-91d8-4942-84e6-c61c292987c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-af6975f6-1b89-4833-bedf-d47854b20158,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-3584451e-428e-4a1f-9ac6-605fff86983f,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-a6093472-03b0-4fa5-9055-838dea59827e,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-fe1d1526-9523-4dce-bc17-42ddfb43186e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626840911-172.17.0.3-1597689769111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-fdfab1f8-488c-47f2-b5e6-d6c40b08db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-02653ab5-da59-448f-815d-82d3a8b9275b,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-a9b5fbb7-0d9f-4609-b15b-d694c1c1c291,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-aa1399a4-91d8-4942-84e6-c61c292987c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-af6975f6-1b89-4833-bedf-d47854b20158,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-3584451e-428e-4a1f-9ac6-605fff86983f,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-a6093472-03b0-4fa5-9055-838dea59827e,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-fe1d1526-9523-4dce-bc17-42ddfb43186e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243076477-172.17.0.3-1597689953341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-b12eda06-66a1-4d5c-abed-d852c24babb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-0315dc27-25db-4516-9844-b7192e7d688d,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-41a8fac2-c8d2-4bc3-b110-19ef9c40c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-e01ad32a-2895-4890-9cea-26a2c3488c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-50936b2b-de20-458a-8106-6cff2605ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-39738bf9-fde0-4bcf-8a5d-f343184061b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2dafa38c-92e9-4f8f-a4c2-5bde3d7ffe31,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9c987c3d-6e9c-4897-a002-ef2676b8abc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243076477-172.17.0.3-1597689953341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-b12eda06-66a1-4d5c-abed-d852c24babb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-0315dc27-25db-4516-9844-b7192e7d688d,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-41a8fac2-c8d2-4bc3-b110-19ef9c40c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-e01ad32a-2895-4890-9cea-26a2c3488c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-50936b2b-de20-458a-8106-6cff2605ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-39738bf9-fde0-4bcf-8a5d-f343184061b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2dafa38c-92e9-4f8f-a4c2-5bde3d7ffe31,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9c987c3d-6e9c-4897-a002-ef2676b8abc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316446075-172.17.0.3-1597690027188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-88b93be0-2e16-4dd0-a6a0-dd340ec8be0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-17150422-1889-418b-86a4-fec1e19e9ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-73e31b1c-d3b8-45c4-be56-1e20baefeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-aba29d27-6292-42de-b65a-9cf56db028bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-4ddc6f79-6f95-47d9-889b-9b4f53eda8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9f7ca40f-8b32-4985-b065-4c3325ee8bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-ad576564-9e39-444b-9d30-bd65cc53a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-839f59aa-5d92-45d8-82f4-b557abdcf86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316446075-172.17.0.3-1597690027188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-88b93be0-2e16-4dd0-a6a0-dd340ec8be0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-17150422-1889-418b-86a4-fec1e19e9ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-73e31b1c-d3b8-45c4-be56-1e20baefeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-aba29d27-6292-42de-b65a-9cf56db028bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-4ddc6f79-6f95-47d9-889b-9b4f53eda8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9f7ca40f-8b32-4985-b065-4c3325ee8bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-ad576564-9e39-444b-9d30-bd65cc53a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-839f59aa-5d92-45d8-82f4-b557abdcf86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045808925-172.17.0.3-1597690092817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-4cd718c9-0bd0-4c94-96bc-95a536584e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-405898c4-e86b-4fc3-89d0-5d78a4b80014,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-c9ca2d4e-3279-4a31-8603-24878d1b596a,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-78393ffc-703c-498a-b9c5-70c3f3a81815,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1138211e-f62b-4232-847d-6c3e3bc58961,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-2deefc7b-1596-4437-81f0-10a1b42f1e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-38e54487-0281-4c07-85ac-c6be0733f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-8d343526-a262-46cf-b747-001e573234ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045808925-172.17.0.3-1597690092817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-4cd718c9-0bd0-4c94-96bc-95a536584e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-405898c4-e86b-4fc3-89d0-5d78a4b80014,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-c9ca2d4e-3279-4a31-8603-24878d1b596a,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-78393ffc-703c-498a-b9c5-70c3f3a81815,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1138211e-f62b-4232-847d-6c3e3bc58961,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-2deefc7b-1596-4437-81f0-10a1b42f1e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-38e54487-0281-4c07-85ac-c6be0733f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-8d343526-a262-46cf-b747-001e573234ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30819086-172.17.0.3-1597690645837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-10cf1fea-60ea-4f32-8654-1ee83c31edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-3c6488c7-535a-4b57-8981-7f459cfef44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-34db42e5-b52b-4ef9-a86c-8d3a4804e954,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-f87841d2-6db0-4420-9bc9-fd77144c926e,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5d916f63-e6b7-4c60-983e-c437a29e5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-eea0a6b9-a660-41b7-9b60-fd028306fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-f7806496-fd5b-4446-a32d-1e7538fb78ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-91bb07a9-527e-477c-8e05-b3a28a19bcfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30819086-172.17.0.3-1597690645837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-10cf1fea-60ea-4f32-8654-1ee83c31edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-3c6488c7-535a-4b57-8981-7f459cfef44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-34db42e5-b52b-4ef9-a86c-8d3a4804e954,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-f87841d2-6db0-4420-9bc9-fd77144c926e,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5d916f63-e6b7-4c60-983e-c437a29e5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-eea0a6b9-a660-41b7-9b60-fd028306fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-f7806496-fd5b-4446-a32d-1e7538fb78ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-91bb07a9-527e-477c-8e05-b3a28a19bcfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897720850-172.17.0.3-1597691338415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-59f109d2-8104-44c5-b529-407982ddc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-caa0e166-eb26-49d1-a037-08ace845cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-d31fa69d-45e9-41ad-8700-0a415fbcd9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-3920ac49-3b07-42e5-a6b6-8794fb38859e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-cbced325-a294-4d13-899a-6130d1a1f27c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-09e4c49a-c596-47b2-83e1-d17cb5ee38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-c96870b5-d9f6-44d2-9288-9c26f4b7c880,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-48a12684-bcf4-448b-855a-93479e22f60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897720850-172.17.0.3-1597691338415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-59f109d2-8104-44c5-b529-407982ddc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-caa0e166-eb26-49d1-a037-08ace845cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-d31fa69d-45e9-41ad-8700-0a415fbcd9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-3920ac49-3b07-42e5-a6b6-8794fb38859e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-cbced325-a294-4d13-899a-6130d1a1f27c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-09e4c49a-c596-47b2-83e1-d17cb5ee38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-c96870b5-d9f6-44d2-9288-9c26f4b7c880,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-48a12684-bcf4-448b-855a-93479e22f60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891141565-172.17.0.3-1597691421981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-6d6b4ea0-a1fc-4bdc-afb2-5227b4e6e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d2094998-8cac-4484-b33c-4badca7d6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-f9bc6b61-f259-4462-a111-9dd740f77964,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-920f01c8-3413-4b7e-a07d-b686b733ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ce1b5b73-6f7f-4c0f-968a-82e7fb1f8346,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-1947bb79-6faf-4e1f-9f4c-75e299056e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-1dd1b9aa-7474-423e-8dc4-887f56999076,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-5fba6cad-1788-4d05-961b-38cfed3fa472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891141565-172.17.0.3-1597691421981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-6d6b4ea0-a1fc-4bdc-afb2-5227b4e6e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-d2094998-8cac-4484-b33c-4badca7d6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-f9bc6b61-f259-4462-a111-9dd740f77964,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-920f01c8-3413-4b7e-a07d-b686b733ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ce1b5b73-6f7f-4c0f-968a-82e7fb1f8346,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-1947bb79-6faf-4e1f-9f4c-75e299056e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-1dd1b9aa-7474-423e-8dc4-887f56999076,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-5fba6cad-1788-4d05-961b-38cfed3fa472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395717645-172.17.0.3-1597691461836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-f5194735-cfd4-4842-bd2f-f2354663b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-3da77287-179f-4317-aac0-e414ad1c4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-d20e8d67-3d10-4d5c-8572-8adaac63a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-8ea7ef52-d999-48f2-99c3-dab74567c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-aa0fb9ac-38bc-4071-a977-c5a34609f385,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-e47aabb9-1872-4768-9218-c86372258038,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-78d4b006-8ab1-4fa7-a1e9-675889b16d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-fe41cf3e-69cc-4680-a06c-6668cd505df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395717645-172.17.0.3-1597691461836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-f5194735-cfd4-4842-bd2f-f2354663b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-3da77287-179f-4317-aac0-e414ad1c4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-d20e8d67-3d10-4d5c-8572-8adaac63a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-8ea7ef52-d999-48f2-99c3-dab74567c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-aa0fb9ac-38bc-4071-a977-c5a34609f385,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-e47aabb9-1872-4768-9218-c86372258038,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-78d4b006-8ab1-4fa7-a1e9-675889b16d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-fe41cf3e-69cc-4680-a06c-6668cd505df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131872453-172.17.0.3-1597691896726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-d1e3c42d-4ac5-46be-888f-20e9a0b0593d,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-fb124461-f37c-45bf-a9a9-24d433aaedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-e930f5bb-c3a2-4c6e-be42-a07460759b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-46cd3f2b-8e52-4c22-bad8-17838f2eb9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-5ec77bd1-bf32-4147-8c34-d3cdfe749e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-0f97dddb-2392-43e8-9abb-28600e15a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-5abc0ea3-aba1-4625-8259-c00826ea2030,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-a70a5dca-8cd6-4213-9567-f935b8034def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131872453-172.17.0.3-1597691896726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-d1e3c42d-4ac5-46be-888f-20e9a0b0593d,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-fb124461-f37c-45bf-a9a9-24d433aaedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-e930f5bb-c3a2-4c6e-be42-a07460759b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-46cd3f2b-8e52-4c22-bad8-17838f2eb9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-5ec77bd1-bf32-4147-8c34-d3cdfe749e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-0f97dddb-2392-43e8-9abb-28600e15a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-5abc0ea3-aba1-4625-8259-c00826ea2030,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-a70a5dca-8cd6-4213-9567-f935b8034def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649811821-172.17.0.3-1597692267247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45810,DS-65f612c5-923b-445a-9522-029246bb20c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-7953134e-92b4-4a03-a05b-4b753a13cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-4541ae69-243e-4285-a830-483425548582,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-56f7e2b3-0655-44e4-9af6-371bd7627d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-9a0fa76b-f54f-4a11-8876-817bebaa5322,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-b7255653-151d-4237-9913-91f6e0814755,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-1a8e76bf-37be-477a-8bbe-04eec7d31948,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-e5610a9a-5ecf-4d0b-bfb7-d3b54e80fe2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649811821-172.17.0.3-1597692267247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45810,DS-65f612c5-923b-445a-9522-029246bb20c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-7953134e-92b4-4a03-a05b-4b753a13cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-4541ae69-243e-4285-a830-483425548582,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-56f7e2b3-0655-44e4-9af6-371bd7627d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-9a0fa76b-f54f-4a11-8876-817bebaa5322,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-b7255653-151d-4237-9913-91f6e0814755,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-1a8e76bf-37be-477a-8bbe-04eec7d31948,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-e5610a9a-5ecf-4d0b-bfb7-d3b54e80fe2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23883570-172.17.0.3-1597692540340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-f6bca387-c9d7-4219-b139-052fdbabb563,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1e3dd6b5-d085-44ab-92d5-aa5c3043ec45,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-9980cd61-82fa-42fe-8d10-32a4c543b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-e732908a-12e5-4d21-ba57-f964a4657fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-036ef908-60bb-4ef4-9af9-7e36110a7094,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-e354cb6f-8639-4837-87a3-776dd635b846,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-931575b2-ef42-4aa4-9f2b-26a10143d774,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-e49070c0-2981-434a-8d29-af520a2c8741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23883570-172.17.0.3-1597692540340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-f6bca387-c9d7-4219-b139-052fdbabb563,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1e3dd6b5-d085-44ab-92d5-aa5c3043ec45,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-9980cd61-82fa-42fe-8d10-32a4c543b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-e732908a-12e5-4d21-ba57-f964a4657fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-036ef908-60bb-4ef4-9af9-7e36110a7094,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-e354cb6f-8639-4837-87a3-776dd635b846,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-931575b2-ef42-4aa4-9f2b-26a10143d774,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-e49070c0-2981-434a-8d29-af520a2c8741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959881965-172.17.0.3-1597692811509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-33d8aee6-c69b-45a1-898c-d265549f126d,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-c8dc3e3d-140b-479b-97ac-0e78a6d9cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-0e2ff8cd-70e5-4c3d-8c9e-2107623ae525,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-184507e2-9a52-4c04-a99c-9b105fcb8906,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-b1eb7312-74ce-4d30-bd1f-817b6fcb16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55332016-4153-4a43-a7ca-bda6d44788a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-47f82ba7-5241-4470-9bf1-f7b18ff8b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-6b56454c-2d8c-4713-b2e9-4f2747e999e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959881965-172.17.0.3-1597692811509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-33d8aee6-c69b-45a1-898c-d265549f126d,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-c8dc3e3d-140b-479b-97ac-0e78a6d9cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-0e2ff8cd-70e5-4c3d-8c9e-2107623ae525,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-184507e2-9a52-4c04-a99c-9b105fcb8906,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-b1eb7312-74ce-4d30-bd1f-817b6fcb16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55332016-4153-4a43-a7ca-bda6d44788a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-47f82ba7-5241-4470-9bf1-f7b18ff8b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-6b56454c-2d8c-4713-b2e9-4f2747e999e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265163976-172.17.0.3-1597692897273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-c5bf5c16-4913-4b36-9b26-9b7567d5f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-a30e19e7-977b-40a4-bfe1-7a4e8e33e226,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-58d72d17-6dd2-4165-8cde-92215c0018ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-4678412f-ac72-44ac-b296-8a0ce16d5411,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0268b56f-7143-4c18-99eb-15c327b0ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-cd09a0d9-4dc2-43c9-bdb9-7f2a97a67c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c5bc94ec-25b3-457c-a8de-fe7621295f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c005a7f2-d2ea-4eba-9f07-daf23481c064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265163976-172.17.0.3-1597692897273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-c5bf5c16-4913-4b36-9b26-9b7567d5f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-a30e19e7-977b-40a4-bfe1-7a4e8e33e226,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-58d72d17-6dd2-4165-8cde-92215c0018ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-4678412f-ac72-44ac-b296-8a0ce16d5411,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0268b56f-7143-4c18-99eb-15c327b0ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-cd09a0d9-4dc2-43c9-bdb9-7f2a97a67c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c5bc94ec-25b3-457c-a8de-fe7621295f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c005a7f2-d2ea-4eba-9f07-daf23481c064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820201145-172.17.0.3-1597692999645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-d2e00655-33bf-4970-88ee-6493bd0f75b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-b26d945b-b71c-4cd6-ae92-2731edad660f,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-0e0997cd-f856-4c84-913f-55738daa86cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-cde94d90-2753-4459-8ce3-4d72f3d217fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-d706b040-c0a4-46fb-a973-a7d74b59a466,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-49e19605-f396-4aa4-ac79-6dfcb37810f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-2e8a6162-4002-4be4-9b13-078783759e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-43b88265-ded1-480a-9386-d7272841a7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820201145-172.17.0.3-1597692999645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-d2e00655-33bf-4970-88ee-6493bd0f75b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-b26d945b-b71c-4cd6-ae92-2731edad660f,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-0e0997cd-f856-4c84-913f-55738daa86cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-cde94d90-2753-4459-8ce3-4d72f3d217fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-d706b040-c0a4-46fb-a973-a7d74b59a466,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-49e19605-f396-4aa4-ac79-6dfcb37810f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-2e8a6162-4002-4be4-9b13-078783759e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-43b88265-ded1-480a-9386-d7272841a7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133392694-172.17.0.3-1597693445937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-9c03be65-182d-493e-a61a-c1af35c0180d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-a421934b-100a-41b8-8243-f3965ffcb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-80738827-f6f8-4815-8610-8be0f44e23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-3e48a2a7-9626-4f2d-8ae5-6e1947a25d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-43e39b80-1be3-4d18-a6b8-cb19d60d57a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-e345e1f3-9211-49a5-bfd3-8231d55814f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-2666c7a7-b9a0-4fb8-99c8-73d2b3f09708,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-6002156d-1b28-401b-9590-636115bb013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133392694-172.17.0.3-1597693445937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-9c03be65-182d-493e-a61a-c1af35c0180d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-a421934b-100a-41b8-8243-f3965ffcb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-80738827-f6f8-4815-8610-8be0f44e23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-3e48a2a7-9626-4f2d-8ae5-6e1947a25d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-43e39b80-1be3-4d18-a6b8-cb19d60d57a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-e345e1f3-9211-49a5-bfd3-8231d55814f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-2666c7a7-b9a0-4fb8-99c8-73d2b3f09708,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-6002156d-1b28-401b-9590-636115bb013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098848553-172.17.0.3-1597693564506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-06ad9582-97b4-4a8f-a733-57699a3554f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-b6b78efa-4c0d-4bae-b3f6-997f4af75fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-9a746414-c8d2-4d74-b029-4e6672d42b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6b28297c-638b-4e80-bbc7-fd0c3b82e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-7a1f128f-b850-402d-a765-016c9f38b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-684c9714-2a71-408d-abe4-d1c534ce12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0205ef1b-582d-454b-8689-6690ca70ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-3d708037-7e13-4b9f-84f9-519ffd502912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098848553-172.17.0.3-1597693564506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-06ad9582-97b4-4a8f-a733-57699a3554f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-b6b78efa-4c0d-4bae-b3f6-997f4af75fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-9a746414-c8d2-4d74-b029-4e6672d42b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6b28297c-638b-4e80-bbc7-fd0c3b82e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-7a1f128f-b850-402d-a765-016c9f38b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-684c9714-2a71-408d-abe4-d1c534ce12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0205ef1b-582d-454b-8689-6690ca70ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-3d708037-7e13-4b9f-84f9-519ffd502912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5743
