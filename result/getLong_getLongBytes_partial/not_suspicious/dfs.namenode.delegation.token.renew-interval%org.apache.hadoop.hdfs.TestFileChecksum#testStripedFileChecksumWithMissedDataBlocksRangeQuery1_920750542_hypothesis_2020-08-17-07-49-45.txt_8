reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188087511-172.17.0.8-1597650716673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-9f57d712-ac5d-4e1e-a570-d6c9d0f5eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-b5a87307-07db-407b-ac71-9fbb0219ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-83c123e4-c650-4de5-ad8f-e90e47faa6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-6cfb3429-9852-4d25-a577-309d41c84564,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ced8638f-fa5f-4e83-afd2-90af0791ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-28e4432f-1c99-4dbe-b1e6-bd5d76a8b380,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-cbb4566a-6d29-4aa0-9dc2-0454fefe3e02,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-01bbc153-7be5-4d38-b767-cf81557d5b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188087511-172.17.0.8-1597650716673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-9f57d712-ac5d-4e1e-a570-d6c9d0f5eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-b5a87307-07db-407b-ac71-9fbb0219ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-83c123e4-c650-4de5-ad8f-e90e47faa6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-6cfb3429-9852-4d25-a577-309d41c84564,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ced8638f-fa5f-4e83-afd2-90af0791ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-28e4432f-1c99-4dbe-b1e6-bd5d76a8b380,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-cbb4566a-6d29-4aa0-9dc2-0454fefe3e02,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-01bbc153-7be5-4d38-b767-cf81557d5b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143749220-172.17.0.8-1597650831939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-512ef798-33c1-43ff-a0da-b9c113a2edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-d7f4d1ab-11cf-4793-92bc-6c0f96d42c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-6c99d1ea-52a2-4df1-b34f-199e83f39148,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-0b8855a5-1e2d-4e4f-b1ad-13f9512aab23,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-43397b13-8c06-4850-9ba8-8c866f041a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-cd8058c2-6b9e-4e65-8b11-523932caf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8241af2d-2efb-4cd6-a626-3eaa8112bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2bd63d80-f915-4027-aa72-7bb712f26c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143749220-172.17.0.8-1597650831939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-512ef798-33c1-43ff-a0da-b9c113a2edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-d7f4d1ab-11cf-4793-92bc-6c0f96d42c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-6c99d1ea-52a2-4df1-b34f-199e83f39148,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-0b8855a5-1e2d-4e4f-b1ad-13f9512aab23,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-43397b13-8c06-4850-9ba8-8c866f041a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-cd8058c2-6b9e-4e65-8b11-523932caf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8241af2d-2efb-4cd6-a626-3eaa8112bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2bd63d80-f915-4027-aa72-7bb712f26c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560849836-172.17.0.8-1597651693751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33730,DS-d947cc30-24ea-41e9-9e9e-f4335c0340f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-a0abc6a0-0517-46b4-a8f8-e04c070e02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-4511ed6b-4f43-4181-b2e8-b137db4050d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-7192c1d3-a255-40a3-b1a5-15a85de408c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c830afe3-26d6-4ed2-96e2-2859c6231265,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-b28e11aa-af5f-4b35-9cbd-d5d598b5caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-e541dd09-3fb5-4432-9e67-61d9c1bab7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-84e2dcee-9a55-4d7f-8e1c-616606e3e7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560849836-172.17.0.8-1597651693751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33730,DS-d947cc30-24ea-41e9-9e9e-f4335c0340f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-a0abc6a0-0517-46b4-a8f8-e04c070e02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-4511ed6b-4f43-4181-b2e8-b137db4050d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-7192c1d3-a255-40a3-b1a5-15a85de408c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c830afe3-26d6-4ed2-96e2-2859c6231265,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-b28e11aa-af5f-4b35-9cbd-d5d598b5caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-e541dd09-3fb5-4432-9e67-61d9c1bab7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-84e2dcee-9a55-4d7f-8e1c-616606e3e7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024988134-172.17.0.8-1597651937407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-ad1149e3-202f-42fd-93a6-2d9806d9eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-dac412a4-953b-44d1-a147-5c32bceaa942,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-c3a07a14-4a01-4513-9474-a3e82744687a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-ae5d89a0-90ef-41d6-b1b6-f8aa87d1085a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-49dd4093-b5df-4e85-becf-151c8e6fcdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a98c81c2-ee72-4791-b071-5ce8d24e2faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-d5a533bb-f61e-4a3f-97f6-84d0f6905be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-c58ad198-ab10-4902-b497-d0bd58b47fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024988134-172.17.0.8-1597651937407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-ad1149e3-202f-42fd-93a6-2d9806d9eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-dac412a4-953b-44d1-a147-5c32bceaa942,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-c3a07a14-4a01-4513-9474-a3e82744687a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-ae5d89a0-90ef-41d6-b1b6-f8aa87d1085a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-49dd4093-b5df-4e85-becf-151c8e6fcdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a98c81c2-ee72-4791-b071-5ce8d24e2faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-d5a533bb-f61e-4a3f-97f6-84d0f6905be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-c58ad198-ab10-4902-b497-d0bd58b47fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292848220-172.17.0.8-1597652181403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-5f15e4cc-41ce-4f76-b5b1-888b5389846c,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-926414ac-a77a-405b-8df0-4fb9c7b5b919,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-c11e1ee8-e821-484a-be41-bcaa06e3aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-fdfbe171-c0bb-41ea-9923-18581327ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-afb11f9f-077d-43f1-b574-156ea1ab5b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-0a59835a-1d14-4306-a572-2befcb4cd087,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-a1c0b87f-37f1-4e84-ac59-a80d5d4e88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-d496bf9a-66dd-4148-a285-7f62219d9ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292848220-172.17.0.8-1597652181403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-5f15e4cc-41ce-4f76-b5b1-888b5389846c,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-926414ac-a77a-405b-8df0-4fb9c7b5b919,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-c11e1ee8-e821-484a-be41-bcaa06e3aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-fdfbe171-c0bb-41ea-9923-18581327ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-afb11f9f-077d-43f1-b574-156ea1ab5b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-0a59835a-1d14-4306-a572-2befcb4cd087,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-a1c0b87f-37f1-4e84-ac59-a80d5d4e88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-d496bf9a-66dd-4148-a285-7f62219d9ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051856712-172.17.0.8-1597652370056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-f938ba30-98ff-4a32-881f-9cb911d9d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-4a829601-1b11-40ed-832b-22ce4a97826e,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-65e731c1-1156-43be-91dd-9974aac1b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-1afdef7c-5c62-4b85-89e3-5c7fe66bb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-04608e57-bae5-45f5-9c3c-9b071ea28dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-f93fe605-5127-4585-998b-043902e96009,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-25c34608-f94c-4e06-b845-a6970ea62468,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-35581730-8bfe-4d61-94d3-1f9959eb14ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051856712-172.17.0.8-1597652370056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-f938ba30-98ff-4a32-881f-9cb911d9d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-4a829601-1b11-40ed-832b-22ce4a97826e,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-65e731c1-1156-43be-91dd-9974aac1b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-1afdef7c-5c62-4b85-89e3-5c7fe66bb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-04608e57-bae5-45f5-9c3c-9b071ea28dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-f93fe605-5127-4585-998b-043902e96009,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-25c34608-f94c-4e06-b845-a6970ea62468,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-35581730-8bfe-4d61-94d3-1f9959eb14ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283657091-172.17.0.8-1597652556925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-76d94ad3-2630-479f-ac8b-814a5b80b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-8fa82d2c-3b40-47a8-8f8f-90c608ae1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-91eee28f-1747-451d-9bc8-91d161b98093,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-3782ac2c-7f20-4ad9-b7c5-3dfe79e0580c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1f0931e8-abe6-4cb5-9e0c-a769d8aae8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-70603c2c-b021-4bfd-baad-21bfb72a96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-e4aaee4b-a6fa-44d6-90dd-04aab81cf6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-fee12afa-0e6d-41fc-8caf-0ad3524e7279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283657091-172.17.0.8-1597652556925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-76d94ad3-2630-479f-ac8b-814a5b80b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-8fa82d2c-3b40-47a8-8f8f-90c608ae1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-91eee28f-1747-451d-9bc8-91d161b98093,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-3782ac2c-7f20-4ad9-b7c5-3dfe79e0580c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1f0931e8-abe6-4cb5-9e0c-a769d8aae8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-70603c2c-b021-4bfd-baad-21bfb72a96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-e4aaee4b-a6fa-44d6-90dd-04aab81cf6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-fee12afa-0e6d-41fc-8caf-0ad3524e7279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57014944-172.17.0.8-1597652747841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-a8ee6375-cd32-402c-8013-a65fb25315d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-2af723e0-af66-4dc3-9a84-028ded8c5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-269ca00c-d2b3-4270-9842-a28e77032181,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-8ed21529-6bd6-4d1e-81c4-230891f16a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-aa16c057-5d6f-4ee7-aa7a-3dafe6d0c496,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8712cf63-2b9c-4604-b576-610c26995fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-f1ff4ab3-5fad-4191-bf4b-c0eec286eb90,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-89214396-71be-4b00-b878-5aff0e7593af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57014944-172.17.0.8-1597652747841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-a8ee6375-cd32-402c-8013-a65fb25315d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-2af723e0-af66-4dc3-9a84-028ded8c5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-269ca00c-d2b3-4270-9842-a28e77032181,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-8ed21529-6bd6-4d1e-81c4-230891f16a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-aa16c057-5d6f-4ee7-aa7a-3dafe6d0c496,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8712cf63-2b9c-4604-b576-610c26995fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-f1ff4ab3-5fad-4191-bf4b-c0eec286eb90,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-89214396-71be-4b00-b878-5aff0e7593af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111671306-172.17.0.8-1597652995139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-9bbaf090-cdd1-4f00-9744-6bb09421df01,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-70d0ae5d-e60a-4809-b783-ea64c4b78aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-360fec0d-0f59-4d61-955b-272e9a120210,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-b034d745-fe88-47cc-9a94-1c740e8fb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-d6ddb0b2-f68a-40bc-98b6-73fe396d6340,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-81a139ed-266e-404f-b148-8e18c0aabec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-de0615a7-6628-4c81-b458-69eace96d983,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-48d802af-057d-4455-80fe-dd39d17c2148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111671306-172.17.0.8-1597652995139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-9bbaf090-cdd1-4f00-9744-6bb09421df01,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-70d0ae5d-e60a-4809-b783-ea64c4b78aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-360fec0d-0f59-4d61-955b-272e9a120210,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-b034d745-fe88-47cc-9a94-1c740e8fb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-d6ddb0b2-f68a-40bc-98b6-73fe396d6340,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-81a139ed-266e-404f-b148-8e18c0aabec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-de0615a7-6628-4c81-b458-69eace96d983,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-48d802af-057d-4455-80fe-dd39d17c2148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046004118-172.17.0.8-1597653362231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-5f06ae2c-1f00-4ebc-a2f4-e429d6e8964a,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-71074314-9079-4a3f-8daa-ae32fc37b772,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-96c41728-b901-4a2f-a98a-899c6b2dd466,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-62128e2f-00f8-4030-b989-7b66cdb12275,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-d15a9ace-f96f-450c-92d4-dad20467042b,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-f1968019-817e-41fb-8cea-5e230c9bfaae,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-03b43844-6561-4785-8c4d-86784c989ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f665ae94-8ca4-44fe-88d8-56e9711dfbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046004118-172.17.0.8-1597653362231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-5f06ae2c-1f00-4ebc-a2f4-e429d6e8964a,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-71074314-9079-4a3f-8daa-ae32fc37b772,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-96c41728-b901-4a2f-a98a-899c6b2dd466,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-62128e2f-00f8-4030-b989-7b66cdb12275,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-d15a9ace-f96f-450c-92d4-dad20467042b,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-f1968019-817e-41fb-8cea-5e230c9bfaae,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-03b43844-6561-4785-8c4d-86784c989ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f665ae94-8ca4-44fe-88d8-56e9711dfbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066807113-172.17.0.8-1597653601063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-92f2afc6-47f7-47f1-ab98-07c97ed517a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-5f8277a9-6245-4b63-8150-7c47e36f387a,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a8c69efd-f96e-4345-a3ab-e52a7b78f088,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b8fc7528-e7e2-4951-bbb2-dc9da86973e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-aad87a63-a75c-4c96-a942-d3a3762bd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-47050fc9-781c-4229-82a4-8434a8980e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-b5909e41-5d99-4cc0-9629-04679b105dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-4923b847-8960-4c49-b8e5-1d207b2aa16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066807113-172.17.0.8-1597653601063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-92f2afc6-47f7-47f1-ab98-07c97ed517a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-5f8277a9-6245-4b63-8150-7c47e36f387a,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a8c69efd-f96e-4345-a3ab-e52a7b78f088,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b8fc7528-e7e2-4951-bbb2-dc9da86973e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-aad87a63-a75c-4c96-a942-d3a3762bd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-47050fc9-781c-4229-82a4-8434a8980e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-b5909e41-5d99-4cc0-9629-04679b105dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-4923b847-8960-4c49-b8e5-1d207b2aa16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261547301-172.17.0.8-1597654371318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-13615e5f-22b1-4744-ae3d-c8f77e8237b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-6d6f7511-1703-4446-802b-c1c012888000,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-826cba72-f748-4082-8cd3-108e587af40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-9e58f788-0ab4-43c4-8f0b-b2eb1a148095,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-0ae048b1-1b61-4c87-b956-c6e51ef6267b,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-6d614936-e91f-4156-aefd-b43966ed58a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-c582fe73-996d-44fa-863a-ace2019f560c,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-7fb4aab9-49a7-45f0-852a-6c66d61fe35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261547301-172.17.0.8-1597654371318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-13615e5f-22b1-4744-ae3d-c8f77e8237b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-6d6f7511-1703-4446-802b-c1c012888000,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-826cba72-f748-4082-8cd3-108e587af40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-9e58f788-0ab4-43c4-8f0b-b2eb1a148095,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-0ae048b1-1b61-4c87-b956-c6e51ef6267b,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-6d614936-e91f-4156-aefd-b43966ed58a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-c582fe73-996d-44fa-863a-ace2019f560c,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-7fb4aab9-49a7-45f0-852a-6c66d61fe35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304832590-172.17.0.8-1597654698109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-c146fbfa-fd36-4115-ac8c-8757205aa47e,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-f16c2d22-0d0f-47ee-869a-aa1017a2781f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-eb48c706-e565-4ac1-b460-efebf7a2c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-f02599e8-e599-430f-aaf6-90678bd1b501,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-c972f20d-5a41-4674-a114-a22ff3645c80,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-2dc90e48-7223-491b-95a8-dea1dc1c2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-8a772ef6-60da-46a4-966e-43f76888c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-ff2e19fb-7057-43f0-a8e4-e387132a6a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304832590-172.17.0.8-1597654698109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-c146fbfa-fd36-4115-ac8c-8757205aa47e,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-f16c2d22-0d0f-47ee-869a-aa1017a2781f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-eb48c706-e565-4ac1-b460-efebf7a2c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-f02599e8-e599-430f-aaf6-90678bd1b501,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-c972f20d-5a41-4674-a114-a22ff3645c80,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-2dc90e48-7223-491b-95a8-dea1dc1c2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-8a772ef6-60da-46a4-966e-43f76888c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-ff2e19fb-7057-43f0-a8e4-e387132a6a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958568657-172.17.0.8-1597654787101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-5253b7ca-c0a6-40b1-9425-90aeccb80638,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-fb8b6269-aa03-4b86-b925-d659b233509b,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-84333bc8-ec5f-471c-bd69-068be1e4c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-61ddf1cb-0188-4bde-9930-cd7551eaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-30229201-8fe9-47ee-8670-b27fde4e1232,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-06922156-0206-4ee9-bd7a-0724a6e531ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-140a2e6c-e637-4295-b8c0-9ec696321ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-9b4708fc-1a93-47d3-a3d0-ee369009555c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958568657-172.17.0.8-1597654787101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-5253b7ca-c0a6-40b1-9425-90aeccb80638,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-fb8b6269-aa03-4b86-b925-d659b233509b,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-84333bc8-ec5f-471c-bd69-068be1e4c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-61ddf1cb-0188-4bde-9930-cd7551eaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-30229201-8fe9-47ee-8670-b27fde4e1232,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-06922156-0206-4ee9-bd7a-0724a6e531ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-140a2e6c-e637-4295-b8c0-9ec696321ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-9b4708fc-1a93-47d3-a3d0-ee369009555c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274791316-172.17.0.8-1597655039196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-073652a7-ae23-4186-89ce-c1a1305d893c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-10e8f254-0b47-4393-b775-25cda7dc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-7b2ac46c-6005-4bca-881f-b9c7ee014a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-5f2636a2-073d-489b-ae27-2e0815de004d,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-7295390f-5208-4c3f-a6b8-cb29f34b0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c3d8ae01-9e4d-4b40-b807-d92b7d61eee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-2f6d14d4-8ea3-4333-b62c-89ae68abf1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-4dc01226-9bb6-4a0f-ac64-b2b0a0ef6b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274791316-172.17.0.8-1597655039196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-073652a7-ae23-4186-89ce-c1a1305d893c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-10e8f254-0b47-4393-b775-25cda7dc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-7b2ac46c-6005-4bca-881f-b9c7ee014a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-5f2636a2-073d-489b-ae27-2e0815de004d,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-7295390f-5208-4c3f-a6b8-cb29f34b0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c3d8ae01-9e4d-4b40-b807-d92b7d61eee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-2f6d14d4-8ea3-4333-b62c-89ae68abf1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-4dc01226-9bb6-4a0f-ac64-b2b0a0ef6b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723359128-172.17.0.8-1597655249957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-fe3c0928-4a37-49ec-9cd1-83c8956fae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-72e6af7e-9af1-42ed-81fd-1b0107619298,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-733801a9-a9aa-4681-946c-eca33889246b,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-66c27b64-e62d-4a27-b27f-13ceb5bdbc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-919b1152-0906-4063-91ae-d5128edae95d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-945bebb8-ab2f-4479-bd0d-e8d460cf0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-6a528b96-11e5-4ecc-bee9-e10c41341454,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-0fde9877-8f60-4e06-bdcc-88c6567781fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723359128-172.17.0.8-1597655249957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-fe3c0928-4a37-49ec-9cd1-83c8956fae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-72e6af7e-9af1-42ed-81fd-1b0107619298,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-733801a9-a9aa-4681-946c-eca33889246b,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-66c27b64-e62d-4a27-b27f-13ceb5bdbc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-919b1152-0906-4063-91ae-d5128edae95d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-945bebb8-ab2f-4479-bd0d-e8d460cf0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-6a528b96-11e5-4ecc-bee9-e10c41341454,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-0fde9877-8f60-4e06-bdcc-88c6567781fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463195698-172.17.0.8-1597655575506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-0bd65b3d-3ed1-4eed-b5eb-b7197fed75f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-61803d93-caf1-4dca-b0a1-1fc4f3d0e391,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e12dd1a8-5b20-4232-a3fc-a90e730d1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-66fbfd9c-d0af-45fa-87b9-7b6c3e98a2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-0de479a1-b713-42cd-935d-ba70acacbbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-080045ac-df80-4090-9862-64fa102a63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-31d92bca-d353-4cae-abf0-2aa88818dde8,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-0bc2e566-3cbe-4cae-b67c-527e7e3f3a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463195698-172.17.0.8-1597655575506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-0bd65b3d-3ed1-4eed-b5eb-b7197fed75f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-61803d93-caf1-4dca-b0a1-1fc4f3d0e391,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e12dd1a8-5b20-4232-a3fc-a90e730d1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-66fbfd9c-d0af-45fa-87b9-7b6c3e98a2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-0de479a1-b713-42cd-935d-ba70acacbbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-080045ac-df80-4090-9862-64fa102a63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-31d92bca-d353-4cae-abf0-2aa88818dde8,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-0bc2e566-3cbe-4cae-b67c-527e7e3f3a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371888603-172.17.0.8-1597656019872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-491f914a-c5eb-4180-8698-04d099aa7ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-b32fbfee-5592-4f06-ad87-5a79ef0a1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-1538ec9b-5efa-4313-9760-4ef79f6ae6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-89f78cfc-0bf5-439f-9ab5-fa695c5c92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-b1826607-61c4-437b-87c6-964991b73481,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a1efc809-2ee4-4e83-9b34-d816073bf558,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-30541a87-2672-4264-8ced-fe1ffa4eddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-aab51a1e-8299-48f9-b385-3f2ca9eff6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371888603-172.17.0.8-1597656019872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-491f914a-c5eb-4180-8698-04d099aa7ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-b32fbfee-5592-4f06-ad87-5a79ef0a1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-1538ec9b-5efa-4313-9760-4ef79f6ae6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-89f78cfc-0bf5-439f-9ab5-fa695c5c92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-b1826607-61c4-437b-87c6-964991b73481,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a1efc809-2ee4-4e83-9b34-d816073bf558,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-30541a87-2672-4264-8ced-fe1ffa4eddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-aab51a1e-8299-48f9-b385-3f2ca9eff6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481207817-172.17.0.8-1597656063240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-1028bbf5-e861-4627-b36c-e95cd84498d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-ef5dfb48-7048-4ad2-8cce-7c26c748fe84,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-0b7d76aa-888e-45d0-9ec9-d107b4dbbebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-af9b3c79-7ecf-40ce-b887-8684b4e7a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-ffb8b8eb-05d4-4dce-86aa-0bfd1ea3cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-34b4dca9-7898-43f6-8927-7ffe03f1d531,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-995987c6-2f27-4d11-8f49-13c4da43b719,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-b6a76f27-0cc7-4fcf-a611-fecf1d1ba4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481207817-172.17.0.8-1597656063240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-1028bbf5-e861-4627-b36c-e95cd84498d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-ef5dfb48-7048-4ad2-8cce-7c26c748fe84,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-0b7d76aa-888e-45d0-9ec9-d107b4dbbebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-af9b3c79-7ecf-40ce-b887-8684b4e7a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-ffb8b8eb-05d4-4dce-86aa-0bfd1ea3cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-34b4dca9-7898-43f6-8927-7ffe03f1d531,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-995987c6-2f27-4d11-8f49-13c4da43b719,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-b6a76f27-0cc7-4fcf-a611-fecf1d1ba4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886838206-172.17.0.8-1597656540493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-868d9456-7409-4cd8-a5af-6bb0beefa401,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-f72c2a7b-54b7-4a0a-8178-a23bf925744f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-ccfcecb1-4892-4b07-8f7f-7aba3a565228,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-d2215080-a117-4f1c-a5f8-cb3643d88cef,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-c96455e6-79a7-44e0-aecd-7cc533c35e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5f8b4d13-cd80-4e0e-b37d-92dd9020ff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-149b0c3a-3b80-4668-ad7d-0faadb7a25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-d5a53869-03dd-419d-a4fb-790a5bd6495f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886838206-172.17.0.8-1597656540493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-868d9456-7409-4cd8-a5af-6bb0beefa401,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-f72c2a7b-54b7-4a0a-8178-a23bf925744f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-ccfcecb1-4892-4b07-8f7f-7aba3a565228,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-d2215080-a117-4f1c-a5f8-cb3643d88cef,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-c96455e6-79a7-44e0-aecd-7cc533c35e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5f8b4d13-cd80-4e0e-b37d-92dd9020ff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-149b0c3a-3b80-4668-ad7d-0faadb7a25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-d5a53869-03dd-419d-a4fb-790a5bd6495f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5985
