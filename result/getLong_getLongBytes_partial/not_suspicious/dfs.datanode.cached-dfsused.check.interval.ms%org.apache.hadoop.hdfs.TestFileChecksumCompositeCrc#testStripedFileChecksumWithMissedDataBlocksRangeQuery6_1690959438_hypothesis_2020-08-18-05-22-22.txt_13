reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614997203-172.17.0.19-1597728239244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-7fcdcf5b-1558-4e39-bb51-1ee87ddeff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-bcb6fe2e-fe33-4038-913b-751a7ac80ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-d554e464-25c9-40df-a17b-925441c78e90,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-80491a11-e256-4275-bb43-107963ed2133,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-510c4d89-e26d-4b7e-b5e0-08a5078c85d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-8459adbe-7f05-40cf-ba1c-8a5ca32c1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-52eef5f9-d842-4105-b0da-fbca18381e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-fcb66b95-d690-4c48-89c3-bc6ff722c7c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614997203-172.17.0.19-1597728239244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-7fcdcf5b-1558-4e39-bb51-1ee87ddeff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-bcb6fe2e-fe33-4038-913b-751a7ac80ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-d554e464-25c9-40df-a17b-925441c78e90,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-80491a11-e256-4275-bb43-107963ed2133,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-510c4d89-e26d-4b7e-b5e0-08a5078c85d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-8459adbe-7f05-40cf-ba1c-8a5ca32c1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-52eef5f9-d842-4105-b0da-fbca18381e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-fcb66b95-d690-4c48-89c3-bc6ff722c7c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870769434-172.17.0.19-1597728358526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-8aae8a8c-e8c6-4b90-94fe-fedacfce915c,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-110c0928-c724-42f1-81c1-f29cc4385ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-994d12b6-f0da-44b9-8133-6ca4cb92cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-7964f745-f4bf-44b0-8849-3c67378f066a,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-7ced2132-0de4-433e-b080-47c11e2d0430,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-bd93da86-a07d-4dc2-b62d-55d9ff56a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-af311556-7653-4a49-9c1c-f3a230da9181,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-62be0af8-e907-4744-b56d-7c611b291a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870769434-172.17.0.19-1597728358526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-8aae8a8c-e8c6-4b90-94fe-fedacfce915c,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-110c0928-c724-42f1-81c1-f29cc4385ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-994d12b6-f0da-44b9-8133-6ca4cb92cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-7964f745-f4bf-44b0-8849-3c67378f066a,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-7ced2132-0de4-433e-b080-47c11e2d0430,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-bd93da86-a07d-4dc2-b62d-55d9ff56a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-af311556-7653-4a49-9c1c-f3a230da9181,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-62be0af8-e907-4744-b56d-7c611b291a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772566362-172.17.0.19-1597728496886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-b6765074-7a0d-4bb1-ac35-cd158b0c4460,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-9a39ef32-f0d5-486b-8f08-602fd5d020c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-40821f0e-498a-4736-84cb-60bb394bf5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-256b027a-128e-4b74-a8f0-dad09e50b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-22e8750a-d0fe-43f7-8a69-70127d22bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-dfa1683d-4930-415a-9a8d-27545b9c8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-7cf42e86-effd-4590-a39c-374b16a29502,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-a329093f-6c5c-449a-9e34-21672debd331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772566362-172.17.0.19-1597728496886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-b6765074-7a0d-4bb1-ac35-cd158b0c4460,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-9a39ef32-f0d5-486b-8f08-602fd5d020c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-40821f0e-498a-4736-84cb-60bb394bf5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-256b027a-128e-4b74-a8f0-dad09e50b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-22e8750a-d0fe-43f7-8a69-70127d22bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-dfa1683d-4930-415a-9a8d-27545b9c8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-7cf42e86-effd-4590-a39c-374b16a29502,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-a329093f-6c5c-449a-9e34-21672debd331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042871939-172.17.0.19-1597728625523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-1e210d7e-c584-41ab-8051-7789370bc9da,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-db022b58-99c6-4357-b4e2-8b1ab1db8d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-956edb98-1483-42b1-bb41-94472dc65955,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-e2e5a6ec-4ab2-4298-9dfd-17a1b2c211df,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-c0da4084-ff90-4876-8949-35c4ab9a8655,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-fda7950e-37fe-4895-bb3d-dc4de284d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-92f1e58b-bce1-43f2-a7a4-5085238d6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-57256086-6451-4168-8e46-74959453bc79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042871939-172.17.0.19-1597728625523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-1e210d7e-c584-41ab-8051-7789370bc9da,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-db022b58-99c6-4357-b4e2-8b1ab1db8d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-956edb98-1483-42b1-bb41-94472dc65955,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-e2e5a6ec-4ab2-4298-9dfd-17a1b2c211df,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-c0da4084-ff90-4876-8949-35c4ab9a8655,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-fda7950e-37fe-4895-bb3d-dc4de284d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-92f1e58b-bce1-43f2-a7a4-5085238d6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-57256086-6451-4168-8e46-74959453bc79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055656000-172.17.0.19-1597729009151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-ba82cbd0-ab25-4248-bec5-ec426a7bdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-346cee7b-8829-497c-b429-e3ebd5d9812e,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-7ec88768-a747-4379-883d-cfa516dae016,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-397ff1e6-8a7c-40c5-acf0-c9e283bbc49c,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-3527aeb8-fe0f-4f80-9a41-93ce28f8b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-deced973-709b-4153-9de5-4a81a2ae1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-bdf7df00-4b1b-48ec-834f-0bf1d8c78780,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-2515626c-fa5e-4b4a-a4ae-276ff87c8b99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055656000-172.17.0.19-1597729009151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-ba82cbd0-ab25-4248-bec5-ec426a7bdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-346cee7b-8829-497c-b429-e3ebd5d9812e,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-7ec88768-a747-4379-883d-cfa516dae016,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-397ff1e6-8a7c-40c5-acf0-c9e283bbc49c,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-3527aeb8-fe0f-4f80-9a41-93ce28f8b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-deced973-709b-4153-9de5-4a81a2ae1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-bdf7df00-4b1b-48ec-834f-0bf1d8c78780,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-2515626c-fa5e-4b4a-a4ae-276ff87c8b99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005238604-172.17.0.19-1597729189087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-1b91845c-a24d-447e-8e16-692b96c8f0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-a110ad91-fbf0-47d4-80f9-c16dd8fb58fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-6c213d38-decc-4c68-88a1-ffb8f818c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-7eea7775-c242-4aed-934d-3596195c3033,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-22df038e-5487-4214-944f-7cdf2b816e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-babbae6a-63a8-4fb6-9213-eb69e1f23123,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-969e5b0e-fd04-4328-9086-b561e1eb2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e6401a03-b191-4256-9e19-51708509bb66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005238604-172.17.0.19-1597729189087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-1b91845c-a24d-447e-8e16-692b96c8f0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-a110ad91-fbf0-47d4-80f9-c16dd8fb58fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-6c213d38-decc-4c68-88a1-ffb8f818c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-7eea7775-c242-4aed-934d-3596195c3033,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-22df038e-5487-4214-944f-7cdf2b816e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-babbae6a-63a8-4fb6-9213-eb69e1f23123,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-969e5b0e-fd04-4328-9086-b561e1eb2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e6401a03-b191-4256-9e19-51708509bb66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905726956-172.17.0.19-1597729745727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-6f7d9504-ab77-4724-9469-380663e8d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-68fdf500-658c-44f6-abd0-d7d331d11202,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-bde0df84-b260-4d90-9394-0c80b842d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-129ec0da-0482-4532-ad54-07f9eb98fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-66374c2e-8181-4c80-ae03-8db19f9f1464,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-22b53ecc-263d-4b0d-920b-31bd5ec88f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-c576b735-5abe-4c09-8c25-b78a9e589fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6794091f-8ff7-43de-ba82-61765045063c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905726956-172.17.0.19-1597729745727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-6f7d9504-ab77-4724-9469-380663e8d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-68fdf500-658c-44f6-abd0-d7d331d11202,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-bde0df84-b260-4d90-9394-0c80b842d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-129ec0da-0482-4532-ad54-07f9eb98fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-66374c2e-8181-4c80-ae03-8db19f9f1464,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-22b53ecc-263d-4b0d-920b-31bd5ec88f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-c576b735-5abe-4c09-8c25-b78a9e589fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-6794091f-8ff7-43de-ba82-61765045063c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603967325-172.17.0.19-1597730011107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-0f3cad96-f669-4a83-bcff-2d3b7a6a3004,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-5854c7b2-d17b-4d3f-ba77-7d00682cb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-be7a5736-af2e-41df-92bb-0841402b076d,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-278f743a-847e-452a-a8e6-de39656c78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-a52a841f-27e5-485a-99d1-92cb7a435e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c94a4f03-0a4c-4279-a990-28cd444ce2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-891e847c-211e-497d-947f-6e462911c20f,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-5e8f8986-7347-4a04-bece-398fc1b0b319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603967325-172.17.0.19-1597730011107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-0f3cad96-f669-4a83-bcff-2d3b7a6a3004,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-5854c7b2-d17b-4d3f-ba77-7d00682cb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-be7a5736-af2e-41df-92bb-0841402b076d,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-278f743a-847e-452a-a8e6-de39656c78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-a52a841f-27e5-485a-99d1-92cb7a435e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c94a4f03-0a4c-4279-a990-28cd444ce2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-891e847c-211e-497d-947f-6e462911c20f,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-5e8f8986-7347-4a04-bece-398fc1b0b319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634481468-172.17.0.19-1597730127231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-35ef14d7-c3e0-49db-afad-adbac5a0177e,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-2e26febf-ffd5-431f-9c10-87f8ff2aec52,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-a436dd55-b2d2-48e6-9eb8-95d50be616ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-c57e0368-2b34-44d9-a952-5c961f198f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c8ff6095-90d5-49dc-ad2d-76a87ce15bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1bfde0a5-d8a2-4a55-b3a4-1224b8fc7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-15d7b59c-05a3-4892-a44b-752e8b47c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3b4c9c16-7d49-4bfc-a383-bb7e2abac00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634481468-172.17.0.19-1597730127231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-35ef14d7-c3e0-49db-afad-adbac5a0177e,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-2e26febf-ffd5-431f-9c10-87f8ff2aec52,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-a436dd55-b2d2-48e6-9eb8-95d50be616ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-c57e0368-2b34-44d9-a952-5c961f198f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c8ff6095-90d5-49dc-ad2d-76a87ce15bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1bfde0a5-d8a2-4a55-b3a4-1224b8fc7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-15d7b59c-05a3-4892-a44b-752e8b47c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3b4c9c16-7d49-4bfc-a383-bb7e2abac00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895523077-172.17.0.19-1597730243003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-9c1bb07b-b28d-4f39-91ce-e8e8dc5a479b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-2b817266-a341-4d98-8e18-d029b1362764,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4b4f9866-24ac-4a36-b559-1462165f4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-3c66844c-f4d9-4754-b4da-2d91d45bbe92,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-ec180a94-59a9-46eb-b214-299ece8b7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-f4c22db0-817c-4314-95f6-48250269492a,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-18d48830-3a80-4ed9-959b-59f0ab59455d,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-b8590375-9c4d-4823-b945-83989bede299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895523077-172.17.0.19-1597730243003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-9c1bb07b-b28d-4f39-91ce-e8e8dc5a479b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-2b817266-a341-4d98-8e18-d029b1362764,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4b4f9866-24ac-4a36-b559-1462165f4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-3c66844c-f4d9-4754-b4da-2d91d45bbe92,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-ec180a94-59a9-46eb-b214-299ece8b7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-f4c22db0-817c-4314-95f6-48250269492a,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-18d48830-3a80-4ed9-959b-59f0ab59455d,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-b8590375-9c4d-4823-b945-83989bede299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204769801-172.17.0.19-1597730971675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-fec20e3e-3e6a-4b85-b6bf-af03395ddf81,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-ea29d231-b2c0-4c48-9095-ee7ce89ea0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-db20a281-26f1-4546-9d02-35f6b688582d,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-38c7a515-feaa-4666-9203-2cbc88d88101,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1db1c5f8-d03c-4df9-a8da-2c6697d9c15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-7b55d3f3-0317-4b11-ab77-6915f6c4473b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-38713d24-0c0b-4cd9-8fca-471f29b21291,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-480ac6c8-0c19-4e51-bf80-3181e5501b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204769801-172.17.0.19-1597730971675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-fec20e3e-3e6a-4b85-b6bf-af03395ddf81,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-ea29d231-b2c0-4c48-9095-ee7ce89ea0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-db20a281-26f1-4546-9d02-35f6b688582d,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-38c7a515-feaa-4666-9203-2cbc88d88101,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1db1c5f8-d03c-4df9-a8da-2c6697d9c15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-7b55d3f3-0317-4b11-ab77-6915f6c4473b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-38713d24-0c0b-4cd9-8fca-471f29b21291,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-480ac6c8-0c19-4e51-bf80-3181e5501b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757891879-172.17.0.19-1597731055807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-e47ac411-5099-4cfe-a45a-8ac50c0b7663,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-a28380d5-4776-492a-a5ea-768c4370c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-2f6a2baa-ef05-4dbc-94ba-84c2af7d7cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-d97e7fee-f91d-4efc-ac6e-890d7c642fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-bdfe323b-bba2-4adf-8353-d0f53b00471a,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-50e2ccd8-faa6-446a-b90b-966581d200fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-3bff4fd2-404a-4132-9b9e-45521a1d13fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-b0139dca-6927-4715-a612-2486c9334e2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757891879-172.17.0.19-1597731055807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-e47ac411-5099-4cfe-a45a-8ac50c0b7663,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-a28380d5-4776-492a-a5ea-768c4370c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-2f6a2baa-ef05-4dbc-94ba-84c2af7d7cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-d97e7fee-f91d-4efc-ac6e-890d7c642fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-bdfe323b-bba2-4adf-8353-d0f53b00471a,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-50e2ccd8-faa6-446a-b90b-966581d200fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-3bff4fd2-404a-4132-9b9e-45521a1d13fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-b0139dca-6927-4715-a612-2486c9334e2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351843053-172.17.0.19-1597731089054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-07fa94f3-db67-4202-ad6a-dd817cc39c76,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-994add83-5ae4-457c-9040-115413bd0712,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-75b2295d-4c4d-405b-9638-28c7de11f794,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-cf45301a-1a64-4fe5-9f3c-ccba7e06eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-3ddc5335-47ba-44f1-9bfb-2e3801aecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-55427618-176f-41d6-bae9-28b7d6965be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-7674d8e9-f152-4002-a345-531ebc81e305,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-01726857-2296-4d1a-b3a8-0e0ad93af9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351843053-172.17.0.19-1597731089054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-07fa94f3-db67-4202-ad6a-dd817cc39c76,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-994add83-5ae4-457c-9040-115413bd0712,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-75b2295d-4c4d-405b-9638-28c7de11f794,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-cf45301a-1a64-4fe5-9f3c-ccba7e06eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-3ddc5335-47ba-44f1-9bfb-2e3801aecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-55427618-176f-41d6-bae9-28b7d6965be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-7674d8e9-f152-4002-a345-531ebc81e305,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-01726857-2296-4d1a-b3a8-0e0ad93af9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048265219-172.17.0.19-1597731126138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-77a40776-623b-4927-ab18-29b314e449f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-c82ac3f2-3a6b-4810-bf97-83a536cbce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-474007fe-a122-4d69-9773-1593247829a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-342654ee-de31-4d55-b663-6f00621448e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-819235a0-b462-4a12-9182-53e9a17d82d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-60cced8a-d551-4f55-a661-3b6ae789cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a9705c25-33db-4dd2-bc57-58102a81c283,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-eaebb57d-164f-4f82-9491-d1916e05eec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048265219-172.17.0.19-1597731126138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-77a40776-623b-4927-ab18-29b314e449f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-c82ac3f2-3a6b-4810-bf97-83a536cbce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-474007fe-a122-4d69-9773-1593247829a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-342654ee-de31-4d55-b663-6f00621448e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-819235a0-b462-4a12-9182-53e9a17d82d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-60cced8a-d551-4f55-a661-3b6ae789cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a9705c25-33db-4dd2-bc57-58102a81c283,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-eaebb57d-164f-4f82-9491-d1916e05eec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352837885-172.17.0.19-1597731362591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-9100d245-6225-4e94-bb57-0814f81d875c,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-7df9eee2-f9bf-43ed-a674-b5e975af0309,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-753ba0d9-e388-469f-b321-81eec1496031,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-aeff6fb6-e70d-48c2-b800-33a737cc9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2a5da4c8-667c-4ada-a33f-5235e3add1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-185a94ce-479d-44b5-a5a2-909163125bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-24edd649-b7f1-4500-b970-8e5e0cf2d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-477509fc-99af-4abb-a442-b4c661265231,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352837885-172.17.0.19-1597731362591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-9100d245-6225-4e94-bb57-0814f81d875c,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-7df9eee2-f9bf-43ed-a674-b5e975af0309,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-753ba0d9-e388-469f-b321-81eec1496031,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-aeff6fb6-e70d-48c2-b800-33a737cc9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2a5da4c8-667c-4ada-a33f-5235e3add1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-185a94ce-479d-44b5-a5a2-909163125bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-24edd649-b7f1-4500-b970-8e5e0cf2d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-477509fc-99af-4abb-a442-b4c661265231,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744593699-172.17.0.19-1597731466935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-ac4e9b17-b1e5-45c5-be38-8a466bb1a226,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8447a407-94cf-4704-922c-c2800f584b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-af0ab189-be73-4e38-a079-ce5ef92abdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-3c0b7f10-4a77-4d85-b66b-3088bd38c06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-89311fcc-6f9b-4d88-8d5b-adf0deccdbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-f1f60fa0-97d7-4e47-bbd9-bd054c9ed4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-4da55c99-0959-48bb-a279-ef60d56cd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-a6ef6e12-9323-4749-8ab0-b3f1f334d3a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744593699-172.17.0.19-1597731466935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-ac4e9b17-b1e5-45c5-be38-8a466bb1a226,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8447a407-94cf-4704-922c-c2800f584b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-af0ab189-be73-4e38-a079-ce5ef92abdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-3c0b7f10-4a77-4d85-b66b-3088bd38c06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-89311fcc-6f9b-4d88-8d5b-adf0deccdbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-f1f60fa0-97d7-4e47-bbd9-bd054c9ed4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-4da55c99-0959-48bb-a279-ef60d56cd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-a6ef6e12-9323-4749-8ab0-b3f1f334d3a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627458085-172.17.0.19-1597731587257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-e5d5a3fe-8186-4540-9ec0-40ab707a2541,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-fd86f6d0-8b0a-438a-a69d-2a82ada6f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-b721e57f-c79f-482e-8780-2932ad3175ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-6ff20138-74df-4fa7-af31-8cd51a901f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-305d047e-554d-4b43-b7c8-ee7ff6d2d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-d8002d2f-5b98-46c4-bb26-26b458dae4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-75896808-eb05-449b-831e-c3cfb8b917cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-762a80c7-00d1-4192-a159-40970514ce7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627458085-172.17.0.19-1597731587257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-e5d5a3fe-8186-4540-9ec0-40ab707a2541,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-fd86f6d0-8b0a-438a-a69d-2a82ada6f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-b721e57f-c79f-482e-8780-2932ad3175ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-6ff20138-74df-4fa7-af31-8cd51a901f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-305d047e-554d-4b43-b7c8-ee7ff6d2d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-d8002d2f-5b98-46c4-bb26-26b458dae4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-75896808-eb05-449b-831e-c3cfb8b917cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-762a80c7-00d1-4192-a159-40970514ce7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696984621-172.17.0.19-1597731626869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-b3890940-14d0-4bd9-b81d-6cb61b674878,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-66c3cadd-128e-4855-9149-abcffa7aa45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-7ad049e5-71bf-48f4-8e65-421f6c6cf9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-f35f9657-0a70-415a-a999-b8441856ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-efaf2ac4-e631-4436-816d-9dac6e97a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c730aed4-57db-426e-8177-6cebde1286c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-47e1563b-ecb0-4049-beb7-3ca7877f369b,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-0282e6d1-6138-40bc-ba53-5a6f1a081c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696984621-172.17.0.19-1597731626869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-b3890940-14d0-4bd9-b81d-6cb61b674878,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-66c3cadd-128e-4855-9149-abcffa7aa45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-7ad049e5-71bf-48f4-8e65-421f6c6cf9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-f35f9657-0a70-415a-a999-b8441856ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-efaf2ac4-e631-4436-816d-9dac6e97a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c730aed4-57db-426e-8177-6cebde1286c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-47e1563b-ecb0-4049-beb7-3ca7877f369b,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-0282e6d1-6138-40bc-ba53-5a6f1a081c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325188749-172.17.0.19-1597731944892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-e563bce7-c08f-44c5-9c65-4c53b15a115d,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e9b8c33c-c385-403c-aab0-563e80a572b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-b313ada2-856d-43e1-84dd-fe1e26d2e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-81a336fe-d849-4b1e-a54c-5d5013138105,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-7346aac4-6efb-4f75-a0e8-113a080cbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-3c207d66-262d-477f-b65e-450c0c410714,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-fa85971a-48a2-47a2-98c3-005ff02e8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-0d534c62-7bdd-4732-b9dd-2d450319472d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325188749-172.17.0.19-1597731944892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-e563bce7-c08f-44c5-9c65-4c53b15a115d,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e9b8c33c-c385-403c-aab0-563e80a572b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-b313ada2-856d-43e1-84dd-fe1e26d2e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-81a336fe-d849-4b1e-a54c-5d5013138105,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-7346aac4-6efb-4f75-a0e8-113a080cbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-3c207d66-262d-477f-b65e-450c0c410714,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-fa85971a-48a2-47a2-98c3-005ff02e8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-0d534c62-7bdd-4732-b9dd-2d450319472d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108136268-172.17.0.19-1597731985245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6caf7d81-796c-4294-be6a-3c071ae28ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4207b5bb-9f7d-4e65-948d-2aad28afae1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-1ab6e402-ee4c-416d-bd81-cae1d4c4c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-9ed73fc7-9167-4ad5-af48-d3b70326693d,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-f62c32da-f6db-4129-b304-f745040537b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-8651bed5-e4ff-4e43-8ecb-fdadb75051a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-fac3cc61-d1f0-4aa9-af66-c043256fd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-b6b6fd82-4826-40e5-be8b-9fcc63642dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108136268-172.17.0.19-1597731985245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6caf7d81-796c-4294-be6a-3c071ae28ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4207b5bb-9f7d-4e65-948d-2aad28afae1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-1ab6e402-ee4c-416d-bd81-cae1d4c4c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-9ed73fc7-9167-4ad5-af48-d3b70326693d,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-f62c32da-f6db-4129-b304-f745040537b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-8651bed5-e4ff-4e43-8ecb-fdadb75051a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-fac3cc61-d1f0-4aa9-af66-c043256fd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-b6b6fd82-4826-40e5-be8b-9fcc63642dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874073552-172.17.0.19-1597732518903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-48642282-ce66-428c-a8a3-fcacaf941831,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-5249ca7f-274c-4e5a-bacd-0e02416dc03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-0f15a66a-3de1-4acb-8a07-5f366868f2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-55b5f573-a07a-46a1-be73-2e9f6d4b5d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-1e34b9ed-46b3-40a0-9bba-fe82c1f62e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2d194073-36ee-4a56-86a0-80fbf5daff90,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-fe04f8c4-7908-415b-a809-beed1741fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9ae6501d-aece-4e1d-8e6b-7ed7caa40cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874073552-172.17.0.19-1597732518903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-48642282-ce66-428c-a8a3-fcacaf941831,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-5249ca7f-274c-4e5a-bacd-0e02416dc03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-0f15a66a-3de1-4acb-8a07-5f366868f2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-55b5f573-a07a-46a1-be73-2e9f6d4b5d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-1e34b9ed-46b3-40a0-9bba-fe82c1f62e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2d194073-36ee-4a56-86a0-80fbf5daff90,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-fe04f8c4-7908-415b-a809-beed1741fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9ae6501d-aece-4e1d-8e6b-7ed7caa40cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8882984-172.17.0.19-1597732697768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42474,DS-15e38692-f751-4426-8733-75eee90b6644,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-294ed85b-2467-4c12-82e4-9415565bda6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-44782219-601f-4e0a-98b2-59bda594b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-41dc980b-6fbd-4345-89b3-c9b5bbe26932,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f70965b5-3c77-46b6-a0ad-95fe0d1ebb38,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-2dae8c22-a5e2-46a5-b4f2-29bffccf8130,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-a9abc7e5-eaa1-4240-b2d0-6cf7d59b1549,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-c2967cf6-4c77-4a7c-bc6c-8348db37b997,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8882984-172.17.0.19-1597732697768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42474,DS-15e38692-f751-4426-8733-75eee90b6644,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-294ed85b-2467-4c12-82e4-9415565bda6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-44782219-601f-4e0a-98b2-59bda594b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-41dc980b-6fbd-4345-89b3-c9b5bbe26932,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f70965b5-3c77-46b6-a0ad-95fe0d1ebb38,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-2dae8c22-a5e2-46a5-b4f2-29bffccf8130,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-a9abc7e5-eaa1-4240-b2d0-6cf7d59b1549,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-c2967cf6-4c77-4a7c-bc6c-8348db37b997,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112434699-172.17.0.19-1597732808292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-d4e5c38e-d081-4b9c-9548-18666b23f362,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-bf00550f-19d1-4a58-9b12-46efd38ad8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-236de8bf-8672-40a2-b175-692a2d3b6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-172844d5-84e4-4ea1-bdf1-b75fd1c888eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-25f26e43-fa21-4824-bf37-0eadac3eb440,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-a2e0fb2d-73bc-40e5-a8ed-56c568edb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-fa15c8c0-5ce6-4da7-9b0b-394bc3b84c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-359e2e5e-10e9-4ca1-842a-5d49c46c5fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112434699-172.17.0.19-1597732808292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-d4e5c38e-d081-4b9c-9548-18666b23f362,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-bf00550f-19d1-4a58-9b12-46efd38ad8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-236de8bf-8672-40a2-b175-692a2d3b6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-172844d5-84e4-4ea1-bdf1-b75fd1c888eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-25f26e43-fa21-4824-bf37-0eadac3eb440,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-a2e0fb2d-73bc-40e5-a8ed-56c568edb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-fa15c8c0-5ce6-4da7-9b0b-394bc3b84c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-359e2e5e-10e9-4ca1-842a-5d49c46c5fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225423247-172.17.0.19-1597732883148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-6125b9c1-acbb-4505-8c8d-76cb6871f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-d82526b9-d675-4469-a591-7cb7e1a33abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-50e2ec19-edbf-49dd-b865-c9fb87d37c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-933be8c8-bd7c-4290-935e-b173605e2f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-6fb5f390-2e8f-4f2b-a197-85d62c34850e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-c4e05b76-62f9-42c4-bdb5-bb26ee34c440,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-61da44e7-3d24-4d35-b95a-2b75e4804b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-887fbe57-b4b2-4f97-b503-a40dfaa29c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225423247-172.17.0.19-1597732883148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-6125b9c1-acbb-4505-8c8d-76cb6871f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-d82526b9-d675-4469-a591-7cb7e1a33abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-50e2ec19-edbf-49dd-b865-c9fb87d37c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-933be8c8-bd7c-4290-935e-b173605e2f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-6fb5f390-2e8f-4f2b-a197-85d62c34850e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-c4e05b76-62f9-42c4-bdb5-bb26ee34c440,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-61da44e7-3d24-4d35-b95a-2b75e4804b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-887fbe57-b4b2-4f97-b503-a40dfaa29c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865448479-172.17.0.19-1597732995222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-bd5e0b3e-5fdb-4467-b991-f2546e111334,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-c605b3ec-418b-4c03-853b-553ba398990f,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-55b07c37-e347-436f-ab9b-5b88973bfd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-70a62934-78a4-49d9-a5f2-8d36dbe902e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-8739ee6c-849f-43f6-9744-8810d42f4cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-52cde1a6-38bc-4a9b-9f55-c6512a5cdf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-46c163fd-d1b5-4055-9ea4-0f80943278a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-ca25e7ed-84fa-455b-9942-56abfc4ebdca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865448479-172.17.0.19-1597732995222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-bd5e0b3e-5fdb-4467-b991-f2546e111334,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-c605b3ec-418b-4c03-853b-553ba398990f,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-55b07c37-e347-436f-ab9b-5b88973bfd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-70a62934-78a4-49d9-a5f2-8d36dbe902e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-8739ee6c-849f-43f6-9744-8810d42f4cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-52cde1a6-38bc-4a9b-9f55-c6512a5cdf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-46c163fd-d1b5-4055-9ea4-0f80943278a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-ca25e7ed-84fa-455b-9942-56abfc4ebdca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548184117-172.17.0.19-1597733138960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-83ffadb4-b7c7-4238-8c6b-8586a0db9293,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-e9bb56f0-c054-4fa1-a557-0b86cb8a7776,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-89961d9e-b148-401d-b45c-ef2493b954aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-ba64925f-24c1-4a7c-a556-ad1582741cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-4a535ce4-93d9-4d22-b8f3-88c35d588797,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-06faa22f-0c53-437a-ac06-b0ae528a89ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-47b063f1-7249-4e78-9df6-6551c0450f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-cd8f8d81-410f-488d-972e-088b1ad0453c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548184117-172.17.0.19-1597733138960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-83ffadb4-b7c7-4238-8c6b-8586a0db9293,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-e9bb56f0-c054-4fa1-a557-0b86cb8a7776,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-89961d9e-b148-401d-b45c-ef2493b954aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-ba64925f-24c1-4a7c-a556-ad1582741cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-4a535ce4-93d9-4d22-b8f3-88c35d588797,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-06faa22f-0c53-437a-ac06-b0ae528a89ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-47b063f1-7249-4e78-9df6-6551c0450f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-cd8f8d81-410f-488d-972e-088b1ad0453c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725687268-172.17.0.19-1597733223210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-d4480051-dc71-4658-955d-e24c1beedd45,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-094a2ada-5d80-4d2b-9b3e-30deb131d713,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-ff65bbe8-66dc-49d9-8a09-fd24567d43b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1ee6d68d-e5c3-4e40-b0a5-fa9e28e42c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-36ba43ed-9515-4a52-9fed-4ded9f7c6cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-3d71a31b-254b-49e1-8762-fb1dea5d8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-4812de5a-70d6-4d13-b792-a292ea8c354c,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-190aada3-4cc9-41f9-885e-6bd76c511603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725687268-172.17.0.19-1597733223210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-d4480051-dc71-4658-955d-e24c1beedd45,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-094a2ada-5d80-4d2b-9b3e-30deb131d713,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-ff65bbe8-66dc-49d9-8a09-fd24567d43b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1ee6d68d-e5c3-4e40-b0a5-fa9e28e42c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-36ba43ed-9515-4a52-9fed-4ded9f7c6cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-3d71a31b-254b-49e1-8762-fb1dea5d8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-4812de5a-70d6-4d13-b792-a292ea8c354c,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-190aada3-4cc9-41f9-885e-6bd76c511603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015038347-172.17.0.19-1597733334248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34139,DS-ed07842b-6422-4e3d-b016-aa3cdae1d457,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-33ede34d-fb98-4233-ba97-c0833779fc79,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-fa2daccc-0655-4130-bbfe-0531bf417854,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-34ee8410-cd6e-49de-b493-9aa52aa1b866,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-c37864c2-c277-4954-bd97-5a302f71803e,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-e729feba-7ad5-4032-8fbc-22dcfa4993a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d8886233-dc0c-4a93-a951-443fc3292321,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-83a3d526-03e4-49a9-ae86-3fc3a481f1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015038347-172.17.0.19-1597733334248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34139,DS-ed07842b-6422-4e3d-b016-aa3cdae1d457,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-33ede34d-fb98-4233-ba97-c0833779fc79,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-fa2daccc-0655-4130-bbfe-0531bf417854,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-34ee8410-cd6e-49de-b493-9aa52aa1b866,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-c37864c2-c277-4954-bd97-5a302f71803e,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-e729feba-7ad5-4032-8fbc-22dcfa4993a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d8886233-dc0c-4a93-a951-443fc3292321,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-83a3d526-03e4-49a9-ae86-3fc3a481f1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359352528-172.17.0.19-1597733360935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-27d79de3-dc89-4dd9-8aad-9bad91121074,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-faf1814d-86d0-463a-878b-d3679a1aa96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-c66ba33a-65a8-4a5d-8001-27e28094a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-d2186c41-b855-4f99-828b-3d1ddf20c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-0699540f-fec2-4018-9eb3-8edf1995702f,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-80d63de7-6b3a-429e-bb70-7c28bf8a44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-6ec0d2b5-ff49-4fa1-9323-20cb5206aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d708ccbd-96f2-4adc-9dd1-a12648c05d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359352528-172.17.0.19-1597733360935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-27d79de3-dc89-4dd9-8aad-9bad91121074,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-faf1814d-86d0-463a-878b-d3679a1aa96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-c66ba33a-65a8-4a5d-8001-27e28094a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-d2186c41-b855-4f99-828b-3d1ddf20c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-0699540f-fec2-4018-9eb3-8edf1995702f,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-80d63de7-6b3a-429e-bb70-7c28bf8a44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-6ec0d2b5-ff49-4fa1-9323-20cb5206aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d708ccbd-96f2-4adc-9dd1-a12648c05d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5708
