reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199247919-172.17.0.5-1597679049025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-e29d4681-9123-4625-8d71-3febfbfa5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-afdb1c2d-78f4-47be-963c-4732500b3f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-f20ee361-837b-407a-a0c2-0ed012d65ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ba2e56c7-0b6d-4ddb-8e80-123a68f76500,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-8d08e01d-2a72-4d3a-8674-639a0d19ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-4cf7494d-2f49-40dc-a6d8-4bb59f1ee79e,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-a318878c-195b-4f35-9969-cb43171b05de,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-b6fc50c0-9bfa-48fd-af54-6758c7b277f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199247919-172.17.0.5-1597679049025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-e29d4681-9123-4625-8d71-3febfbfa5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-afdb1c2d-78f4-47be-963c-4732500b3f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-f20ee361-837b-407a-a0c2-0ed012d65ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ba2e56c7-0b6d-4ddb-8e80-123a68f76500,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-8d08e01d-2a72-4d3a-8674-639a0d19ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-4cf7494d-2f49-40dc-a6d8-4bb59f1ee79e,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-a318878c-195b-4f35-9969-cb43171b05de,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-b6fc50c0-9bfa-48fd-af54-6758c7b277f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057412144-172.17.0.5-1597679091480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-49d82c91-12d4-402e-aaa2-c2b1e6f3d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-d601121f-d173-489f-ac1f-438cec78c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-700716e6-b4f1-495b-a00b-5d65d57b3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-7ff85a4b-e347-43c3-a731-5231f8b59191,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-95c3439b-b14d-4912-995a-2e450985a669,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-8929645d-05f5-48ab-bfb4-05fb4801ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-f9c8294d-f010-49ea-863c-5516485e7aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6f7bd37a-6fbc-4b34-b493-f05aa0348a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057412144-172.17.0.5-1597679091480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-49d82c91-12d4-402e-aaa2-c2b1e6f3d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-d601121f-d173-489f-ac1f-438cec78c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-700716e6-b4f1-495b-a00b-5d65d57b3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-7ff85a4b-e347-43c3-a731-5231f8b59191,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-95c3439b-b14d-4912-995a-2e450985a669,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-8929645d-05f5-48ab-bfb4-05fb4801ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-f9c8294d-f010-49ea-863c-5516485e7aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6f7bd37a-6fbc-4b34-b493-f05aa0348a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397050544-172.17.0.5-1597679200782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-4b1f5f78-7bac-40a9-82c5-f10d5e13b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e2117f4b-5a0d-4139-8e37-02c5d3161515,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-a1384026-7c23-4f5d-b02d-bd4a0800fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-2670f530-9787-4f5c-8e46-73035d7106d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9c74a761-dcef-4f54-be15-9b7b0f02e397,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-db52a6aa-56a7-4b96-8720-fd8ba9e6713d,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-460f7fb1-a37a-4a20-aabf-2d9ae3aef8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-76575f26-6be5-4fb4-a7f4-f035aeeb0b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397050544-172.17.0.5-1597679200782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-4b1f5f78-7bac-40a9-82c5-f10d5e13b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e2117f4b-5a0d-4139-8e37-02c5d3161515,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-a1384026-7c23-4f5d-b02d-bd4a0800fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-2670f530-9787-4f5c-8e46-73035d7106d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9c74a761-dcef-4f54-be15-9b7b0f02e397,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-db52a6aa-56a7-4b96-8720-fd8ba9e6713d,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-460f7fb1-a37a-4a20-aabf-2d9ae3aef8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-76575f26-6be5-4fb4-a7f4-f035aeeb0b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928535798-172.17.0.5-1597679765701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-b46d6b98-6115-4678-b9ea-77dc665d654e,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2baf3ed3-b758-4f9c-b233-f8b2781f9f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-decfa9a8-aad0-43ae-aaa0-efd4b1a94274,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-b47a2da6-6557-4913-b620-9d411d7a0271,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-790bc8e1-8c1b-401a-96bb-fd1bdc8b896d,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-45f5d29d-0b02-4c01-86f7-7ea7fe5e193a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-edee94ff-da19-42e6-bf87-e3cd3f58eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-a7ad0298-2c3f-4a2d-87b2-ac7727d5fdb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928535798-172.17.0.5-1597679765701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-b46d6b98-6115-4678-b9ea-77dc665d654e,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2baf3ed3-b758-4f9c-b233-f8b2781f9f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-decfa9a8-aad0-43ae-aaa0-efd4b1a94274,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-b47a2da6-6557-4913-b620-9d411d7a0271,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-790bc8e1-8c1b-401a-96bb-fd1bdc8b896d,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-45f5d29d-0b02-4c01-86f7-7ea7fe5e193a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-edee94ff-da19-42e6-bf87-e3cd3f58eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-a7ad0298-2c3f-4a2d-87b2-ac7727d5fdb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120709818-172.17.0.5-1597680073826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-a73dda60-599a-4e39-99eb-53e75f9896f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-94801e70-1432-4cd2-b236-6bd8b35f173e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-c9c4e1c7-f2c2-4a87-aa9f-edfce9a23314,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-a0de551c-60f5-4de4-862d-798d00734cef,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-23779fac-18c0-49d9-ae98-d1bccf985a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-795966ba-efc9-4c93-a06c-34933f71fe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-af4686f0-5411-4386-ab9e-e04c77f2eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-d24a8cb6-4d74-40fe-985c-31d489544042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120709818-172.17.0.5-1597680073826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-a73dda60-599a-4e39-99eb-53e75f9896f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-94801e70-1432-4cd2-b236-6bd8b35f173e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-c9c4e1c7-f2c2-4a87-aa9f-edfce9a23314,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-a0de551c-60f5-4de4-862d-798d00734cef,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-23779fac-18c0-49d9-ae98-d1bccf985a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-795966ba-efc9-4c93-a06c-34933f71fe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-af4686f0-5411-4386-ab9e-e04c77f2eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-d24a8cb6-4d74-40fe-985c-31d489544042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772917770-172.17.0.5-1597680147772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-8d80907f-583d-42ce-8ae7-3dff27cf9451,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-c60f0eeb-443e-4723-abab-5419c1ae9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-a9516d53-2a12-4f7c-935b-f86b69597d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-784f329e-e18b-4a52-b41d-34bc7bdeb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-213ade5f-732c-43c0-99d7-3b0d83ffdbba,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-88d87cb7-fac2-4ff2-af59-7108e7625541,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8deace10-ec0e-4d57-9a66-813c1aed00de,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-2808d6dd-e5f6-4219-a980-07e9e6a1638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772917770-172.17.0.5-1597680147772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-8d80907f-583d-42ce-8ae7-3dff27cf9451,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-c60f0eeb-443e-4723-abab-5419c1ae9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-a9516d53-2a12-4f7c-935b-f86b69597d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-784f329e-e18b-4a52-b41d-34bc7bdeb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-213ade5f-732c-43c0-99d7-3b0d83ffdbba,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-88d87cb7-fac2-4ff2-af59-7108e7625541,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8deace10-ec0e-4d57-9a66-813c1aed00de,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-2808d6dd-e5f6-4219-a980-07e9e6a1638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166890071-172.17.0.5-1597680215558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-f7800b91-fdd5-4782-87b3-25f94d9c502e,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-e99c3604-e717-4253-b2b9-d20d82a5cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-3758438a-45b1-483d-862e-4d64d7658898,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-1a926211-c69c-4ab8-a217-bd00557a5c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-d038289e-fcd8-4a02-8347-575cbe04140f,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-5ca0d849-7b9a-4b15-a0fb-21fde4d53981,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-73b99252-5f40-4145-a3c4-2b055cb49d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-3191f3e6-27c7-4b6e-b490-9bf1c2401853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166890071-172.17.0.5-1597680215558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-f7800b91-fdd5-4782-87b3-25f94d9c502e,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-e99c3604-e717-4253-b2b9-d20d82a5cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-3758438a-45b1-483d-862e-4d64d7658898,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-1a926211-c69c-4ab8-a217-bd00557a5c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-d038289e-fcd8-4a02-8347-575cbe04140f,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-5ca0d849-7b9a-4b15-a0fb-21fde4d53981,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-73b99252-5f40-4145-a3c4-2b055cb49d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-3191f3e6-27c7-4b6e-b490-9bf1c2401853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732778995-172.17.0.5-1597680292864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-c3687bc5-2333-4e0e-aed2-a7d6cc49f294,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-0797d1f4-12b0-49e7-9bf4-36655229fff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-752fac96-6f1e-4ae7-b6a8-743870c00b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-60a95e65-9ba5-420a-a1dd-fd12ec9f3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-eb215a3e-cf56-4d1b-a566-b7683e7d1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-1ea346ec-7525-4738-a3b5-36df290373e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-4033c89a-091d-4110-b9d2-84dfb37a60b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-5cc62432-a25f-4d77-b0a6-c368c300aea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732778995-172.17.0.5-1597680292864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-c3687bc5-2333-4e0e-aed2-a7d6cc49f294,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-0797d1f4-12b0-49e7-9bf4-36655229fff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-752fac96-6f1e-4ae7-b6a8-743870c00b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-60a95e65-9ba5-420a-a1dd-fd12ec9f3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-eb215a3e-cf56-4d1b-a566-b7683e7d1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-1ea346ec-7525-4738-a3b5-36df290373e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-4033c89a-091d-4110-b9d2-84dfb37a60b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-5cc62432-a25f-4d77-b0a6-c368c300aea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046357452-172.17.0.5-1597681133481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-2b418da5-18fe-40f2-aa01-73829c769db9,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-c3b8ef66-c4f0-4078-8246-a5b3326ab4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-b78d75da-0fe0-4ba1-8f63-8f7ba4372ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-078711c8-c35c-4f33-8f0b-c62b5fe099c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-235d0044-560d-477b-9f02-db81c9c1c333,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-276154d3-d154-405d-9191-9774a849fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-d8733890-ccd3-40d8-8f19-74ec4024f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-c98ae754-3a18-45ed-8163-2116c87b23f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046357452-172.17.0.5-1597681133481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-2b418da5-18fe-40f2-aa01-73829c769db9,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-c3b8ef66-c4f0-4078-8246-a5b3326ab4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-b78d75da-0fe0-4ba1-8f63-8f7ba4372ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-078711c8-c35c-4f33-8f0b-c62b5fe099c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-235d0044-560d-477b-9f02-db81c9c1c333,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-276154d3-d154-405d-9191-9774a849fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-d8733890-ccd3-40d8-8f19-74ec4024f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-c98ae754-3a18-45ed-8163-2116c87b23f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918932750-172.17.0.5-1597682133278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-86c4add3-43a4-4265-a534-227c0cf0dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-33d6dc95-332b-4742-bbbb-8066da36f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-395c9fce-436e-4343-acd7-c89d676436cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-f0575472-f4aa-418b-a045-b454422c695f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-2aac3259-5a99-47e0-8c91-c234dae7b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-ad41fd13-cc7b-4516-81b6-d1b62e4bd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-a10909a6-b606-4e60-9c10-0d625c8b9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-d9be158e-ef96-423a-9872-80fe55391af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918932750-172.17.0.5-1597682133278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-86c4add3-43a4-4265-a534-227c0cf0dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-33d6dc95-332b-4742-bbbb-8066da36f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-395c9fce-436e-4343-acd7-c89d676436cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-f0575472-f4aa-418b-a045-b454422c695f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-2aac3259-5a99-47e0-8c91-c234dae7b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-ad41fd13-cc7b-4516-81b6-d1b62e4bd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-a10909a6-b606-4e60-9c10-0d625c8b9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-d9be158e-ef96-423a-9872-80fe55391af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999682563-172.17.0.5-1597682404047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-a748c630-9eaa-4c58-b658-4a58b771d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a887ce8a-a4de-4b34-a19f-3e62e7908368,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-7f6538b4-b565-4bc8-9776-a46177be4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-3322be88-a344-4a5b-9391-cb8cd759740e,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-f945ea91-1f9c-4dc2-9741-2d0c5c7ad7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-f34dc74a-6a17-4783-954b-1c546028f319,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1c6deddc-5c13-4a50-aad7-321b081a8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-b34d1d20-6a5e-4c97-9e68-994f8494b6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999682563-172.17.0.5-1597682404047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-a748c630-9eaa-4c58-b658-4a58b771d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a887ce8a-a4de-4b34-a19f-3e62e7908368,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-7f6538b4-b565-4bc8-9776-a46177be4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-3322be88-a344-4a5b-9391-cb8cd759740e,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-f945ea91-1f9c-4dc2-9741-2d0c5c7ad7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-f34dc74a-6a17-4783-954b-1c546028f319,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-1c6deddc-5c13-4a50-aad7-321b081a8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-b34d1d20-6a5e-4c97-9e68-994f8494b6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745346158-172.17.0.5-1597682520932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-253cbadb-c8a9-4732-853b-86cec50a7a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-12c5b5eb-fa41-4cf6-88dd-a9469f2d14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a518f54d-b806-4f08-975c-d93b5b263b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-49e19c20-84d5-4730-8cc7-dcc805ae87cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-a0603dae-9da8-4c64-b8ec-b4522fe702a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d0ba9f3e-88a9-4b02-ae3e-fda8376cd3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-25bd7312-53a0-4a75-85c1-9221ad05931c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-e5c74978-70dd-422f-b6f0-87db8c22007d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745346158-172.17.0.5-1597682520932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-253cbadb-c8a9-4732-853b-86cec50a7a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-12c5b5eb-fa41-4cf6-88dd-a9469f2d14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a518f54d-b806-4f08-975c-d93b5b263b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-49e19c20-84d5-4730-8cc7-dcc805ae87cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-a0603dae-9da8-4c64-b8ec-b4522fe702a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d0ba9f3e-88a9-4b02-ae3e-fda8376cd3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-25bd7312-53a0-4a75-85c1-9221ad05931c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-e5c74978-70dd-422f-b6f0-87db8c22007d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575896920-172.17.0.5-1597682596222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-28ce64d5-198c-4bd2-84a4-5a22dfdf2053,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-dc9c8ff1-6089-4190-a963-ea0220c1975a,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-3a5351c2-7c83-4668-85e6-1cfa1cf9cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-915acf9e-8a49-4708-b40b-0f01de79d672,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-6b3822e7-9d0f-4128-b2db-a234aedee434,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-9296b1fb-8f58-4972-a52b-44f67a6d9532,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-a486fdd3-7b7a-4de1-9e55-1b1abd7c5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-42c80e4e-12fa-41ef-b2a0-89cb91646220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575896920-172.17.0.5-1597682596222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-28ce64d5-198c-4bd2-84a4-5a22dfdf2053,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-dc9c8ff1-6089-4190-a963-ea0220c1975a,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-3a5351c2-7c83-4668-85e6-1cfa1cf9cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-915acf9e-8a49-4708-b40b-0f01de79d672,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-6b3822e7-9d0f-4128-b2db-a234aedee434,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-9296b1fb-8f58-4972-a52b-44f67a6d9532,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-a486fdd3-7b7a-4de1-9e55-1b1abd7c5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-42c80e4e-12fa-41ef-b2a0-89cb91646220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301008292-172.17.0.5-1597682659516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-c359f63d-cf61-496b-9bb9-4b6601077e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-f5806072-353e-4e68-b425-ad4551d7323a,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-65c96c46-c1ab-4a79-9537-fcbdea91454a,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-71439027-35c0-44e1-8c83-95ed8923028b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-cda21b88-f2f6-464b-b53e-d0088ed5fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-02875540-cddf-47fb-9e24-21ec438ccc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b138261e-eb6a-4b01-be12-bd61c19c4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-a0b0910a-7f9c-491f-bf88-a862cdc23726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301008292-172.17.0.5-1597682659516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-c359f63d-cf61-496b-9bb9-4b6601077e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-f5806072-353e-4e68-b425-ad4551d7323a,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-65c96c46-c1ab-4a79-9537-fcbdea91454a,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-71439027-35c0-44e1-8c83-95ed8923028b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-cda21b88-f2f6-464b-b53e-d0088ed5fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-02875540-cddf-47fb-9e24-21ec438ccc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b138261e-eb6a-4b01-be12-bd61c19c4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-a0b0910a-7f9c-491f-bf88-a862cdc23726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031314608-172.17.0.5-1597683110204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44368,DS-d4a57054-fc00-4d3b-a15b-be5f3c553075,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-65b2488a-345d-4dc6-92dc-afedb262fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-2de93e46-5c08-4fdf-97bd-f62512ece75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-4b82bff8-1638-46b4-af8c-e11d625298fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-90b41447-ee4e-49d8-b994-1bb31c974d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-89b1b2fa-69d8-495f-9b50-3a9c9efe34a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-4fe58c48-9ee9-4fa0-afbf-e48b830eabea,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-eb54aed1-9af0-48fe-b186-47d54256abfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031314608-172.17.0.5-1597683110204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44368,DS-d4a57054-fc00-4d3b-a15b-be5f3c553075,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-65b2488a-345d-4dc6-92dc-afedb262fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-2de93e46-5c08-4fdf-97bd-f62512ece75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-4b82bff8-1638-46b4-af8c-e11d625298fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-90b41447-ee4e-49d8-b994-1bb31c974d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-89b1b2fa-69d8-495f-9b50-3a9c9efe34a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-4fe58c48-9ee9-4fa0-afbf-e48b830eabea,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-eb54aed1-9af0-48fe-b186-47d54256abfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370393697-172.17.0.5-1597683236298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-fb5d48ff-d594-4591-9150-aa8be19e8041,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-800907ff-cf70-4802-8e35-b67f4b42c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8088a688-3924-4922-affd-1934789accd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-e579180f-5a14-4ec9-8af3-0e7282c3bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-0f470da1-a0df-4f58-ae7f-64355ff8e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-015d692a-3bc0-4907-aedd-9799d9072070,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-c8a6b7d7-3b0c-4268-842e-5219a58782d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-7f99a6da-c3c6-4ae2-8de9-ac918e616c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370393697-172.17.0.5-1597683236298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-fb5d48ff-d594-4591-9150-aa8be19e8041,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-800907ff-cf70-4802-8e35-b67f4b42c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8088a688-3924-4922-affd-1934789accd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-e579180f-5a14-4ec9-8af3-0e7282c3bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-0f470da1-a0df-4f58-ae7f-64355ff8e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-015d692a-3bc0-4907-aedd-9799d9072070,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-c8a6b7d7-3b0c-4268-842e-5219a58782d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-7f99a6da-c3c6-4ae2-8de9-ac918e616c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924535757-172.17.0.5-1597683569380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-5b05b5fb-991d-421b-9ffe-8262f5ce1206,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-a01582d7-9c8c-4bc1-9363-627fd1c155da,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-cc435f5a-75cb-4153-879f-9911aea1c708,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-89d3d4fe-2d2c-4456-80fa-b46966a209db,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-28b775db-d7db-4543-87ed-d5ac7175b9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-09747723-fa45-4b96-84b1-28c8600b3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-302df3b8-3e29-451e-8f46-bddaf8e17097,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b2aa62c-451f-4300-b1ec-a0ab2651885d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924535757-172.17.0.5-1597683569380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-5b05b5fb-991d-421b-9ffe-8262f5ce1206,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-a01582d7-9c8c-4bc1-9363-627fd1c155da,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-cc435f5a-75cb-4153-879f-9911aea1c708,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-89d3d4fe-2d2c-4456-80fa-b46966a209db,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-28b775db-d7db-4543-87ed-d5ac7175b9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-09747723-fa45-4b96-84b1-28c8600b3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-302df3b8-3e29-451e-8f46-bddaf8e17097,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9b2aa62c-451f-4300-b1ec-a0ab2651885d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368956460-172.17.0.5-1597683872826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-ae70ef15-0bf1-4ba5-b9b7-281bd52b542f,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-cd97118d-e71d-4d80-99b4-9c86f850ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-5de6a439-25c5-47ce-9f6c-5326a08d400a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-1199e8e4-73c2-4ba1-a0d4-62537c3cc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-e5478452-c7f0-4658-b4bd-acd1604039e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-2e84a911-9606-4b17-b7dd-648461eb9016,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-5cd29a3f-b881-4602-9171-5d564375dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fa26e8cb-c910-4fb2-a3fa-813484c08616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368956460-172.17.0.5-1597683872826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-ae70ef15-0bf1-4ba5-b9b7-281bd52b542f,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-cd97118d-e71d-4d80-99b4-9c86f850ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-5de6a439-25c5-47ce-9f6c-5326a08d400a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-1199e8e4-73c2-4ba1-a0d4-62537c3cc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-e5478452-c7f0-4658-b4bd-acd1604039e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-2e84a911-9606-4b17-b7dd-648461eb9016,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-5cd29a3f-b881-4602-9171-5d564375dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fa26e8cb-c910-4fb2-a3fa-813484c08616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727423695-172.17.0.5-1597683981222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-1cec4db4-df64-459b-b67c-65db3428c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-0abe1b40-6713-44de-8417-419cc1aebbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-53a2b605-1b0c-499a-bc79-964818e47f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-42fc73dc-2757-45a8-9971-858c033f2fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-b92deb37-01f8-4234-a6fc-ed6fce2570dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-a2f56a64-e1ce-45cd-a3e2-179949514a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6e1de63a-8e66-4181-bd7d-75bb4aab9e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-0bddfe33-ee7a-4be0-8093-875f6a5d0286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727423695-172.17.0.5-1597683981222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-1cec4db4-df64-459b-b67c-65db3428c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-0abe1b40-6713-44de-8417-419cc1aebbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-53a2b605-1b0c-499a-bc79-964818e47f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-42fc73dc-2757-45a8-9971-858c033f2fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-b92deb37-01f8-4234-a6fc-ed6fce2570dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-a2f56a64-e1ce-45cd-a3e2-179949514a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6e1de63a-8e66-4181-bd7d-75bb4aab9e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-0bddfe33-ee7a-4be0-8093-875f6a5d0286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094459619-172.17.0.5-1597684055949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-44f5897e-7c5e-49d4-a315-19b921cbbae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-e68072e2-2185-4fb0-8243-76b77763955e,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-80357795-7590-4491-b0a5-1235835e94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-fed053ea-c04a-49cf-b23c-d38cbe5c1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-3d5d0f7b-8bc1-4c7f-b35a-eba7af9d17ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-5f8d9bf7-c373-4cee-b2a9-d93061f0a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-b76dbffd-dc7b-4b8c-9af4-8fc626c73db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-1828a85a-cd78-476b-9c43-6f9d73bd4bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094459619-172.17.0.5-1597684055949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-44f5897e-7c5e-49d4-a315-19b921cbbae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-e68072e2-2185-4fb0-8243-76b77763955e,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-80357795-7590-4491-b0a5-1235835e94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-fed053ea-c04a-49cf-b23c-d38cbe5c1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-3d5d0f7b-8bc1-4c7f-b35a-eba7af9d17ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-5f8d9bf7-c373-4cee-b2a9-d93061f0a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-b76dbffd-dc7b-4b8c-9af4-8fc626c73db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-1828a85a-cd78-476b-9c43-6f9d73bd4bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5547
