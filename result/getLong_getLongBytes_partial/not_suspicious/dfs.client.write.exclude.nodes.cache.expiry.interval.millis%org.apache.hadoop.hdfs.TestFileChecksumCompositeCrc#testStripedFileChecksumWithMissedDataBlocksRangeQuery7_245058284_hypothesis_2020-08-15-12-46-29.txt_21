reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730790465-172.17.0.5-1597496256304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-2a635885-8d22-434e-8427-bb1a7109f94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-bbc064dc-10b2-4d91-94bd-3578cfdf8046,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-9caab6e5-8ba1-4872-8a90-9eac213c9779,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-af02b5b9-ecee-4d7e-8843-e626676ee89e,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-cb5cef50-ce73-4297-9968-782b37e22cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-2c5014bf-b084-4fe2-8037-cc2c2f56db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-df58128d-9fe2-4b8b-828e-a0039ff76122,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-9cd756b0-ed33-4f66-bcf1-b4844a6278e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730790465-172.17.0.5-1597496256304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-2a635885-8d22-434e-8427-bb1a7109f94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-bbc064dc-10b2-4d91-94bd-3578cfdf8046,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-9caab6e5-8ba1-4872-8a90-9eac213c9779,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-af02b5b9-ecee-4d7e-8843-e626676ee89e,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-cb5cef50-ce73-4297-9968-782b37e22cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-2c5014bf-b084-4fe2-8037-cc2c2f56db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-df58128d-9fe2-4b8b-828e-a0039ff76122,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-9cd756b0-ed33-4f66-bcf1-b4844a6278e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146666218-172.17.0.5-1597496343053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-a2e82283-e594-424f-a4f5-bb483d49269d,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-e0efef1a-5a2d-421b-8b50-e076f4e5718d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-4ed52191-5ff4-4939-b8df-fb878672c591,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-fd57f995-2d3a-4e71-97ef-b291d950788d,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-1fbbb3f2-d2e7-4f62-a063-3df42b8a97e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-cbc38814-e260-4d91-98d7-f787f9a4f3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-3530f130-0a00-4ab1-9b25-0aaac4e30144,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-2cfb9ccd-18ee-44fb-9bd0-f7ca30b670bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146666218-172.17.0.5-1597496343053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-a2e82283-e594-424f-a4f5-bb483d49269d,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-e0efef1a-5a2d-421b-8b50-e076f4e5718d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-4ed52191-5ff4-4939-b8df-fb878672c591,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-fd57f995-2d3a-4e71-97ef-b291d950788d,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-1fbbb3f2-d2e7-4f62-a063-3df42b8a97e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-cbc38814-e260-4d91-98d7-f787f9a4f3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-3530f130-0a00-4ab1-9b25-0aaac4e30144,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-2cfb9ccd-18ee-44fb-9bd0-f7ca30b670bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381989257-172.17.0.5-1597496526373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-47a09038-32ea-46b1-8f98-d705c5cabae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-759ebb44-6760-4488-ac22-4aa492217ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-c25531c6-4b32-4047-8609-3364f488e735,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-4dc16704-4356-4254-ad6c-d11495f77a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-52eb0a4f-7429-4b58-9367-7a0bb8588d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-afccf5a7-5972-42b6-9778-15ad91c170fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-146c7c47-65b5-418e-9b0d-9597a8db865b,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-476a2320-86e3-447c-a456-53e5eade94dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381989257-172.17.0.5-1597496526373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-47a09038-32ea-46b1-8f98-d705c5cabae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-759ebb44-6760-4488-ac22-4aa492217ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-c25531c6-4b32-4047-8609-3364f488e735,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-4dc16704-4356-4254-ad6c-d11495f77a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-52eb0a4f-7429-4b58-9367-7a0bb8588d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-afccf5a7-5972-42b6-9778-15ad91c170fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-146c7c47-65b5-418e-9b0d-9597a8db865b,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-476a2320-86e3-447c-a456-53e5eade94dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046468592-172.17.0.5-1597496624903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-0ee927ac-f3a4-4da6-9cdc-9afd2a36ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-7f949b2b-1456-4a03-9e67-ede9357910f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-a1ccb52d-fb09-46e9-a015-b37611c01ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-3d736d2b-99da-4303-a56d-61b22f43b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-30c7d45f-9a4d-4e96-9ff0-6de352f1f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-7907ef51-9f8e-4f15-b28a-c6981e07f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-00c610b8-80f7-4e6c-b3b9-3c3993930d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4ca360a9-a63f-4d99-aeeb-009263a43cf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046468592-172.17.0.5-1597496624903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-0ee927ac-f3a4-4da6-9cdc-9afd2a36ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-7f949b2b-1456-4a03-9e67-ede9357910f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-a1ccb52d-fb09-46e9-a015-b37611c01ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-3d736d2b-99da-4303-a56d-61b22f43b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-30c7d45f-9a4d-4e96-9ff0-6de352f1f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-7907ef51-9f8e-4f15-b28a-c6981e07f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-00c610b8-80f7-4e6c-b3b9-3c3993930d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4ca360a9-a63f-4d99-aeeb-009263a43cf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289768678-172.17.0.5-1597496755962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-62d70aa8-06fd-4f29-a0cd-79c7820b02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-f143ac08-014f-4bb5-bb37-41397fbf988c,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-ebc33872-1029-4af8-a95a-206180629ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e95f200e-52b7-477d-9648-cb3923aa27af,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-f079690d-4e24-4493-a5ab-12590a2c4dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-379480e0-83f4-4aa5-b227-55c7fd38b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-b1d14b4b-d752-4ae0-9d05-a4ca832d21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-aed20444-f590-4ee5-b40b-82e0677c5927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289768678-172.17.0.5-1597496755962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-62d70aa8-06fd-4f29-a0cd-79c7820b02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-f143ac08-014f-4bb5-bb37-41397fbf988c,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-ebc33872-1029-4af8-a95a-206180629ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e95f200e-52b7-477d-9648-cb3923aa27af,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-f079690d-4e24-4493-a5ab-12590a2c4dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-379480e0-83f4-4aa5-b227-55c7fd38b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-b1d14b4b-d752-4ae0-9d05-a4ca832d21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-aed20444-f590-4ee5-b40b-82e0677c5927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777035172-172.17.0.5-1597496853362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-03c8b0f3-6bc5-46bd-9145-e62336596e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-a31afa23-94e5-4c32-a0d3-560b8f34001b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-4183f1f3-3994-465c-ad25-41d0a5449f94,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-71fdf559-cf60-43ba-bf95-fff9006bc36c,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-04321595-1bc9-4027-9687-a8a6db4785ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-5fed450a-b62c-41ed-8710-5f9b8efb85e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-5ad3dfcb-8abd-4cca-b8fd-d85febc8f708,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-e202adfc-e5fa-41f9-8487-b122ec684f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777035172-172.17.0.5-1597496853362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-03c8b0f3-6bc5-46bd-9145-e62336596e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-a31afa23-94e5-4c32-a0d3-560b8f34001b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-4183f1f3-3994-465c-ad25-41d0a5449f94,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-71fdf559-cf60-43ba-bf95-fff9006bc36c,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-04321595-1bc9-4027-9687-a8a6db4785ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-5fed450a-b62c-41ed-8710-5f9b8efb85e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-5ad3dfcb-8abd-4cca-b8fd-d85febc8f708,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-e202adfc-e5fa-41f9-8487-b122ec684f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381316639-172.17.0.5-1597496898905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-1c58299b-5d20-4541-9c98-280625df5890,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-4b9ca63f-9032-486b-96d6-5052239187ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-8c777b64-3ce2-4210-b37f-17beba45fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-7f8be9db-0d7f-4aab-9078-992fec9b38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-0dc6b941-2a6c-405a-9c3b-4d934c364f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-150db74e-9540-4daf-ad24-8adf9fdc2548,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-47b68ebb-6367-41ea-ac89-129a60c33c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-6676be9e-7f9f-4dea-b4e2-ed0329861550,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381316639-172.17.0.5-1597496898905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-1c58299b-5d20-4541-9c98-280625df5890,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-4b9ca63f-9032-486b-96d6-5052239187ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-8c777b64-3ce2-4210-b37f-17beba45fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-7f8be9db-0d7f-4aab-9078-992fec9b38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-0dc6b941-2a6c-405a-9c3b-4d934c364f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-150db74e-9540-4daf-ad24-8adf9fdc2548,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-47b68ebb-6367-41ea-ac89-129a60c33c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-6676be9e-7f9f-4dea-b4e2-ed0329861550,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278157307-172.17.0.5-1597496944560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-54363972-09ff-4055-a250-6ab5c0aa2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-f8dcfa5d-454d-4d4e-bf92-c2b3be466d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-d7fb451a-1946-41d8-87c4-037484ed72be,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-bb91e380-4211-4cdb-89e3-ec9a3ec59287,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ad97716c-7cdc-4c6e-ba79-e765361fd9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b6849c87-91ba-462d-8834-54b768035c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-47ed03aa-d661-4abe-9a73-0f88ae228cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-1ce2451e-dc9e-4647-831b-297e856eef7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278157307-172.17.0.5-1597496944560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-54363972-09ff-4055-a250-6ab5c0aa2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-f8dcfa5d-454d-4d4e-bf92-c2b3be466d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-d7fb451a-1946-41d8-87c4-037484ed72be,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-bb91e380-4211-4cdb-89e3-ec9a3ec59287,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ad97716c-7cdc-4c6e-ba79-e765361fd9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b6849c87-91ba-462d-8834-54b768035c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-47ed03aa-d661-4abe-9a73-0f88ae228cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-1ce2451e-dc9e-4647-831b-297e856eef7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142626871-172.17.0.5-1597496994634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-356a32cb-e56b-4bdc-990d-dc1b8d634ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-d085596e-d932-49d3-8aa6-4a5d366e4f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-32ac7446-5d53-4095-b809-efeba6514279,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-397b9c9f-8efa-4768-bc33-fdef1c778b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-125de928-6ceb-4af4-b8ae-b7be22482b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-649805bc-1173-49ec-9ec1-3da7ff94a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-066d1bfb-0394-4817-aa8d-eece9f30064b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-b9537b89-c443-43de-972a-ee76f73b2320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142626871-172.17.0.5-1597496994634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-356a32cb-e56b-4bdc-990d-dc1b8d634ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-d085596e-d932-49d3-8aa6-4a5d366e4f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-32ac7446-5d53-4095-b809-efeba6514279,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-397b9c9f-8efa-4768-bc33-fdef1c778b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-125de928-6ceb-4af4-b8ae-b7be22482b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-649805bc-1173-49ec-9ec1-3da7ff94a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-066d1bfb-0394-4817-aa8d-eece9f30064b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-b9537b89-c443-43de-972a-ee76f73b2320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977043568-172.17.0.5-1597497116106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-cbf8c0c6-3875-43b7-8621-0c941d523a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-42b94047-4c30-41ed-8859-abd61bf0c2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-2d61cf30-00b9-4d13-a60a-6106eb1e9281,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-38092b42-2100-4b4e-8915-ed3e9db7d632,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-d8cc7a78-8a76-4435-9f34-f96fa9ae50b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-bcda4c42-bdd7-47b4-87fd-837eccba1990,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-745bc422-4c99-4674-a48c-54ffb1237b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-ed5984af-9262-4494-a217-4d9df29300f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977043568-172.17.0.5-1597497116106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-cbf8c0c6-3875-43b7-8621-0c941d523a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-42b94047-4c30-41ed-8859-abd61bf0c2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-2d61cf30-00b9-4d13-a60a-6106eb1e9281,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-38092b42-2100-4b4e-8915-ed3e9db7d632,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-d8cc7a78-8a76-4435-9f34-f96fa9ae50b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-bcda4c42-bdd7-47b4-87fd-837eccba1990,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-745bc422-4c99-4674-a48c-54ffb1237b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-ed5984af-9262-4494-a217-4d9df29300f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792724374-172.17.0.5-1597497161938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-d401de74-ae85-4f9a-bf47-56602ebb6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1337fe64-bbd7-46e7-9e6d-528a3ea58825,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-14982107-bde7-4bcd-86e6-a7b903907824,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-66f8ead9-1151-4238-98cf-7a822cd8f0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-68b84622-4c5c-40df-b87b-4a3b79cde9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-09a01486-e7fa-4f28-b4fa-e0a2241989d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-8efd07f5-3b1d-420f-b3b0-554c6b9b0882,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-3b638f96-4421-449b-a4c9-60a6a5c525e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792724374-172.17.0.5-1597497161938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-d401de74-ae85-4f9a-bf47-56602ebb6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1337fe64-bbd7-46e7-9e6d-528a3ea58825,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-14982107-bde7-4bcd-86e6-a7b903907824,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-66f8ead9-1151-4238-98cf-7a822cd8f0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-68b84622-4c5c-40df-b87b-4a3b79cde9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-09a01486-e7fa-4f28-b4fa-e0a2241989d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-8efd07f5-3b1d-420f-b3b0-554c6b9b0882,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-3b638f96-4421-449b-a4c9-60a6a5c525e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474657209-172.17.0.5-1597497349384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-2b9d354f-c566-45ea-98de-639caf76c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-97db0bd7-0f9b-434e-aa26-d31052266e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-679b7d1a-e97c-4db3-a24f-0303fd983137,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1b94d057-2f77-4dd6-884b-3ed9b99ec05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-dfaca6f1-5fd7-4a54-917d-30854cfc13be,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-64e15039-936d-415f-9fba-68f13e17d839,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3708474f-f61e-4050-bd54-4e5b5241c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-40413bb0-d4d6-4c6c-b280-d2f034d5bfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474657209-172.17.0.5-1597497349384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-2b9d354f-c566-45ea-98de-639caf76c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-97db0bd7-0f9b-434e-aa26-d31052266e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-679b7d1a-e97c-4db3-a24f-0303fd983137,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1b94d057-2f77-4dd6-884b-3ed9b99ec05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-dfaca6f1-5fd7-4a54-917d-30854cfc13be,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-64e15039-936d-415f-9fba-68f13e17d839,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3708474f-f61e-4050-bd54-4e5b5241c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-40413bb0-d4d6-4c6c-b280-d2f034d5bfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373997637-172.17.0.5-1597498460775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38187,DS-da4801ec-7e3c-4167-8b11-123bc1d99583,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8091e003-5276-48fc-8cd2-edc3ae9c5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-18055fab-f252-4be9-8bc8-3395dd7f49f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-d693fab6-2e95-4c9e-8867-c37438179866,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-dfee3545-0ad7-4f8a-b005-97c6ead90414,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-abd276b5-18fc-450c-a224-5511b6cc93b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-e3a3b221-a508-4798-b201-dd91ae74a5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-bb3054de-925d-4ab6-8c84-bc41d28186dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373997637-172.17.0.5-1597498460775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38187,DS-da4801ec-7e3c-4167-8b11-123bc1d99583,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8091e003-5276-48fc-8cd2-edc3ae9c5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-18055fab-f252-4be9-8bc8-3395dd7f49f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-d693fab6-2e95-4c9e-8867-c37438179866,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-dfee3545-0ad7-4f8a-b005-97c6ead90414,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-abd276b5-18fc-450c-a224-5511b6cc93b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-e3a3b221-a508-4798-b201-dd91ae74a5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-bb3054de-925d-4ab6-8c84-bc41d28186dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740432117-172.17.0.5-1597498687122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-2f8b05dc-142c-4f21-a4e7-c42a99cbacd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-d8eb1798-b785-400b-8e6e-186331bb2add,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-4f58126c-3850-45c5-b21f-00b796193ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-06ccda6a-c676-42e5-913d-5dba9f2ddb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-ce1ce178-361e-4f19-9fdc-707803506caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-2f7883a8-48cc-4890-9e43-3d4429994fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1771cf68-a357-4767-b23c-c4c8e95b8abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-ef793c6d-3fae-4fb6-87ec-5ab7b559ab3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740432117-172.17.0.5-1597498687122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-2f8b05dc-142c-4f21-a4e7-c42a99cbacd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-d8eb1798-b785-400b-8e6e-186331bb2add,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-4f58126c-3850-45c5-b21f-00b796193ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-06ccda6a-c676-42e5-913d-5dba9f2ddb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-ce1ce178-361e-4f19-9fdc-707803506caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-2f7883a8-48cc-4890-9e43-3d4429994fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1771cf68-a357-4767-b23c-c4c8e95b8abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-ef793c6d-3fae-4fb6-87ec-5ab7b559ab3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621662087-172.17.0.5-1597498917142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-5931cf20-8e2c-4646-b2c8-f1c2a10e539e,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-87a5a49c-ac47-421c-9e7e-7e35e4d66588,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-41bed4b5-fb1b-4ee3-9eaf-63dda9f2c43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-7471ed61-52ce-4c17-a84e-a17adab184a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-34f90549-53bd-4f6c-8869-ba8a2dbdb1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-aa96a495-5f91-46cd-982e-d60b743bdabf,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-4316c9d7-2fb5-45fb-9fde-6fd01f139586,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-006d3840-1997-41f0-9915-acd91d1ed8c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621662087-172.17.0.5-1597498917142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-5931cf20-8e2c-4646-b2c8-f1c2a10e539e,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-87a5a49c-ac47-421c-9e7e-7e35e4d66588,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-41bed4b5-fb1b-4ee3-9eaf-63dda9f2c43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-7471ed61-52ce-4c17-a84e-a17adab184a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-34f90549-53bd-4f6c-8869-ba8a2dbdb1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-aa96a495-5f91-46cd-982e-d60b743bdabf,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-4316c9d7-2fb5-45fb-9fde-6fd01f139586,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-006d3840-1997-41f0-9915-acd91d1ed8c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8271312-172.17.0.5-1597499017977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-81afb348-a306-476b-9ae1-57182544057a,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-c52e7c0c-e594-4b10-aa7e-9008689b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-03b532f5-5ea1-4042-ac91-8554e3977fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-3fcdae57-372b-4b6e-8bb7-ebc93c8a80b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-9fc35aae-7303-4e3a-a67a-ae2ba4be1373,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-0e939557-6119-457f-87ca-da057a040f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-a0be41b9-6860-4fd8-9efd-84eabbf20520,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-234d9262-a472-4892-b8b5-5c56b3b99559,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8271312-172.17.0.5-1597499017977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-81afb348-a306-476b-9ae1-57182544057a,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-c52e7c0c-e594-4b10-aa7e-9008689b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-03b532f5-5ea1-4042-ac91-8554e3977fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-3fcdae57-372b-4b6e-8bb7-ebc93c8a80b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-9fc35aae-7303-4e3a-a67a-ae2ba4be1373,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-0e939557-6119-457f-87ca-da057a040f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-a0be41b9-6860-4fd8-9efd-84eabbf20520,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-234d9262-a472-4892-b8b5-5c56b3b99559,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467170337-172.17.0.5-1597499205195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-02e737b8-8749-4e6a-8cff-898380bb1512,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-43f0eb3a-7dce-4c45-ba5d-222810382fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-c608186a-dcf4-4cfb-98b0-e917b80a1d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-68e85569-2682-48bd-abea-bbfc768babd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-319317e7-c957-4570-ab29-a4ee10bbb2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-8648ef64-2ae9-432b-8620-a52d7b70159b,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-1dec06d3-9ce8-49ea-87d8-ad66c6123e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-e430e910-f4b0-47d5-ac48-799de37c481e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467170337-172.17.0.5-1597499205195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-02e737b8-8749-4e6a-8cff-898380bb1512,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-43f0eb3a-7dce-4c45-ba5d-222810382fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-c608186a-dcf4-4cfb-98b0-e917b80a1d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-68e85569-2682-48bd-abea-bbfc768babd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-319317e7-c957-4570-ab29-a4ee10bbb2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-8648ef64-2ae9-432b-8620-a52d7b70159b,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-1dec06d3-9ce8-49ea-87d8-ad66c6123e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-e430e910-f4b0-47d5-ac48-799de37c481e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251685429-172.17.0.5-1597499478025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37146,DS-fa20a47f-c7d8-4711-be75-8f086fbd5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-820e7d88-dbf7-4068-9cdd-8911507be2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-027affd0-1984-4891-a93e-cbb930f0e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-9b4361d5-fbf0-4338-903e-07849d637438,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-921c348b-50db-4188-8156-b27f0d39ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-27b32d30-a34c-4684-b5a8-34e3639acd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-0f462bfc-721d-4502-9ea4-2bf7dbffaa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-cd657aed-c6e5-4083-80b6-bff9dfff3068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251685429-172.17.0.5-1597499478025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37146,DS-fa20a47f-c7d8-4711-be75-8f086fbd5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-820e7d88-dbf7-4068-9cdd-8911507be2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-027affd0-1984-4891-a93e-cbb930f0e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-9b4361d5-fbf0-4338-903e-07849d637438,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-921c348b-50db-4188-8156-b27f0d39ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-27b32d30-a34c-4684-b5a8-34e3639acd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-0f462bfc-721d-4502-9ea4-2bf7dbffaa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-cd657aed-c6e5-4083-80b6-bff9dfff3068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101724069-172.17.0.5-1597499822167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-1e8a424a-f0ba-446f-9e61-654b26749daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-a6f48380-c608-4a66-945b-0e52536980ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-a0eea079-bd31-4ab6-bdd8-1502a5facfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-db7b56b5-77e9-4d16-8ca0-05493637acce,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-8461429b-c307-4c0b-b554-b3e035c74f05,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-da4ff019-1053-42aa-98fc-c66639be75a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-fd4305e7-f584-4ce8-aa3f-6cbf8663a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-6bbf1a67-291d-49e8-aa3e-7d5cd501115a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101724069-172.17.0.5-1597499822167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-1e8a424a-f0ba-446f-9e61-654b26749daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-a6f48380-c608-4a66-945b-0e52536980ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-a0eea079-bd31-4ab6-bdd8-1502a5facfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-db7b56b5-77e9-4d16-8ca0-05493637acce,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-8461429b-c307-4c0b-b554-b3e035c74f05,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-da4ff019-1053-42aa-98fc-c66639be75a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-fd4305e7-f584-4ce8-aa3f-6cbf8663a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-6bbf1a67-291d-49e8-aa3e-7d5cd501115a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776509429-172.17.0.5-1597499867835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-4b9938e1-acae-48af-9e08-c5f2145a6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-17bd2a63-abab-4293-a2df-5caf6dd3c601,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-143e1527-96a8-4fdd-88e7-604826aed3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-128b0ff0-7181-4bb7-bcc9-631b9f0fd21f,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-e63faba1-deb4-4d24-864c-c7341c5f7af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-90880329-e29d-4238-8a5e-6089c95197e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-8e3cecd3-da98-44a2-85ba-5fa9317838db,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-903ee3b7-ba07-4003-8850-f4a706dd4fe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776509429-172.17.0.5-1597499867835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-4b9938e1-acae-48af-9e08-c5f2145a6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-17bd2a63-abab-4293-a2df-5caf6dd3c601,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-143e1527-96a8-4fdd-88e7-604826aed3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-128b0ff0-7181-4bb7-bcc9-631b9f0fd21f,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-e63faba1-deb4-4d24-864c-c7341c5f7af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-90880329-e29d-4238-8a5e-6089c95197e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-8e3cecd3-da98-44a2-85ba-5fa9317838db,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-903ee3b7-ba07-4003-8850-f4a706dd4fe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379542309-172.17.0.5-1597500250336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-9a7a374d-7b4c-44d0-b166-db14179118a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-65893b43-4b96-4dd8-9d69-70e4c9cef6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-54ee937f-d7ac-4cb0-802e-489f1afa12f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-405d046a-c05f-4a7e-add8-9bc226bb4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-85861634-ca04-4c82-92ec-c238e4d6def0,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-26a6fc10-f93d-4718-b144-e9a5e3015446,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-e555f3e8-8823-4673-a426-7fca85128a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-08bfa617-41d1-4574-89fe-f648b4f0e250,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379542309-172.17.0.5-1597500250336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-9a7a374d-7b4c-44d0-b166-db14179118a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-65893b43-4b96-4dd8-9d69-70e4c9cef6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-54ee937f-d7ac-4cb0-802e-489f1afa12f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-405d046a-c05f-4a7e-add8-9bc226bb4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-85861634-ca04-4c82-92ec-c238e4d6def0,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-26a6fc10-f93d-4718-b144-e9a5e3015446,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-e555f3e8-8823-4673-a426-7fca85128a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-08bfa617-41d1-4574-89fe-f648b4f0e250,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982027448-172.17.0.5-1597500342632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-8211bebd-38dc-43a6-93f2-a39f68c7a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-94491043-7511-40c3-b1df-d8899cfe4ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-efc4505b-7327-45d2-af7b-aed620220f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-3c6421dc-e973-45a0-9424-1f173db9530d,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-36e4a2fc-ca0d-42cb-8c6e-37fb3842fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-9ef865ee-5966-4fd8-8451-283950601de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-7308f18b-32c7-4ad6-9a0e-4427eab77961,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-560333ec-5c22-4a9b-a044-ee94bf17f860,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982027448-172.17.0.5-1597500342632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-8211bebd-38dc-43a6-93f2-a39f68c7a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-94491043-7511-40c3-b1df-d8899cfe4ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-efc4505b-7327-45d2-af7b-aed620220f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-3c6421dc-e973-45a0-9424-1f173db9530d,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-36e4a2fc-ca0d-42cb-8c6e-37fb3842fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-9ef865ee-5966-4fd8-8451-283950601de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-7308f18b-32c7-4ad6-9a0e-4427eab77961,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-560333ec-5c22-4a9b-a044-ee94bf17f860,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806095508-172.17.0.5-1597500589840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-915737ca-50af-463d-83e7-de50d2353848,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-98359855-c12d-4748-9eb4-75e1d711f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-e5c8ebc0-f61c-4c36-92cc-42afa2afaff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d4174608-77a9-45f2-9af7-bf781082bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-74c89e9d-69b4-43f2-9473-8bb934a86f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-e0de2535-5569-4702-9e79-bd556a078b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ca868480-3d4b-43f9-9b96-9afb5ba70b72,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-46810fa7-1338-498d-8033-07381573f8fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806095508-172.17.0.5-1597500589840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-915737ca-50af-463d-83e7-de50d2353848,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-98359855-c12d-4748-9eb4-75e1d711f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-e5c8ebc0-f61c-4c36-92cc-42afa2afaff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d4174608-77a9-45f2-9af7-bf781082bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-74c89e9d-69b4-43f2-9473-8bb934a86f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-e0de2535-5569-4702-9e79-bd556a078b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ca868480-3d4b-43f9-9b96-9afb5ba70b72,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-46810fa7-1338-498d-8033-07381573f8fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286977829-172.17.0.5-1597500688583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-c78fe2cc-34e7-469a-a8c0-431964b43e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-e48b8331-c40e-4acd-8597-5c888ab77a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-9c4c7a8b-34af-4719-b1d9-af16a4c64c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-6fb67ef9-4cf7-48df-95e9-ddfcc1d66de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-5cdb9dc6-7e29-43bf-a10e-739c49719496,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-8ba35bed-9530-4a91-b789-aa2feebb9acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-9007e013-f24e-4679-8aa0-85bab5814ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-b670b819-e21b-4de9-bc24-84697d41b133,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286977829-172.17.0.5-1597500688583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-c78fe2cc-34e7-469a-a8c0-431964b43e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-e48b8331-c40e-4acd-8597-5c888ab77a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-9c4c7a8b-34af-4719-b1d9-af16a4c64c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-6fb67ef9-4cf7-48df-95e9-ddfcc1d66de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-5cdb9dc6-7e29-43bf-a10e-739c49719496,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-8ba35bed-9530-4a91-b789-aa2feebb9acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-9007e013-f24e-4679-8aa0-85bab5814ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-b670b819-e21b-4de9-bc24-84697d41b133,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950157747-172.17.0.5-1597501010154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-a18f261a-9c8a-4f92-97f5-5187e0516edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-e84eddf2-aad0-4e4f-b951-4e904c8ed047,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-aeb8b825-c412-420c-b656-9ae7ac1502e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-2752ee70-74ad-439b-9b56-6ceb544f70ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-588dc935-a728-4dc6-b06b-95ed8b6de559,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6bca0ffa-3ca7-4e82-8c89-3c6438b781cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-f2e76b85-4a8a-4186-86e5-48ace808b078,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-2dd69ce8-d87b-44c8-b35c-f5cf31500296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950157747-172.17.0.5-1597501010154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-a18f261a-9c8a-4f92-97f5-5187e0516edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-e84eddf2-aad0-4e4f-b951-4e904c8ed047,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-aeb8b825-c412-420c-b656-9ae7ac1502e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-2752ee70-74ad-439b-9b56-6ceb544f70ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-588dc935-a728-4dc6-b06b-95ed8b6de559,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6bca0ffa-3ca7-4e82-8c89-3c6438b781cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-f2e76b85-4a8a-4186-86e5-48ace808b078,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-2dd69ce8-d87b-44c8-b35c-f5cf31500296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824961931-172.17.0.5-1597501148164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43796,DS-04eb29ba-dfda-4294-aba8-02acea191e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-13044e5a-3555-4fa8-9987-facde9671014,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-2563eaac-709b-4a34-8395-e739c9b7d605,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-102d3423-fccf-49f6-8061-ba239a2265ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-190c51c1-f836-44b8-8fee-6b5e2687e242,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-982d6c51-5c04-4106-9083-ef7c2da642e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-c2104187-007a-4111-9a0d-a702e6f10ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-aae76836-6d26-4321-813c-c0717cb10b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824961931-172.17.0.5-1597501148164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43796,DS-04eb29ba-dfda-4294-aba8-02acea191e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-13044e5a-3555-4fa8-9987-facde9671014,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-2563eaac-709b-4a34-8395-e739c9b7d605,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-102d3423-fccf-49f6-8061-ba239a2265ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-190c51c1-f836-44b8-8fee-6b5e2687e242,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-982d6c51-5c04-4106-9083-ef7c2da642e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-c2104187-007a-4111-9a0d-a702e6f10ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-aae76836-6d26-4321-813c-c0717cb10b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247291220-172.17.0.5-1597501483535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-51ffc6d6-e551-4b8d-8e6f-933e57201fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-15207cce-cdd2-4432-8ea7-7e6b573f4fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-e780a3db-967d-40b2-8f15-cb88247da916,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-d77ef34c-3949-449e-9030-303037b05c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-b50dc723-288e-4003-8255-82710d46382b,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-c0812e57-096f-4c30-b547-4378f64986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-01f4ebbc-21d1-4f80-ad5f-8567446c496a,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-7bb84bcf-1ec9-4fb6-9f16-9b69935bcc92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247291220-172.17.0.5-1597501483535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-51ffc6d6-e551-4b8d-8e6f-933e57201fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-15207cce-cdd2-4432-8ea7-7e6b573f4fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-e780a3db-967d-40b2-8f15-cb88247da916,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-d77ef34c-3949-449e-9030-303037b05c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-b50dc723-288e-4003-8255-82710d46382b,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-c0812e57-096f-4c30-b547-4378f64986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-01f4ebbc-21d1-4f80-ad5f-8567446c496a,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-7bb84bcf-1ec9-4fb6-9f16-9b69935bcc92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395644898-172.17.0.5-1597501576054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-9831f5e0-c090-4c26-8f12-f63cf8f9f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-85b53c47-c032-4787-be98-6b9a4b0efc66,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-d08d9d7e-200c-4569-acff-148bc009bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-7b3f8ac2-00e0-4cb5-8826-11e262d67fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-7b29ce27-5cd8-443a-8ec4-f4bcb4f13924,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d29a3957-12d2-47c6-8724-c0c861847ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-f2a13cb7-7442-48a3-a303-4a01e966b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-b559b373-cb98-4e88-8973-3e49a02f80df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395644898-172.17.0.5-1597501576054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-9831f5e0-c090-4c26-8f12-f63cf8f9f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-85b53c47-c032-4787-be98-6b9a4b0efc66,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-d08d9d7e-200c-4569-acff-148bc009bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-7b3f8ac2-00e0-4cb5-8826-11e262d67fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-7b29ce27-5cd8-443a-8ec4-f4bcb4f13924,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d29a3957-12d2-47c6-8724-c0c861847ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-f2a13cb7-7442-48a3-a303-4a01e966b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-b559b373-cb98-4e88-8973-3e49a02f80df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505681309-172.17.0.5-1597501622838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-93ca49b2-23b0-4662-b7e7-47ae4c2b07e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-7fec21b5-85b3-4edd-9f04-60469947f162,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-e6850852-a1d7-4fdf-87e0-4263ac83947d,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-1ec97c6c-143e-460a-b34e-04f2b674847d,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-a4113606-1dd6-4a67-9a1d-d85757837973,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-8222e045-788c-465e-9120-5fd968502d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bba89bb1-6e49-4b07-aa3d-60e9311a3be9,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-68164272-c860-45a3-812b-9ff95bf83b90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505681309-172.17.0.5-1597501622838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-93ca49b2-23b0-4662-b7e7-47ae4c2b07e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-7fec21b5-85b3-4edd-9f04-60469947f162,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-e6850852-a1d7-4fdf-87e0-4263ac83947d,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-1ec97c6c-143e-460a-b34e-04f2b674847d,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-a4113606-1dd6-4a67-9a1d-d85757837973,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-8222e045-788c-465e-9120-5fd968502d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bba89bb1-6e49-4b07-aa3d-60e9311a3be9,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-68164272-c860-45a3-812b-9ff95bf83b90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090630115-172.17.0.5-1597501716335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-b3411902-b7d7-43cc-b5cd-2498af6ac20c,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-7e6f6433-2bf6-4660-8503-9cddc36191cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-c880893a-2726-45f9-89a9-b706097920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-3f527594-aeec-4c4e-baf2-d61bbcbdf1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-c166b40f-fe06-432a-aef4-a5eda5528d37,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-8587b5c9-f90e-407a-939d-7edfaf49a555,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-801e7367-13b7-42b5-97dd-265e70468130,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-63596a68-ee08-4e9b-88f2-5fcdee7e9ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090630115-172.17.0.5-1597501716335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-b3411902-b7d7-43cc-b5cd-2498af6ac20c,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-7e6f6433-2bf6-4660-8503-9cddc36191cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-c880893a-2726-45f9-89a9-b706097920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-3f527594-aeec-4c4e-baf2-d61bbcbdf1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-c166b40f-fe06-432a-aef4-a5eda5528d37,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-8587b5c9-f90e-407a-939d-7edfaf49a555,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-801e7367-13b7-42b5-97dd-265e70468130,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-63596a68-ee08-4e9b-88f2-5fcdee7e9ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139742838-172.17.0.5-1597501761961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-a4cf83cf-5eb6-4199-9c0f-dbdbe47e83fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-aac2ed64-51eb-46b0-bee6-3a8c9b51875c,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5e25f775-4491-4e73-98e7-607bb728a414,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-e60fe683-2833-48e6-b390-ca14d7fa06f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-2c37e883-ba2b-4f3d-9175-a9ce003411ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-b34118e1-17bf-4fc6-8243-feeda7d800ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-9744d43f-fc70-436c-8f38-03f2ce2da321,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-c09566dd-8020-4057-ae68-cb719c51d4aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139742838-172.17.0.5-1597501761961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-a4cf83cf-5eb6-4199-9c0f-dbdbe47e83fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-aac2ed64-51eb-46b0-bee6-3a8c9b51875c,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5e25f775-4491-4e73-98e7-607bb728a414,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-e60fe683-2833-48e6-b390-ca14d7fa06f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-2c37e883-ba2b-4f3d-9175-a9ce003411ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-b34118e1-17bf-4fc6-8243-feeda7d800ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-9744d43f-fc70-436c-8f38-03f2ce2da321,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-c09566dd-8020-4057-ae68-cb719c51d4aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851979147-172.17.0.5-1597502016203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-01cbda47-c20a-4c0d-a44a-009f8489008e,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0c1524c0-dea2-4545-84f0-51b3c435f170,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c6644f2f-2610-4478-b807-b32634045205,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-20fd7a23-ee3e-493c-ad9a-bf18691a172d,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-481fd63a-1d22-4079-bbdf-97d15aa40a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-95a7cd05-b362-40d9-b5ca-d8c504acc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-37a671f7-b80e-4556-9124-a5f3d6d7ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-6aef7923-f081-475e-a137-0b6538fb9a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851979147-172.17.0.5-1597502016203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-01cbda47-c20a-4c0d-a44a-009f8489008e,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0c1524c0-dea2-4545-84f0-51b3c435f170,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c6644f2f-2610-4478-b807-b32634045205,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-20fd7a23-ee3e-493c-ad9a-bf18691a172d,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-481fd63a-1d22-4079-bbdf-97d15aa40a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-95a7cd05-b362-40d9-b5ca-d8c504acc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-37a671f7-b80e-4556-9124-a5f3d6d7ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-6aef7923-f081-475e-a137-0b6538fb9a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409473569-172.17.0.5-1597502134818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41462,DS-36dccb28-568f-48d3-9dd0-9c26ed0961ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-7cd7a0d3-ffe5-484b-8e1a-5b075912dcca,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3ef9c80d-c851-4ad9-9a96-6ace07b4d055,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-8269738e-825a-42cd-a538-9f49987fdd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-80d58336-3034-4271-94f6-dc4038234f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-afa24a88-a456-4cb7-869b-6908297ac7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-38c2c23b-2cf0-46fd-a762-11c93b896617,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-4d6a9749-f1a5-4ddb-b3b8-64c084d3c9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409473569-172.17.0.5-1597502134818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41462,DS-36dccb28-568f-48d3-9dd0-9c26ed0961ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-7cd7a0d3-ffe5-484b-8e1a-5b075912dcca,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3ef9c80d-c851-4ad9-9a96-6ace07b4d055,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-8269738e-825a-42cd-a538-9f49987fdd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-80d58336-3034-4271-94f6-dc4038234f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-afa24a88-a456-4cb7-869b-6908297ac7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-38c2c23b-2cf0-46fd-a762-11c93b896617,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-4d6a9749-f1a5-4ddb-b3b8-64c084d3c9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715771008-172.17.0.5-1597502312909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-0dd72cad-d5be-41cf-bae1-a9df9b60da04,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-2cf897f4-2d56-4d5b-8521-df8ec0e04538,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-314bfd50-f16b-424f-9a22-f92583801a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-ac2416e5-5146-4866-adda-97f0c19ba97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-bc72995e-aca0-473a-aec9-bf85b654d8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-1e82fa94-3650-4a90-a59a-cd7cd5f4cf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-38187f73-1f93-4675-b681-9e0ec4a3b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-30055449-0151-4850-86e5-d71e7718108b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715771008-172.17.0.5-1597502312909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-0dd72cad-d5be-41cf-bae1-a9df9b60da04,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-2cf897f4-2d56-4d5b-8521-df8ec0e04538,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-314bfd50-f16b-424f-9a22-f92583801a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-ac2416e5-5146-4866-adda-97f0c19ba97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-bc72995e-aca0-473a-aec9-bf85b654d8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-1e82fa94-3650-4a90-a59a-cd7cd5f4cf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-38187f73-1f93-4675-b681-9e0ec4a3b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-30055449-0151-4850-86e5-d71e7718108b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 6839
