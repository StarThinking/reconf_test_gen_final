reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004082728-172.17.0.7-1597457567473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-3ece7516-3e01-4160-aa97-aec23855f086,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d27df5ad-e312-4c24-8705-992d39abe319,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-6feb0cb2-18d0-4a33-a67e-e16ae4e84e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-b8d4a739-e5bd-4d4b-9f5f-59208116715f,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-c307c86c-d442-4cac-8470-6fdd632dbfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9ef3d374-5926-463b-b05e-f8e279d4e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-61f14415-2045-4186-b90e-d03f48381694,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-247afd5a-678c-4c39-9f71-c4aa1af4e815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004082728-172.17.0.7-1597457567473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-3ece7516-3e01-4160-aa97-aec23855f086,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d27df5ad-e312-4c24-8705-992d39abe319,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-6feb0cb2-18d0-4a33-a67e-e16ae4e84e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-b8d4a739-e5bd-4d4b-9f5f-59208116715f,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-c307c86c-d442-4cac-8470-6fdd632dbfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9ef3d374-5926-463b-b05e-f8e279d4e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-61f14415-2045-4186-b90e-d03f48381694,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-247afd5a-678c-4c39-9f71-c4aa1af4e815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177548327-172.17.0.7-1597457735449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-a37f664b-b9b7-4c4a-b82c-09c3edea8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-e4119c62-6b0d-4e2a-841c-4770b0a298d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-dfe70655-0898-4600-baba-22c583e72e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-1dfd5d8e-07b3-47c1-b59d-f8043b3f05c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-d180501e-5908-4c13-9b89-a8a8c8f4aec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-88f94fd3-ec2f-4599-9cc1-979a98ebe6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-1ff42cb2-5963-4de6-9d6a-4973343ce2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6f325190-7373-466b-9deb-110c1be5b688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177548327-172.17.0.7-1597457735449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-a37f664b-b9b7-4c4a-b82c-09c3edea8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-e4119c62-6b0d-4e2a-841c-4770b0a298d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-dfe70655-0898-4600-baba-22c583e72e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-1dfd5d8e-07b3-47c1-b59d-f8043b3f05c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-d180501e-5908-4c13-9b89-a8a8c8f4aec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-88f94fd3-ec2f-4599-9cc1-979a98ebe6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-1ff42cb2-5963-4de6-9d6a-4973343ce2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6f325190-7373-466b-9deb-110c1be5b688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289716644-172.17.0.7-1597458075610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-a440eb92-dfda-4c27-9d95-6291210f10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-bf59e6b6-0212-44f7-9b20-c454403bec95,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-754e3c32-533c-4ca8-a2ce-c7df42ecf4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-215f07dc-24ce-4cc5-89f2-56aff471b549,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-50ed10e7-2c13-4564-b3ae-2a7420d25c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a5f1af78-32ac-4b68-bce1-ef51ac8d6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-31e3469e-4328-454c-ac14-9a92e5daa30e,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-a6464c11-cabb-4548-9727-5b75ec297896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289716644-172.17.0.7-1597458075610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-a440eb92-dfda-4c27-9d95-6291210f10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-bf59e6b6-0212-44f7-9b20-c454403bec95,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-754e3c32-533c-4ca8-a2ce-c7df42ecf4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-215f07dc-24ce-4cc5-89f2-56aff471b549,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-50ed10e7-2c13-4564-b3ae-2a7420d25c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a5f1af78-32ac-4b68-bce1-ef51ac8d6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-31e3469e-4328-454c-ac14-9a92e5daa30e,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-a6464c11-cabb-4548-9727-5b75ec297896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297908511-172.17.0.7-1597458295744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-c4b842c6-07fc-48a2-a02e-0244877386a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-597b0fc0-935f-48c8-aa78-20cd1f2dc694,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-54ddb769-f4ad-44d6-9872-dcfb46f574a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-f39e17ff-e5c9-4231-85eb-e442ffa61854,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-69642400-35fb-4720-bce2-13e619f167d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-f4065ed7-a83c-4500-a2b4-e62d2a416cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-0d5c0c76-ace6-4788-9e50-6d107b8c29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-26f217bf-b3fb-4d6b-bf5a-2e6894ccc2c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297908511-172.17.0.7-1597458295744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-c4b842c6-07fc-48a2-a02e-0244877386a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-597b0fc0-935f-48c8-aa78-20cd1f2dc694,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-54ddb769-f4ad-44d6-9872-dcfb46f574a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-f39e17ff-e5c9-4231-85eb-e442ffa61854,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-69642400-35fb-4720-bce2-13e619f167d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-f4065ed7-a83c-4500-a2b4-e62d2a416cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-0d5c0c76-ace6-4788-9e50-6d107b8c29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-26f217bf-b3fb-4d6b-bf5a-2e6894ccc2c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347448594-172.17.0.7-1597458420118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-1ed5e2c5-897b-47cb-b31c-3f2f8c642d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-cd9f7d89-773f-4533-937a-115d16a3486d,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-8519ad18-8d42-40c3-9e59-7b557169bf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-ade0de0f-4050-406a-9189-cf5621dad292,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-c355eea7-7871-4871-86ed-d0f97d76f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-ad018823-1a0a-4fac-b280-8c7e5f61b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-e24099db-c867-483f-8187-21fb4620a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1012840b-4332-4fc8-bb8b-36293f660905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347448594-172.17.0.7-1597458420118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-1ed5e2c5-897b-47cb-b31c-3f2f8c642d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-cd9f7d89-773f-4533-937a-115d16a3486d,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-8519ad18-8d42-40c3-9e59-7b557169bf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-ade0de0f-4050-406a-9189-cf5621dad292,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-c355eea7-7871-4871-86ed-d0f97d76f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-ad018823-1a0a-4fac-b280-8c7e5f61b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-e24099db-c867-483f-8187-21fb4620a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1012840b-4332-4fc8-bb8b-36293f660905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993291669-172.17.0.7-1597458698416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-c338b32b-fb17-44ef-9d6d-8668f80d9657,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-f709f58d-7b81-49a8-b579-d28ba511a835,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-de1ffc98-2d39-409f-a599-f418815a9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-713c6806-c350-4988-bdeb-05e35b26db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-8f40be18-8ad4-4dc6-bb4d-9e552a39b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-ca52ac8c-58f0-40b5-9075-77409ed62e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-561e5f52-a40c-42fa-b374-dac8b804f551,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-0301521b-3fec-4047-9016-4fc8b282caf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993291669-172.17.0.7-1597458698416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-c338b32b-fb17-44ef-9d6d-8668f80d9657,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-f709f58d-7b81-49a8-b579-d28ba511a835,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-de1ffc98-2d39-409f-a599-f418815a9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-713c6806-c350-4988-bdeb-05e35b26db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-8f40be18-8ad4-4dc6-bb4d-9e552a39b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-ca52ac8c-58f0-40b5-9075-77409ed62e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-561e5f52-a40c-42fa-b374-dac8b804f551,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-0301521b-3fec-4047-9016-4fc8b282caf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470952166-172.17.0.7-1597458936396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-470e2ee1-9591-43e8-90a5-5e7c02d6459a,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-5cd8166b-2a99-4a32-a213-686ee5f52081,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-37b56fa0-4451-4d9e-9fc6-045f54036042,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-e9108f37-b8a8-4c15-a538-4363a0496764,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-2539311e-16b7-453f-8ab3-35a01265910c,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-f329b8bb-343a-4d54-ae0b-4af5cb86be94,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2b7a1c21-c99d-4fd5-b45c-19385300f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-4785ebee-594e-4001-aad0-b8b6b854f927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470952166-172.17.0.7-1597458936396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-470e2ee1-9591-43e8-90a5-5e7c02d6459a,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-5cd8166b-2a99-4a32-a213-686ee5f52081,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-37b56fa0-4451-4d9e-9fc6-045f54036042,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-e9108f37-b8a8-4c15-a538-4363a0496764,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-2539311e-16b7-453f-8ab3-35a01265910c,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-f329b8bb-343a-4d54-ae0b-4af5cb86be94,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2b7a1c21-c99d-4fd5-b45c-19385300f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-4785ebee-594e-4001-aad0-b8b6b854f927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155419486-172.17.0.7-1597458977146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-b7df9455-b8bb-45ae-b97d-f93ebee6830e,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-7e0c8774-3a14-43db-b50e-72797c311e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2d01b072-90fd-42c6-8ced-17350453807b,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-3eb95a8a-01ba-4ad7-b447-ba2d09eb3a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-ca85eac9-5e30-4d33-98e2-7de25427984b,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4c744ca6-56ee-4bfb-9a66-a62f9b739aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-6cc4499f-1b27-46f8-804c-8cdc59ad6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-f6acfd44-e7bb-4f2a-a938-01f7f6c58658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155419486-172.17.0.7-1597458977146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-b7df9455-b8bb-45ae-b97d-f93ebee6830e,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-7e0c8774-3a14-43db-b50e-72797c311e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2d01b072-90fd-42c6-8ced-17350453807b,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-3eb95a8a-01ba-4ad7-b447-ba2d09eb3a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-ca85eac9-5e30-4d33-98e2-7de25427984b,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4c744ca6-56ee-4bfb-9a66-a62f9b739aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-6cc4499f-1b27-46f8-804c-8cdc59ad6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-f6acfd44-e7bb-4f2a-a938-01f7f6c58658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617127983-172.17.0.7-1597459017006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-3eddd590-d75d-402f-9a6a-66e4832b3391,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-eccf78f5-f89e-4908-9602-8b4bb557df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-290eca75-e1f1-47f6-a8b3-211c7574a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-3944f759-5fef-433d-ba6a-3eddec6083b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-d85d94e1-61f8-47be-9eb6-fd4c9f52ecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-ecdb9d0f-fbf7-491b-94d0-741f22683446,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9aba2c13-d6cb-46cb-a1db-2418cbb5a718,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-37304130-8169-49fa-a6ee-f69b0d4be822,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617127983-172.17.0.7-1597459017006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-3eddd590-d75d-402f-9a6a-66e4832b3391,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-eccf78f5-f89e-4908-9602-8b4bb557df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-290eca75-e1f1-47f6-a8b3-211c7574a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-3944f759-5fef-433d-ba6a-3eddec6083b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-d85d94e1-61f8-47be-9eb6-fd4c9f52ecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-ecdb9d0f-fbf7-491b-94d0-741f22683446,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9aba2c13-d6cb-46cb-a1db-2418cbb5a718,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-37304130-8169-49fa-a6ee-f69b0d4be822,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582418828-172.17.0.7-1597459059450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-cd59e69d-5f58-414c-9954-011b3292ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-3ae28c22-1b29-4c84-9092-66a0aaf6e636,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-00e1db51-26a7-42fe-b3c1-e41044a62348,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-258e875b-5df4-45d3-9aab-8fdf452775f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-0e8b86ee-4c4a-4c14-9568-beff3fb52eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-3f76b2e0-fc63-4454-ab5d-1fedb500fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-0fdcc0cb-ef69-4efd-9a41-0448b52c8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6112874d-542d-45f4-88c8-a9ab0bb2a760,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582418828-172.17.0.7-1597459059450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-cd59e69d-5f58-414c-9954-011b3292ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-3ae28c22-1b29-4c84-9092-66a0aaf6e636,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-00e1db51-26a7-42fe-b3c1-e41044a62348,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-258e875b-5df4-45d3-9aab-8fdf452775f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-0e8b86ee-4c4a-4c14-9568-beff3fb52eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-3f76b2e0-fc63-4454-ab5d-1fedb500fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-0fdcc0cb-ef69-4efd-9a41-0448b52c8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6112874d-542d-45f4-88c8-a9ab0bb2a760,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65495864-172.17.0.7-1597459371380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-012ad771-0cf3-4b81-a3d7-0da2fc757555,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-ac6919fc-569f-4ee9-aa87-530363ef9ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-f82b1b71-609f-4444-b568-7522539f7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d38b2183-bd87-4411-8caa-06551942c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-cf99f990-501e-4883-ae90-e46dded28f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0ace0fb0-cb58-4472-9359-848b1b1a8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-88e7c76b-6d43-499e-bda9-a9a96fb23a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-dec7ccac-0fa5-422b-992f-6d0c6eab86fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65495864-172.17.0.7-1597459371380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-012ad771-0cf3-4b81-a3d7-0da2fc757555,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-ac6919fc-569f-4ee9-aa87-530363ef9ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-f82b1b71-609f-4444-b568-7522539f7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d38b2183-bd87-4411-8caa-06551942c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-cf99f990-501e-4883-ae90-e46dded28f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0ace0fb0-cb58-4472-9359-848b1b1a8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-88e7c76b-6d43-499e-bda9-a9a96fb23a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-dec7ccac-0fa5-422b-992f-6d0c6eab86fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790360423-172.17.0.7-1597459491122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39787,DS-cbf2d283-e19a-483d-87b4-9a92530d2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-d9aa2c78-59b2-4e0e-b057-6d5b43d695fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-bec3714d-019a-4247-8ef0-3c1964cb10ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-b8d5dad2-0b87-4123-98d8-0142767b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-6b71eb3e-024c-428f-a084-02e956e57022,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-1890070d-86d1-4e03-98ea-407304f68656,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-bceaf269-9a6a-4283-836b-7c149cce60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-e6bb7e23-8e9b-45fb-b615-449e2ab083c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790360423-172.17.0.7-1597459491122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39787,DS-cbf2d283-e19a-483d-87b4-9a92530d2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-d9aa2c78-59b2-4e0e-b057-6d5b43d695fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-bec3714d-019a-4247-8ef0-3c1964cb10ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-b8d5dad2-0b87-4123-98d8-0142767b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-6b71eb3e-024c-428f-a084-02e956e57022,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-1890070d-86d1-4e03-98ea-407304f68656,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-bceaf269-9a6a-4283-836b-7c149cce60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-e6bb7e23-8e9b-45fb-b615-449e2ab083c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658931287-172.17.0.7-1597459678104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-51802092-8fad-410d-a9cb-50b4ee51cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-af3c90ae-a5b5-4efc-9fcf-18ee380024b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-8911e094-fae6-446a-8b48-92e734e5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-69cce06c-3ea2-4b3e-ab5b-fc0912726cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-3d9f6532-21e6-45c5-b1d7-65d77ef0fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-33dcb1c9-9eb8-43b7-8769-9cdb707367d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-24163e8a-7eb6-4385-9b2a-25651c2659db,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-5b0a78d0-bdd5-47ef-8ed4-c8236f7a3a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658931287-172.17.0.7-1597459678104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-51802092-8fad-410d-a9cb-50b4ee51cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-af3c90ae-a5b5-4efc-9fcf-18ee380024b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-8911e094-fae6-446a-8b48-92e734e5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-69cce06c-3ea2-4b3e-ab5b-fc0912726cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-3d9f6532-21e6-45c5-b1d7-65d77ef0fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-33dcb1c9-9eb8-43b7-8769-9cdb707367d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-24163e8a-7eb6-4385-9b2a-25651c2659db,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-5b0a78d0-bdd5-47ef-8ed4-c8236f7a3a07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845254921-172.17.0.7-1597459750066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-939d7e5f-6176-497e-aa66-e15fcdab2a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9cc5d179-5df0-4a4f-8ff6-170301a663af,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-2e3c3986-cefd-4512-93f6-2076586ca969,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-9bebf46b-be10-4023-8645-ea9bba3de26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-8bc420eb-2afe-4e0e-9fca-e649a615d891,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-3ac28c8a-4cdf-4d82-b633-9da875af0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-642af55a-b428-4163-963c-80bcb98cc93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-f2dea1bd-834d-471a-8439-841f078469f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845254921-172.17.0.7-1597459750066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-939d7e5f-6176-497e-aa66-e15fcdab2a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9cc5d179-5df0-4a4f-8ff6-170301a663af,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-2e3c3986-cefd-4512-93f6-2076586ca969,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-9bebf46b-be10-4023-8645-ea9bba3de26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-8bc420eb-2afe-4e0e-9fca-e649a615d891,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-3ac28c8a-4cdf-4d82-b633-9da875af0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-642af55a-b428-4163-963c-80bcb98cc93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-f2dea1bd-834d-471a-8439-841f078469f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071385669-172.17.0.7-1597460444251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-6126451c-9c3f-4dc4-a72a-3166b15cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-df41be24-af3e-4b24-be90-fb41c3b7c011,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e825f043-085e-400c-98c7-c2bad9f025ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-eaf25473-2e5e-49f5-a2ad-69bc51cd4d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-3422dc61-6071-4ab8-8063-93ea5a2d49a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-864c89aa-4d72-4b81-a6d1-55418ccd49d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-2df456d0-c6d8-4370-865a-c511a8575da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-4839e064-6cb0-4fbe-bf59-3a80a6bd1000,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071385669-172.17.0.7-1597460444251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-6126451c-9c3f-4dc4-a72a-3166b15cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-df41be24-af3e-4b24-be90-fb41c3b7c011,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e825f043-085e-400c-98c7-c2bad9f025ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-eaf25473-2e5e-49f5-a2ad-69bc51cd4d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-3422dc61-6071-4ab8-8063-93ea5a2d49a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-864c89aa-4d72-4b81-a6d1-55418ccd49d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-2df456d0-c6d8-4370-865a-c511a8575da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-4839e064-6cb0-4fbe-bf59-3a80a6bd1000,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634899166-172.17.0.7-1597460749400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-d8b16b74-97eb-4bd7-bd39-778193cadecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-7a5eb833-b59f-4460-93c9-bed992f1fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-b36f6632-be4c-43e8-9498-58f4c70780b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-22013570-df96-49d3-8565-f70360598521,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-03b5432a-489e-4d91-a169-3118a015efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-315abdbd-11ec-48d7-a632-e168e9d4ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d883c104-5ffb-4e9e-956e-1b565047855e,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-d1d20195-69d0-47e3-9cd5-c95b4e5d6f17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634899166-172.17.0.7-1597460749400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-d8b16b74-97eb-4bd7-bd39-778193cadecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-7a5eb833-b59f-4460-93c9-bed992f1fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-b36f6632-be4c-43e8-9498-58f4c70780b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-22013570-df96-49d3-8565-f70360598521,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-03b5432a-489e-4d91-a169-3118a015efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-315abdbd-11ec-48d7-a632-e168e9d4ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d883c104-5ffb-4e9e-956e-1b565047855e,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-d1d20195-69d0-47e3-9cd5-c95b4e5d6f17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257503369-172.17.0.7-1597460854081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-73d6b934-528b-41ab-9452-3317a7629193,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-194711bc-0c50-42c8-a33c-f8726ffff8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-5b818be7-c8f7-41ab-a8fd-c1d54b7666ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-118cc436-b9df-4071-b7ef-bded75a7f583,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-811c9336-4067-4a1f-a684-b1cee328204b,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-5e50dcd9-25cc-4453-b8d8-e9b147071aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d818f166-6ede-4406-b923-c74858eead88,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-dfca6c1a-7579-4e3d-8558-f4ce666d634f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257503369-172.17.0.7-1597460854081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-73d6b934-528b-41ab-9452-3317a7629193,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-194711bc-0c50-42c8-a33c-f8726ffff8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-5b818be7-c8f7-41ab-a8fd-c1d54b7666ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-118cc436-b9df-4071-b7ef-bded75a7f583,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-811c9336-4067-4a1f-a684-b1cee328204b,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-5e50dcd9-25cc-4453-b8d8-e9b147071aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d818f166-6ede-4406-b923-c74858eead88,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-dfca6c1a-7579-4e3d-8558-f4ce666d634f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907332645-172.17.0.7-1597461028668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-3cbc3723-1651-417d-9f77-aec89a163880,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d10c5799-e3a4-4020-8924-0a8f0115d044,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-ce142e2c-f46b-4be0-b88f-25f28d81f380,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b29ab356-a0a3-41e4-a04c-01a92afbf2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-a5b75218-e35a-4b0d-afbb-f9f7eec382a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-070fc3e8-79d6-475a-ad93-af7fbe69c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-34f7fe5d-7fe4-4775-a409-0f6ba6c60d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-c9de53a5-777d-4f79-844a-95f71ccaecd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907332645-172.17.0.7-1597461028668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-3cbc3723-1651-417d-9f77-aec89a163880,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d10c5799-e3a4-4020-8924-0a8f0115d044,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-ce142e2c-f46b-4be0-b88f-25f28d81f380,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b29ab356-a0a3-41e4-a04c-01a92afbf2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-a5b75218-e35a-4b0d-afbb-f9f7eec382a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-070fc3e8-79d6-475a-ad93-af7fbe69c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-34f7fe5d-7fe4-4775-a409-0f6ba6c60d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-c9de53a5-777d-4f79-844a-95f71ccaecd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104796726-172.17.0.7-1597461281199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-5dd271dc-86dc-403b-9d8e-32eac8d41f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-7ab013e9-e86f-4c78-83f7-c8a9f9f5b755,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-a67bf6ca-b7c3-4213-8445-491913abe68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cefd664a-65bc-462c-be2a-145951aefe74,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-065c2bf2-10b6-4210-b262-8a566b59cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-faaeab0c-fb1d-46ac-bc11-757b91209d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-a5e3cf53-eda2-4d7d-8c4e-76b71c6eb08e,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-cdc5b05c-09c8-482d-b474-0b2d24288324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104796726-172.17.0.7-1597461281199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-5dd271dc-86dc-403b-9d8e-32eac8d41f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-7ab013e9-e86f-4c78-83f7-c8a9f9f5b755,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-a67bf6ca-b7c3-4213-8445-491913abe68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cefd664a-65bc-462c-be2a-145951aefe74,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-065c2bf2-10b6-4210-b262-8a566b59cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-faaeab0c-fb1d-46ac-bc11-757b91209d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-a5e3cf53-eda2-4d7d-8c4e-76b71c6eb08e,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-cdc5b05c-09c8-482d-b474-0b2d24288324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724705080-172.17.0.7-1597461361952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-392be2d2-35ca-4a69-8dbb-7d0c667fe0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-3d0fdbdb-5446-452b-8191-765c99fb1ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b88a6fb9-cf14-4157-867b-1225d24df917,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-583a5659-d5b4-4bed-9bb5-654143500447,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-92572c1d-9161-452b-98fa-dd4fa1bfa197,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-9f154925-5c9c-406f-ab00-20ebe1f53116,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-910cf0f9-e766-40b2-8a94-5092e016c624,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-91ae7178-31c0-4459-a4ba-680fd06d0076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724705080-172.17.0.7-1597461361952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-392be2d2-35ca-4a69-8dbb-7d0c667fe0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-3d0fdbdb-5446-452b-8191-765c99fb1ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b88a6fb9-cf14-4157-867b-1225d24df917,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-583a5659-d5b4-4bed-9bb5-654143500447,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-92572c1d-9161-452b-98fa-dd4fa1bfa197,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-9f154925-5c9c-406f-ab00-20ebe1f53116,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-910cf0f9-e766-40b2-8a94-5092e016c624,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-91ae7178-31c0-4459-a4ba-680fd06d0076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036080541-172.17.0.7-1597461549353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-4648167b-ee81-465e-b379-60d80fb69d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a9805ad8-987e-4542-8875-81680ddb6780,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-4965e444-889a-4028-9a81-bda74f7c0f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-d16e1df3-b080-4d2b-bd56-34b2a4c897cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-90b73e94-265f-4305-9bf2-ad2770f6f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5f19de4e-f68b-4910-b206-c073fecfdd85,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-d7d7ea78-ccfc-4b9d-87ab-1041e66c005a,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-b97fe36b-8fa7-4c8b-8a0f-b59c92a29895,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036080541-172.17.0.7-1597461549353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-4648167b-ee81-465e-b379-60d80fb69d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a9805ad8-987e-4542-8875-81680ddb6780,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-4965e444-889a-4028-9a81-bda74f7c0f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-d16e1df3-b080-4d2b-bd56-34b2a4c897cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-90b73e94-265f-4305-9bf2-ad2770f6f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5f19de4e-f68b-4910-b206-c073fecfdd85,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-d7d7ea78-ccfc-4b9d-87ab-1041e66c005a,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-b97fe36b-8fa7-4c8b-8a0f-b59c92a29895,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391695345-172.17.0.7-1597461693712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-cf6e819d-a7d1-4974-8846-df45a1073d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0b170c27-96ab-4721-89d7-d441e8e01a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ac898e50-635e-406f-a45e-6f694c7ca2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-396911aa-2659-494b-830f-16655ab6126d,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-61358f8d-fd2d-41b7-baee-ede12f1877f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-da94e1b8-71de-4c90-a08f-12849028e253,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8b87cd15-7ff4-4151-aef9-019b03c81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-f1d7e3ec-2f7d-4df7-a14b-96ea2dbbc430,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391695345-172.17.0.7-1597461693712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-cf6e819d-a7d1-4974-8846-df45a1073d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0b170c27-96ab-4721-89d7-d441e8e01a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ac898e50-635e-406f-a45e-6f694c7ca2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-396911aa-2659-494b-830f-16655ab6126d,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-61358f8d-fd2d-41b7-baee-ede12f1877f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-da94e1b8-71de-4c90-a08f-12849028e253,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8b87cd15-7ff4-4151-aef9-019b03c81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-f1d7e3ec-2f7d-4df7-a14b-96ea2dbbc430,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150485779-172.17.0.7-1597461881137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-27f3cf36-a0e5-48f1-9457-f8be6555664c,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-be80e9b1-3d9b-4532-a2dd-5ea9799e1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-74171e8f-e665-4447-aa3d-8945cef8196f,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-e7c60d38-22b3-4e9e-9dea-24581182316f,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-23e945ae-3f46-4a95-94aa-0aabc2bfaa14,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-106cc767-52f5-42a4-a343-c52bf064bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-e89eb214-7ac8-45d3-8e2b-464533544d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-354fa04c-cda8-4a8e-bd82-469a837967df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150485779-172.17.0.7-1597461881137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-27f3cf36-a0e5-48f1-9457-f8be6555664c,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-be80e9b1-3d9b-4532-a2dd-5ea9799e1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-74171e8f-e665-4447-aa3d-8945cef8196f,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-e7c60d38-22b3-4e9e-9dea-24581182316f,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-23e945ae-3f46-4a95-94aa-0aabc2bfaa14,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-106cc767-52f5-42a4-a343-c52bf064bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-e89eb214-7ac8-45d3-8e2b-464533544d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-354fa04c-cda8-4a8e-bd82-469a837967df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152687892-172.17.0.7-1597462159797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-2f24993d-e20d-4f17-874f-2781e84254ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-a6750714-1187-429a-acb9-8199cea6288d,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-1ce3c774-ffd7-45d5-94ca-a3444095213b,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-bb07e4c6-dbb1-4e90-a5fa-b2771f8259a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-2d722889-a2bf-41b1-92ca-b97602e67c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-753ba229-aa04-42e0-a580-c6b4b6fab5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ca4dcc48-8d2d-4fad-aa91-c738741132cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-79b7689c-3c8a-4fee-ab3b-a99fcbaf2176,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152687892-172.17.0.7-1597462159797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-2f24993d-e20d-4f17-874f-2781e84254ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-a6750714-1187-429a-acb9-8199cea6288d,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-1ce3c774-ffd7-45d5-94ca-a3444095213b,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-bb07e4c6-dbb1-4e90-a5fa-b2771f8259a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-2d722889-a2bf-41b1-92ca-b97602e67c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-753ba229-aa04-42e0-a580-c6b4b6fab5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ca4dcc48-8d2d-4fad-aa91-c738741132cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-79b7689c-3c8a-4fee-ab3b-a99fcbaf2176,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298377603-172.17.0.7-1597462457420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-a69bd9fc-dbcf-4d37-9812-4e241c8f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-8b5a3f4c-b297-417c-beba-8b6a6ba61109,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fd6a61eb-5cc9-4ffc-87ed-741ea8dc6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-34ad7d07-4e4c-4b69-920d-7524ea0b04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-3734f8e1-54d5-4292-bb9c-0b25f3f96e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-22896ada-d5dc-4461-aee8-a64f1ca22366,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-6ef6436c-eca1-4f17-9190-e90b97451b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-13e68b78-eaaf-4d49-856f-ad997039ad36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298377603-172.17.0.7-1597462457420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-a69bd9fc-dbcf-4d37-9812-4e241c8f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-8b5a3f4c-b297-417c-beba-8b6a6ba61109,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fd6a61eb-5cc9-4ffc-87ed-741ea8dc6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-34ad7d07-4e4c-4b69-920d-7524ea0b04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-3734f8e1-54d5-4292-bb9c-0b25f3f96e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-22896ada-d5dc-4461-aee8-a64f1ca22366,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-6ef6436c-eca1-4f17-9190-e90b97451b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-13e68b78-eaaf-4d49-856f-ad997039ad36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079452895-172.17.0.7-1597462496363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-7bf2fd93-752c-405f-b4f1-31f1800d8ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-701e85cf-4f4c-41b9-92f8-8160df989dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-43709b60-b988-4f6a-a9da-1a5ef16237e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-445a8aad-070c-4c54-a847-d9e6e9dc5ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-21d1a13d-0d45-43c0-92db-7d3efee2f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-f136006b-65b7-48e8-97d6-ec987828bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-2e74be8f-b1ef-48e8-ad56-4a0ea4fbdd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c5d18b58-c07e-45d9-8b25-86394859b347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079452895-172.17.0.7-1597462496363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-7bf2fd93-752c-405f-b4f1-31f1800d8ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-701e85cf-4f4c-41b9-92f8-8160df989dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-43709b60-b988-4f6a-a9da-1a5ef16237e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-445a8aad-070c-4c54-a847-d9e6e9dc5ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-21d1a13d-0d45-43c0-92db-7d3efee2f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-f136006b-65b7-48e8-97d6-ec987828bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-2e74be8f-b1ef-48e8-ad56-4a0ea4fbdd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c5d18b58-c07e-45d9-8b25-86394859b347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493338118-172.17.0.7-1597462626243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39242,DS-549f1e1d-9de7-4cbf-8269-d0ddf3c1aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-40ec58a5-4a22-4562-a2e0-886e1b7bc899,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-2c0475ef-f8ad-4bd4-8749-4b500eb9a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-483de794-bec3-432e-9393-3c72a30fb047,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-75a1ceef-5539-4b6a-b08f-e8e40cacf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-688dea61-a794-4a28-b94b-39c7c180e144,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-76b97aad-8540-4c7c-aa6e-b37d4738cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-8e00fe01-eb69-4ffb-8d1e-a25c06b9821e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493338118-172.17.0.7-1597462626243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39242,DS-549f1e1d-9de7-4cbf-8269-d0ddf3c1aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-40ec58a5-4a22-4562-a2e0-886e1b7bc899,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-2c0475ef-f8ad-4bd4-8749-4b500eb9a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-483de794-bec3-432e-9393-3c72a30fb047,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-75a1ceef-5539-4b6a-b08f-e8e40cacf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-688dea61-a794-4a28-b94b-39c7c180e144,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-76b97aad-8540-4c7c-aa6e-b37d4738cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-8e00fe01-eb69-4ffb-8d1e-a25c06b9821e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723098619-172.17.0.7-1597462667824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-0b66a9e5-d67c-4495-93a9-6872f098b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-76693e82-94e8-46b7-8137-cf8144d5ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-dab7902b-ac56-44cf-9480-b8f730b8856c,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-2e9f9f06-2b9f-4603-9e04-8b20e9bacbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-500c4b51-363c-400c-9f2c-8c6007694750,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-89f64c76-c20f-44b9-88e6-2a9ca3612c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-df33df82-dffb-4cf1-952e-57c8b5c1d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-0608c7a3-15c6-4834-8713-bd2e9f118010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723098619-172.17.0.7-1597462667824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-0b66a9e5-d67c-4495-93a9-6872f098b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-76693e82-94e8-46b7-8137-cf8144d5ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-dab7902b-ac56-44cf-9480-b8f730b8856c,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-2e9f9f06-2b9f-4603-9e04-8b20e9bacbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-500c4b51-363c-400c-9f2c-8c6007694750,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-89f64c76-c20f-44b9-88e6-2a9ca3612c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-df33df82-dffb-4cf1-952e-57c8b5c1d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-0608c7a3-15c6-4834-8713-bd2e9f118010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525663951-172.17.0.7-1597462814447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-13420055-234e-4e72-af77-7e7423863b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-170c44ec-e86a-4b88-9a07-16d1e4510cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-83744979-06da-440c-ba08-a4738ca4af7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-7af790c2-b7b6-4261-bf3f-e58cd0950119,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-28baaf1a-9ff8-4240-8845-0b9f78a31c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-2d6360d4-4660-4e4f-b94b-f68e438e9950,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-c5179a79-d1b0-4a85-8a8e-c97c591033eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-1078e811-2c88-4566-9c37-edf5df899a3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525663951-172.17.0.7-1597462814447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-13420055-234e-4e72-af77-7e7423863b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-170c44ec-e86a-4b88-9a07-16d1e4510cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-83744979-06da-440c-ba08-a4738ca4af7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-7af790c2-b7b6-4261-bf3f-e58cd0950119,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-28baaf1a-9ff8-4240-8845-0b9f78a31c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-2d6360d4-4660-4e4f-b94b-f68e438e9950,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-c5179a79-d1b0-4a85-8a8e-c97c591033eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-1078e811-2c88-4566-9c37-edf5df899a3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356897251-172.17.0.7-1597462856206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-6e4ed5e5-bf43-46f8-8414-e05ea9e53c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-c192ac32-8a20-4c0e-8a97-0da91400b6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-b7005768-1aad-4d98-913e-4bdb4bddf8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-004b5797-c8e6-4e13-a1e0-9129b173dd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-c1da4b81-0145-4d2a-b19e-7ab20ac57eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-a73e7517-c162-4cd2-8ff1-44b391769daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-b722ee65-1ae2-4e70-bd68-280b8312b113,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-78b486a8-5c41-491b-924f-e12891a11b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356897251-172.17.0.7-1597462856206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-6e4ed5e5-bf43-46f8-8414-e05ea9e53c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-c192ac32-8a20-4c0e-8a97-0da91400b6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-b7005768-1aad-4d98-913e-4bdb4bddf8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-004b5797-c8e6-4e13-a1e0-9129b173dd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-c1da4b81-0145-4d2a-b19e-7ab20ac57eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-a73e7517-c162-4cd2-8ff1-44b391769daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-b722ee65-1ae2-4e70-bd68-280b8312b113,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-78b486a8-5c41-491b-924f-e12891a11b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295239516-172.17.0.7-1597462886412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-ca1dce28-6452-488e-9cea-71614c8f752a,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-a1db5dd5-b340-47bd-9da0-e99afce4a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-e560110c-615b-464a-adbe-03ad437e4858,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-b29c5da3-45f0-42ca-9e91-2053bb29dcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-dd71b782-f631-4709-a512-e042fd7f8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-5e233f2b-d643-4c18-a8f3-88420d64ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ee904a8d-bcac-4d1c-a037-4bed6c0a5b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-05420351-2989-4335-a257-71f3d76f3970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295239516-172.17.0.7-1597462886412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-ca1dce28-6452-488e-9cea-71614c8f752a,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-a1db5dd5-b340-47bd-9da0-e99afce4a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-e560110c-615b-464a-adbe-03ad437e4858,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-b29c5da3-45f0-42ca-9e91-2053bb29dcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-dd71b782-f631-4709-a512-e042fd7f8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-5e233f2b-d643-4c18-a8f3-88420d64ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ee904a8d-bcac-4d1c-a037-4bed6c0a5b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-05420351-2989-4335-a257-71f3d76f3970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5726
