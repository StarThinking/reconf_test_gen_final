reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025954390-172.17.0.6-1597518850008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-b4d1f455-53e0-4d6d-bca0-7f3f1b1c67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-cddcdf56-09b5-474d-bc57-24d1625f040b,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-97a10507-328a-49e7-b1f1-82c7a9cbb7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-c12e71ad-f18f-4134-8af5-351c37c47368,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-14b0a8c9-0cc4-4af3-8e55-3d0833c7f352,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-c4305a91-5cb1-488e-a42c-0f22ac730783,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-4248bb21-a311-41c4-a988-a9b8df282d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-1f67de01-080b-4f12-97d0-2ab647e14869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025954390-172.17.0.6-1597518850008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-b4d1f455-53e0-4d6d-bca0-7f3f1b1c67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-cddcdf56-09b5-474d-bc57-24d1625f040b,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-97a10507-328a-49e7-b1f1-82c7a9cbb7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-c12e71ad-f18f-4134-8af5-351c37c47368,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-14b0a8c9-0cc4-4af3-8e55-3d0833c7f352,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-c4305a91-5cb1-488e-a42c-0f22ac730783,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-4248bb21-a311-41c4-a988-a9b8df282d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-1f67de01-080b-4f12-97d0-2ab647e14869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814101567-172.17.0.6-1597518960813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-0987bfec-db8e-4d24-8989-e975b6eb0852,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-922ac10f-60d5-49d0-8cb0-77c41e943bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-983e80f6-c7ec-4eb6-b3c4-a018bfc46ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-64caa268-f93e-474f-bfd3-bf6db1b4083a,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-2415e749-d6e5-440c-b385-3ecc53f5f641,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-7514e5bb-b59e-4b46-8b23-c56db8de6dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-17d714b9-d740-49cf-81c1-271cafb9517d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a2981df8-f3d3-4edc-83c4-ed040dd026a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814101567-172.17.0.6-1597518960813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-0987bfec-db8e-4d24-8989-e975b6eb0852,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-922ac10f-60d5-49d0-8cb0-77c41e943bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-983e80f6-c7ec-4eb6-b3c4-a018bfc46ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-64caa268-f93e-474f-bfd3-bf6db1b4083a,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-2415e749-d6e5-440c-b385-3ecc53f5f641,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-7514e5bb-b59e-4b46-8b23-c56db8de6dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-17d714b9-d740-49cf-81c1-271cafb9517d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a2981df8-f3d3-4edc-83c4-ed040dd026a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80513450-172.17.0.6-1597519169715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-be55888c-0dae-407b-ae15-788c52ca4286,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-76ce31b9-7148-499e-9089-b133b6b13914,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-c699a7d9-1c75-4f59-ae2b-9b914ca3a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-83c4a94f-5a45-4424-aaea-f6123c324b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-854af154-766e-4e2a-b4f8-b7fb8e831d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-3dbd446c-eaf9-4273-8596-2499ba6e8c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-bbc19136-b325-40f3-8207-a45e55bf92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-dd624c0f-52be-4027-ab3b-7306153b4fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80513450-172.17.0.6-1597519169715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-be55888c-0dae-407b-ae15-788c52ca4286,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-76ce31b9-7148-499e-9089-b133b6b13914,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-c699a7d9-1c75-4f59-ae2b-9b914ca3a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-83c4a94f-5a45-4424-aaea-f6123c324b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-854af154-766e-4e2a-b4f8-b7fb8e831d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-3dbd446c-eaf9-4273-8596-2499ba6e8c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-bbc19136-b325-40f3-8207-a45e55bf92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-dd624c0f-52be-4027-ab3b-7306153b4fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435440546-172.17.0.6-1597519288460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-79fbd5e9-ba27-49b1-8fbb-4a5597050527,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-5721c49b-428d-44df-b223-38cb3d0752b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-63b57515-d718-4a22-8f9d-136eb6b69816,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d210432e-eec4-4a94-93c4-12bcf97ba6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-429249fb-035b-4011-985f-67833ffb739d,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-ff659956-b0e9-4364-8966-7d0daa7ff36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-cf1040f3-3e52-4b4e-8d9f-49246d1dcaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-aaff1392-7e8c-47b7-b2c4-1ff246d11a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435440546-172.17.0.6-1597519288460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-79fbd5e9-ba27-49b1-8fbb-4a5597050527,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-5721c49b-428d-44df-b223-38cb3d0752b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-63b57515-d718-4a22-8f9d-136eb6b69816,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d210432e-eec4-4a94-93c4-12bcf97ba6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-429249fb-035b-4011-985f-67833ffb739d,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-ff659956-b0e9-4364-8966-7d0daa7ff36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-cf1040f3-3e52-4b4e-8d9f-49246d1dcaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-aaff1392-7e8c-47b7-b2c4-1ff246d11a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378259302-172.17.0.6-1597520590829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-c36bd121-ab3a-4628-9099-be166ba40c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d8dd9bfc-6eb1-42cd-a4d0-d01ff89b8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-766f9add-5b56-4077-bbd6-f5a1e2c441a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-f0495735-e392-4f86-8d6c-758d04028485,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5a21be29-85b4-4ca8-a973-6ae183743df4,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-c94d4017-e7ba-4bf1-8c37-9e7355341df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-0305818d-963b-42c5-8619-c1d1b30b6694,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-2e7576db-8472-47c9-8dda-327ec886b7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378259302-172.17.0.6-1597520590829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-c36bd121-ab3a-4628-9099-be166ba40c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d8dd9bfc-6eb1-42cd-a4d0-d01ff89b8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-766f9add-5b56-4077-bbd6-f5a1e2c441a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-f0495735-e392-4f86-8d6c-758d04028485,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5a21be29-85b4-4ca8-a973-6ae183743df4,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-c94d4017-e7ba-4bf1-8c37-9e7355341df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-0305818d-963b-42c5-8619-c1d1b30b6694,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-2e7576db-8472-47c9-8dda-327ec886b7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376293543-172.17.0.6-1597521066131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-e1171e19-a54d-4fb1-9954-4594ff607293,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-edd9da28-9ff1-4254-b4cb-23945140c779,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-760c0614-e8c3-4261-baf3-da657888fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-e4cf944f-9ee7-4529-a0f6-4ab658c1d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-5fbb15a8-9f87-4e3f-8164-2ebd6421a519,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-36c4db5b-3886-4794-b4a2-63d4191f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-7cda9b71-211b-41b4-831a-5531dd87807b,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-69660d47-5d63-4a4a-92e7-cfe1ce27d69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376293543-172.17.0.6-1597521066131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-e1171e19-a54d-4fb1-9954-4594ff607293,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-edd9da28-9ff1-4254-b4cb-23945140c779,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-760c0614-e8c3-4261-baf3-da657888fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-e4cf944f-9ee7-4529-a0f6-4ab658c1d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-5fbb15a8-9f87-4e3f-8164-2ebd6421a519,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-36c4db5b-3886-4794-b4a2-63d4191f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-7cda9b71-211b-41b4-831a-5531dd87807b,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-69660d47-5d63-4a4a-92e7-cfe1ce27d69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508307860-172.17.0.6-1597521473496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-e137a32e-0b72-4c92-806e-49a0b23d93e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-76c66338-09cb-4eb2-a8f3-6d920c516f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-461ecc70-234e-46e0-bfa0-5c2bfd2b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-6a70b22c-9d47-42a1-8035-56c2fe3424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-41fab244-c598-4346-9ada-e22dc2b4ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-14116c53-c27f-4753-9863-ced7097461d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9245bbfa-2db7-4ada-ae88-3b312c7fb64d,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-27a0c486-4b74-4162-b755-7b65a5e05284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508307860-172.17.0.6-1597521473496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-e137a32e-0b72-4c92-806e-49a0b23d93e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-76c66338-09cb-4eb2-a8f3-6d920c516f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-461ecc70-234e-46e0-bfa0-5c2bfd2b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-6a70b22c-9d47-42a1-8035-56c2fe3424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-41fab244-c598-4346-9ada-e22dc2b4ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-14116c53-c27f-4753-9863-ced7097461d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-9245bbfa-2db7-4ada-ae88-3b312c7fb64d,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-27a0c486-4b74-4162-b755-7b65a5e05284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72232862-172.17.0.6-1597522145333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41286,DS-fa6deef0-5f91-4b9d-b012-17712a7d1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-aa48cc6c-35b4-4bfb-af3e-7d56009454c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-167ceaa0-51be-4bd9-a9e9-a41e41235e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-80d769fc-00fb-4f6e-8f6e-8935448db371,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-0a491a86-46dc-4093-9967-21c0a3d96f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-46c5dcc4-beed-47a8-90ad-fc69dda3c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-94db8481-a257-4002-991a-24abf06b0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-c03ffcfa-fee8-4f20-afc0-0d18edadb19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72232862-172.17.0.6-1597522145333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41286,DS-fa6deef0-5f91-4b9d-b012-17712a7d1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-aa48cc6c-35b4-4bfb-af3e-7d56009454c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-167ceaa0-51be-4bd9-a9e9-a41e41235e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-80d769fc-00fb-4f6e-8f6e-8935448db371,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-0a491a86-46dc-4093-9967-21c0a3d96f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-46c5dcc4-beed-47a8-90ad-fc69dda3c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-94db8481-a257-4002-991a-24abf06b0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-c03ffcfa-fee8-4f20-afc0-0d18edadb19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925673241-172.17.0.6-1597522227971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-97335f97-87a5-46b5-91b2-1eb64c793678,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-eae350f9-2c5f-4699-8557-1578de2c3806,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8ba6b951-3287-4b58-8ea7-a7bc772b5550,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-749e078e-f0b0-455b-b0c9-e777ceea19b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-028ceebc-7c37-4503-b270-1b6ff11417b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-81ebc956-f180-4894-a3b9-e596b781bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-232a31b5-15f4-4337-9268-97db97471d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-284d5fca-f73b-4249-834c-709e72b12c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925673241-172.17.0.6-1597522227971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-97335f97-87a5-46b5-91b2-1eb64c793678,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-eae350f9-2c5f-4699-8557-1578de2c3806,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8ba6b951-3287-4b58-8ea7-a7bc772b5550,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-749e078e-f0b0-455b-b0c9-e777ceea19b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-028ceebc-7c37-4503-b270-1b6ff11417b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-81ebc956-f180-4894-a3b9-e596b781bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-232a31b5-15f4-4337-9268-97db97471d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-284d5fca-f73b-4249-834c-709e72b12c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007387156-172.17.0.6-1597523716822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-dbe3f2e5-10c6-4de9-b50b-48e964071d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-1b4f52d3-d6dc-423e-bdec-5a8c66a24545,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-c0bc969e-3ebe-406c-9dbd-cf1253fa92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-8c391f8f-78dd-4a99-8c40-3acfe9694ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-68685c56-7951-45af-9a5b-eed987f89acd,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-84d87bd3-50e1-4196-b70c-63fbde15d80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-a9183ce8-9146-4bb6-82fe-5881fd8acc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-f1271e13-77d3-4c92-ada2-d0b522f07d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007387156-172.17.0.6-1597523716822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-dbe3f2e5-10c6-4de9-b50b-48e964071d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-1b4f52d3-d6dc-423e-bdec-5a8c66a24545,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-c0bc969e-3ebe-406c-9dbd-cf1253fa92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-8c391f8f-78dd-4a99-8c40-3acfe9694ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-68685c56-7951-45af-9a5b-eed987f89acd,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-84d87bd3-50e1-4196-b70c-63fbde15d80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-a9183ce8-9146-4bb6-82fe-5881fd8acc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-f1271e13-77d3-4c92-ada2-d0b522f07d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709331261-172.17.0.6-1597523837571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-25e710f3-5706-40b0-824b-d660aa3adec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-2395105a-59b3-4183-8ff2-1e4151f25c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-fbb01133-24c1-4088-a06f-af57d8417980,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-e3f3acf6-cfdf-46ff-b310-5bbb4b243a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-fd08b2c7-3c77-4ade-a850-c9025bed4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-67696e62-bf07-45e7-a966-f5122ac3781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a3076aef-4be0-44aa-a6bd-e69f550cd366,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-0b516310-c51e-4f56-88d0-46487b1e6221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709331261-172.17.0.6-1597523837571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-25e710f3-5706-40b0-824b-d660aa3adec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-2395105a-59b3-4183-8ff2-1e4151f25c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-fbb01133-24c1-4088-a06f-af57d8417980,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-e3f3acf6-cfdf-46ff-b310-5bbb4b243a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-fd08b2c7-3c77-4ade-a850-c9025bed4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-67696e62-bf07-45e7-a966-f5122ac3781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a3076aef-4be0-44aa-a6bd-e69f550cd366,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-0b516310-c51e-4f56-88d0-46487b1e6221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700925482-172.17.0.6-1597524135056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40347,DS-ed525466-1baa-4fd7-8c2a-61d95230988b,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-44507e19-08a5-4f92-b750-12b83c64649b,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-70fc578b-08ec-4b75-bf4a-7e63a78bb1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-462a1f10-da35-43c0-80b8-2aca5553dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-39ba423f-61e5-47c3-be06-9e7763291f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a7076908-7a35-42b2-a129-6647379b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-73fbe4ea-da42-46fd-9de0-c23ded424db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-fc68ba4e-cd06-4f50-8d33-2b81507bfe2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700925482-172.17.0.6-1597524135056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40347,DS-ed525466-1baa-4fd7-8c2a-61d95230988b,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-44507e19-08a5-4f92-b750-12b83c64649b,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-70fc578b-08ec-4b75-bf4a-7e63a78bb1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-462a1f10-da35-43c0-80b8-2aca5553dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-39ba423f-61e5-47c3-be06-9e7763291f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a7076908-7a35-42b2-a129-6647379b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-73fbe4ea-da42-46fd-9de0-c23ded424db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-fc68ba4e-cd06-4f50-8d33-2b81507bfe2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5592
