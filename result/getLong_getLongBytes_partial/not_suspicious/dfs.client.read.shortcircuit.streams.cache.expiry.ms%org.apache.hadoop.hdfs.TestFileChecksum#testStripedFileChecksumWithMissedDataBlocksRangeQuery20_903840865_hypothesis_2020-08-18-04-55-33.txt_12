reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597016075-172.17.0.9-1597728213968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-1f8bc010-836a-40c9-821f-0fcab0085e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-12def1f1-f611-4a31-ac1a-82787c1b6462,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-e92c27d8-45bf-42b9-b8e0-1b7415b96924,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-f4c1f73d-ed8f-435c-9559-1680623cd9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-20c7dafa-5f28-41f0-bee8-1232d6520916,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-80d6c0e8-9ee6-43b5-a999-7fc4a42c93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-673e8191-4b4f-40c7-b295-3cec73fffe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-c8e5bf72-6ae2-4690-8bbd-1243f4fae298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597016075-172.17.0.9-1597728213968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-1f8bc010-836a-40c9-821f-0fcab0085e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-12def1f1-f611-4a31-ac1a-82787c1b6462,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-e92c27d8-45bf-42b9-b8e0-1b7415b96924,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-f4c1f73d-ed8f-435c-9559-1680623cd9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-20c7dafa-5f28-41f0-bee8-1232d6520916,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-80d6c0e8-9ee6-43b5-a999-7fc4a42c93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-673e8191-4b4f-40c7-b295-3cec73fffe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-c8e5bf72-6ae2-4690-8bbd-1243f4fae298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441527886-172.17.0.9-1597728584512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-8b6529c4-10c5-4ecc-a84f-a63d21a8ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-503f8584-2bc8-4668-bcfa-efbf90d7be37,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-4878ea9d-0bf3-4429-926e-7e02d7242d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-fcc6fb03-08b0-47ef-897d-b3caeeb625c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-8e5a5413-fc8c-46b5-b2c7-f20d1a998a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-050d9675-df88-42c4-8d48-062b502e23ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b3fe8772-1be4-4cfc-8520-961836e34be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-c00df1ce-6e9b-4ff0-9ca7-e42ed608f0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441527886-172.17.0.9-1597728584512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-8b6529c4-10c5-4ecc-a84f-a63d21a8ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-503f8584-2bc8-4668-bcfa-efbf90d7be37,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-4878ea9d-0bf3-4429-926e-7e02d7242d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-fcc6fb03-08b0-47ef-897d-b3caeeb625c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-8e5a5413-fc8c-46b5-b2c7-f20d1a998a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-050d9675-df88-42c4-8d48-062b502e23ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b3fe8772-1be4-4cfc-8520-961836e34be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-c00df1ce-6e9b-4ff0-9ca7-e42ed608f0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733765796-172.17.0.9-1597728650555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-731911cb-c177-423f-afa1-145a9adcd508,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-6f1bf84d-3de4-444a-ab64-8bbd3f527c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-758dd402-a62e-4492-9b88-d2c09b3826b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-cc5c6a52-3110-44aa-9ed8-69e6065740d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-325e3cfc-4872-4852-8d53-d5feb7cd57a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-da4507af-25db-45c1-9e88-4ebb3f3ed522,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-d654d734-c46c-42a8-9b5c-cee91dfffa85,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f192e53a-fc4a-4617-8e22-c5baaff43ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733765796-172.17.0.9-1597728650555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-731911cb-c177-423f-afa1-145a9adcd508,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-6f1bf84d-3de4-444a-ab64-8bbd3f527c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-758dd402-a62e-4492-9b88-d2c09b3826b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-cc5c6a52-3110-44aa-9ed8-69e6065740d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-325e3cfc-4872-4852-8d53-d5feb7cd57a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-da4507af-25db-45c1-9e88-4ebb3f3ed522,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-d654d734-c46c-42a8-9b5c-cee91dfffa85,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f192e53a-fc4a-4617-8e22-c5baaff43ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114798768-172.17.0.9-1597728759885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-2c846189-b513-484b-ab44-4e2ecbcb25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-989003e4-5c36-4d1c-a391-cd34bbea0278,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-354fd37f-a9b6-41cd-aee2-9b8fc6d7aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-53dac251-dc3c-4557-99c9-4de54309a495,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-2aa37678-b876-498e-9ce4-294cb5d60d04,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-2a9a98d7-82da-4035-a8e5-23a8750ff047,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-55a3989a-7acd-4c1c-92d9-0bd98cdf3711,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-84aff60a-cac8-4f91-9731-ceb84e2dcf1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114798768-172.17.0.9-1597728759885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-2c846189-b513-484b-ab44-4e2ecbcb25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-989003e4-5c36-4d1c-a391-cd34bbea0278,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-354fd37f-a9b6-41cd-aee2-9b8fc6d7aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-53dac251-dc3c-4557-99c9-4de54309a495,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-2aa37678-b876-498e-9ce4-294cb5d60d04,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-2a9a98d7-82da-4035-a8e5-23a8750ff047,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-55a3989a-7acd-4c1c-92d9-0bd98cdf3711,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-84aff60a-cac8-4f91-9731-ceb84e2dcf1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930719229-172.17.0.9-1597728792831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-f6faa3b9-e02a-4311-b1ae-a407183b9c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-7d11ebb3-b9eb-4082-83f8-b7ffb1e2efed,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-5f869254-9791-4c54-b712-9a8ff62f5bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-29e1a1c7-58b2-4334-b717-c886ea767ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-e0d50a02-ba80-4289-9d63-ad9ab50e1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-f60bdefe-f809-4522-9456-e2f73072c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-89646f82-7027-4237-9ca2-383145da0782,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-6776aa27-2625-4eb5-85ac-c0968f2e3ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930719229-172.17.0.9-1597728792831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-f6faa3b9-e02a-4311-b1ae-a407183b9c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-7d11ebb3-b9eb-4082-83f8-b7ffb1e2efed,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-5f869254-9791-4c54-b712-9a8ff62f5bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-29e1a1c7-58b2-4334-b717-c886ea767ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-e0d50a02-ba80-4289-9d63-ad9ab50e1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-f60bdefe-f809-4522-9456-e2f73072c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-89646f82-7027-4237-9ca2-383145da0782,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-6776aa27-2625-4eb5-85ac-c0968f2e3ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307428273-172.17.0.9-1597729223931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-094beab3-b886-4c2c-ab76-c0bce0ee8c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-46615cd7-75da-4e58-a71d-d5db3078013b,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-1df3c67a-8dd6-406f-beb9-d8d549da4079,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-01ef6a55-ba65-4383-b49b-e30896b4e277,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-f34dc26e-bfb2-4fbd-a0d5-5f25ad07a437,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f7e8f56a-f299-49f2-9741-fcaaad631bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-d74cc866-664f-47d9-9140-cbe2a39c8019,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-611d5336-1691-43c8-890f-0e7bc90caa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307428273-172.17.0.9-1597729223931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-094beab3-b886-4c2c-ab76-c0bce0ee8c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-46615cd7-75da-4e58-a71d-d5db3078013b,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-1df3c67a-8dd6-406f-beb9-d8d549da4079,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-01ef6a55-ba65-4383-b49b-e30896b4e277,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-f34dc26e-bfb2-4fbd-a0d5-5f25ad07a437,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f7e8f56a-f299-49f2-9741-fcaaad631bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-d74cc866-664f-47d9-9140-cbe2a39c8019,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-611d5336-1691-43c8-890f-0e7bc90caa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587586602-172.17.0.9-1597729711784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-2a8233f8-8deb-4d4a-9bad-250a60edde04,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-aec5c6f2-c307-487c-ae6f-bf427b5d04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-6c3ac2e5-89f8-4bb1-9f4e-9611b3073527,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5d03ba7f-aab5-4653-a3aa-7c9c15401695,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-148c286f-bd37-4a9f-85e2-15a3a189dd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ced6cc61-0f24-4ff7-80f3-5aec36b1e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-5171ee1f-625a-4ab3-a73d-3e602588f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-27e97e44-f2ea-4c82-8e23-845a65bcea20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587586602-172.17.0.9-1597729711784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-2a8233f8-8deb-4d4a-9bad-250a60edde04,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-aec5c6f2-c307-487c-ae6f-bf427b5d04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-6c3ac2e5-89f8-4bb1-9f4e-9611b3073527,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5d03ba7f-aab5-4653-a3aa-7c9c15401695,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-148c286f-bd37-4a9f-85e2-15a3a189dd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ced6cc61-0f24-4ff7-80f3-5aec36b1e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-5171ee1f-625a-4ab3-a73d-3e602588f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-27e97e44-f2ea-4c82-8e23-845a65bcea20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682733448-172.17.0.9-1597729831515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-64a411c1-87dd-4896-b50e-45e7e6d5736d,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-2a790241-77c0-4dad-b6ee-f8dee3acce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-00c791af-f71f-4e5d-9166-ccf62291f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-b5307281-7fdc-4d25-a846-ea1484df295c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-11513fec-a39b-4dfc-a92c-82790e76079c,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1adc6f06-ab81-4052-a378-d16deba263a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-01a6562f-a1ef-4dd8-be1c-8bae55489053,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ccf78280-becb-4fde-bcc5-d690ed9ff166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682733448-172.17.0.9-1597729831515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-64a411c1-87dd-4896-b50e-45e7e6d5736d,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-2a790241-77c0-4dad-b6ee-f8dee3acce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-00c791af-f71f-4e5d-9166-ccf62291f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-b5307281-7fdc-4d25-a846-ea1484df295c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-11513fec-a39b-4dfc-a92c-82790e76079c,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1adc6f06-ab81-4052-a378-d16deba263a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-01a6562f-a1ef-4dd8-be1c-8bae55489053,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ccf78280-becb-4fde-bcc5-d690ed9ff166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42456385-172.17.0.9-1597731106846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-b6bc2f7e-f694-4618-8814-f229a1eeae40,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-c25a3a76-79b6-4277-8c8f-038369370ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-e17080f0-aa90-44df-8040-aa4ec95d0526,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-6093606d-350b-4251-bd43-512bfcfe9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-39fb9fd4-519b-41e0-b3c1-1b7effd83aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-0001aa50-e574-4a89-abe8-b8eee07e1265,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-5a1da31b-ee37-4140-9e13-14ea3c9fd9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-7f6667d6-0da1-43e2-8b07-d63c03fe4c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42456385-172.17.0.9-1597731106846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-b6bc2f7e-f694-4618-8814-f229a1eeae40,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-c25a3a76-79b6-4277-8c8f-038369370ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-e17080f0-aa90-44df-8040-aa4ec95d0526,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-6093606d-350b-4251-bd43-512bfcfe9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-39fb9fd4-519b-41e0-b3c1-1b7effd83aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-0001aa50-e574-4a89-abe8-b8eee07e1265,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-5a1da31b-ee37-4140-9e13-14ea3c9fd9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-7f6667d6-0da1-43e2-8b07-d63c03fe4c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985161665-172.17.0.9-1597731263337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-f0c26f2b-8bb8-4f87-98af-29fe2f7da117,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-12cf4edd-9648-42d5-af27-ddba41164f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-2af8d0c7-aebf-4907-a4f4-31e82cbaaecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-fd96f45c-59ba-4dde-851a-38ffce026466,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-796cbf50-2f41-43c8-a6d7-5a21136c1bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-4817ee61-ad7d-4549-9a07-f601c4b8f721,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-0bd8b632-6361-4c69-9bb1-b557b0ea1d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-c7ffe494-f436-466e-8328-6cfee0fa0282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985161665-172.17.0.9-1597731263337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-f0c26f2b-8bb8-4f87-98af-29fe2f7da117,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-12cf4edd-9648-42d5-af27-ddba41164f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-2af8d0c7-aebf-4907-a4f4-31e82cbaaecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-fd96f45c-59ba-4dde-851a-38ffce026466,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-796cbf50-2f41-43c8-a6d7-5a21136c1bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-4817ee61-ad7d-4549-9a07-f601c4b8f721,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-0bd8b632-6361-4c69-9bb1-b557b0ea1d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-c7ffe494-f436-466e-8328-6cfee0fa0282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217535755-172.17.0.9-1597731835181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-6e598418-1e1a-483b-876b-51d4514f9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-3580907e-23af-4cc4-ade4-8580574b04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-b73b65e8-b691-41e8-8869-3dcbc68ef9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2ab928b9-66d6-4b13-9986-75637a619553,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-36a6450f-47ae-4db5-80d6-14321e5d5ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-f9614ebb-843d-4b50-a1e5-7ab866ee1e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3c44902-b07a-4236-bcb2-1404356f1fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-00b17315-64d7-4c67-8d8f-24041a165b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217535755-172.17.0.9-1597731835181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-6e598418-1e1a-483b-876b-51d4514f9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-3580907e-23af-4cc4-ade4-8580574b04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-b73b65e8-b691-41e8-8869-3dcbc68ef9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2ab928b9-66d6-4b13-9986-75637a619553,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-36a6450f-47ae-4db5-80d6-14321e5d5ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-f9614ebb-843d-4b50-a1e5-7ab866ee1e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3c44902-b07a-4236-bcb2-1404356f1fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-00b17315-64d7-4c67-8d8f-24041a165b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991852747-172.17.0.9-1597732125789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41857,DS-bc264e20-f6dd-40d2-8923-5f248ba0a856,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-bc8ae1e5-498d-4a5b-8a20-8d412c251960,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-2448fd37-9d44-4511-8fc6-0e5f6170b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-97ee97b0-3b4e-4ee6-88ab-158f1a76d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-9e6bd344-85b6-4631-b583-e5214043b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bd6e349e-0fae-4494-ba4f-cb47538d69cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-cdb7868d-d81d-4968-a0e9-ba57c973c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-dacbd060-0c25-4214-bacb-fd83d891a09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991852747-172.17.0.9-1597732125789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41857,DS-bc264e20-f6dd-40d2-8923-5f248ba0a856,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-bc8ae1e5-498d-4a5b-8a20-8d412c251960,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-2448fd37-9d44-4511-8fc6-0e5f6170b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-97ee97b0-3b4e-4ee6-88ab-158f1a76d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-9e6bd344-85b6-4631-b583-e5214043b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bd6e349e-0fae-4494-ba4f-cb47538d69cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-cdb7868d-d81d-4968-a0e9-ba57c973c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-dacbd060-0c25-4214-bacb-fd83d891a09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5611
