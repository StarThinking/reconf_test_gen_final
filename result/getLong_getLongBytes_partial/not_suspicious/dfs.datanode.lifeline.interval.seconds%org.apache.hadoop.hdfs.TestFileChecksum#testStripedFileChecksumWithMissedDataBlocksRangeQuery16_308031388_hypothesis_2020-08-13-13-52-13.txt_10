reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033318954-172.17.0.2-1597327237927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37769,DS-87283af0-d36c-4d99-9149-adc08b51a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-083b2ca5-e739-49ec-bf67-3de122ec7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-15fc69a7-bfd3-4b25-adc7-0e9c880d15ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-93c38bbf-29a1-4132-8d56-12c49db456f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-9441df69-47fc-4434-9042-9af3057b8a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-79ef24e2-c86f-4b2e-b389-de16bf071b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-87170b52-f2e8-4ab9-a998-9c4b8633c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-85dd0bb5-77b6-48ba-8e0c-efe5f13c0ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033318954-172.17.0.2-1597327237927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37769,DS-87283af0-d36c-4d99-9149-adc08b51a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-083b2ca5-e739-49ec-bf67-3de122ec7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-15fc69a7-bfd3-4b25-adc7-0e9c880d15ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-93c38bbf-29a1-4132-8d56-12c49db456f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-9441df69-47fc-4434-9042-9af3057b8a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-79ef24e2-c86f-4b2e-b389-de16bf071b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-87170b52-f2e8-4ab9-a998-9c4b8633c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-85dd0bb5-77b6-48ba-8e0c-efe5f13c0ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434791873-172.17.0.2-1597327309221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-3a1f1f2e-3f2a-4a9e-8062-dde14d32027e,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-38609327-aee5-43ca-9a15-5b257aa9253d,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-4aa36be4-ca67-4915-a15a-e9e2756d5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-8787cd4b-ebbb-47de-aaaa-177bbcaaadbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-4a04f238-15c9-499c-87dc-5aba19a4cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-019402e9-057d-41b6-bb7e-cd13853a2322,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-aa76cd1e-e639-46e8-81b5-5c1e5bb80c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-9f8ed3a8-10d8-4e21-a2a3-8c0c5ceadca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434791873-172.17.0.2-1597327309221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-3a1f1f2e-3f2a-4a9e-8062-dde14d32027e,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-38609327-aee5-43ca-9a15-5b257aa9253d,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-4aa36be4-ca67-4915-a15a-e9e2756d5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-8787cd4b-ebbb-47de-aaaa-177bbcaaadbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-4a04f238-15c9-499c-87dc-5aba19a4cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-019402e9-057d-41b6-bb7e-cd13853a2322,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-aa76cd1e-e639-46e8-81b5-5c1e5bb80c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-9f8ed3a8-10d8-4e21-a2a3-8c0c5ceadca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52772445-172.17.0.2-1597328023368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-f839de96-a8f0-493c-81ae-291cb6b523a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-962a01d3-f4b0-400e-8527-c2711c5b8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-534aa6a6-2b81-48ce-a5d8-8fd90c3bdae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d065eb5c-e931-486b-b335-29bec92862f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-f627bd55-0e75-43a5-84ca-d0a64c31d211,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-e9329495-aef9-4422-a3c2-6349d2b71bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f3f30f82-fc7e-49ce-9115-06eba4ea764e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-586818fa-8f98-431c-afde-9336dae2057e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52772445-172.17.0.2-1597328023368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-f839de96-a8f0-493c-81ae-291cb6b523a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-962a01d3-f4b0-400e-8527-c2711c5b8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-534aa6a6-2b81-48ce-a5d8-8fd90c3bdae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d065eb5c-e931-486b-b335-29bec92862f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-f627bd55-0e75-43a5-84ca-d0a64c31d211,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-e9329495-aef9-4422-a3c2-6349d2b71bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f3f30f82-fc7e-49ce-9115-06eba4ea764e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-586818fa-8f98-431c-afde-9336dae2057e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604599250-172.17.0.2-1597329773367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-f1834064-34ac-4d44-a23a-6c0653c7b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-2d9f9854-167e-475d-bb11-6843536881c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-40f1ab35-2545-4738-87c7-e23a2593d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-04a79632-cb7c-4e23-9e56-41b209cb06bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-0735a4c2-a230-4139-8ecd-6f4dace90fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-a04fb09d-e78a-4723-8421-9b2990a63e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-92cfa1a8-c00b-40f3-bc80-67e589295290,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-9d4c597f-8075-4e31-b823-e8537761b3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604599250-172.17.0.2-1597329773367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-f1834064-34ac-4d44-a23a-6c0653c7b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-2d9f9854-167e-475d-bb11-6843536881c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-40f1ab35-2545-4738-87c7-e23a2593d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-04a79632-cb7c-4e23-9e56-41b209cb06bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-0735a4c2-a230-4139-8ecd-6f4dace90fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-a04fb09d-e78a-4723-8421-9b2990a63e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-92cfa1a8-c00b-40f3-bc80-67e589295290,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-9d4c597f-8075-4e31-b823-e8537761b3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580383858-172.17.0.2-1597329811994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-0947236f-f4bc-4d89-a2e5-29b09c5966fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-02cfcbe8-2fb5-4e83-b5c1-c22d5a714714,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-1cb35a64-fe84-4758-8d58-b19111e64f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-e456d969-f30a-4cd8-8267-94c62e3ab4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-b7d1531e-af3c-4812-a384-f1e6a941aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-ea6c2eae-3513-4448-9819-e859bf62e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-0a438604-34ea-4d5f-890a-bdc2fcd837e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-cc4b479e-153d-4ff6-956e-c44e3d6ffb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580383858-172.17.0.2-1597329811994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-0947236f-f4bc-4d89-a2e5-29b09c5966fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-02cfcbe8-2fb5-4e83-b5c1-c22d5a714714,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-1cb35a64-fe84-4758-8d58-b19111e64f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-e456d969-f30a-4cd8-8267-94c62e3ab4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-b7d1531e-af3c-4812-a384-f1e6a941aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-ea6c2eae-3513-4448-9819-e859bf62e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-0a438604-34ea-4d5f-890a-bdc2fcd837e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-cc4b479e-153d-4ff6-956e-c44e3d6ffb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466669109-172.17.0.2-1597330063651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-3d32967e-d270-4e86-b922-c6f85b9faf43,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-083190af-c106-445b-be31-2efb0b14aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-7f5a2fbc-e293-4e0c-befa-72d7d3cad319,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9b5ae585-6efd-4763-bbaa-8fae6b63ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-718efc46-b2b2-449b-8d78-5262844c91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-39bedd5c-c739-4b0e-ad0a-d36755e10a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-aace8c1c-93c6-48fd-94b3-4422cf0afe61,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ac315448-db4f-4615-adec-3f375717cabc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466669109-172.17.0.2-1597330063651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-3d32967e-d270-4e86-b922-c6f85b9faf43,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-083190af-c106-445b-be31-2efb0b14aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-7f5a2fbc-e293-4e0c-befa-72d7d3cad319,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9b5ae585-6efd-4763-bbaa-8fae6b63ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-718efc46-b2b2-449b-8d78-5262844c91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-39bedd5c-c739-4b0e-ad0a-d36755e10a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-aace8c1c-93c6-48fd-94b3-4422cf0afe61,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ac315448-db4f-4615-adec-3f375717cabc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438594566-172.17.0.2-1597330386246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-1ad22b5b-65cb-4593-8cc2-a2c4d8af8bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-105acb53-7361-47fd-a33d-b5df2afbc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-22076674-e609-4a77-9853-cb6ecb366a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-75be0be7-2db2-46d0-8d7a-2bd03dc95766,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-53ff3310-336b-4cf9-a108-5a9268527d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-607785fa-820e-4f8f-bbb9-fc5440fa37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-982b2edc-e9fd-4cfb-8a7e-311a96737813,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-d839ccb9-e70b-42c1-ba6b-0b04339c2fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438594566-172.17.0.2-1597330386246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-1ad22b5b-65cb-4593-8cc2-a2c4d8af8bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-105acb53-7361-47fd-a33d-b5df2afbc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-22076674-e609-4a77-9853-cb6ecb366a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-75be0be7-2db2-46d0-8d7a-2bd03dc95766,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-53ff3310-336b-4cf9-a108-5a9268527d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-607785fa-820e-4f8f-bbb9-fc5440fa37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-982b2edc-e9fd-4cfb-8a7e-311a96737813,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-d839ccb9-e70b-42c1-ba6b-0b04339c2fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547004890-172.17.0.2-1597330543453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-a2ee47d7-82e8-41fb-ac46-9f90dc20af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-9da7a658-db4f-46ff-b75d-5623bcf0ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-25bdeae2-f6fe-42d3-99a7-921e4b660934,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-80181a8e-5d56-4db4-a506-e2f9c734289b,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-77b47630-e166-492c-a965-b58bd6f02ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-ff4ab89d-b44e-46b2-abc9-576ab2986f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-f442d2ff-d3fd-4685-9a34-5634eb3545dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-a45ba6c2-78a2-4c94-a2b3-d9bce6b39ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547004890-172.17.0.2-1597330543453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-a2ee47d7-82e8-41fb-ac46-9f90dc20af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-9da7a658-db4f-46ff-b75d-5623bcf0ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-25bdeae2-f6fe-42d3-99a7-921e4b660934,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-80181a8e-5d56-4db4-a506-e2f9c734289b,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-77b47630-e166-492c-a965-b58bd6f02ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-ff4ab89d-b44e-46b2-abc9-576ab2986f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-f442d2ff-d3fd-4685-9a34-5634eb3545dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-a45ba6c2-78a2-4c94-a2b3-d9bce6b39ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594896803-172.17.0.2-1597330653759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-cd1b7e30-3851-457a-9fca-8be85138455e,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-05e42da3-f67d-4fa5-bdd5-0be09000e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-43db68b1-f9aa-4d5f-a090-bb63d7d79bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-80fe9026-ae86-47cb-b652-8f547154ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-e90bd0c6-7840-4eea-8c0f-586f57b15bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-59203ccc-382f-45bc-a636-efe6c3122e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-ecda8865-c84c-45f4-979f-3b7f77dceb33,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-e5d81520-9a43-42ac-9889-0892ba987302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594896803-172.17.0.2-1597330653759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-cd1b7e30-3851-457a-9fca-8be85138455e,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-05e42da3-f67d-4fa5-bdd5-0be09000e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-43db68b1-f9aa-4d5f-a090-bb63d7d79bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-80fe9026-ae86-47cb-b652-8f547154ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-e90bd0c6-7840-4eea-8c0f-586f57b15bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-59203ccc-382f-45bc-a636-efe6c3122e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-ecda8865-c84c-45f4-979f-3b7f77dceb33,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-e5d81520-9a43-42ac-9889-0892ba987302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951130981-172.17.0.2-1597330909392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42222,DS-9a56998a-4fed-4ae3-8b6d-28e4fc9159dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-2e18e043-f09e-4964-9b44-b7068c66087e,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-245f91a0-e331-4513-b6fa-aa19721cd379,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-0bd7f673-a58f-4a30-b2f1-7d975240690f,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-9c9164dd-3c8a-4900-b845-ab0c7cf7f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-f63de3d9-b9bb-4cff-aa3a-0dd4d5f5ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e6a3d3bd-6713-41b5-93e7-7ac62166d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-3aed2db6-611a-4fc5-9d3f-eef5e86b3a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951130981-172.17.0.2-1597330909392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42222,DS-9a56998a-4fed-4ae3-8b6d-28e4fc9159dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-2e18e043-f09e-4964-9b44-b7068c66087e,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-245f91a0-e331-4513-b6fa-aa19721cd379,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-0bd7f673-a58f-4a30-b2f1-7d975240690f,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-9c9164dd-3c8a-4900-b845-ab0c7cf7f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-f63de3d9-b9bb-4cff-aa3a-0dd4d5f5ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e6a3d3bd-6713-41b5-93e7-7ac62166d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-3aed2db6-611a-4fc5-9d3f-eef5e86b3a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741035501-172.17.0.2-1597331139168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-54290e89-069e-4009-bee6-2624deccc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-20052054-b0e5-4fd7-bce7-acd691d78811,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-5fb02d99-443a-4601-a45d-60e7f048c491,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6bc31ac6-8afa-4717-bd3b-fd7c2765ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-759c0232-4e1d-4c29-8785-81892f80adee,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-4050c419-9de0-4867-9ed7-a12889ea71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-f05172ad-ee1f-4495-b5fd-dd38731e5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-351ef4f3-9ce0-4988-bd17-1b939d9ac058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741035501-172.17.0.2-1597331139168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-54290e89-069e-4009-bee6-2624deccc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-20052054-b0e5-4fd7-bce7-acd691d78811,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-5fb02d99-443a-4601-a45d-60e7f048c491,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6bc31ac6-8afa-4717-bd3b-fd7c2765ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-759c0232-4e1d-4c29-8785-81892f80adee,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-4050c419-9de0-4867-9ed7-a12889ea71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-f05172ad-ee1f-4495-b5fd-dd38731e5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-351ef4f3-9ce0-4988-bd17-1b939d9ac058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516011158-172.17.0.2-1597331566579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-db5cac91-affa-4282-b9fa-17b5a64df781,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-43b9cc11-9df6-4856-bb03-7554ae81ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-b947cde8-1c7b-4c1c-883b-f7642116c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-7b228627-f80d-417c-bc15-200f89fd57cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-62675aea-2585-4ee4-a218-6b5c0254cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-fe7a7521-8bb8-4dbe-a03d-069cbff187eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-f5099350-9077-4d14-8052-d40c2e6d0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-9c2995f7-8010-426e-a37f-8dc97fd8abc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516011158-172.17.0.2-1597331566579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-db5cac91-affa-4282-b9fa-17b5a64df781,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-43b9cc11-9df6-4856-bb03-7554ae81ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-b947cde8-1c7b-4c1c-883b-f7642116c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-7b228627-f80d-417c-bc15-200f89fd57cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-62675aea-2585-4ee4-a218-6b5c0254cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-fe7a7521-8bb8-4dbe-a03d-069cbff187eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-f5099350-9077-4d14-8052-d40c2e6d0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-9c2995f7-8010-426e-a37f-8dc97fd8abc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5274
