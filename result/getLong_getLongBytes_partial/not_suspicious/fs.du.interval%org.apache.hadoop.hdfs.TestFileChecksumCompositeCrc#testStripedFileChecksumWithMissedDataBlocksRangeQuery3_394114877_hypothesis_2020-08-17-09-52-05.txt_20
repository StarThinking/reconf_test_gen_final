reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767902569-172.17.0.3-1597657946707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-a31124d4-ac12-4b1a-9f43-de5964e36593,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-c8388622-4a00-463a-9370-eb315c680d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-ac6efded-3900-44ae-b97e-7b9de16914d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b2020e7a-6169-4bfc-bec8-21dc32b5780d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-36d7367f-66fb-40a2-ab84-019485e28e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-4e28a9c4-e567-4098-aff2-341b207c0852,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-46a39064-ba3f-496b-9966-682b1accf67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-49537fa6-c443-4f54-a894-062131544e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767902569-172.17.0.3-1597657946707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-a31124d4-ac12-4b1a-9f43-de5964e36593,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-c8388622-4a00-463a-9370-eb315c680d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-ac6efded-3900-44ae-b97e-7b9de16914d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b2020e7a-6169-4bfc-bec8-21dc32b5780d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-36d7367f-66fb-40a2-ab84-019485e28e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-4e28a9c4-e567-4098-aff2-341b207c0852,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-46a39064-ba3f-496b-9966-682b1accf67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-49537fa6-c443-4f54-a894-062131544e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491257718-172.17.0.3-1597658408231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-372a03e0-9490-4ef1-b355-727abb471558,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8cf1a11a-0ed9-4dd0-9584-9c6f5c969208,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-18c44f39-3c82-4d76-af24-9923dd8b133e,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-b4373053-fbd7-4d49-821d-3e1ad8c07097,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-901a90a0-aec9-463d-9d37-266c44eff2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-1ed06698-b6e3-4d47-9854-182123283adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-bd35e8b9-a259-4ffa-aa06-98dd24c85e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c351948f-0445-49a9-913f-af4b2d554108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491257718-172.17.0.3-1597658408231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-372a03e0-9490-4ef1-b355-727abb471558,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8cf1a11a-0ed9-4dd0-9584-9c6f5c969208,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-18c44f39-3c82-4d76-af24-9923dd8b133e,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-b4373053-fbd7-4d49-821d-3e1ad8c07097,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-901a90a0-aec9-463d-9d37-266c44eff2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-1ed06698-b6e3-4d47-9854-182123283adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-bd35e8b9-a259-4ffa-aa06-98dd24c85e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c351948f-0445-49a9-913f-af4b2d554108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718567736-172.17.0.3-1597659184471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-344f5fd0-69fe-4eac-b356-b53323a2e672,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-d778db42-34c8-40e4-8020-6966a0cdebd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-57a9fece-052b-465e-ba89-dd37adf47c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-9dbb31ef-221e-424b-ab34-12ccf12bf4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6e6abb03-f231-43b8-a2d7-12009a45bddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-c69523fd-de17-4a19-8137-38b2c7fc035a,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-77d55e84-9766-4c3f-9473-dacd88d44584,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-209a98db-e8b5-4aaa-9844-4c226834b29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718567736-172.17.0.3-1597659184471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-344f5fd0-69fe-4eac-b356-b53323a2e672,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-d778db42-34c8-40e4-8020-6966a0cdebd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-57a9fece-052b-465e-ba89-dd37adf47c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-9dbb31ef-221e-424b-ab34-12ccf12bf4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6e6abb03-f231-43b8-a2d7-12009a45bddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-c69523fd-de17-4a19-8137-38b2c7fc035a,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-77d55e84-9766-4c3f-9473-dacd88d44584,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-209a98db-e8b5-4aaa-9844-4c226834b29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017815349-172.17.0.3-1597659513386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-f5e5254e-9f1b-415e-a5f4-2bb4605f303f,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-532d3d8e-d200-42c9-b453-c7cc42880dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-cd54ecfa-93d0-40e1-bde6-adacc0218ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-57c9463d-a07d-401e-9fcd-ccdb54306dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-f490982a-1916-4a0a-aefd-ef0c5b8ac535,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-434b170b-921b-4db1-8f1a-2969772f8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-7d679d2b-ad5c-4697-a519-af532b5ad163,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d40ba6e9-f6f6-4adb-8c76-6978124862e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017815349-172.17.0.3-1597659513386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-f5e5254e-9f1b-415e-a5f4-2bb4605f303f,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-532d3d8e-d200-42c9-b453-c7cc42880dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-cd54ecfa-93d0-40e1-bde6-adacc0218ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-57c9463d-a07d-401e-9fcd-ccdb54306dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-f490982a-1916-4a0a-aefd-ef0c5b8ac535,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-434b170b-921b-4db1-8f1a-2969772f8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-7d679d2b-ad5c-4697-a519-af532b5ad163,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d40ba6e9-f6f6-4adb-8c76-6978124862e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306160702-172.17.0.3-1597659554217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-39e9b051-7089-4cae-8506-86253e0c0858,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-34d970b2-c49b-42f4-8bca-cd9f8a6d0bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-57dc0a57-0487-419e-8c1d-d19bcf69f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-4795920f-8f45-4f43-a77a-17214e280d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-f5e86fb1-ac19-43b8-a39a-136cc7ec1ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-8f3d1cbc-8873-4a13-bfc2-e7fd1fefa3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-0eee60d5-80fc-4f49-8d4f-5f2802db25e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-dd87a010-b66a-4fd1-86ac-ab45ca919bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306160702-172.17.0.3-1597659554217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-39e9b051-7089-4cae-8506-86253e0c0858,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-34d970b2-c49b-42f4-8bca-cd9f8a6d0bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-57dc0a57-0487-419e-8c1d-d19bcf69f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-4795920f-8f45-4f43-a77a-17214e280d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-f5e86fb1-ac19-43b8-a39a-136cc7ec1ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-8f3d1cbc-8873-4a13-bfc2-e7fd1fefa3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-0eee60d5-80fc-4f49-8d4f-5f2802db25e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-dd87a010-b66a-4fd1-86ac-ab45ca919bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60953376-172.17.0.3-1597659673730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-6b85ff0f-1e86-449c-b60b-6417b6d07ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-8be22e41-03aa-46c9-bc4e-3826d7b68cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2ee4cd88-2245-422b-96ba-eaa457bea1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-30020125-8953-4057-9a01-f5271d3cb824,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-e362db6a-1bbf-4902-afdd-f3c97553606b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5486bbe0-d501-4e20-a836-17f850890ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-36f5e421-ae94-4524-99fa-0cb9b78190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-97ee42bc-83aa-4716-972b-5111b528285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60953376-172.17.0.3-1597659673730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-6b85ff0f-1e86-449c-b60b-6417b6d07ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-8be22e41-03aa-46c9-bc4e-3826d7b68cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2ee4cd88-2245-422b-96ba-eaa457bea1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-30020125-8953-4057-9a01-f5271d3cb824,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-e362db6a-1bbf-4902-afdd-f3c97553606b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5486bbe0-d501-4e20-a836-17f850890ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-36f5e421-ae94-4524-99fa-0cb9b78190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-97ee42bc-83aa-4716-972b-5111b528285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610068950-172.17.0.3-1597660212633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-43ea1e7e-e72f-471a-aabf-fb75b44b3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-44256e3a-d43c-4410-8904-2b8716084569,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-897029d3-39fa-4fea-9202-04de7bdfb947,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-f42a3df7-3932-4089-9f0b-18acc7be87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-f925df3e-fa10-49fe-abe5-5c68d3531285,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-ec7c61d9-82d1-496c-a5f1-37b2cd5fe0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-92a6b5ce-921a-4d7f-9316-6a188ec4ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-8b56c48c-0d1c-4915-b980-8629bfc4349b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610068950-172.17.0.3-1597660212633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-43ea1e7e-e72f-471a-aabf-fb75b44b3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-44256e3a-d43c-4410-8904-2b8716084569,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-897029d3-39fa-4fea-9202-04de7bdfb947,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-f42a3df7-3932-4089-9f0b-18acc7be87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-f925df3e-fa10-49fe-abe5-5c68d3531285,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-ec7c61d9-82d1-496c-a5f1-37b2cd5fe0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-92a6b5ce-921a-4d7f-9316-6a188ec4ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-8b56c48c-0d1c-4915-b980-8629bfc4349b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100794102-172.17.0.3-1597660482642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45812,DS-1a6eea07-b042-4be7-93c1-50fd323cdea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-3f9f124a-3fc7-41f5-91fa-17afb14428bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-1ab7f3e5-528e-4113-8ee5-cf8fb9d57617,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-c1cdd0be-8943-446a-9e04-8af4160ef50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-b159ad3e-fa2e-4b13-acbd-6528a67794fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-b4467c28-2e81-49c3-806e-6ca9e4a3da92,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-49e88143-e0c7-4f36-8ec2-a61687af318c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-24243940-7209-4617-a16e-d8fac9be067d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100794102-172.17.0.3-1597660482642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45812,DS-1a6eea07-b042-4be7-93c1-50fd323cdea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-3f9f124a-3fc7-41f5-91fa-17afb14428bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-1ab7f3e5-528e-4113-8ee5-cf8fb9d57617,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-c1cdd0be-8943-446a-9e04-8af4160ef50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-b159ad3e-fa2e-4b13-acbd-6528a67794fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-b4467c28-2e81-49c3-806e-6ca9e4a3da92,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-49e88143-e0c7-4f36-8ec2-a61687af318c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-24243940-7209-4617-a16e-d8fac9be067d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649094629-172.17.0.3-1597660692161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-2c43fdc5-9255-4414-9f66-8ff323c2f865,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-99e6cf68-2d37-44e6-a970-ddc264d19f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-2c67472d-0c4d-432d-9ab5-d2925d69255c,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-34fe87e3-009d-4349-93f5-2319f7158e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-4635f1b1-f7cb-4000-97ee-434b5b73bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-d19ccbc4-bc8a-41b1-b31b-072642b0e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-386a8856-7d5a-4e6d-b79c-5f953e48d698,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-54ca813a-0159-4b56-8127-b0f449cd5f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649094629-172.17.0.3-1597660692161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-2c43fdc5-9255-4414-9f66-8ff323c2f865,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-99e6cf68-2d37-44e6-a970-ddc264d19f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-2c67472d-0c4d-432d-9ab5-d2925d69255c,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-34fe87e3-009d-4349-93f5-2319f7158e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-4635f1b1-f7cb-4000-97ee-434b5b73bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-d19ccbc4-bc8a-41b1-b31b-072642b0e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-386a8856-7d5a-4e6d-b79c-5f953e48d698,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-54ca813a-0159-4b56-8127-b0f449cd5f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494394009-172.17.0.3-1597660829615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-dfd7a370-23d1-437c-8757-28370b9dfbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-c5e8fa62-3749-4673-b03c-229a188ab56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-cc0a4b73-eb82-4039-8e59-6df6016a0e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-102c22bc-25c0-4204-9ebd-87319bb027bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-e7f0bab9-9e43-4bc9-9f39-5e63f36d9007,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-0e52502c-c421-431d-a2fd-7515ee124383,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-885f7657-9912-46ed-a4a8-81df1a3fc067,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-dd3873ba-7f56-4109-9279-77a394672122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494394009-172.17.0.3-1597660829615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-dfd7a370-23d1-437c-8757-28370b9dfbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-c5e8fa62-3749-4673-b03c-229a188ab56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-cc0a4b73-eb82-4039-8e59-6df6016a0e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-102c22bc-25c0-4204-9ebd-87319bb027bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-e7f0bab9-9e43-4bc9-9f39-5e63f36d9007,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-0e52502c-c421-431d-a2fd-7515ee124383,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-885f7657-9912-46ed-a4a8-81df1a3fc067,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-dd3873ba-7f56-4109-9279-77a394672122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999894844-172.17.0.3-1597661324381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-762e7e6b-678e-4f4e-8ff5-e5b28e4e6e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-7cdaf71e-cf0a-4d09-9caa-5c89b9cda5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-a36b33f6-6da5-4253-95b1-af32b430c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-f2c186ff-54e1-43f7-861d-06ec57b7ef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-ed2332c0-775a-4d6e-8380-11611222983b,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-06875bb4-149b-43d8-baa2-071aad03acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e7b7f5a9-1326-44a4-be9a-e1924ff6b270,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-297b5319-9287-4cdd-a7e9-77a4c56f166c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999894844-172.17.0.3-1597661324381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-762e7e6b-678e-4f4e-8ff5-e5b28e4e6e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-7cdaf71e-cf0a-4d09-9caa-5c89b9cda5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-a36b33f6-6da5-4253-95b1-af32b430c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-f2c186ff-54e1-43f7-861d-06ec57b7ef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-ed2332c0-775a-4d6e-8380-11611222983b,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-06875bb4-149b-43d8-baa2-071aad03acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e7b7f5a9-1326-44a4-be9a-e1924ff6b270,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-297b5319-9287-4cdd-a7e9-77a4c56f166c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013455940-172.17.0.3-1597661413924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-d0ab43bd-ea01-469f-872d-7ae1b06f705b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-60e24e3c-1a54-4a22-a04f-478f3362a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-87346366-075b-4e29-be76-f111439a5eae,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-6c252a78-e18a-410a-835f-adc7a40fd59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-50102beb-9918-4d6a-b6a1-b22de926c895,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-a01669f7-8e10-494d-9686-b59006fd8947,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-39b32517-2c4e-48d1-9339-d23013a8bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-2cac9871-a49e-484f-bac5-8a8efed59b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013455940-172.17.0.3-1597661413924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-d0ab43bd-ea01-469f-872d-7ae1b06f705b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-60e24e3c-1a54-4a22-a04f-478f3362a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-87346366-075b-4e29-be76-f111439a5eae,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-6c252a78-e18a-410a-835f-adc7a40fd59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-50102beb-9918-4d6a-b6a1-b22de926c895,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-a01669f7-8e10-494d-9686-b59006fd8947,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-39b32517-2c4e-48d1-9339-d23013a8bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-2cac9871-a49e-484f-bac5-8a8efed59b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62198088-172.17.0.3-1597661519572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-88947cfd-7e49-4597-bdd4-4f2e698225a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-12519a7e-3a49-44bd-ba01-1f2c1465dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-d230e505-bbe4-4c1b-bcbc-6f89adcfb12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8f9dc7e1-abba-44a5-892e-5cd63858d767,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-3392dcad-39bc-4708-83a0-6cc0db6be685,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-a59e8bf6-b54b-4644-bb0a-2e95d73f2333,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-0f08221a-5625-4280-bd63-706b78562182,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-5d49e710-b3ed-4b6a-9d0a-bc356b4a9f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62198088-172.17.0.3-1597661519572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-88947cfd-7e49-4597-bdd4-4f2e698225a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-12519a7e-3a49-44bd-ba01-1f2c1465dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-d230e505-bbe4-4c1b-bcbc-6f89adcfb12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8f9dc7e1-abba-44a5-892e-5cd63858d767,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-3392dcad-39bc-4708-83a0-6cc0db6be685,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-a59e8bf6-b54b-4644-bb0a-2e95d73f2333,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-0f08221a-5625-4280-bd63-706b78562182,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-5d49e710-b3ed-4b6a-9d0a-bc356b4a9f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551641846-172.17.0.3-1597662037701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-d935e6a6-3755-4964-ace5-f21f23231bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-95f972cb-3cde-487a-aee2-2dde481a716d,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-cdcd1a50-0712-46ef-ad12-d7cd357ea4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-6fe50b28-c38b-4b21-89f2-04b9f2d74552,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-fea50197-d498-41f3-ad41-f7af6e49ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-046158c6-ba90-41c5-96d9-99189a775cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-249e8706-5e0a-4309-92f9-31ace0213dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-0ec9be6c-b14b-4df1-971a-b2f11e4c2dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551641846-172.17.0.3-1597662037701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-d935e6a6-3755-4964-ace5-f21f23231bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-95f972cb-3cde-487a-aee2-2dde481a716d,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-cdcd1a50-0712-46ef-ad12-d7cd357ea4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-6fe50b28-c38b-4b21-89f2-04b9f2d74552,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-fea50197-d498-41f3-ad41-f7af6e49ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-046158c6-ba90-41c5-96d9-99189a775cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-249e8706-5e0a-4309-92f9-31ace0213dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-0ec9be6c-b14b-4df1-971a-b2f11e4c2dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981799393-172.17.0.3-1597662167518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36684,DS-aa524448-0387-4f73-b4de-9da710f6f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-bd22e9f7-4899-4950-84b5-f0999233924d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-f66f865d-1f2a-4305-828a-34d66a9c35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2fb09b82-cfe9-46e4-ba70-c7001e9c0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-86123dd0-03e2-49af-801d-f2d7eaf3aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-cb5d9071-f658-4b7f-8dda-d63bdb0ee87f,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-e3fc236b-f5f1-4ffb-9035-f7b7b9f6d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-db6c6746-510f-4f1b-a589-91884c527978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981799393-172.17.0.3-1597662167518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36684,DS-aa524448-0387-4f73-b4de-9da710f6f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-bd22e9f7-4899-4950-84b5-f0999233924d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-f66f865d-1f2a-4305-828a-34d66a9c35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2fb09b82-cfe9-46e4-ba70-c7001e9c0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-86123dd0-03e2-49af-801d-f2d7eaf3aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-cb5d9071-f658-4b7f-8dda-d63bdb0ee87f,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-e3fc236b-f5f1-4ffb-9035-f7b7b9f6d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-db6c6746-510f-4f1b-a589-91884c527978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560534185-172.17.0.3-1597662210822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-a6209761-40fb-458a-ac6b-6298b02cc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-f0841cec-185b-40ba-a13c-746503862574,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-9bc60ba0-c2f4-4900-86da-0bb561d71832,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-c5c87533-7297-43e0-9e46-f90e2b3e9f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-dd67b89e-80e6-4254-9b73-1b16247f5ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-994cb959-2c7f-48de-a7bd-9d62b23e67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-58f17d70-dabe-4934-b721-ba3fff1df632,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-f86f5955-e2ec-4c28-ab5d-5d37e3e65ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560534185-172.17.0.3-1597662210822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-a6209761-40fb-458a-ac6b-6298b02cc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-f0841cec-185b-40ba-a13c-746503862574,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-9bc60ba0-c2f4-4900-86da-0bb561d71832,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-c5c87533-7297-43e0-9e46-f90e2b3e9f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-dd67b89e-80e6-4254-9b73-1b16247f5ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-994cb959-2c7f-48de-a7bd-9d62b23e67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-58f17d70-dabe-4934-b721-ba3fff1df632,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-f86f5955-e2ec-4c28-ab5d-5d37e3e65ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150410306-172.17.0.3-1597663855637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45364,DS-44b9e888-69f0-4b5c-8007-fc59369c5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-f70bedaf-32d1-413f-940f-1d5a0709f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-da4c301a-7975-43cf-b194-2747fe3c188c,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-631fd4a5-6f73-49af-881e-573560bde251,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-169e2de0-3ec7-44f0-9452-4cd132472e41,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-cc3fadbc-b78e-4fd2-9403-93dc5133b913,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-85fb2983-3e8f-44cb-965c-5756377c92dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-35844e93-04fc-4b17-92ba-d73dae30fd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150410306-172.17.0.3-1597663855637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45364,DS-44b9e888-69f0-4b5c-8007-fc59369c5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-f70bedaf-32d1-413f-940f-1d5a0709f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-da4c301a-7975-43cf-b194-2747fe3c188c,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-631fd4a5-6f73-49af-881e-573560bde251,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-169e2de0-3ec7-44f0-9452-4cd132472e41,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-cc3fadbc-b78e-4fd2-9403-93dc5133b913,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-85fb2983-3e8f-44cb-965c-5756377c92dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-35844e93-04fc-4b17-92ba-d73dae30fd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672699169-172.17.0.3-1597664261367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34621,DS-bbc8e707-f220-4406-a2ed-04f9bbcff411,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-b2ff57a9-eaab-404a-a7c9-3c5182b99a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-7b6ae838-2b9c-4bd7-a533-e3d6eb16e347,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-c3fe1bcd-9284-4180-9de1-a7fc726b5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-a4cf69a0-4ded-4439-bcc6-359ebab97767,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-7f01f37d-9e68-4196-97b0-098c2fe33878,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-34c19443-5559-4aa0-88ec-74036a40f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-da0d7f6c-43af-423b-af1a-fa62aa983350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672699169-172.17.0.3-1597664261367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34621,DS-bbc8e707-f220-4406-a2ed-04f9bbcff411,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-b2ff57a9-eaab-404a-a7c9-3c5182b99a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-7b6ae838-2b9c-4bd7-a533-e3d6eb16e347,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-c3fe1bcd-9284-4180-9de1-a7fc726b5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-a4cf69a0-4ded-4439-bcc6-359ebab97767,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-7f01f37d-9e68-4196-97b0-098c2fe33878,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-34c19443-5559-4aa0-88ec-74036a40f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-da0d7f6c-43af-423b-af1a-fa62aa983350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6547
