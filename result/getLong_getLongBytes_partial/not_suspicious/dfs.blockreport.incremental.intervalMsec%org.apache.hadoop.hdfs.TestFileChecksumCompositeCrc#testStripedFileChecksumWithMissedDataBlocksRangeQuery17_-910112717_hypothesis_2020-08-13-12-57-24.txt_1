reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638330456-172.17.0.10-1597324208325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-8a884cf4-c6d9-44a6-9d02-cbbe624515f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-47015ade-0e14-4734-af40-ed973233e7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-216999ff-68c8-42bb-8290-77ccac7aeb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-4eb610ad-b599-41a5-b54f-3dd062804eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-fa99adb9-1280-48e7-83a6-e824e680fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-2ba82853-839d-4ce0-978e-93b74a27565a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-cd96b532-5c38-423d-8559-a8e09ca6d944,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-32d99954-6637-4c96-ab04-e00389142529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638330456-172.17.0.10-1597324208325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-8a884cf4-c6d9-44a6-9d02-cbbe624515f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-47015ade-0e14-4734-af40-ed973233e7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-216999ff-68c8-42bb-8290-77ccac7aeb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-4eb610ad-b599-41a5-b54f-3dd062804eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-fa99adb9-1280-48e7-83a6-e824e680fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-2ba82853-839d-4ce0-978e-93b74a27565a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-cd96b532-5c38-423d-8559-a8e09ca6d944,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-32d99954-6637-4c96-ab04-e00389142529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988267763-172.17.0.10-1597324803562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-af627222-2e30-4bae-a8d1-5221e84d7750,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-516e928e-4467-46ef-ad81-e7629b1d39b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-bca1915d-1359-4aa8-a41d-df0dbe18899a,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-cc4c794a-2999-489b-baf0-6ce4cc7a49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8ab252eb-19a2-4e82-8f92-b3dd79b4d745,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-cd564d18-953c-47d5-9a02-75e28cbc490d,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-e46d74fb-cd5e-4b38-9297-fb9ccdb7a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-698d70e0-b983-41ef-961e-ba5856c2ee7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988267763-172.17.0.10-1597324803562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-af627222-2e30-4bae-a8d1-5221e84d7750,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-516e928e-4467-46ef-ad81-e7629b1d39b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-bca1915d-1359-4aa8-a41d-df0dbe18899a,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-cc4c794a-2999-489b-baf0-6ce4cc7a49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8ab252eb-19a2-4e82-8f92-b3dd79b4d745,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-cd564d18-953c-47d5-9a02-75e28cbc490d,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-e46d74fb-cd5e-4b38-9297-fb9ccdb7a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-698d70e0-b983-41ef-961e-ba5856c2ee7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168315962-172.17.0.10-1597325354158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-47e11ab6-aa21-4878-9a9c-a31ab3ef3ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-d3c6830d-033b-4295-a422-d703865563ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-863956c6-c8ab-4f9a-a8a0-24f6e7da95e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-6ea939c4-890d-4fd2-9a4d-940cb146b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-f1c1c71d-019b-4176-b746-88338e44482c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-ca4be6d4-00e7-4b50-9c92-07e24275f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-6082730b-694c-4ec3-b4a9-41c21de5ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-5ea69904-bd94-4580-b642-d660e63fee16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168315962-172.17.0.10-1597325354158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-47e11ab6-aa21-4878-9a9c-a31ab3ef3ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-d3c6830d-033b-4295-a422-d703865563ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-863956c6-c8ab-4f9a-a8a0-24f6e7da95e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-6ea939c4-890d-4fd2-9a4d-940cb146b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-f1c1c71d-019b-4176-b746-88338e44482c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-ca4be6d4-00e7-4b50-9c92-07e24275f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-6082730b-694c-4ec3-b4a9-41c21de5ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-5ea69904-bd94-4580-b642-d660e63fee16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279006433-172.17.0.10-1597325440977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-1b71be09-f736-4218-9874-1309e5d7e050,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9e650fb8-84f6-452b-8ec0-e919f15a120c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-1f0ce98b-7133-4f3c-8f98-e0be956e58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-6564d18e-0cf8-4466-bf98-9219660e3419,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-7935bda3-f4db-4bc5-938d-baead350df30,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-dfd05e63-f363-4576-afad-de5ffe474e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-8240522a-5f90-40f9-a374-2831fea5dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-08a4ef50-c912-45b3-958a-99d3b7a62c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279006433-172.17.0.10-1597325440977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-1b71be09-f736-4218-9874-1309e5d7e050,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9e650fb8-84f6-452b-8ec0-e919f15a120c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-1f0ce98b-7133-4f3c-8f98-e0be956e58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-6564d18e-0cf8-4466-bf98-9219660e3419,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-7935bda3-f4db-4bc5-938d-baead350df30,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-dfd05e63-f363-4576-afad-de5ffe474e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-8240522a-5f90-40f9-a374-2831fea5dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-08a4ef50-c912-45b3-958a-99d3b7a62c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639842156-172.17.0.10-1597325882660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-27c69d28-40b8-446c-bfc0-94c2b4c53783,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-fbd6261e-43c1-4a9d-a2bc-c5ccd411ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0a3064e4-003e-444d-b4eb-4687e4c46747,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-89a4dbaa-73f2-4322-8289-832cc86e2f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-56edec84-19d1-4e1a-a205-4d61e7110b84,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-8f82bcc7-be8c-4de8-8151-2c2591e1e360,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-86dd36d5-bc25-44a0-a9f0-e9cc40f7c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-3b4da6d3-8ab6-41a3-ae11-f0b7d4e852b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639842156-172.17.0.10-1597325882660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-27c69d28-40b8-446c-bfc0-94c2b4c53783,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-fbd6261e-43c1-4a9d-a2bc-c5ccd411ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0a3064e4-003e-444d-b4eb-4687e4c46747,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-89a4dbaa-73f2-4322-8289-832cc86e2f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-56edec84-19d1-4e1a-a205-4d61e7110b84,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-8f82bcc7-be8c-4de8-8151-2c2591e1e360,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-86dd36d5-bc25-44a0-a9f0-e9cc40f7c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-3b4da6d3-8ab6-41a3-ae11-f0b7d4e852b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325410422-172.17.0.10-1597326276291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-647fb171-f6a6-4465-9195-f2cc529725ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-4c822ceb-e47d-4e57-90ef-4dcf9dfbd089,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8a59b0a7-ec25-4f5a-8b60-eb7c76bb3439,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-e5dd4d4a-1462-444b-8059-4b86df6efb70,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-251f6dde-dacb-4323-94aa-b5f7cc04745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-6b0771c2-4fe5-4b83-a9f1-6f55464482be,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0b0e8ab2-1b45-4eec-b90a-c6af1d901bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-fbc02d3e-a239-467c-989d-ff403b0f60f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325410422-172.17.0.10-1597326276291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-647fb171-f6a6-4465-9195-f2cc529725ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-4c822ceb-e47d-4e57-90ef-4dcf9dfbd089,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8a59b0a7-ec25-4f5a-8b60-eb7c76bb3439,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-e5dd4d4a-1462-444b-8059-4b86df6efb70,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-251f6dde-dacb-4323-94aa-b5f7cc04745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-6b0771c2-4fe5-4b83-a9f1-6f55464482be,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0b0e8ab2-1b45-4eec-b90a-c6af1d901bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-fbc02d3e-a239-467c-989d-ff403b0f60f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652911683-172.17.0.10-1597326317711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-59c08e0d-26f3-4659-ae42-d508b97bdeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-97221e4a-e6ac-43ed-9d42-9fcc91e01017,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-48879284-1af3-4c70-9e72-b4accb162619,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-a008de0d-b8b0-419c-8937-559913831541,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0b496214-9603-4e21-87f9-6535f54d812e,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-c5c7408c-d340-4701-80ec-558c2788fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-aaddab64-efa2-4e80-be56-855ac96f4865,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-59553918-6435-49af-969d-e1c416162eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652911683-172.17.0.10-1597326317711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-59c08e0d-26f3-4659-ae42-d508b97bdeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-97221e4a-e6ac-43ed-9d42-9fcc91e01017,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-48879284-1af3-4c70-9e72-b4accb162619,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-a008de0d-b8b0-419c-8937-559913831541,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0b496214-9603-4e21-87f9-6535f54d812e,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-c5c7408c-d340-4701-80ec-558c2788fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-aaddab64-efa2-4e80-be56-855ac96f4865,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-59553918-6435-49af-969d-e1c416162eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421134458-172.17.0.10-1597327156015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39157,DS-4503e8ad-af77-4748-bf3f-85b91e93624e,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-3028f440-de0b-427a-a768-1fe0a27d6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-ad519be8-0409-403f-b1ff-dde1f81e3733,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1d6daa99-c1a2-46ba-803d-5d9494e74b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-178ad76c-6b9e-40b8-aba3-5a9df48ce488,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-76c20633-7fe0-4603-9b48-6f32d9343544,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-f8b0d0ea-3859-4904-af14-3000079b2cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-330d9a19-12dd-4d94-b9ba-a805a343e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421134458-172.17.0.10-1597327156015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39157,DS-4503e8ad-af77-4748-bf3f-85b91e93624e,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-3028f440-de0b-427a-a768-1fe0a27d6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-ad519be8-0409-403f-b1ff-dde1f81e3733,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1d6daa99-c1a2-46ba-803d-5d9494e74b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-178ad76c-6b9e-40b8-aba3-5a9df48ce488,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-76c20633-7fe0-4603-9b48-6f32d9343544,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-f8b0d0ea-3859-4904-af14-3000079b2cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-330d9a19-12dd-4d94-b9ba-a805a343e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866235277-172.17.0.10-1597327239786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-4f8706c9-ca1a-44c4-9e0e-d25cc5b56bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-66522516-9fe1-4d70-b181-210bf8acfe86,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-6d8f6691-5632-4911-b015-9630f9a93a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-b6e681d4-7bbd-4b6a-9b21-92c97a89b162,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-91f4f9db-7d2a-43cd-8842-77895290461d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d2398391-bd08-4f68-96c0-0079e822823a,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-0fc081a6-56cb-4352-b4c6-932bb81e0141,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-90b04fa0-490d-4b26-895b-b7b048003c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866235277-172.17.0.10-1597327239786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-4f8706c9-ca1a-44c4-9e0e-d25cc5b56bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-66522516-9fe1-4d70-b181-210bf8acfe86,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-6d8f6691-5632-4911-b015-9630f9a93a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-b6e681d4-7bbd-4b6a-9b21-92c97a89b162,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-91f4f9db-7d2a-43cd-8842-77895290461d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d2398391-bd08-4f68-96c0-0079e822823a,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-0fc081a6-56cb-4352-b4c6-932bb81e0141,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-90b04fa0-490d-4b26-895b-b7b048003c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70853750-172.17.0.10-1597327401684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37622,DS-2bae123e-ef93-435e-ad78-2f43b62263dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-959cf1f9-a677-4055-a57c-faa7a9ac5812,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-afb3eac7-83dd-449c-9d00-38e2fc56a389,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-2d630b9d-805a-4c5e-ae68-f49f06945a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-1568db58-1b1f-4fd6-bbfc-2ab4c8eee3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-06b3abb4-9f65-41ac-9ec8-d04d185fede5,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c2274c5b-0ed6-470e-b51e-202f8c174d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-08426395-927f-4832-b118-bf32c4a9e21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70853750-172.17.0.10-1597327401684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37622,DS-2bae123e-ef93-435e-ad78-2f43b62263dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-959cf1f9-a677-4055-a57c-faa7a9ac5812,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-afb3eac7-83dd-449c-9d00-38e2fc56a389,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-2d630b9d-805a-4c5e-ae68-f49f06945a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-1568db58-1b1f-4fd6-bbfc-2ab4c8eee3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-06b3abb4-9f65-41ac-9ec8-d04d185fede5,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c2274c5b-0ed6-470e-b51e-202f8c174d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-08426395-927f-4832-b118-bf32c4a9e21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624478218-172.17.0.10-1597327757327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-dbd9dd53-db1f-4b6f-8155-1a804c02c146,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-10298ba5-b4b9-4e4b-bc16-eec6baedb4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-aba9321a-794c-4f6c-be64-485737351dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-c6c14716-250e-4bb3-9305-ed974de08c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-2bd96531-4d98-4e9d-8e22-9b08afd23eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-2e146a45-39a7-49d1-b4c8-b385d5c627ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-152b9df3-848f-4ee9-94e1-64a5638525f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-5673119f-7b70-4ba3-b0b3-7364aea2ba85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624478218-172.17.0.10-1597327757327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-dbd9dd53-db1f-4b6f-8155-1a804c02c146,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-10298ba5-b4b9-4e4b-bc16-eec6baedb4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-aba9321a-794c-4f6c-be64-485737351dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-c6c14716-250e-4bb3-9305-ed974de08c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-2bd96531-4d98-4e9d-8e22-9b08afd23eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-2e146a45-39a7-49d1-b4c8-b385d5c627ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-152b9df3-848f-4ee9-94e1-64a5638525f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-5673119f-7b70-4ba3-b0b3-7364aea2ba85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418618977-172.17.0.10-1597327962240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-8d6061c6-ee58-4365-803d-2bac03601222,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-b2681fcf-7eba-48f5-9530-447f38595bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-607b2487-b339-432a-a2e0-93a4eddddd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-2fe96f2c-464f-41ed-9f36-8a8528c9c6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-122f1978-bdeb-46f3-a9ea-c9abe770993e,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-7cada61e-97f8-4464-9253-6c656ca1b552,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-cf0d5814-f6c5-470c-a0ba-75154e59f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-fd8ed060-71a4-432a-9d7c-15ea89ddb16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418618977-172.17.0.10-1597327962240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-8d6061c6-ee58-4365-803d-2bac03601222,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-b2681fcf-7eba-48f5-9530-447f38595bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-607b2487-b339-432a-a2e0-93a4eddddd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-2fe96f2c-464f-41ed-9f36-8a8528c9c6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-122f1978-bdeb-46f3-a9ea-c9abe770993e,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-7cada61e-97f8-4464-9253-6c656ca1b552,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-cf0d5814-f6c5-470c-a0ba-75154e59f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-fd8ed060-71a4-432a-9d7c-15ea89ddb16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008963827-172.17.0.10-1597328133283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37570,DS-d2ab7cb6-fe36-4eec-8aac-644b124f990c,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-bcc570c3-feb0-4141-bebb-13ffca4bdd48,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-34c039e0-aa35-4c13-9070-5b93eecf008a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-7f98298c-0780-4d66-96ad-237d9d733392,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b4ea234-ad29-49aa-9849-bea71ea7a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-52ae4eff-0dbd-45b5-96fb-2778adca7137,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-25f87cbf-ec69-4d3a-845e-abbc07637a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-b1d132e9-33a9-4d72-9b72-0189d7795166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008963827-172.17.0.10-1597328133283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37570,DS-d2ab7cb6-fe36-4eec-8aac-644b124f990c,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-bcc570c3-feb0-4141-bebb-13ffca4bdd48,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-34c039e0-aa35-4c13-9070-5b93eecf008a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-7f98298c-0780-4d66-96ad-237d9d733392,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b4ea234-ad29-49aa-9849-bea71ea7a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-52ae4eff-0dbd-45b5-96fb-2778adca7137,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-25f87cbf-ec69-4d3a-845e-abbc07637a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-b1d132e9-33a9-4d72-9b72-0189d7795166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781803489-172.17.0.10-1597328173152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-c40b5b53-253f-43c1-afb2-2fef71446e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-ff4456bb-36b0-4cd6-8bc5-196cd4e42e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-48141041-303e-4f93-ab21-9e345aa744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-5c5f9de3-c6c1-423d-ba39-fee7de8d3f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-9e3250cc-eae0-44ce-9a08-9f44f42df296,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-762c9dd8-c814-4cc7-acff-bfa90c73f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d55103c7-e1bc-48b0-801d-550b966506c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-cbd198f3-926f-4ed2-b57e-5614adef1e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781803489-172.17.0.10-1597328173152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-c40b5b53-253f-43c1-afb2-2fef71446e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-ff4456bb-36b0-4cd6-8bc5-196cd4e42e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-48141041-303e-4f93-ab21-9e345aa744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-5c5f9de3-c6c1-423d-ba39-fee7de8d3f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-9e3250cc-eae0-44ce-9a08-9f44f42df296,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-762c9dd8-c814-4cc7-acff-bfa90c73f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d55103c7-e1bc-48b0-801d-550b966506c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-cbd198f3-926f-4ed2-b57e-5614adef1e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566878509-172.17.0.10-1597328222628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-5a873c0d-95a4-47ab-accd-d7924669bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-843dc915-6b58-4143-9662-868fab53151e,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-82bb3fe5-329f-4501-99dd-f5d249129341,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-8a4bc5ee-f9fe-457f-a06a-f4e659e7e274,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-2ec9c471-7acc-4853-ac3e-3dbbfb555643,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-6bb61c42-b78f-400e-ad86-8893c6e2582c,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-e2d523ea-2abd-44e5-9e96-1a1925249bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-eebd2c52-5f14-4449-92df-8ebcb7bae5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566878509-172.17.0.10-1597328222628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-5a873c0d-95a4-47ab-accd-d7924669bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-843dc915-6b58-4143-9662-868fab53151e,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-82bb3fe5-329f-4501-99dd-f5d249129341,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-8a4bc5ee-f9fe-457f-a06a-f4e659e7e274,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-2ec9c471-7acc-4853-ac3e-3dbbfb555643,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-6bb61c42-b78f-400e-ad86-8893c6e2582c,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-e2d523ea-2abd-44e5-9e96-1a1925249bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-eebd2c52-5f14-4449-92df-8ebcb7bae5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356835324-172.17.0.10-1597328350084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-bad50956-91f2-4c1a-81d4-33eee90dd70c,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-7845d58d-2d2e-44f0-afc8-e18859183562,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e58bdc70-df70-4146-a7c5-80262449a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-75023ee2-a013-472e-9e09-4c89581a1c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-ac89120f-a2cc-4b97-99f6-5aa70617c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-77b95afd-014f-41c3-bfb9-088b4e49b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-0de42203-9801-4f42-a01f-c846b1faff71,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-85e4b0c9-3c9c-4bc6-b378-36cc60f861eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356835324-172.17.0.10-1597328350084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-bad50956-91f2-4c1a-81d4-33eee90dd70c,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-7845d58d-2d2e-44f0-afc8-e18859183562,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e58bdc70-df70-4146-a7c5-80262449a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-75023ee2-a013-472e-9e09-4c89581a1c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-ac89120f-a2cc-4b97-99f6-5aa70617c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-77b95afd-014f-41c3-bfb9-088b4e49b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-0de42203-9801-4f42-a01f-c846b1faff71,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-85e4b0c9-3c9c-4bc6-b378-36cc60f861eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590083383-172.17.0.10-1597328678189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43025,DS-aa29647f-54cb-4d57-812f-8e649216adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-ed9fa31f-1327-490d-b9dd-69f908ce550c,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-d5e30120-5f4a-415c-af06-4b12320b152c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-699ca695-cebf-4249-9c7b-0a82f46a68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-a7896dbe-d348-41b5-a2b3-4e45be3b7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-bc8631a8-ef64-4bae-988d-b44c1bbd7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-3ddc57ae-4bc1-4821-96d9-1a4dcffae6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-4d2292e9-23b0-40b7-922e-d9b3d2f22dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590083383-172.17.0.10-1597328678189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43025,DS-aa29647f-54cb-4d57-812f-8e649216adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-ed9fa31f-1327-490d-b9dd-69f908ce550c,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-d5e30120-5f4a-415c-af06-4b12320b152c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-699ca695-cebf-4249-9c7b-0a82f46a68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-a7896dbe-d348-41b5-a2b3-4e45be3b7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-bc8631a8-ef64-4bae-988d-b44c1bbd7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-3ddc57ae-4bc1-4821-96d9-1a4dcffae6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-4d2292e9-23b0-40b7-922e-d9b3d2f22dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476037625-172.17.0.10-1597329014673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-21720d1a-ed23-45b1-b157-064bd24fa85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-019c8414-f074-4f18-ad80-2d548253cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-29cb0908-203b-40e0-96a2-1c4da6d7dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-6d692086-c5fd-4091-b6a2-464cf7b95240,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-c912f432-986c-4fd5-8a05-5e0911765603,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-b61e5105-b48c-470b-a2ac-a20164b8694c,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fafea731-2f44-4e22-ae34-e553861c29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-2f417236-5d2b-4942-b797-e91311c79daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476037625-172.17.0.10-1597329014673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-21720d1a-ed23-45b1-b157-064bd24fa85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-019c8414-f074-4f18-ad80-2d548253cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-29cb0908-203b-40e0-96a2-1c4da6d7dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-6d692086-c5fd-4091-b6a2-464cf7b95240,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-c912f432-986c-4fd5-8a05-5e0911765603,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-b61e5105-b48c-470b-a2ac-a20164b8694c,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fafea731-2f44-4e22-ae34-e553861c29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-2f417236-5d2b-4942-b797-e91311c79daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6415
