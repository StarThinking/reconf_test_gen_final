reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379353213-172.17.0.12-1597456003506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-2f28a940-0c08-4f8a-9243-f1bb401a06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-fe8039f9-1310-4f19-a990-3ccf823eba57,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-6e216d42-8688-4ba5-a5f5-5d8dbefcef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9d1781b0-04d2-4a75-9b1b-a0fd870dbfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-591bb665-4332-4e13-b9a1-e79961c04d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-214709be-89bf-499f-b84e-92bfe94bfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-b07656e6-0bdc-4fcb-bcc8-b6977445d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-cc1ec082-8571-4c23-8109-eea2f8ffeef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379353213-172.17.0.12-1597456003506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-2f28a940-0c08-4f8a-9243-f1bb401a06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-fe8039f9-1310-4f19-a990-3ccf823eba57,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-6e216d42-8688-4ba5-a5f5-5d8dbefcef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9d1781b0-04d2-4a75-9b1b-a0fd870dbfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-591bb665-4332-4e13-b9a1-e79961c04d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-214709be-89bf-499f-b84e-92bfe94bfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-b07656e6-0bdc-4fcb-bcc8-b6977445d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-cc1ec082-8571-4c23-8109-eea2f8ffeef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483536887-172.17.0.12-1597456371132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-f62cdf59-16ec-4943-af06-1fc3686b8921,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-2a3e3127-35c6-4d03-9b99-d0b336740bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-4a5fb1bb-9c92-4402-b6f1-de96bb29d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-ec4313d9-9b41-489d-9c6f-325b0e406906,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-8f471e14-dd22-4759-a096-f7e52db4153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-3e992516-2862-45e9-9964-55a8b9989ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-c537cf47-80e8-48aa-a836-c987f48699d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-8838b803-8a5f-4550-987b-f723941106ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483536887-172.17.0.12-1597456371132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-f62cdf59-16ec-4943-af06-1fc3686b8921,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-2a3e3127-35c6-4d03-9b99-d0b336740bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-4a5fb1bb-9c92-4402-b6f1-de96bb29d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-ec4313d9-9b41-489d-9c6f-325b0e406906,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-8f471e14-dd22-4759-a096-f7e52db4153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-3e992516-2862-45e9-9964-55a8b9989ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-c537cf47-80e8-48aa-a836-c987f48699d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-8838b803-8a5f-4550-987b-f723941106ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806752796-172.17.0.12-1597456673792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-8dde484d-4874-476c-8e40-1811e4296bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d75b3c51-fd1f-4111-a2d1-b27f03178bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2def4f92-4628-4e5f-9c2a-0395fd5c0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-93aaf352-aa55-42ac-94fc-2c6054caf590,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-e4cda79f-6870-48e7-994e-31c68244af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-a8e80eb8-b70a-4006-8a72-f648b83723df,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-daf92c62-4c44-4be5-a524-8c8cdfca247c,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-31e3ac17-2471-4d63-8596-b35173154a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806752796-172.17.0.12-1597456673792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-8dde484d-4874-476c-8e40-1811e4296bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d75b3c51-fd1f-4111-a2d1-b27f03178bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2def4f92-4628-4e5f-9c2a-0395fd5c0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-93aaf352-aa55-42ac-94fc-2c6054caf590,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-e4cda79f-6870-48e7-994e-31c68244af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-a8e80eb8-b70a-4006-8a72-f648b83723df,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-daf92c62-4c44-4be5-a524-8c8cdfca247c,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-31e3ac17-2471-4d63-8596-b35173154a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561453872-172.17.0.12-1597456793882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-ed77c73c-11af-417d-91e4-6b21d06b1ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-354d5854-c363-4c5c-8c52-7ae6cfbd5b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-102d2709-4f7d-48d5-bb9f-0f5c735483af,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-474ec296-e97f-41ee-8e4f-6be86499d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-a05d802d-554d-4a9b-b9df-578fed3e50af,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-3629d3f0-eb5f-42f4-8c38-9eea70c564a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-1241ed60-8677-439a-864e-a18198aa16ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1cb9db46-83f3-4fa6-849c-2e0983315211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561453872-172.17.0.12-1597456793882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-ed77c73c-11af-417d-91e4-6b21d06b1ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-354d5854-c363-4c5c-8c52-7ae6cfbd5b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-102d2709-4f7d-48d5-bb9f-0f5c735483af,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-474ec296-e97f-41ee-8e4f-6be86499d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-a05d802d-554d-4a9b-b9df-578fed3e50af,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-3629d3f0-eb5f-42f4-8c38-9eea70c564a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-1241ed60-8677-439a-864e-a18198aa16ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1cb9db46-83f3-4fa6-849c-2e0983315211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862544023-172.17.0.12-1597458413568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-410aca7f-fd55-41f2-a0b5-2db3720b901d,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-de7ffc4d-3979-495c-ae1b-0f92bba9e409,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-74955b8f-af65-434f-b56c-075a8f694b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-aafd9d2a-cf62-45fd-8331-aae6eed8f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-17eb6ec7-b2b4-4069-b004-d18e48602b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-5015d776-2c6c-4715-82fa-159990c8a644,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-4c43d5d3-eb30-4436-8ea3-ac77e064503f,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-8936951e-1be0-4e38-beaf-40df60e5abef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862544023-172.17.0.12-1597458413568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-410aca7f-fd55-41f2-a0b5-2db3720b901d,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-de7ffc4d-3979-495c-ae1b-0f92bba9e409,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-74955b8f-af65-434f-b56c-075a8f694b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-aafd9d2a-cf62-45fd-8331-aae6eed8f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-17eb6ec7-b2b4-4069-b004-d18e48602b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-5015d776-2c6c-4715-82fa-159990c8a644,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-4c43d5d3-eb30-4436-8ea3-ac77e064503f,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-8936951e-1be0-4e38-beaf-40df60e5abef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269312362-172.17.0.12-1597458569281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-0b150c3d-e9fc-47eb-9400-9e797a272da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-c91ffcf2-7a2c-43cf-8884-dc55ef63840a,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-c876a3ec-61af-4b23-9a1b-702850729f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-6c507ade-e621-4371-bdf8-abb9abb199b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c9ef6105-b785-4b08-9840-3fb23b2c0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-a01d7748-8558-4c84-ad8c-7c95909fb3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-54e025ad-e54b-4b01-abd9-2dbba70469f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b1721bef-820e-4ea4-855f-0ad74e0afa93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269312362-172.17.0.12-1597458569281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-0b150c3d-e9fc-47eb-9400-9e797a272da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-c91ffcf2-7a2c-43cf-8884-dc55ef63840a,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-c876a3ec-61af-4b23-9a1b-702850729f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-6c507ade-e621-4371-bdf8-abb9abb199b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c9ef6105-b785-4b08-9840-3fb23b2c0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-a01d7748-8558-4c84-ad8c-7c95909fb3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-54e025ad-e54b-4b01-abd9-2dbba70469f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b1721bef-820e-4ea4-855f-0ad74e0afa93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842430293-172.17.0.12-1597458869811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-fa5097df-dc22-436c-ba07-0f987a5397f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2a1ef527-eda0-4bfa-b1de-ad6775916560,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-51bcb082-3f20-4af1-981d-064ba4a4deca,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-7d862d7a-1df1-431a-b570-b7d0bb88fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e57782b7-3702-41fa-b282-677b547d0381,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-9053eea8-da90-4fde-9fc7-7d73dbc323c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-ab7a735d-7fc5-4714-b53d-2ded768a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-bff4049e-0f89-4b99-b345-d48582bd5553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842430293-172.17.0.12-1597458869811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-fa5097df-dc22-436c-ba07-0f987a5397f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2a1ef527-eda0-4bfa-b1de-ad6775916560,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-51bcb082-3f20-4af1-981d-064ba4a4deca,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-7d862d7a-1df1-431a-b570-b7d0bb88fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e57782b7-3702-41fa-b282-677b547d0381,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-9053eea8-da90-4fde-9fc7-7d73dbc323c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-ab7a735d-7fc5-4714-b53d-2ded768a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-bff4049e-0f89-4b99-b345-d48582bd5553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856487273-172.17.0.12-1597459123530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-145fc33b-f6d4-4940-9d6a-ef4b8dd63725,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-fe330bdb-597b-421d-835d-b60760f59e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-94780da3-45d5-471b-9305-d1240316ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-c591e1d6-831d-427e-99d4-e8268b649581,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-075ca127-bd89-4857-9b78-14bf21b5346c,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-192b17cb-b2d8-4079-848f-f63b80865dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-0379cce7-3eb2-4f44-96f0-3359dbd567e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-0ad3cf31-f02e-4818-9356-22fcc61a66e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856487273-172.17.0.12-1597459123530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-145fc33b-f6d4-4940-9d6a-ef4b8dd63725,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-fe330bdb-597b-421d-835d-b60760f59e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-94780da3-45d5-471b-9305-d1240316ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-c591e1d6-831d-427e-99d4-e8268b649581,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-075ca127-bd89-4857-9b78-14bf21b5346c,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-192b17cb-b2d8-4079-848f-f63b80865dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-0379cce7-3eb2-4f44-96f0-3359dbd567e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-0ad3cf31-f02e-4818-9356-22fcc61a66e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571204422-172.17.0.12-1597459242351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-79c994b4-cf0d-4a73-a82d-6adb817bca51,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-017fe250-7021-4b38-bfb6-9bd2c5dd5f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-886c4207-4f37-4192-8a19-f4f39d8d7983,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-7b433a36-36f3-4d9f-bd3a-940de2b69d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a378edbe-0c7d-417c-b62d-67f6035764b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-f1749b6d-e009-4cde-a674-fda6ba640ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-90140e25-a0d0-4650-8c8c-87b3fd9c6459,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-3bd34e1b-e04d-4df1-b137-5e789a0866c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571204422-172.17.0.12-1597459242351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-79c994b4-cf0d-4a73-a82d-6adb817bca51,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-017fe250-7021-4b38-bfb6-9bd2c5dd5f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-886c4207-4f37-4192-8a19-f4f39d8d7983,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-7b433a36-36f3-4d9f-bd3a-940de2b69d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a378edbe-0c7d-417c-b62d-67f6035764b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-f1749b6d-e009-4cde-a674-fda6ba640ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-90140e25-a0d0-4650-8c8c-87b3fd9c6459,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-3bd34e1b-e04d-4df1-b137-5e789a0866c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178345669-172.17.0.12-1597459669636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-a8130476-2f2c-4eca-818f-8f2f710d0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-8579a523-d4ba-4749-b6b6-76676c7f6ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-15497aaa-1070-48bb-b63f-4bbfd4b3657f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-4e674993-bb07-48b0-9e3f-93e1a16baf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a31df916-53bf-4c5a-a23c-dbfca40e23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-5f7f6b18-4066-44f2-843d-61965620898a,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-6afc38db-31f4-4fe4-8f8c-cd349770dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-566af733-225d-4f7e-9f28-d4602af93aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178345669-172.17.0.12-1597459669636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-a8130476-2f2c-4eca-818f-8f2f710d0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-8579a523-d4ba-4749-b6b6-76676c7f6ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-15497aaa-1070-48bb-b63f-4bbfd4b3657f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-4e674993-bb07-48b0-9e3f-93e1a16baf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a31df916-53bf-4c5a-a23c-dbfca40e23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-5f7f6b18-4066-44f2-843d-61965620898a,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-6afc38db-31f4-4fe4-8f8c-cd349770dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-566af733-225d-4f7e-9f28-d4602af93aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362939892-172.17.0.12-1597459896507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-5782b217-99fb-4b80-bd3b-1ae8ef21d416,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-767e01c9-31f1-4569-b53a-9eecf47daf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-e78c9e7e-07c7-4e48-8d9a-5d5be8b9dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d9a2b2b0-cfeb-428b-9c74-163522909962,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-e953754b-740e-4b8f-867f-d3b9c8f9b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5d01373f-5a4b-45c5-8b49-0c0e265c9087,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-6407c0d9-7945-46b5-86e6-574b55b4e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-30d4a219-0687-4a6a-b30d-1bf2eed6f7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362939892-172.17.0.12-1597459896507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-5782b217-99fb-4b80-bd3b-1ae8ef21d416,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-767e01c9-31f1-4569-b53a-9eecf47daf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-e78c9e7e-07c7-4e48-8d9a-5d5be8b9dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d9a2b2b0-cfeb-428b-9c74-163522909962,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-e953754b-740e-4b8f-867f-d3b9c8f9b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5d01373f-5a4b-45c5-8b49-0c0e265c9087,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-6407c0d9-7945-46b5-86e6-574b55b4e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-30d4a219-0687-4a6a-b30d-1bf2eed6f7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938163996-172.17.0.12-1597460634804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-5aca0b96-8ed1-4ca5-aeea-13949e98b5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-80c25eca-1d67-46d8-ad8f-7840edeb4547,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-6845e9b0-1f96-4d4f-8bfe-ae5a3441c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-dc1d1a5f-a54f-4869-8d00-de578a60af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-a5a3495e-9bd1-4536-8f9c-3f9f53d9db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-c2ee5042-7bf5-4f82-a820-586d5913e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-10073503-2a5b-4505-a52d-91b21f229a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-59d7b52f-c0e1-4010-bf2e-18492c61c3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938163996-172.17.0.12-1597460634804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-5aca0b96-8ed1-4ca5-aeea-13949e98b5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-80c25eca-1d67-46d8-ad8f-7840edeb4547,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-6845e9b0-1f96-4d4f-8bfe-ae5a3441c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-dc1d1a5f-a54f-4869-8d00-de578a60af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-a5a3495e-9bd1-4536-8f9c-3f9f53d9db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-c2ee5042-7bf5-4f82-a820-586d5913e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-10073503-2a5b-4505-a52d-91b21f229a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-59d7b52f-c0e1-4010-bf2e-18492c61c3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2879266-172.17.0.12-1597460673235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-e728abf6-7ac2-4d4d-bfd2-63485864c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-94a8ae6d-caba-49f2-8ed4-90a2fac111a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-964cdcfd-b4d1-4a4f-8dde-44362bb1e152,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-1009317e-2bb8-473c-902f-bef36948b779,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-d9fe67fd-155f-4262-bae2-5fab2d07f513,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-80f6d1dd-1e25-4007-a668-63d4d25a62b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-442f6cc1-f73b-4b20-8ae0-37f7c57cc493,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-203c5d45-df8e-4db1-8f5e-4731184b55ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2879266-172.17.0.12-1597460673235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-e728abf6-7ac2-4d4d-bfd2-63485864c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-94a8ae6d-caba-49f2-8ed4-90a2fac111a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-964cdcfd-b4d1-4a4f-8dde-44362bb1e152,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-1009317e-2bb8-473c-902f-bef36948b779,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-d9fe67fd-155f-4262-bae2-5fab2d07f513,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-80f6d1dd-1e25-4007-a668-63d4d25a62b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-442f6cc1-f73b-4b20-8ae0-37f7c57cc493,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-203c5d45-df8e-4db1-8f5e-4731184b55ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888095925-172.17.0.12-1597461046048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-aa10d0b1-a3f1-4cae-bed3-73e75c4e9b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-6c204f8c-ad85-40f5-80ba-888f5e513dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-f78fbed8-f235-479d-bada-a5e65b78828c,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-ec173487-a715-44da-839d-690ca496e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-136deca2-87da-4331-9ddd-1fb5243e8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-4e0864c1-a240-4f04-971e-6c03a5efc9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-ee2bb72a-f0e9-4e4e-bc88-5140d8dd0589,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-19b57eed-df1d-43e0-a932-362bcd33e3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888095925-172.17.0.12-1597461046048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-aa10d0b1-a3f1-4cae-bed3-73e75c4e9b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-6c204f8c-ad85-40f5-80ba-888f5e513dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-f78fbed8-f235-479d-bada-a5e65b78828c,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-ec173487-a715-44da-839d-690ca496e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-136deca2-87da-4331-9ddd-1fb5243e8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-4e0864c1-a240-4f04-971e-6c03a5efc9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-ee2bb72a-f0e9-4e4e-bc88-5140d8dd0589,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-19b57eed-df1d-43e0-a932-362bcd33e3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181889133-172.17.0.12-1597461164613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-6bc8efdd-351d-4cd0-a120-226d7e03399b,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-2f6f116e-df6b-43bb-9ae8-1ad9490f021e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ab4f04e2-a656-4ad8-a574-4d10075ff26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4fed83fd-631f-41c3-8e6a-804770dd6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-88cb5301-b6eb-4c75-a279-b5a9960125a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5b8d093b-4b31-4c07-a187-6de03c6c0dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-2e810ae5-cefc-44d2-962b-22ce9bbfee24,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-cf5ca26c-3f5a-4ff7-80d4-b4056ca9082c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181889133-172.17.0.12-1597461164613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-6bc8efdd-351d-4cd0-a120-226d7e03399b,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-2f6f116e-df6b-43bb-9ae8-1ad9490f021e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ab4f04e2-a656-4ad8-a574-4d10075ff26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4fed83fd-631f-41c3-8e6a-804770dd6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-88cb5301-b6eb-4c75-a279-b5a9960125a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5b8d093b-4b31-4c07-a187-6de03c6c0dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-2e810ae5-cefc-44d2-962b-22ce9bbfee24,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-cf5ca26c-3f5a-4ff7-80d4-b4056ca9082c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693885956-172.17.0.12-1597461367125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-2e4b6c81-2d44-40ce-9022-b84283305467,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-c5ba8834-23d7-4730-ad2e-83d05f2c254e,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-816655af-c021-4e78-a867-300ec5a6c084,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-a751c1ef-a515-4ef9-9c20-3c6fa94f57e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-1727ca39-b2b6-468d-9191-a1859e73ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5bf0df9f-98e4-43fe-8c0b-cc7cf505ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-dd65fe03-69e1-4601-9f9c-0a2271cb310b,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-1f2f113f-8598-40ee-9c31-ec5f4305194f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693885956-172.17.0.12-1597461367125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-2e4b6c81-2d44-40ce-9022-b84283305467,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-c5ba8834-23d7-4730-ad2e-83d05f2c254e,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-816655af-c021-4e78-a867-300ec5a6c084,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-a751c1ef-a515-4ef9-9c20-3c6fa94f57e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-1727ca39-b2b6-468d-9191-a1859e73ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5bf0df9f-98e4-43fe-8c0b-cc7cf505ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-dd65fe03-69e1-4601-9f9c-0a2271cb310b,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-1f2f113f-8598-40ee-9c31-ec5f4305194f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634421926-172.17.0.12-1597461643849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-43fd2f5f-e322-4f38-945a-f03a56b2a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-621d862f-43bd-46cb-9d37-268ad0e5ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-86b1ad0e-9837-4330-8f91-0ee83d84c5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-33835fa8-d540-497d-8a49-01a3f899985e,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-e8031072-9a65-4883-9eb5-bae16f7afd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-87e3e0f1-e7b2-4509-be79-28197179e178,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-493f6fe3-f678-492d-89f7-371f78da2642,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-ddf6664f-4c1c-4f1b-b20e-b40f7d0d4cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634421926-172.17.0.12-1597461643849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-43fd2f5f-e322-4f38-945a-f03a56b2a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-621d862f-43bd-46cb-9d37-268ad0e5ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-86b1ad0e-9837-4330-8f91-0ee83d84c5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-33835fa8-d540-497d-8a49-01a3f899985e,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-e8031072-9a65-4883-9eb5-bae16f7afd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-87e3e0f1-e7b2-4509-be79-28197179e178,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-493f6fe3-f678-492d-89f7-371f78da2642,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-ddf6664f-4c1c-4f1b-b20e-b40f7d0d4cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5807
