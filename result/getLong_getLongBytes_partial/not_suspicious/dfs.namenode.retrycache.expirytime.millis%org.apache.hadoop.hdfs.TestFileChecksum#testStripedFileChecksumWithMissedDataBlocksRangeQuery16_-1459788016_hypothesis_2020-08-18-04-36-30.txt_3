reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983231838-172.17.0.20-1597726593537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-9864a082-5fd8-4f5d-9c76-e0947d7d743f,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-50d095d5-9cb4-455c-ad3d-9790f4fc4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-6793d7d7-ba24-4557-89f1-d0edba47b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-c42a12ae-06dd-4c2b-98eb-20c6449671c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-a077e75d-e277-48c0-86e7-d5fae4097b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-69e79aca-5417-40b3-9ddf-6986427e3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-78e05c4e-11c0-4b8d-b945-5b931e5aff03,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-92f412ac-18ea-4c38-b6c3-76988afd1bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983231838-172.17.0.20-1597726593537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-9864a082-5fd8-4f5d-9c76-e0947d7d743f,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-50d095d5-9cb4-455c-ad3d-9790f4fc4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-6793d7d7-ba24-4557-89f1-d0edba47b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-c42a12ae-06dd-4c2b-98eb-20c6449671c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-a077e75d-e277-48c0-86e7-d5fae4097b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-69e79aca-5417-40b3-9ddf-6986427e3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-78e05c4e-11c0-4b8d-b945-5b931e5aff03,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-92f412ac-18ea-4c38-b6c3-76988afd1bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449253642-172.17.0.20-1597727149623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-ef75741a-8049-43c4-ad4b-8a59cb4828c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-051baa19-3ea8-4ff0-aad5-55e1e85fd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a8596a4d-ec7c-4dc7-a317-9b5f26bca5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-ad59c36c-0534-4eb4-8748-a1c8f68440fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-e1b0ec46-de89-4eb2-8ac5-2a9ba740cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e6e4cd2e-244c-43cc-ba90-6d6b65082e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a54de257-9f06-418c-94fe-955eabc5389a,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-10b42617-37ca-4638-b3cd-aa5798bb51ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449253642-172.17.0.20-1597727149623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-ef75741a-8049-43c4-ad4b-8a59cb4828c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-051baa19-3ea8-4ff0-aad5-55e1e85fd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a8596a4d-ec7c-4dc7-a317-9b5f26bca5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-ad59c36c-0534-4eb4-8748-a1c8f68440fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-e1b0ec46-de89-4eb2-8ac5-2a9ba740cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e6e4cd2e-244c-43cc-ba90-6d6b65082e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a54de257-9f06-418c-94fe-955eabc5389a,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-10b42617-37ca-4638-b3cd-aa5798bb51ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817911851-172.17.0.20-1597728205174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-edab2d40-cb7a-4837-a0c0-fc4bd172522d,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1d195378-a0cf-408e-b6f3-2e081573b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ee574a63-a79a-40f4-9e80-e0767373cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-b01bb3a5-fdf5-48a1-8241-c4335bbb91ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-3fec94b9-849a-4716-8cd7-f81face98b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-96ef61f1-e807-4f1e-8779-8a396d5f46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-7812c4af-859a-4d5d-9d52-02ad4f8cd135,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-6d3f8521-6a0b-405f-9eed-d3cb7f2ebf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817911851-172.17.0.20-1597728205174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-edab2d40-cb7a-4837-a0c0-fc4bd172522d,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1d195378-a0cf-408e-b6f3-2e081573b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ee574a63-a79a-40f4-9e80-e0767373cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-b01bb3a5-fdf5-48a1-8241-c4335bbb91ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-3fec94b9-849a-4716-8cd7-f81face98b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-96ef61f1-e807-4f1e-8779-8a396d5f46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-7812c4af-859a-4d5d-9d52-02ad4f8cd135,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-6d3f8521-6a0b-405f-9eed-d3cb7f2ebf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935507309-172.17.0.20-1597728380584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-9a9c966a-fb26-4c6b-9be4-48a8f7e8135d,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-321d7439-9580-4ea0-a151-ff8c3af1b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-f5c9647d-b6ff-4c0d-9659-11ac188bef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d79debb2-be99-425e-8c77-1066ef5e1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-5532b778-0e1b-4ec3-85e6-e97f73d1edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-31d88af6-d775-4a34-a6be-170962f36a91,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-3ac68fa9-afc1-4e85-927c-90732c89b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-34289ad1-6986-4d59-aee9-75e5e833d834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935507309-172.17.0.20-1597728380584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-9a9c966a-fb26-4c6b-9be4-48a8f7e8135d,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-321d7439-9580-4ea0-a151-ff8c3af1b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-f5c9647d-b6ff-4c0d-9659-11ac188bef3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d79debb2-be99-425e-8c77-1066ef5e1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-5532b778-0e1b-4ec3-85e6-e97f73d1edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-31d88af6-d775-4a34-a6be-170962f36a91,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-3ac68fa9-afc1-4e85-927c-90732c89b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-34289ad1-6986-4d59-aee9-75e5e833d834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153641765-172.17.0.20-1597728415319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-ea5b8914-14cc-430d-a884-bcbe7e75ad68,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-b7c13cba-b2b5-4f84-9407-9360a4bea218,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-8c3850e0-0792-4753-982d-4e9bc8c5202c,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-eb157a75-64cc-4f0d-af6c-6ac9dd039870,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-24ad246f-e745-4fe1-9dd3-95f07253316b,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-914dbeb0-2750-470f-a34c-fdeaf40abf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-568210e3-7a77-40eb-bd2b-fd851c4cba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-0d62789d-6003-4b50-9c90-4ffa84659ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153641765-172.17.0.20-1597728415319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-ea5b8914-14cc-430d-a884-bcbe7e75ad68,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-b7c13cba-b2b5-4f84-9407-9360a4bea218,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-8c3850e0-0792-4753-982d-4e9bc8c5202c,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-eb157a75-64cc-4f0d-af6c-6ac9dd039870,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-24ad246f-e745-4fe1-9dd3-95f07253316b,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-914dbeb0-2750-470f-a34c-fdeaf40abf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-568210e3-7a77-40eb-bd2b-fd851c4cba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-0d62789d-6003-4b50-9c90-4ffa84659ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690331237-172.17.0.20-1597728692518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-e3e940bb-8948-48d7-8c81-4007f2a12628,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b08a4388-929e-4751-8a2b-5dcfffd66963,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-47a2cfcf-e8ee-4d42-95a1-765ee8f0e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-fa44cbe5-94ca-446a-b1ac-16538bab1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-26bf0de0-aedd-4bc4-ab6f-83b62b73fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-8df27d76-d36e-4291-b240-7c876829043b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-17c72e0a-e666-4820-b1c5-6a95af451e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-f7ce472b-d1c1-40e6-9333-069f0b7611bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690331237-172.17.0.20-1597728692518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-e3e940bb-8948-48d7-8c81-4007f2a12628,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b08a4388-929e-4751-8a2b-5dcfffd66963,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-47a2cfcf-e8ee-4d42-95a1-765ee8f0e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-fa44cbe5-94ca-446a-b1ac-16538bab1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-26bf0de0-aedd-4bc4-ab6f-83b62b73fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-8df27d76-d36e-4291-b240-7c876829043b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-17c72e0a-e666-4820-b1c5-6a95af451e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-f7ce472b-d1c1-40e6-9333-069f0b7611bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50544448-172.17.0.20-1597729667337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-76706173-27bd-4f4a-8a7d-e9be4563f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-8541a06a-f7e7-4973-b088-06332eb4bfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-1288a934-5fd2-49ad-9da8-fe99120794f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-f8031e76-386b-4da9-a8bb-10af11b7e958,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-5045288f-bb0a-4ebb-a476-3323c573d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-de4121d2-6152-4b20-adf9-a7867d14b4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-1c7d8836-d927-4d06-b0c6-61b1bd844de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c7ac08af-0baa-4866-b627-0c313b496610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50544448-172.17.0.20-1597729667337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-76706173-27bd-4f4a-8a7d-e9be4563f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-8541a06a-f7e7-4973-b088-06332eb4bfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-1288a934-5fd2-49ad-9da8-fe99120794f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-f8031e76-386b-4da9-a8bb-10af11b7e958,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-5045288f-bb0a-4ebb-a476-3323c573d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-de4121d2-6152-4b20-adf9-a7867d14b4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-1c7d8836-d927-4d06-b0c6-61b1bd844de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c7ac08af-0baa-4866-b627-0c313b496610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670286501-172.17.0.20-1597729997471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39240,DS-7c42167d-907f-4fff-ad38-79ff097f0ece,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-2c502ee8-f874-45c4-8dc3-e4de850b170d,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ebd2f854-c73d-4fe7-8603-046058179706,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-f9be371a-00b7-4cd9-a564-8d13b71792a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-5c1ca3f7-8ab0-4503-ad1a-1730ef07c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3301131f-fa4b-43a5-bdd4-128df42551e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-0194815f-a23e-48f9-9223-f72308cebf24,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b75e344f-e773-4d1f-81b8-5fa16ef78c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670286501-172.17.0.20-1597729997471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39240,DS-7c42167d-907f-4fff-ad38-79ff097f0ece,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-2c502ee8-f874-45c4-8dc3-e4de850b170d,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ebd2f854-c73d-4fe7-8603-046058179706,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-f9be371a-00b7-4cd9-a564-8d13b71792a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-5c1ca3f7-8ab0-4503-ad1a-1730ef07c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3301131f-fa4b-43a5-bdd4-128df42551e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-0194815f-a23e-48f9-9223-f72308cebf24,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b75e344f-e773-4d1f-81b8-5fa16ef78c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828440206-172.17.0.20-1597730177786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-f1393196-60d7-4206-b862-f95c6bf896c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-9c51e66b-bcdc-4b72-9d01-d31bb817d988,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-9214fa36-127a-4aac-a5c0-83f0ecc0878e,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-25b255fd-8ba4-4158-b349-055450bb3789,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-29664fa9-08fd-4884-a513-36fff5e2e509,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-19920a58-e76f-43a8-8444-808e4dc361d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8a6a35c8-61a3-41a3-9860-5b3194c47119,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-3140e887-63a6-4f52-b2b4-f9f8c6103613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828440206-172.17.0.20-1597730177786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-f1393196-60d7-4206-b862-f95c6bf896c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-9c51e66b-bcdc-4b72-9d01-d31bb817d988,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-9214fa36-127a-4aac-a5c0-83f0ecc0878e,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-25b255fd-8ba4-4158-b349-055450bb3789,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-29664fa9-08fd-4884-a513-36fff5e2e509,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-19920a58-e76f-43a8-8444-808e4dc361d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8a6a35c8-61a3-41a3-9860-5b3194c47119,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-3140e887-63a6-4f52-b2b4-f9f8c6103613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309699584-172.17.0.20-1597730483744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-2d51be66-deb2-47dd-ab32-b2215ceb8b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-f9f37e0b-ea6f-4692-b42e-81e0bda3f988,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-90c09cab-fb1e-4c0d-a83f-48b01715f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-1fd82c6b-1a54-43a4-a06d-855e65cf6039,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-ec6cd9fa-52d0-42d3-8030-9b6a5475b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-dad7987e-72ec-4c0a-9222-be5a98624fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-eb18467a-5ca7-4bbf-be6d-d7965e065bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-802162dd-8b39-4494-8e6f-8c64117e14c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309699584-172.17.0.20-1597730483744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-2d51be66-deb2-47dd-ab32-b2215ceb8b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-f9f37e0b-ea6f-4692-b42e-81e0bda3f988,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-90c09cab-fb1e-4c0d-a83f-48b01715f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-1fd82c6b-1a54-43a4-a06d-855e65cf6039,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-ec6cd9fa-52d0-42d3-8030-9b6a5475b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-dad7987e-72ec-4c0a-9222-be5a98624fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-eb18467a-5ca7-4bbf-be6d-d7965e065bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-802162dd-8b39-4494-8e6f-8c64117e14c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145006154-172.17.0.20-1597730517134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41971,DS-e2a6bb2b-a9e0-4cb6-908b-d74fc6f2b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e18029b2-0497-4956-9ddc-9b6eebf475ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c51b4eb-fa48-4718-9219-ad3eedfcc02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-c39ad2ec-bc38-4250-8c28-fca90caa8c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5d46e32d-4b96-445c-af3e-8d6f4c904ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-914b9d27-aa3d-4c48-9624-62c04b597147,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-d088f13f-bcba-45e7-8c0e-bb9b8f139bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-76cb5cd4-2554-4e29-9679-aec425545c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145006154-172.17.0.20-1597730517134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41971,DS-e2a6bb2b-a9e0-4cb6-908b-d74fc6f2b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e18029b2-0497-4956-9ddc-9b6eebf475ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c51b4eb-fa48-4718-9219-ad3eedfcc02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-c39ad2ec-bc38-4250-8c28-fca90caa8c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5d46e32d-4b96-445c-af3e-8d6f4c904ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-914b9d27-aa3d-4c48-9624-62c04b597147,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-d088f13f-bcba-45e7-8c0e-bb9b8f139bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-76cb5cd4-2554-4e29-9679-aec425545c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460361452-172.17.0.20-1597730633714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-df0fa9fc-f240-4ef0-949f-45c5cbf7f092,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-fb5f4619-abaa-43b1-b9cf-d25dab7ebfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-2505fc3f-c91d-4822-89ab-ced781f9942b,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-771756bf-26b3-4031-99dc-8b35558c0aab,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-e711eb84-592f-4a36-b144-54f327987c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-e604cad8-1442-4169-93db-8f304a137230,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-ad371eea-02ca-4500-8066-89cdecd98d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a363c338-fcd1-4f4d-ab66-4ff925f56991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460361452-172.17.0.20-1597730633714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-df0fa9fc-f240-4ef0-949f-45c5cbf7f092,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-fb5f4619-abaa-43b1-b9cf-d25dab7ebfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-2505fc3f-c91d-4822-89ab-ced781f9942b,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-771756bf-26b3-4031-99dc-8b35558c0aab,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-e711eb84-592f-4a36-b144-54f327987c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-e604cad8-1442-4169-93db-8f304a137230,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-ad371eea-02ca-4500-8066-89cdecd98d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a363c338-fcd1-4f4d-ab66-4ff925f56991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5477
