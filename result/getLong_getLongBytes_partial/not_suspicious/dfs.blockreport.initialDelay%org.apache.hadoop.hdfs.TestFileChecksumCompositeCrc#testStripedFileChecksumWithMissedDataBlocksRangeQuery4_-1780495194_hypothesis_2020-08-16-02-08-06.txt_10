reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730431510-172.17.0.6-1597543944332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-92d9216d-7a1b-45b6-9ccc-5e9cfef65488,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-58abde2c-46b9-4849-bba4-066345aa9653,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-04cc30d4-03b9-432a-8afe-35c95c99bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-f293a7ba-8b07-4834-a191-1d0cf33b9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-6202d179-4732-4ac9-8e39-680e7fc46602,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-a33abcf2-3349-4cb8-958d-8fe58429b882,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-8a11eb20-36c2-4902-8001-2764c44b9c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-8927b765-ab90-4f9e-9764-9eec840cbf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730431510-172.17.0.6-1597543944332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-92d9216d-7a1b-45b6-9ccc-5e9cfef65488,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-58abde2c-46b9-4849-bba4-066345aa9653,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-04cc30d4-03b9-432a-8afe-35c95c99bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-f293a7ba-8b07-4834-a191-1d0cf33b9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-6202d179-4732-4ac9-8e39-680e7fc46602,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-a33abcf2-3349-4cb8-958d-8fe58429b882,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-8a11eb20-36c2-4902-8001-2764c44b9c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-8927b765-ab90-4f9e-9764-9eec840cbf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185269332-172.17.0.6-1597544221644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-474f11a2-fa3e-468f-929c-8a75753337d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1366dcb9-ac4d-4ec0-ae16-50a59bd958be,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-cffee24c-4787-44aa-90d1-825bda459ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-e44d7fcc-40b3-432a-a479-2918aae76baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-eeb5e5e6-26dc-461c-b38d-c9d951c289d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-eae15206-bbc8-4fb2-9188-990c4d4ba092,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-26d2e48a-a9e3-4446-864b-0454379f2681,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-28deaf27-ef41-4540-b727-324971db5f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185269332-172.17.0.6-1597544221644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-474f11a2-fa3e-468f-929c-8a75753337d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1366dcb9-ac4d-4ec0-ae16-50a59bd958be,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-cffee24c-4787-44aa-90d1-825bda459ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-e44d7fcc-40b3-432a-a479-2918aae76baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-eeb5e5e6-26dc-461c-b38d-c9d951c289d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-eae15206-bbc8-4fb2-9188-990c4d4ba092,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-26d2e48a-a9e3-4446-864b-0454379f2681,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-28deaf27-ef41-4540-b727-324971db5f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757344220-172.17.0.6-1597544255514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4080332b-d075-41fc-aba5-3e30f1428378,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-dccf07ec-e870-47ca-adab-a01f49850fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-76a40ced-8955-41ad-81d1-126b2c685996,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5c22dc64-c1d3-408a-9cb3-fb71714cf8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-c6098872-7d2b-4425-a6c4-ca66dbb24cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-9b3a945e-3d5e-4965-bfd1-2995b2078d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-230d093f-d76c-4d17-8f48-fb8ebfe26194,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-304bd41e-012f-46d2-bd4e-584ce60c3dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757344220-172.17.0.6-1597544255514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4080332b-d075-41fc-aba5-3e30f1428378,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-dccf07ec-e870-47ca-adab-a01f49850fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-76a40ced-8955-41ad-81d1-126b2c685996,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5c22dc64-c1d3-408a-9cb3-fb71714cf8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-c6098872-7d2b-4425-a6c4-ca66dbb24cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-9b3a945e-3d5e-4965-bfd1-2995b2078d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-230d093f-d76c-4d17-8f48-fb8ebfe26194,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-304bd41e-012f-46d2-bd4e-584ce60c3dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965476456-172.17.0.6-1597544515324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39529,DS-48540600-39e9-490c-be54-b57875f4b100,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-16f42210-94e3-4c4c-9f6f-2afd0bc6a1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-aef9758a-2c7f-4644-ab1a-f425ad546c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-e215c448-f299-4253-8ba9-78e2cfc3ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-04eff781-d0d6-493c-9e8f-18d500042add,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-30f229f5-cd42-4c3d-992a-132b41919021,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-20bc9109-16a9-490e-8fb7-7a20981cd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-fc4736e4-e246-4ec5-ac97-44401499c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965476456-172.17.0.6-1597544515324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39529,DS-48540600-39e9-490c-be54-b57875f4b100,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-16f42210-94e3-4c4c-9f6f-2afd0bc6a1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-aef9758a-2c7f-4644-ab1a-f425ad546c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-e215c448-f299-4253-8ba9-78e2cfc3ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-04eff781-d0d6-493c-9e8f-18d500042add,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-30f229f5-cd42-4c3d-992a-132b41919021,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-20bc9109-16a9-490e-8fb7-7a20981cd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-fc4736e4-e246-4ec5-ac97-44401499c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940968590-172.17.0.6-1597544890297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-3a3718a4-1a92-4306-be8e-3efe488c98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-8063a0c2-29c3-4f7b-ad48-2ca844f4b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-52ef2ac1-6b0b-49c3-a429-9586967529ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-304d89a8-c52b-4b92-910e-630dda4b3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-c1a97800-e847-4fba-b1e3-1f8a143529be,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2551c01d-d71c-4e67-90ca-419170e9187a,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-66b606f2-d0a8-4cdb-beb9-b426b19e5379,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c8a88a0b-acff-41bc-a8e9-4e66b8c24810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940968590-172.17.0.6-1597544890297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-3a3718a4-1a92-4306-be8e-3efe488c98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-8063a0c2-29c3-4f7b-ad48-2ca844f4b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-52ef2ac1-6b0b-49c3-a429-9586967529ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-304d89a8-c52b-4b92-910e-630dda4b3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-c1a97800-e847-4fba-b1e3-1f8a143529be,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2551c01d-d71c-4e67-90ca-419170e9187a,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-66b606f2-d0a8-4cdb-beb9-b426b19e5379,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c8a88a0b-acff-41bc-a8e9-4e66b8c24810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986503081-172.17.0.6-1597545365788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-a46e5d54-e5a6-4203-b984-dee17f612b81,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d073a686-9d4a-4e66-accb-7c6599baf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-b373bb4e-a295-47ee-af66-f629f75eebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-87b011fe-e8fc-447e-a7dd-1a92e37833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-80485531-47d5-41b8-a45c-2f3a092acd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9f546d34-50a7-4739-8608-a13844799b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-e778d3ff-7431-4031-9edd-fcefaa95a930,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bac9c883-2754-41c8-bad1-e1aa422aac1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986503081-172.17.0.6-1597545365788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-a46e5d54-e5a6-4203-b984-dee17f612b81,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d073a686-9d4a-4e66-accb-7c6599baf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-b373bb4e-a295-47ee-af66-f629f75eebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-87b011fe-e8fc-447e-a7dd-1a92e37833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-80485531-47d5-41b8-a45c-2f3a092acd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9f546d34-50a7-4739-8608-a13844799b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-e778d3ff-7431-4031-9edd-fcefaa95a930,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bac9c883-2754-41c8-bad1-e1aa422aac1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557498288-172.17.0.6-1597545466078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42472,DS-17ae0ad1-5413-4857-899d-36752b9c9186,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-93ab2fd2-fbc3-415a-b541-34927d77be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-eaaf074c-2e1e-4171-8833-88eca9dd7721,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e937884d-5f46-419d-9c4b-b6feb68125c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-93e28c15-afd0-40a9-a6e3-adfad409ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-bc609668-c7db-45d5-9cc8-8d2c1187adec,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-f47d5449-eb1e-4720-a4ed-854197da8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-6b3dbfba-4538-4eb7-8482-cf5441efe0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557498288-172.17.0.6-1597545466078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42472,DS-17ae0ad1-5413-4857-899d-36752b9c9186,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-93ab2fd2-fbc3-415a-b541-34927d77be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-eaaf074c-2e1e-4171-8833-88eca9dd7721,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e937884d-5f46-419d-9c4b-b6feb68125c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-93e28c15-afd0-40a9-a6e3-adfad409ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-bc609668-c7db-45d5-9cc8-8d2c1187adec,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-f47d5449-eb1e-4720-a4ed-854197da8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-6b3dbfba-4538-4eb7-8482-cf5441efe0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097119575-172.17.0.6-1597545858449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-beb6af5b-05c9-4b67-ac86-5fcb20a7bb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ccd09944-e034-4e93-b6a1-396c66b3a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-22246352-dbfe-48a5-8ca3-4e91d548bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b29fdfb6-75b2-49a5-aa3e-625502ae800b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-07516a10-e986-4123-8816-40f972e37c73,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bc5e583c-2a35-43f7-aba2-732062ed0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-984c3115-50a0-4ff0-a88c-e07a649424d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4bd3fe7f-8bc6-43f5-a171-2ae362df4d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097119575-172.17.0.6-1597545858449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-beb6af5b-05c9-4b67-ac86-5fcb20a7bb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ccd09944-e034-4e93-b6a1-396c66b3a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-22246352-dbfe-48a5-8ca3-4e91d548bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b29fdfb6-75b2-49a5-aa3e-625502ae800b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-07516a10-e986-4123-8816-40f972e37c73,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bc5e583c-2a35-43f7-aba2-732062ed0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-984c3115-50a0-4ff0-a88c-e07a649424d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4bd3fe7f-8bc6-43f5-a171-2ae362df4d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721918709-172.17.0.6-1597545965788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-43f7dab4-6a9e-4b39-8f8a-d9efd7135dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-b6016a09-1c38-407a-a2d8-e56182af2212,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6f1ca3f4-ff14-45e2-a9aa-8af967594ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-4d082059-ea3a-432a-82f4-42fcf8257663,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-72a3912e-66f3-4761-b931-f4a7c9632bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-c386e490-13bd-478e-8fe8-fd2ddada80ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-bc393231-02fb-49be-b19c-360e86dd7727,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ae0ab93b-5d7d-49fa-bf70-533b413fad12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721918709-172.17.0.6-1597545965788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-43f7dab4-6a9e-4b39-8f8a-d9efd7135dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-b6016a09-1c38-407a-a2d8-e56182af2212,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6f1ca3f4-ff14-45e2-a9aa-8af967594ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-4d082059-ea3a-432a-82f4-42fcf8257663,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-72a3912e-66f3-4761-b931-f4a7c9632bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-c386e490-13bd-478e-8fe8-fd2ddada80ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-bc393231-02fb-49be-b19c-360e86dd7727,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ae0ab93b-5d7d-49fa-bf70-533b413fad12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143813679-172.17.0.6-1597546302452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-cbc14036-5ca5-4178-8fde-a6ac6799fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-25f3412a-e434-43be-9219-9aa16253cded,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-cdb8cbd4-0a2e-4288-8283-43f8cda7aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-bf0a818f-1e9d-4b7d-9b9d-65f7b05103f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-10f0f3d8-8779-4c3a-97b2-868fea0867b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1f485057-ab3c-49c6-9dbe-65c922057146,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-899caab0-1330-4a4a-86da-c7a0ad9fd33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-21e2118a-9a18-4c8d-8a22-1d614c1745df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143813679-172.17.0.6-1597546302452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-cbc14036-5ca5-4178-8fde-a6ac6799fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-25f3412a-e434-43be-9219-9aa16253cded,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-cdb8cbd4-0a2e-4288-8283-43f8cda7aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-bf0a818f-1e9d-4b7d-9b9d-65f7b05103f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-10f0f3d8-8779-4c3a-97b2-868fea0867b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1f485057-ab3c-49c6-9dbe-65c922057146,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-899caab0-1330-4a4a-86da-c7a0ad9fd33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-21e2118a-9a18-4c8d-8a22-1d614c1745df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636703291-172.17.0.6-1597546342211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-837e951f-eda4-4544-8cf6-1cabbe60e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-0bb222cf-5237-4bbe-b444-5570a23fe078,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-c9d01486-24f5-45d8-9220-3c7b13cdce70,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-0ec0c166-3807-4326-b666-f5e60d346ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-e0cad2d9-5c2a-417b-97a5-623decfe92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-8ce1f2f5-ae62-4198-9e33-c269e4495f66,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-60346e29-4652-4f5a-a5c0-48618f0ef1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-25071682-fd01-4971-90a1-603549d0b348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636703291-172.17.0.6-1597546342211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-837e951f-eda4-4544-8cf6-1cabbe60e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-0bb222cf-5237-4bbe-b444-5570a23fe078,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-c9d01486-24f5-45d8-9220-3c7b13cdce70,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-0ec0c166-3807-4326-b666-f5e60d346ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-e0cad2d9-5c2a-417b-97a5-623decfe92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-8ce1f2f5-ae62-4198-9e33-c269e4495f66,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-60346e29-4652-4f5a-a5c0-48618f0ef1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-25071682-fd01-4971-90a1-603549d0b348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496134955-172.17.0.6-1597546485191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-fca02379-f885-46a6-a65d-e4f19b39d347,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-8f437019-be91-4131-a094-2793208d85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-21ad32a2-30b5-40ee-a1da-0d84c569fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-c577c4ec-8794-49eb-b144-13597dd8a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8f3942c0-5b2c-4531-8d1c-520b3ff9fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-896c27cf-9d84-4aff-9afa-4fd05f6f4c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-d53c54ee-c53d-4afd-9e09-86b3aa5965ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-98b0a4c9-71d8-4a91-9bf2-d2efc0871e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496134955-172.17.0.6-1597546485191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-fca02379-f885-46a6-a65d-e4f19b39d347,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-8f437019-be91-4131-a094-2793208d85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-21ad32a2-30b5-40ee-a1da-0d84c569fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-c577c4ec-8794-49eb-b144-13597dd8a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8f3942c0-5b2c-4531-8d1c-520b3ff9fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-896c27cf-9d84-4aff-9afa-4fd05f6f4c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-d53c54ee-c53d-4afd-9e09-86b3aa5965ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-98b0a4c9-71d8-4a91-9bf2-d2efc0871e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353055703-172.17.0.6-1597546560837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-79293483-d471-44e1-8583-babd6d14b886,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-f60a5911-39c9-41f0-a769-6a8d0193a709,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-7cb0a63c-9a3b-4e70-84ec-01cdc1aff604,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-fa8fdf71-493f-4d58-96a7-d15661a23ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-a3d25b76-bb80-4e95-a52d-c9111a73d959,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-0d1e3bb0-5713-4a86-9d01-82122a98ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-fbb4ed07-ab24-4118-8a89-f35337a759f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-7f95ffa4-d67f-4274-911c-6af83fcc70c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353055703-172.17.0.6-1597546560837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-79293483-d471-44e1-8583-babd6d14b886,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-f60a5911-39c9-41f0-a769-6a8d0193a709,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-7cb0a63c-9a3b-4e70-84ec-01cdc1aff604,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-fa8fdf71-493f-4d58-96a7-d15661a23ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-a3d25b76-bb80-4e95-a52d-c9111a73d959,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-0d1e3bb0-5713-4a86-9d01-82122a98ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-fbb4ed07-ab24-4118-8a89-f35337a759f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-7f95ffa4-d67f-4274-911c-6af83fcc70c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966673048-172.17.0.6-1597546645138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-b2244524-1a8c-4785-9a85-2b88d6117f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-0ac46086-a97b-4ea6-8c4a-dda32632f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-23e0924e-4053-4284-b25b-ecb0f41e2102,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b383a7e2-a35e-48f2-9ce6-84da69c1e602,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-ff93ab98-fdbd-4e4c-acd2-5bbc0ada38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-b859ade3-47d9-4c6f-8094-49388b6334fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c8443c1b-e263-44ab-bfcb-211d910b2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-4dcb684a-003a-47a3-b776-cc8f516bb5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966673048-172.17.0.6-1597546645138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-b2244524-1a8c-4785-9a85-2b88d6117f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-0ac46086-a97b-4ea6-8c4a-dda32632f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-23e0924e-4053-4284-b25b-ecb0f41e2102,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b383a7e2-a35e-48f2-9ce6-84da69c1e602,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-ff93ab98-fdbd-4e4c-acd2-5bbc0ada38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-b859ade3-47d9-4c6f-8094-49388b6334fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c8443c1b-e263-44ab-bfcb-211d910b2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-4dcb684a-003a-47a3-b776-cc8f516bb5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077892555-172.17.0.6-1597547041336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-18c682d7-2f73-4bc7-ab8c-d5d6bac6908a,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-6e3964f3-24e8-4d2d-88c2-90f81aef44a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-a971c011-f531-43e8-a82b-eabab477800c,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-164c0e25-daf0-4d81-921e-54fea99a851a,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-751a188b-c632-4209-80ef-831c6a4eb8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-2e042082-c8fa-4084-b659-459708be4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-7e9d8f64-2187-4835-8739-ec9341958372,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-6335573c-2697-4a82-ade5-afb0ccae4d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077892555-172.17.0.6-1597547041336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-18c682d7-2f73-4bc7-ab8c-d5d6bac6908a,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-6e3964f3-24e8-4d2d-88c2-90f81aef44a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-a971c011-f531-43e8-a82b-eabab477800c,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-164c0e25-daf0-4d81-921e-54fea99a851a,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-751a188b-c632-4209-80ef-831c6a4eb8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-2e042082-c8fa-4084-b659-459708be4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-7e9d8f64-2187-4835-8739-ec9341958372,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-6335573c-2697-4a82-ade5-afb0ccae4d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796777700-172.17.0.6-1597547154161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-425663b3-394b-429b-9b82-99a96846fe62,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-81197645-2852-436f-b1db-00a11a3293ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1242b8f3-75d5-4bd6-a954-6027609686f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-cef9bf63-c04d-46b8-905d-872757da4ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-6eebfcee-002f-44ba-a652-8b0f154ae0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-6879c86c-7470-471d-91fc-b1a5a9831502,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-fa5c0c96-6f3d-4a9c-9e6a-20f42f25cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-13b3e35c-e1b6-4cee-baae-8d93caa0a5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796777700-172.17.0.6-1597547154161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-425663b3-394b-429b-9b82-99a96846fe62,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-81197645-2852-436f-b1db-00a11a3293ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1242b8f3-75d5-4bd6-a954-6027609686f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-cef9bf63-c04d-46b8-905d-872757da4ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-6eebfcee-002f-44ba-a652-8b0f154ae0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-6879c86c-7470-471d-91fc-b1a5a9831502,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-fa5c0c96-6f3d-4a9c-9e6a-20f42f25cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-13b3e35c-e1b6-4cee-baae-8d93caa0a5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680362704-172.17.0.6-1597547196336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-a72af582-ba44-4409-91cf-acb01281b645,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-5af65355-17a6-43fa-b4bb-67028642856e,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-e8e99df1-2afd-4a5c-b6de-18c6786d9735,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-2ab5f01f-43dd-4976-b207-a605c4b73da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-e81e1a66-2133-4a78-82d5-edd6daf5e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-012b7d82-905d-411b-a6c9-468f9039daad,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-31db03f3-52dd-48ee-850b-65659a370483,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-1ac7fded-a6a0-41d1-b411-975830367fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680362704-172.17.0.6-1597547196336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-a72af582-ba44-4409-91cf-acb01281b645,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-5af65355-17a6-43fa-b4bb-67028642856e,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-e8e99df1-2afd-4a5c-b6de-18c6786d9735,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-2ab5f01f-43dd-4976-b207-a605c4b73da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-e81e1a66-2133-4a78-82d5-edd6daf5e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-012b7d82-905d-411b-a6c9-468f9039daad,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-31db03f3-52dd-48ee-850b-65659a370483,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-1ac7fded-a6a0-41d1-b411-975830367fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903107742-172.17.0.6-1597547601183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-76249404-7a0b-4bb6-aa54-07e2171cd4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-6a46bc57-f155-4154-b530-cda7fceea71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-eca7791b-aa16-403b-b567-06e550d7a055,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-c4948527-7295-4f2d-aea9-ddf25c5d7645,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-5689cdfb-8c0d-4278-a405-c7eda04044ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-f2c77b46-7ad2-4170-bac5-02cb73656b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-5324e5b8-a033-4528-b0dc-53077347da62,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-b92b7f69-ad24-4799-a757-93842a558afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903107742-172.17.0.6-1597547601183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-76249404-7a0b-4bb6-aa54-07e2171cd4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-6a46bc57-f155-4154-b530-cda7fceea71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-eca7791b-aa16-403b-b567-06e550d7a055,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-c4948527-7295-4f2d-aea9-ddf25c5d7645,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-5689cdfb-8c0d-4278-a405-c7eda04044ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-f2c77b46-7ad2-4170-bac5-02cb73656b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-5324e5b8-a033-4528-b0dc-53077347da62,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-b92b7f69-ad24-4799-a757-93842a558afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365837415-172.17.0.6-1597548166344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-37d703fa-fbfe-4950-983c-14943b7909b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-79455e96-1ca8-449e-8474-3ffbf8798806,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-7622ec36-083a-4373-85e6-ca517e323de6,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-1b5fed2e-16da-41b8-872e-3182f262c7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-542676c9-54f3-404a-b450-2047b96e3713,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-175dadde-c0bc-4405-acbd-62699f3d7d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-86e0d38c-33c9-4c9b-b71e-110bf6419a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-27cab81d-f64d-4084-a82b-7ed6e5c1175f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365837415-172.17.0.6-1597548166344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-37d703fa-fbfe-4950-983c-14943b7909b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-79455e96-1ca8-449e-8474-3ffbf8798806,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-7622ec36-083a-4373-85e6-ca517e323de6,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-1b5fed2e-16da-41b8-872e-3182f262c7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-542676c9-54f3-404a-b450-2047b96e3713,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-175dadde-c0bc-4405-acbd-62699f3d7d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-86e0d38c-33c9-4c9b-b71e-110bf6419a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-27cab81d-f64d-4084-a82b-7ed6e5c1175f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597442302-172.17.0.6-1597548403093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-4f6f64aa-8a82-49ba-ac9a-b05ee59b66ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-7ee31782-4fb5-4ef1-8af7-df3330ac2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-1246ac1f-bc70-449c-b7e2-104420e0ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-2357f875-355c-4c83-9efc-93cb087ea60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-62aec691-ed22-414d-b671-440e4651e37c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-981b340a-3906-4900-a98e-a8d5b283370e,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-65f8b4a8-f5e1-47c7-8d90-3a3dff1e38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-ee0e1780-118f-47a5-897b-105c9c363fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597442302-172.17.0.6-1597548403093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-4f6f64aa-8a82-49ba-ac9a-b05ee59b66ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-7ee31782-4fb5-4ef1-8af7-df3330ac2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-1246ac1f-bc70-449c-b7e2-104420e0ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-2357f875-355c-4c83-9efc-93cb087ea60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-62aec691-ed22-414d-b671-440e4651e37c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-981b340a-3906-4900-a98e-a8d5b283370e,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-65f8b4a8-f5e1-47c7-8d90-3a3dff1e38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-ee0e1780-118f-47a5-897b-105c9c363fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142567196-172.17.0.6-1597548519007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-b20f1e6e-3955-4574-81c9-f18f8d364477,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-a33c8433-8fce-4f27-9ffc-95e6647f0a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-2f0ca602-b964-4a05-a3c0-4ae3a529107a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-eecf83e3-8da0-427e-a3be-08bcf987f113,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8c175f00-749e-4d03-a8de-cb65a593e816,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-c1f9a934-4d7d-4732-8e23-5f38b1a8afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-4896cc10-725c-43ab-ae13-44b2138e2087,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-060640ed-9123-48dd-ba87-b031567c12d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142567196-172.17.0.6-1597548519007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-b20f1e6e-3955-4574-81c9-f18f8d364477,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-a33c8433-8fce-4f27-9ffc-95e6647f0a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-2f0ca602-b964-4a05-a3c0-4ae3a529107a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-eecf83e3-8da0-427e-a3be-08bcf987f113,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8c175f00-749e-4d03-a8de-cb65a593e816,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-c1f9a934-4d7d-4732-8e23-5f38b1a8afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-4896cc10-725c-43ab-ae13-44b2138e2087,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-060640ed-9123-48dd-ba87-b031567c12d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391025111-172.17.0.6-1597549120083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44228,DS-04ada752-fb43-454d-837f-3a690bc26d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-db737fff-e852-41ca-b7a3-7ce170238984,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-845dfe1b-ff5f-4924-a0d6-415da96b3092,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-915f8fc2-0c0e-4ce7-b3c1-0963a2de787e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5b641203-94e4-46f8-af6e-4dc57ceb0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-1a41fc01-0e60-466f-80ad-7ea963460c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-19431693-2262-4d61-b5a9-3b3ffdca945c,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-0d742867-34fe-4c93-a8cb-94ab1aa60a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391025111-172.17.0.6-1597549120083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44228,DS-04ada752-fb43-454d-837f-3a690bc26d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-db737fff-e852-41ca-b7a3-7ce170238984,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-845dfe1b-ff5f-4924-a0d6-415da96b3092,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-915f8fc2-0c0e-4ce7-b3c1-0963a2de787e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5b641203-94e4-46f8-af6e-4dc57ceb0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-1a41fc01-0e60-466f-80ad-7ea963460c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-19431693-2262-4d61-b5a9-3b3ffdca945c,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-0d742867-34fe-4c93-a8cb-94ab1aa60a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5529
