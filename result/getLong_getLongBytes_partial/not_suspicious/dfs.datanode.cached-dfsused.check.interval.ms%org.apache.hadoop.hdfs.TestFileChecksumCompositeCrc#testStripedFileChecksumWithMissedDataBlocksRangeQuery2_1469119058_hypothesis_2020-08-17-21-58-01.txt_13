reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567049580-172.17.0.12-1597701836105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32903,DS-c8305ad9-b1eb-4ab1-a444-f7dc6022e587,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-fa134021-10de-4256-b646-1da28dfaa10c,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-784c43f7-14e3-438c-b410-962c9e82a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-a80dc91d-bfe9-46fe-ad08-f0f45b1c306d,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-7ad63f34-fa71-4ae9-af6d-7cdcba420123,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-a8e6de1f-6186-41af-9578-c84525c849fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-282fdda5-76bc-4c5b-9633-f21f56793ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-5883c7f7-6527-4c9c-80b9-e7a74061767a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567049580-172.17.0.12-1597701836105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32903,DS-c8305ad9-b1eb-4ab1-a444-f7dc6022e587,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-fa134021-10de-4256-b646-1da28dfaa10c,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-784c43f7-14e3-438c-b410-962c9e82a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-a80dc91d-bfe9-46fe-ad08-f0f45b1c306d,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-7ad63f34-fa71-4ae9-af6d-7cdcba420123,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-a8e6de1f-6186-41af-9578-c84525c849fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-282fdda5-76bc-4c5b-9633-f21f56793ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-5883c7f7-6527-4c9c-80b9-e7a74061767a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302461075-172.17.0.12-1597701919401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-e68cd860-ecdb-43c0-ae78-a6bafb3bf754,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-c1c892c0-b0cf-4ae3-a8d2-051cf666be80,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-7ab4ca4f-7fe9-4448-a1bf-b7cc6a3889f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-3a6c7099-f33d-4e1b-b226-2502ceac7ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a7cb15a0-aa31-4489-97a5-f1d1e34e6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-b2d6da87-9396-4dda-ab6a-42c430d246ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2bffd346-1ed2-4980-b97c-5a461556be50,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-5957ff04-8d02-4092-a104-0c3149f34698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302461075-172.17.0.12-1597701919401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-e68cd860-ecdb-43c0-ae78-a6bafb3bf754,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-c1c892c0-b0cf-4ae3-a8d2-051cf666be80,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-7ab4ca4f-7fe9-4448-a1bf-b7cc6a3889f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-3a6c7099-f33d-4e1b-b226-2502ceac7ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a7cb15a0-aa31-4489-97a5-f1d1e34e6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-b2d6da87-9396-4dda-ab6a-42c430d246ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2bffd346-1ed2-4980-b97c-5a461556be50,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-5957ff04-8d02-4092-a104-0c3149f34698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062465186-172.17.0.12-1597702369120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-7a7df93d-afbe-4698-b4e1-fef414d202db,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-61ae7bb0-e617-4676-896b-a5a9ed7165a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ed587295-263e-4c36-84b2-8574c0a24419,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-45976400-3c0c-4249-b312-2152dfbd2151,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d03fc1ce-05c3-434f-9ecb-365b4c655b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-2ace435e-a914-451b-b741-2055f6d42001,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-f1cf2dd5-fb23-4f26-ab3a-54635a60c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-4753816a-1f99-4520-811a-723aab26d8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062465186-172.17.0.12-1597702369120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-7a7df93d-afbe-4698-b4e1-fef414d202db,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-61ae7bb0-e617-4676-896b-a5a9ed7165a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ed587295-263e-4c36-84b2-8574c0a24419,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-45976400-3c0c-4249-b312-2152dfbd2151,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d03fc1ce-05c3-434f-9ecb-365b4c655b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-2ace435e-a914-451b-b741-2055f6d42001,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-f1cf2dd5-fb23-4f26-ab3a-54635a60c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-4753816a-1f99-4520-811a-723aab26d8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278436054-172.17.0.12-1597702960926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-6a11753d-4d6e-4dbf-8162-a01275faa003,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-953851db-fb57-4e49-87b3-b0596c925ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-cecb1224-39b5-4847-8f78-f82f45f901be,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bb6becae-295f-46be-8c5d-155e83848f50,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-5a09b723-88dc-41a8-8f8e-93bfb20d63c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-c529c920-950b-43e0-a2b4-ed0286187bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-82a2c197-9229-4443-b26a-8e9dff669db2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-109ea090-b55e-4625-bf79-575c3018b7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278436054-172.17.0.12-1597702960926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-6a11753d-4d6e-4dbf-8162-a01275faa003,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-953851db-fb57-4e49-87b3-b0596c925ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-cecb1224-39b5-4847-8f78-f82f45f901be,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bb6becae-295f-46be-8c5d-155e83848f50,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-5a09b723-88dc-41a8-8f8e-93bfb20d63c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-c529c920-950b-43e0-a2b4-ed0286187bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-82a2c197-9229-4443-b26a-8e9dff669db2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-109ea090-b55e-4625-bf79-575c3018b7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46063246-172.17.0.12-1597703009412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-19aa9037-d190-4254-a8c7-dd76bc61eaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-e125530e-2651-41b2-b530-278212771929,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-906d197b-e152-4a60-8b14-2861cef311c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-5c5a7e55-50a3-40c0-8bae-3a3dbfc4b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-7c964771-0c72-4cad-8ec2-7221d986093b,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-b4a0daad-977e-4376-8b40-0b6ed3e26211,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-983dd98a-419e-4555-986c-9d8cee6d2022,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-7b648795-4971-4d64-9d01-608e92161d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46063246-172.17.0.12-1597703009412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-19aa9037-d190-4254-a8c7-dd76bc61eaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-e125530e-2651-41b2-b530-278212771929,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-906d197b-e152-4a60-8b14-2861cef311c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-5c5a7e55-50a3-40c0-8bae-3a3dbfc4b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-7c964771-0c72-4cad-8ec2-7221d986093b,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-b4a0daad-977e-4376-8b40-0b6ed3e26211,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-983dd98a-419e-4555-986c-9d8cee6d2022,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-7b648795-4971-4d64-9d01-608e92161d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002011520-172.17.0.12-1597703738950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-789e69be-6fa1-4707-80d4-f3e81e72c569,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a8da2e05-f4c4-4202-96f9-145d914b1f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-c3bcbbce-27df-417f-82b8-8a705a7be2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-9df2796d-dad2-4bf3-b6ad-737b54647379,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-3fff4392-2fad-408a-b1d2-ba25833734d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7f383cc5-0710-44aa-a91d-11a1530c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-53191f73-a23c-40cf-b3c4-b31423276485,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-b1c69074-28f6-41f7-a5b5-60940f34b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002011520-172.17.0.12-1597703738950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-789e69be-6fa1-4707-80d4-f3e81e72c569,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a8da2e05-f4c4-4202-96f9-145d914b1f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-c3bcbbce-27df-417f-82b8-8a705a7be2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-9df2796d-dad2-4bf3-b6ad-737b54647379,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-3fff4392-2fad-408a-b1d2-ba25833734d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7f383cc5-0710-44aa-a91d-11a1530c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-53191f73-a23c-40cf-b3c4-b31423276485,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-b1c69074-28f6-41f7-a5b5-60940f34b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167559534-172.17.0.12-1597704489016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-1b97b10b-daa0-46d3-8e4a-eb0755609ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-cdb42c43-8454-4f24-ad35-650e045c4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-4a4c5e96-0509-416f-b1fc-9a960387bd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-db0d50c6-30a8-49be-8e4d-1555480f1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-5280a10d-8a7b-4fce-8eba-910e949af40c,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-45349b62-a742-451b-a36f-760bbecb7ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-94ccff29-28c0-4d86-8706-8c53e4c922ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-aa4119d8-3b13-4452-bd60-e6d562b69c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167559534-172.17.0.12-1597704489016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-1b97b10b-daa0-46d3-8e4a-eb0755609ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-cdb42c43-8454-4f24-ad35-650e045c4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-4a4c5e96-0509-416f-b1fc-9a960387bd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-db0d50c6-30a8-49be-8e4d-1555480f1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-5280a10d-8a7b-4fce-8eba-910e949af40c,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-45349b62-a742-451b-a36f-760bbecb7ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-94ccff29-28c0-4d86-8706-8c53e4c922ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-aa4119d8-3b13-4452-bd60-e6d562b69c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682222405-172.17.0.12-1597704749323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-14f46c42-73ef-4122-93e5-d17ef34b919b,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-5422d131-7332-4693-bceb-d640d41b47a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-5bec985e-0dc4-4105-8ec5-2427869426d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-ae179a8c-7ddf-4a27-87f1-cf6f8d24ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-47043ead-efdf-42a3-b988-134da0510884,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a18bf20f-9e30-4970-abe2-e2786d07c793,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-d15f6c1f-0fd9-497a-9040-520c8cec5493,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-d076727d-e508-48e0-9837-5dc4743710cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682222405-172.17.0.12-1597704749323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-14f46c42-73ef-4122-93e5-d17ef34b919b,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-5422d131-7332-4693-bceb-d640d41b47a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-5bec985e-0dc4-4105-8ec5-2427869426d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-ae179a8c-7ddf-4a27-87f1-cf6f8d24ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-47043ead-efdf-42a3-b988-134da0510884,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a18bf20f-9e30-4970-abe2-e2786d07c793,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-d15f6c1f-0fd9-497a-9040-520c8cec5493,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-d076727d-e508-48e0-9837-5dc4743710cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184252274-172.17.0.12-1597704786482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-0e644d62-fbde-4904-9dd9-d2d48c90e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-74edafa1-4198-48d3-83c7-0a372f935135,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-aec13c04-0966-4128-8d4e-13551c376fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-f9c672ca-4e56-43c5-afc7-36a4e5f79de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-e243bd3f-11e5-48a6-8dbd-f09de65b624b,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-5d34490e-40d8-424e-a2aa-cf42973f78f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-1e8b6389-3737-4878-915b-4c0f0de4de75,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-08e3f02a-8fb9-482c-94a7-a8581cc394d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184252274-172.17.0.12-1597704786482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-0e644d62-fbde-4904-9dd9-d2d48c90e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-74edafa1-4198-48d3-83c7-0a372f935135,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-aec13c04-0966-4128-8d4e-13551c376fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-f9c672ca-4e56-43c5-afc7-36a4e5f79de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-e243bd3f-11e5-48a6-8dbd-f09de65b624b,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-5d34490e-40d8-424e-a2aa-cf42973f78f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-1e8b6389-3737-4878-915b-4c0f0de4de75,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-08e3f02a-8fb9-482c-94a7-a8581cc394d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986592058-172.17.0.12-1597705456125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33577,DS-ce539c6f-8c29-416a-b954-123207fe0ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-cecdcee3-d7b5-45d1-98c9-205f7a8b19d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6b76f699-801f-4863-b413-84d03bf5c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-01231134-1e53-48a9-8c16-3bdab42a084a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-abf80674-43eb-4150-a191-88c57d1208e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-d8cd0eea-9ff2-4685-b1c9-e3209a538a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-c113bdc1-5ae9-4ec6-bbbe-3bf3dbf59c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-190984ae-7a1a-40c8-b45e-79e62fce990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986592058-172.17.0.12-1597705456125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33577,DS-ce539c6f-8c29-416a-b954-123207fe0ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-cecdcee3-d7b5-45d1-98c9-205f7a8b19d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6b76f699-801f-4863-b413-84d03bf5c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-01231134-1e53-48a9-8c16-3bdab42a084a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-abf80674-43eb-4150-a191-88c57d1208e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-d8cd0eea-9ff2-4685-b1c9-e3209a538a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-c113bdc1-5ae9-4ec6-bbbe-3bf3dbf59c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-190984ae-7a1a-40c8-b45e-79e62fce990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251655462-172.17.0.12-1597706579957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-414d9706-ec2c-4ca5-a510-f18f7bde1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-09ab0fcd-6c98-4082-ae65-dd6ba4552ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4b24dd92-6585-4243-b56a-b8b2572f0a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-3637d07c-8039-4b95-85c1-cfb304dd0afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3ad7f016-07ae-493c-af87-f9d987130e27,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-50c82271-d09f-42fa-8bdf-8a00a08053b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-014f5eac-42a2-4a7d-87c9-617075544d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5e585f14-47fd-409e-888c-2ea1ef6d9efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251655462-172.17.0.12-1597706579957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-414d9706-ec2c-4ca5-a510-f18f7bde1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-09ab0fcd-6c98-4082-ae65-dd6ba4552ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4b24dd92-6585-4243-b56a-b8b2572f0a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-3637d07c-8039-4b95-85c1-cfb304dd0afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3ad7f016-07ae-493c-af87-f9d987130e27,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-50c82271-d09f-42fa-8bdf-8a00a08053b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-014f5eac-42a2-4a7d-87c9-617075544d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5e585f14-47fd-409e-888c-2ea1ef6d9efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790552283-172.17.0.12-1597706799649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-283ec88d-0e0b-423b-8908-f6ae9781df43,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-000343d8-4571-447d-a8ef-be055757111b,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-de896f5b-5660-4eb5-a5d6-6b3e20674b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-e9a924a9-ca27-4fe0-a6ed-d8e33278ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-66ac6255-c565-4b87-a11f-c69154eeab94,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-2e2d687c-4204-468f-88a6-8e4b59123c01,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-31fd3bf0-8a2e-429a-837c-b34b1f472993,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-02c88d8b-41f7-42b8-a3cd-3de7d3bff07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790552283-172.17.0.12-1597706799649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-283ec88d-0e0b-423b-8908-f6ae9781df43,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-000343d8-4571-447d-a8ef-be055757111b,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-de896f5b-5660-4eb5-a5d6-6b3e20674b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-e9a924a9-ca27-4fe0-a6ed-d8e33278ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-66ac6255-c565-4b87-a11f-c69154eeab94,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-2e2d687c-4204-468f-88a6-8e4b59123c01,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-31fd3bf0-8a2e-429a-837c-b34b1f472993,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-02c88d8b-41f7-42b8-a3cd-3de7d3bff07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766644347-172.17.0.12-1597707485038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-58ff7f1f-bb7b-434d-8fde-e984e0309502,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-d9a43922-f17d-4114-8585-944d41692ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-b66583ee-1d7f-485b-9f34-0fa36303a52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-90a5e562-fc0c-4d5f-9b8c-01c57ec6599c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-4843aa64-e9b1-49aa-aa4a-47e9a61bccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-729acd02-c97d-49ed-8b4f-801652b40552,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-121fcd9e-68f7-4643-ab17-831e161ad435,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-8f25d1f9-b1ac-493a-8622-663c6a069d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766644347-172.17.0.12-1597707485038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-58ff7f1f-bb7b-434d-8fde-e984e0309502,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-d9a43922-f17d-4114-8585-944d41692ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-b66583ee-1d7f-485b-9f34-0fa36303a52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-90a5e562-fc0c-4d5f-9b8c-01c57ec6599c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-4843aa64-e9b1-49aa-aa4a-47e9a61bccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-729acd02-c97d-49ed-8b4f-801652b40552,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-121fcd9e-68f7-4643-ab17-831e161ad435,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-8f25d1f9-b1ac-493a-8622-663c6a069d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977040659-172.17.0.12-1597707536622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-45645b9d-3418-4f1f-bb33-08844cae158b,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-1e81df4d-070f-4fff-9abd-1c7c0bafd432,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-6b193f87-4597-4240-aa29-ca20ec2f682d,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-77d22e7a-4a57-4cb3-b846-d53d0d8920c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-41bfff59-1650-453d-a06a-21938ea7a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-53ce9c04-a960-41f1-97bd-b3c551432376,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-6501fcd2-f08e-44de-bdbc-595ad2b56f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-12058832-999a-4bd7-8edd-da3f16e8c6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977040659-172.17.0.12-1597707536622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-45645b9d-3418-4f1f-bb33-08844cae158b,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-1e81df4d-070f-4fff-9abd-1c7c0bafd432,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-6b193f87-4597-4240-aa29-ca20ec2f682d,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-77d22e7a-4a57-4cb3-b846-d53d0d8920c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-41bfff59-1650-453d-a06a-21938ea7a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-53ce9c04-a960-41f1-97bd-b3c551432376,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-6501fcd2-f08e-44de-bdbc-595ad2b56f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-12058832-999a-4bd7-8edd-da3f16e8c6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547705188-172.17.0.12-1597707774463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-5fcb6529-e024-4df2-8ce9-e3400723f7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-e27d165b-4b51-44ba-a972-76ca58534814,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-07e2c34a-a0e7-41b6-b161-e3287e31c600,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b45dc159-07a8-484d-8e4d-717b50ec6d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-69359dcb-88b0-4d7a-9ac5-bb127261ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e3018cdb-9287-4cb2-a3d9-82012939141c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-5de8a0b1-96d5-4694-a0d3-8336eb06ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-f6383530-951e-46ff-931e-85fcf7e038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547705188-172.17.0.12-1597707774463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-5fcb6529-e024-4df2-8ce9-e3400723f7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-e27d165b-4b51-44ba-a972-76ca58534814,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-07e2c34a-a0e7-41b6-b161-e3287e31c600,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b45dc159-07a8-484d-8e4d-717b50ec6d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-69359dcb-88b0-4d7a-9ac5-bb127261ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e3018cdb-9287-4cb2-a3d9-82012939141c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-5de8a0b1-96d5-4694-a0d3-8336eb06ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-f6383530-951e-46ff-931e-85fcf7e038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6670
