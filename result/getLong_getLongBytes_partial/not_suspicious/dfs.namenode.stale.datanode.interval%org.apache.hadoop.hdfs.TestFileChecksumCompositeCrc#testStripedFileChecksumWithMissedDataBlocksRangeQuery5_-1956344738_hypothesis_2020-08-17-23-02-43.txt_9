reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543773254-172.17.0.20-1597705791824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-d4ac99a6-0371-44ba-90bc-8f8f5789104f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b355f4bc-0c30-4b40-baf6-d47d9c91656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-64da73a3-30fc-4b29-94ea-10459cd8f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-a8af6cc3-e431-48b3-8c4a-e90c9258700a,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-b5166f47-f744-4402-a63a-7c6d373193f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-a340f710-e0ed-439c-a99b-d91a672ded47,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1ca92c09-6398-4e5c-a901-654f46efecba,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-bdf628c8-948b-4ba9-86b8-b93bbb74a749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543773254-172.17.0.20-1597705791824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-d4ac99a6-0371-44ba-90bc-8f8f5789104f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b355f4bc-0c30-4b40-baf6-d47d9c91656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-64da73a3-30fc-4b29-94ea-10459cd8f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-a8af6cc3-e431-48b3-8c4a-e90c9258700a,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-b5166f47-f744-4402-a63a-7c6d373193f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-a340f710-e0ed-439c-a99b-d91a672ded47,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1ca92c09-6398-4e5c-a901-654f46efecba,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-bdf628c8-948b-4ba9-86b8-b93bbb74a749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957554403-172.17.0.20-1597706107265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-f03a8e23-c5bf-45a1-b498-19a22c4abd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-3ec12374-0df7-4ee1-9c7e-5358e3764589,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7ed687fd-c360-4ba1-a2bf-fa7e5d1fcad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-fd730b25-174c-4181-a8c5-eb745dedb553,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-81c7602c-2bc1-46ca-83a2-3a5e61390374,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a0fc4506-9ca2-4a73-8bef-7e2bba7b15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-a2f695dc-1de7-4582-aaef-b2569e27111c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-68a0c6ce-1a16-47df-86d5-281df8e88eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957554403-172.17.0.20-1597706107265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-f03a8e23-c5bf-45a1-b498-19a22c4abd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-3ec12374-0df7-4ee1-9c7e-5358e3764589,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7ed687fd-c360-4ba1-a2bf-fa7e5d1fcad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-fd730b25-174c-4181-a8c5-eb745dedb553,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-81c7602c-2bc1-46ca-83a2-3a5e61390374,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a0fc4506-9ca2-4a73-8bef-7e2bba7b15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-a2f695dc-1de7-4582-aaef-b2569e27111c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-68a0c6ce-1a16-47df-86d5-281df8e88eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611624348-172.17.0.20-1597706187010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-ed1c99b0-8054-4bd0-a335-30bca391bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-f356adf1-9c98-4067-8531-fd1f6cd434fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-b00899ab-0296-4d78-a265-7814f7ee304a,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-2fd4b70f-e988-4b8d-89eb-7f8efe966093,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-d4df473e-f0c8-47e4-9d00-6603b149a265,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-2eb85baf-d16a-4ac9-acd9-7da2f79ac306,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-191621fe-6b5d-4971-af4d-c382cbaad2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-61ad6695-ac09-4889-b457-2d19ea51bb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611624348-172.17.0.20-1597706187010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-ed1c99b0-8054-4bd0-a335-30bca391bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-f356adf1-9c98-4067-8531-fd1f6cd434fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-b00899ab-0296-4d78-a265-7814f7ee304a,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-2fd4b70f-e988-4b8d-89eb-7f8efe966093,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-d4df473e-f0c8-47e4-9d00-6603b149a265,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-2eb85baf-d16a-4ac9-acd9-7da2f79ac306,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-191621fe-6b5d-4971-af4d-c382cbaad2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-61ad6695-ac09-4889-b457-2d19ea51bb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844540313-172.17.0.20-1597706224510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-d015bf9f-d248-4dd6-ab03-0308215c787d,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-cd2928dc-8590-4a27-bf85-cf7f829d7095,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-5c1cab75-b957-4bad-a418-283f2f0811c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-bd1b4904-0600-4f86-8ad1-0903cda8b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-de2f573f-3afe-47d1-9d74-914f3228916c,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-bd5c4810-0462-43c3-9b4f-75d83bf4a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-7311fb36-b938-4322-8234-ee3796adb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-af2d6df8-1c95-45b1-bb1f-73490e89e9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844540313-172.17.0.20-1597706224510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-d015bf9f-d248-4dd6-ab03-0308215c787d,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-cd2928dc-8590-4a27-bf85-cf7f829d7095,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-5c1cab75-b957-4bad-a418-283f2f0811c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-bd1b4904-0600-4f86-8ad1-0903cda8b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-de2f573f-3afe-47d1-9d74-914f3228916c,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-bd5c4810-0462-43c3-9b4f-75d83bf4a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-7311fb36-b938-4322-8234-ee3796adb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-af2d6df8-1c95-45b1-bb1f-73490e89e9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233125571-172.17.0.20-1597706292664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c6ac36fd-eb7a-4663-873f-f1a0129f0e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-93d1701e-e67f-4d32-abf0-ba6841e53071,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-31833e57-e304-47fe-9328-9ae79565f1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-7ef420cb-2c2d-41ea-bfba-25f8a730ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-6d8c992a-5fbd-4405-bb32-7dfed0afd253,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-35aee777-5b07-40c8-8163-d489ab0a3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-1fbe021f-e3ef-4c2d-a5cf-3c32c8ef421c,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-d23a470e-f7a7-4360-9c48-bebc568b58a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233125571-172.17.0.20-1597706292664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c6ac36fd-eb7a-4663-873f-f1a0129f0e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-93d1701e-e67f-4d32-abf0-ba6841e53071,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-31833e57-e304-47fe-9328-9ae79565f1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-7ef420cb-2c2d-41ea-bfba-25f8a730ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-6d8c992a-5fbd-4405-bb32-7dfed0afd253,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-35aee777-5b07-40c8-8163-d489ab0a3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-1fbe021f-e3ef-4c2d-a5cf-3c32c8ef421c,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-d23a470e-f7a7-4360-9c48-bebc568b58a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860571225-172.17.0.20-1597706406515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-0305bec1-99d4-4be6-bea9-508b1265a428,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-9c080a1e-5ae8-4ed7-a9c5-77c1556cc778,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ad3cd162-6575-4771-8cf8-299af6ff9608,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c6d010f9-8ef8-4104-88de-8afa3a018445,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-f3275364-a839-44f0-a94f-5f101dccaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-5f9f9b21-54be-42a6-8449-b2d786551b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-e818a68f-f8a5-47d9-8f69-26d1c6e5e109,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-db298f85-2c2b-431f-b16d-a23a548264a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860571225-172.17.0.20-1597706406515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-0305bec1-99d4-4be6-bea9-508b1265a428,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-9c080a1e-5ae8-4ed7-a9c5-77c1556cc778,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ad3cd162-6575-4771-8cf8-299af6ff9608,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c6d010f9-8ef8-4104-88de-8afa3a018445,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-f3275364-a839-44f0-a94f-5f101dccaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-5f9f9b21-54be-42a6-8449-b2d786551b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-e818a68f-f8a5-47d9-8f69-26d1c6e5e109,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-db298f85-2c2b-431f-b16d-a23a548264a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109721731-172.17.0.20-1597707059679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-b71160f6-a974-422f-88e0-7db8b6dc0145,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-e4cffead-8e7b-41c1-8458-6ba7f8ae555f,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-53e4a00e-1e44-4574-8d24-563fa2f1a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-bee44b5b-ea4a-46be-8a91-8abc44e08f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cbd58fe3-276c-4356-be77-1fadb5d8eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-246a421b-0016-421e-bbb5-631e4d1c8852,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-3b53c965-0a0c-473f-9eab-74a873209ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-172189f0-6dc3-4f2f-9742-7bce8b3ee142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109721731-172.17.0.20-1597707059679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-b71160f6-a974-422f-88e0-7db8b6dc0145,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-e4cffead-8e7b-41c1-8458-6ba7f8ae555f,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-53e4a00e-1e44-4574-8d24-563fa2f1a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-bee44b5b-ea4a-46be-8a91-8abc44e08f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cbd58fe3-276c-4356-be77-1fadb5d8eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-246a421b-0016-421e-bbb5-631e4d1c8852,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-3b53c965-0a0c-473f-9eab-74a873209ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-172189f0-6dc3-4f2f-9742-7bce8b3ee142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765325464-172.17.0.20-1597707174871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-f6865320-0159-4af0-b367-877a7acf7ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-5b8da9bc-349d-457c-b10a-ef71ddf1ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-3ddebcd1-a7c3-49de-bcef-301228ec5591,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-3cbe364e-7364-496b-8cf2-7f89f1de2924,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-a60320ca-ae9f-43e9-9043-0666a2cd2677,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-f36143f3-133c-4599-9459-137760ef3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-4563db3c-27a3-4a45-b73b-5bac28db1501,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5650e27a-db5a-469e-8c11-aaf55942c021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765325464-172.17.0.20-1597707174871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-f6865320-0159-4af0-b367-877a7acf7ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-5b8da9bc-349d-457c-b10a-ef71ddf1ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-3ddebcd1-a7c3-49de-bcef-301228ec5591,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-3cbe364e-7364-496b-8cf2-7f89f1de2924,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-a60320ca-ae9f-43e9-9043-0666a2cd2677,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-f36143f3-133c-4599-9459-137760ef3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-4563db3c-27a3-4a45-b73b-5bac28db1501,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5650e27a-db5a-469e-8c11-aaf55942c021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154827400-172.17.0.20-1597707212914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-92f4fa42-e905-49ae-93b8-4d1d46857658,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-d175fe0f-53bf-48bf-9741-f587d41ecba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-3b0ea109-90cb-4ac1-86d3-9e44825aa594,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-525899ec-4192-4202-855d-eef3c5327d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-27a174ee-0090-4cff-b17b-46d1798b29e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-b20355a7-8db0-4877-b27e-18973057cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-1ad612f1-5565-48cd-827c-f2fb690a9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-84ea6830-d522-4c03-954e-87d3ef94aaf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154827400-172.17.0.20-1597707212914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-92f4fa42-e905-49ae-93b8-4d1d46857658,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-d175fe0f-53bf-48bf-9741-f587d41ecba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-3b0ea109-90cb-4ac1-86d3-9e44825aa594,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-525899ec-4192-4202-855d-eef3c5327d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-27a174ee-0090-4cff-b17b-46d1798b29e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-b20355a7-8db0-4877-b27e-18973057cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-1ad612f1-5565-48cd-827c-f2fb690a9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-84ea6830-d522-4c03-954e-87d3ef94aaf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051289149-172.17.0.20-1597707288485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35173,DS-57910eb8-d479-4408-8dc2-7fb9268a07f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-d6623290-3202-4ae6-be69-6c26b5783c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c29ab68a-f334-4460-9bf9-0e23cf2e18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-38687086-7ba5-45f8-872d-5745632b3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a7295c64-5f00-4175-8c1f-09b94c47e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-cf77c3bd-ebb4-4536-a7ba-10ada381c690,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-e740054b-8a3c-4fb8-b792-ecd79c4b65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9a6c4d63-b19c-4b3e-8ae9-789e3db5aaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051289149-172.17.0.20-1597707288485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35173,DS-57910eb8-d479-4408-8dc2-7fb9268a07f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-d6623290-3202-4ae6-be69-6c26b5783c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c29ab68a-f334-4460-9bf9-0e23cf2e18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-38687086-7ba5-45f8-872d-5745632b3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a7295c64-5f00-4175-8c1f-09b94c47e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-cf77c3bd-ebb4-4536-a7ba-10ada381c690,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-e740054b-8a3c-4fb8-b792-ecd79c4b65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9a6c4d63-b19c-4b3e-8ae9-789e3db5aaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107812110-172.17.0.20-1597707409101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-11f842c1-4031-446c-9413-d7b5629fb79e,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-8cac1e68-87b2-4201-b324-ce875437a586,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-40b018a7-a779-4c7d-a5ca-a658e1a3eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-37eebdbf-b4f1-4033-8823-d613d002450c,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-9aa26476-8331-4122-bfe3-dc0103bd8d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-81a29c36-c679-4aef-a955-e45cd953409b,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-8c91ff73-bd16-4953-9b2a-36e4201e22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-37ff7ceb-8764-4b8a-b3dc-165f81e23ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107812110-172.17.0.20-1597707409101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-11f842c1-4031-446c-9413-d7b5629fb79e,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-8cac1e68-87b2-4201-b324-ce875437a586,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-40b018a7-a779-4c7d-a5ca-a658e1a3eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-37eebdbf-b4f1-4033-8823-d613d002450c,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-9aa26476-8331-4122-bfe3-dc0103bd8d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-81a29c36-c679-4aef-a955-e45cd953409b,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-8c91ff73-bd16-4953-9b2a-36e4201e22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-37ff7ceb-8764-4b8a-b3dc-165f81e23ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942150633-172.17.0.20-1597707827537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-faacf03e-ebf3-444f-a3bf-7694d34c68dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-40f4060c-2698-4e6d-bf19-ab03ba19626c,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-7d77e1ad-f2d3-4384-923e-b15845eb1436,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-eba7fc37-1682-48d2-a7d0-9a95456062ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-5cbbb033-f599-475f-81f9-5b8a0875b900,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-a1606c80-494e-4c91-af70-6f9a27ee448a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-7a32e1ca-fd6c-4deb-9599-c7aaaada9271,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-794e4dfe-31f3-496d-b3db-8c0a6bb552b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942150633-172.17.0.20-1597707827537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-faacf03e-ebf3-444f-a3bf-7694d34c68dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-40f4060c-2698-4e6d-bf19-ab03ba19626c,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-7d77e1ad-f2d3-4384-923e-b15845eb1436,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-eba7fc37-1682-48d2-a7d0-9a95456062ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-5cbbb033-f599-475f-81f9-5b8a0875b900,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-a1606c80-494e-4c91-af70-6f9a27ee448a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-7a32e1ca-fd6c-4deb-9599-c7aaaada9271,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-794e4dfe-31f3-496d-b3db-8c0a6bb552b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335477723-172.17.0.20-1597708519357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-94e5005a-0042-4afe-815f-9cd1729dfb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9513034c-3455-4638-aaa9-d2efb9be2f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8953608f-bc39-4b80-bb73-430397921c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-e2602876-be3f-4a82-8e3a-f72f7932d8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-5cdcd55c-bf0d-4169-a118-f57ea7096bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-db9e532d-9ac3-48cb-a6b8-2d6eddab57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-18ed5e90-8683-4220-a650-c3246d93b749,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-a03a343c-b8eb-44e0-b62a-1301fac8cdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335477723-172.17.0.20-1597708519357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-94e5005a-0042-4afe-815f-9cd1729dfb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9513034c-3455-4638-aaa9-d2efb9be2f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8953608f-bc39-4b80-bb73-430397921c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-e2602876-be3f-4a82-8e3a-f72f7932d8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-5cdcd55c-bf0d-4169-a118-f57ea7096bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-db9e532d-9ac3-48cb-a6b8-2d6eddab57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-18ed5e90-8683-4220-a650-c3246d93b749,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-a03a343c-b8eb-44e0-b62a-1301fac8cdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551240438-172.17.0.20-1597708623751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-4d1ca837-fd24-425a-9127-ab15395dc3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-53b74b4c-5b19-4eb3-9ddc-4d0aadd951d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-f45117d2-bd3f-49d8-9efc-afe6dab00009,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-021e0400-68be-442e-a1d2-2be90659d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-4cdb197b-a708-44a6-b7b5-d4ac43f6c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-068848de-fabf-4d21-9294-a47b2444fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-d1907b36-f95e-472b-99a1-9f2c5bfb9734,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-1405e7b4-fb11-4e66-8217-cdce7e8063c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551240438-172.17.0.20-1597708623751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-4d1ca837-fd24-425a-9127-ab15395dc3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-53b74b4c-5b19-4eb3-9ddc-4d0aadd951d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-f45117d2-bd3f-49d8-9efc-afe6dab00009,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-021e0400-68be-442e-a1d2-2be90659d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-4cdb197b-a708-44a6-b7b5-d4ac43f6c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-068848de-fabf-4d21-9294-a47b2444fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-d1907b36-f95e-472b-99a1-9f2c5bfb9734,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-1405e7b4-fb11-4e66-8217-cdce7e8063c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763023554-172.17.0.20-1597709338260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33190,DS-9fa98578-e183-4d52-bc94-9c6d1532dbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-4ab04a82-17ea-4a32-8873-c27e8102c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-b5277c7e-e0f5-466c-85f3-5ed9df633b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-2ee33cdb-a659-4ff7-a7a6-bc2a02c882c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3a288eee-1432-4a86-9a21-090a7e5da9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-cdb2a6d4-d938-4639-88e3-78517504c416,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-e5b08f4d-05ee-46f7-95fc-45a48395433a,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-69af93be-de0a-49ca-b433-ef5cb79407af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763023554-172.17.0.20-1597709338260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33190,DS-9fa98578-e183-4d52-bc94-9c6d1532dbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-4ab04a82-17ea-4a32-8873-c27e8102c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-b5277c7e-e0f5-466c-85f3-5ed9df633b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-2ee33cdb-a659-4ff7-a7a6-bc2a02c882c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3a288eee-1432-4a86-9a21-090a7e5da9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-cdb2a6d4-d938-4639-88e3-78517504c416,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-e5b08f4d-05ee-46f7-95fc-45a48395433a,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-69af93be-de0a-49ca-b433-ef5cb79407af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324686727-172.17.0.20-1597710899417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-e6e4a2a3-eeaf-491a-ba9e-66803e427388,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-4f54d12b-2233-4851-9460-db53e0dfccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-b5796ce2-d9f1-4ea0-9b38-8acd69888f09,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-c4409310-ac78-4981-95a3-9a9b479247d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-95b204e7-be5e-4a3e-ab5c-4cc02c0eb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-afb15b28-624a-471a-872b-cd0d6d673a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-8d6fb5fd-0d38-4bc0-9271-0c77415966c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-40877937-ebbd-437c-829c-312b5d5293f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324686727-172.17.0.20-1597710899417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-e6e4a2a3-eeaf-491a-ba9e-66803e427388,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-4f54d12b-2233-4851-9460-db53e0dfccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-b5796ce2-d9f1-4ea0-9b38-8acd69888f09,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-c4409310-ac78-4981-95a3-9a9b479247d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-95b204e7-be5e-4a3e-ab5c-4cc02c0eb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-afb15b28-624a-471a-872b-cd0d6d673a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-8d6fb5fd-0d38-4bc0-9271-0c77415966c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-40877937-ebbd-437c-829c-312b5d5293f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5561
