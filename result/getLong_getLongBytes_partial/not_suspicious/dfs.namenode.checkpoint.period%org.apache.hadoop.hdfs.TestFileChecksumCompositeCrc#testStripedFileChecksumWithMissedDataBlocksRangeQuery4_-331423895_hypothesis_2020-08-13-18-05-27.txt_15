reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325937689-172.17.0.7-1597342880224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41525,DS-7dd1f3b8-8f85-4808-8d51-18fd63b22f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-f6cd5550-b5dc-456f-85c6-2ee80289c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-c7a4b311-e33b-45ab-8ede-e8bec650605c,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f0240e62-ddad-4549-b7a3-aea6c58a45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d0da421f-805b-496b-8d80-30b63d93d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-ed2eebb3-4032-48a8-bd47-5d57f173c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-8c7416de-0adb-4602-8914-13f59f4eed4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-b653dee5-6611-471f-930c-5b929438ab61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325937689-172.17.0.7-1597342880224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41525,DS-7dd1f3b8-8f85-4808-8d51-18fd63b22f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-f6cd5550-b5dc-456f-85c6-2ee80289c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-c7a4b311-e33b-45ab-8ede-e8bec650605c,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f0240e62-ddad-4549-b7a3-aea6c58a45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d0da421f-805b-496b-8d80-30b63d93d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-ed2eebb3-4032-48a8-bd47-5d57f173c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-8c7416de-0adb-4602-8914-13f59f4eed4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-b653dee5-6611-471f-930c-5b929438ab61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785729001-172.17.0.7-1597343510436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-41048bd8-340a-4ca5-b470-3fa3447879ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-4e6297f8-6ca8-416a-997d-1d16eb74d031,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-11abc608-fdbc-4cdb-8b41-59b58ff15bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-f1e4ff82-2c80-458b-aaa8-990e1a181742,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-e5c81f13-1962-4dfa-b248-74ec585a4876,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-84123e8e-8887-40a6-a12b-7c2f17db0063,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-04c014ab-9026-40ce-a214-dedefe8d13d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-483b511c-b089-4628-8316-efc4749d4e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785729001-172.17.0.7-1597343510436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-41048bd8-340a-4ca5-b470-3fa3447879ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-4e6297f8-6ca8-416a-997d-1d16eb74d031,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-11abc608-fdbc-4cdb-8b41-59b58ff15bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-f1e4ff82-2c80-458b-aaa8-990e1a181742,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-e5c81f13-1962-4dfa-b248-74ec585a4876,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-84123e8e-8887-40a6-a12b-7c2f17db0063,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-04c014ab-9026-40ce-a214-dedefe8d13d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-483b511c-b089-4628-8316-efc4749d4e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965535065-172.17.0.7-1597344037608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-a1efcfb3-b2e9-4190-937f-dcb85a170eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-887b8a12-ff57-4f49-aa4a-dd77f8658c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-9979c894-4c1f-4547-b0b5-923eda6c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-2554417e-6162-41f9-a343-b186a96a2702,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-45949dd7-6cea-4c28-943b-2f7753af0107,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-6a4664d5-12be-4f0b-bc6a-70b7a9868f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b35fa869-0ee3-42f3-88d8-92a052536dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-92f5b500-f655-4685-a65b-8a4b06ffbf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965535065-172.17.0.7-1597344037608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-a1efcfb3-b2e9-4190-937f-dcb85a170eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-887b8a12-ff57-4f49-aa4a-dd77f8658c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-9979c894-4c1f-4547-b0b5-923eda6c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-2554417e-6162-41f9-a343-b186a96a2702,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-45949dd7-6cea-4c28-943b-2f7753af0107,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-6a4664d5-12be-4f0b-bc6a-70b7a9868f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-b35fa869-0ee3-42f3-88d8-92a052536dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-92f5b500-f655-4685-a65b-8a4b06ffbf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563481297-172.17.0.7-1597344269043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40286,DS-cd5486d8-e863-4d69-864e-d62df0d8ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-0c9dceda-c252-4c60-a0d1-67763ab8fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-3da4e491-dc32-4603-b7ca-e74d4ea541da,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-a8e748a9-34b4-4804-8a5e-3bb096ae0eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-4b66b110-37b5-41b2-8bfb-6ab28e2879d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-e78eb5eb-d02d-4ece-a608-da15926ab48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-02fdbd88-e68e-4c8e-bb5d-bee4f92ac33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-edf4afbe-4d8a-4a91-a8d5-322bfb988d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563481297-172.17.0.7-1597344269043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40286,DS-cd5486d8-e863-4d69-864e-d62df0d8ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-0c9dceda-c252-4c60-a0d1-67763ab8fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-3da4e491-dc32-4603-b7ca-e74d4ea541da,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-a8e748a9-34b4-4804-8a5e-3bb096ae0eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-4b66b110-37b5-41b2-8bfb-6ab28e2879d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-e78eb5eb-d02d-4ece-a608-da15926ab48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-02fdbd88-e68e-4c8e-bb5d-bee4f92ac33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-edf4afbe-4d8a-4a91-a8d5-322bfb988d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308709342-172.17.0.7-1597344549650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-ecd7c5c9-e161-487f-895d-3f6ca2f56416,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-fe9e0497-b31b-4e90-bcc2-948eaf273948,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ddcf5253-8b56-45a7-bb97-f0811579493b,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b84f2802-fda4-4811-903a-63088e943ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-b5e8001d-18c2-4c13-ad87-30ff2a16b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-a35b1833-70e6-46cc-808b-cc9d344803a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-664660b9-ffeb-4d77-ae4f-5bcfde77ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e5068bc7-cf3b-459d-9917-7de5b008cdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308709342-172.17.0.7-1597344549650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-ecd7c5c9-e161-487f-895d-3f6ca2f56416,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-fe9e0497-b31b-4e90-bcc2-948eaf273948,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ddcf5253-8b56-45a7-bb97-f0811579493b,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b84f2802-fda4-4811-903a-63088e943ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-b5e8001d-18c2-4c13-ad87-30ff2a16b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-a35b1833-70e6-46cc-808b-cc9d344803a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-664660b9-ffeb-4d77-ae4f-5bcfde77ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e5068bc7-cf3b-459d-9917-7de5b008cdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019804477-172.17.0.7-1597344947494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-6eb7e4ec-fe22-4257-8adc-71eef3aca4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-921ad57a-7b86-4575-8201-d4a3a33f0421,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-2f3db957-6ad4-40bf-a928-746cfb20c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-f4375a30-efcb-4f24-9084-d4a5b698103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-54a9b5ec-b9a1-41bd-b557-a336726989f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-51dc98dc-390e-4469-bbc5-6f1dae97ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-5935113b-30f8-4e36-b131-07728f49df34,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-86fe5b8b-815f-4eac-a303-6acff7e39e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019804477-172.17.0.7-1597344947494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-6eb7e4ec-fe22-4257-8adc-71eef3aca4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-921ad57a-7b86-4575-8201-d4a3a33f0421,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-2f3db957-6ad4-40bf-a928-746cfb20c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-f4375a30-efcb-4f24-9084-d4a5b698103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-54a9b5ec-b9a1-41bd-b557-a336726989f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-51dc98dc-390e-4469-bbc5-6f1dae97ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-5935113b-30f8-4e36-b131-07728f49df34,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-86fe5b8b-815f-4eac-a303-6acff7e39e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058173857-172.17.0.7-1597345146564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-38764d63-a5c1-40a4-b0e9-5453a9253037,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-aaf2e68c-bcd5-4ce6-976c-60e614861ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-07c9effd-cb9c-4980-b529-628a304f774d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e6c8e7b5-fa1b-4876-9b2b-ef33fca7b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-2b70810e-3e0a-40d6-b392-b8fb8a203c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-026afe3c-fc23-457e-a533-ff8c6c74949a,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-808f858e-d7a6-4f55-8d85-013e6c2f7815,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-64255c06-6efb-45a0-b3e5-36140bd0c4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058173857-172.17.0.7-1597345146564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-38764d63-a5c1-40a4-b0e9-5453a9253037,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-aaf2e68c-bcd5-4ce6-976c-60e614861ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-07c9effd-cb9c-4980-b529-628a304f774d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e6c8e7b5-fa1b-4876-9b2b-ef33fca7b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-2b70810e-3e0a-40d6-b392-b8fb8a203c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-026afe3c-fc23-457e-a533-ff8c6c74949a,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-808f858e-d7a6-4f55-8d85-013e6c2f7815,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-64255c06-6efb-45a0-b3e5-36140bd0c4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650498735-172.17.0.7-1597345812803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-d65e5cd6-2945-4759-a756-5de8dc4c5002,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-4baa675f-023d-4fe9-8c2f-eb9bb088d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c6611fc4-7152-432b-952b-73202f813293,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-b5c408bd-d9d0-4c93-b014-8f816bdf8099,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0e1c9f02-5856-441f-8f6e-db9d173c9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-922e3927-9d1d-43b0-a3d6-6772063141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-f2945804-3c9f-45f4-b0e5-af86046e272d,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8b515577-8308-4959-8b74-366f521fdd85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650498735-172.17.0.7-1597345812803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-d65e5cd6-2945-4759-a756-5de8dc4c5002,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-4baa675f-023d-4fe9-8c2f-eb9bb088d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c6611fc4-7152-432b-952b-73202f813293,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-b5c408bd-d9d0-4c93-b014-8f816bdf8099,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0e1c9f02-5856-441f-8f6e-db9d173c9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-922e3927-9d1d-43b0-a3d6-6772063141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-f2945804-3c9f-45f4-b0e5-af86046e272d,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8b515577-8308-4959-8b74-366f521fdd85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458379469-172.17.0.7-1597346058326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34288,DS-96e96852-1460-4649-98eb-8a150e166a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-80b131ae-10fb-4d86-a37a-ade2628fe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c23adebd-34a0-463a-a51c-39b1dfce3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-21f2bf04-e1d0-4cbd-9f49-e7c3b7ff1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-25dbaf4b-4148-4b49-afba-eddfd3d7d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-2c9372fb-09e9-4179-aaa3-627520354ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b7d2ec21-dfee-4efd-a66b-8975cc155464,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-80b12ea2-9252-45ca-998c-a1d331054c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458379469-172.17.0.7-1597346058326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34288,DS-96e96852-1460-4649-98eb-8a150e166a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-80b131ae-10fb-4d86-a37a-ade2628fe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c23adebd-34a0-463a-a51c-39b1dfce3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-21f2bf04-e1d0-4cbd-9f49-e7c3b7ff1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-25dbaf4b-4148-4b49-afba-eddfd3d7d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-2c9372fb-09e9-4179-aaa3-627520354ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b7d2ec21-dfee-4efd-a66b-8975cc155464,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-80b12ea2-9252-45ca-998c-a1d331054c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843230071-172.17.0.7-1597346282030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-3fdf8085-fd17-4855-a4ab-a80cf09f42be,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-4fb37069-08f8-4d22-ba22-adf7533c7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-f2999eae-724f-451d-9e4d-9d1c659848c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-5944ed21-fe65-40f8-9a0d-b8d35b865c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-6ebf556d-a3a4-453e-bb08-b4890c2c8366,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-1ff7c5de-4c4f-48e9-b2d4-3db51f27b260,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d391499e-3c66-4a36-9fbb-ffb73d17a875,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-16328530-bd1e-428c-9857-d465bac16869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843230071-172.17.0.7-1597346282030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-3fdf8085-fd17-4855-a4ab-a80cf09f42be,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-4fb37069-08f8-4d22-ba22-adf7533c7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-f2999eae-724f-451d-9e4d-9d1c659848c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-5944ed21-fe65-40f8-9a0d-b8d35b865c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-6ebf556d-a3a4-453e-bb08-b4890c2c8366,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-1ff7c5de-4c4f-48e9-b2d4-3db51f27b260,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d391499e-3c66-4a36-9fbb-ffb73d17a875,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-16328530-bd1e-428c-9857-d465bac16869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118078691-172.17.0.7-1597346321988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-05737619-fe06-4a96-baa5-2c507691b887,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fd1a8510-1462-4bb5-ad96-d071a19b43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-cedf7f18-eb3f-4b03-857e-b8d576827694,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-0ad4df0c-cfab-4410-81f7-8467550e33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4c2a8ab3-7889-4231-8950-4966fa23a079,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-807e0428-d44b-4b7c-8005-578165d0ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-2196dad6-3c42-483f-b23b-55acf1692c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-607edc94-b427-41f3-8dcf-ff11c7ca671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118078691-172.17.0.7-1597346321988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-05737619-fe06-4a96-baa5-2c507691b887,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fd1a8510-1462-4bb5-ad96-d071a19b43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-cedf7f18-eb3f-4b03-857e-b8d576827694,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-0ad4df0c-cfab-4410-81f7-8467550e33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4c2a8ab3-7889-4231-8950-4966fa23a079,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-807e0428-d44b-4b7c-8005-578165d0ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-2196dad6-3c42-483f-b23b-55acf1692c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-607edc94-b427-41f3-8dcf-ff11c7ca671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308746014-172.17.0.7-1597346397707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-fb675a17-de29-4930-bfcc-b9e411eac510,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-0662b022-c472-4469-a71d-2b4967a1c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-820a1027-7627-4ed7-9e3f-b5bfa1a37c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-8f337c46-a5b0-4f70-bdfc-3dcd4a382368,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-84ca376d-2aa4-40d6-a7fd-cbbc66ec807f,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-991aaa74-0560-4471-9d84-81369a153548,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-3832542e-f87f-4775-9550-3bdd5093f38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-dde046d2-1e2b-4ae3-b8f5-1a1d56166633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308746014-172.17.0.7-1597346397707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-fb675a17-de29-4930-bfcc-b9e411eac510,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-0662b022-c472-4469-a71d-2b4967a1c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-820a1027-7627-4ed7-9e3f-b5bfa1a37c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-8f337c46-a5b0-4f70-bdfc-3dcd4a382368,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-84ca376d-2aa4-40d6-a7fd-cbbc66ec807f,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-991aaa74-0560-4471-9d84-81369a153548,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-3832542e-f87f-4775-9550-3bdd5093f38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-dde046d2-1e2b-4ae3-b8f5-1a1d56166633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043198407-172.17.0.7-1597346935248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34393,DS-4e9b4f81-1d3a-4b6a-b759-2eea37a73a51,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-622e38ed-2077-4b8f-b96f-be8daa083fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-a662cb51-0836-415f-afb1-39a22a0fcd57,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-4a4d83d8-ad6d-4117-8cb1-50953f794001,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-ed66c538-e9ba-4f48-b0d0-28e6aa7f34c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-f746f57c-7d81-482e-9188-330acec445fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-406fbd14-02df-4a69-8d57-dbe0af2093a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-24f6bef4-d451-4c3d-be7e-3deb5950dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043198407-172.17.0.7-1597346935248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34393,DS-4e9b4f81-1d3a-4b6a-b759-2eea37a73a51,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-622e38ed-2077-4b8f-b96f-be8daa083fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-a662cb51-0836-415f-afb1-39a22a0fcd57,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-4a4d83d8-ad6d-4117-8cb1-50953f794001,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-ed66c538-e9ba-4f48-b0d0-28e6aa7f34c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-f746f57c-7d81-482e-9188-330acec445fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-406fbd14-02df-4a69-8d57-dbe0af2093a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-24f6bef4-d451-4c3d-be7e-3deb5950dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916498238-172.17.0.7-1597346966711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-86ad595c-f2b2-4f0b-a1b9-01cf8c85fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-bcf36371-8929-4e2e-943e-fc429115e703,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5a96773c-ba4a-4389-bb4b-372be50d9426,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-3ab7eb3a-cc3e-46b0-9b18-ac95f7dcaad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-935c42ea-5a65-463c-90d2-6fdeb65e3943,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-685f1b10-ad6b-4104-9414-8fe99273e239,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f767e10e-deab-432e-8643-00706f729544,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-98a89a6c-3aa7-4b74-bf02-f7ea57b0a221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916498238-172.17.0.7-1597346966711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-86ad595c-f2b2-4f0b-a1b9-01cf8c85fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-bcf36371-8929-4e2e-943e-fc429115e703,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5a96773c-ba4a-4389-bb4b-372be50d9426,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-3ab7eb3a-cc3e-46b0-9b18-ac95f7dcaad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-935c42ea-5a65-463c-90d2-6fdeb65e3943,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-685f1b10-ad6b-4104-9414-8fe99273e239,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f767e10e-deab-432e-8643-00706f729544,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-98a89a6c-3aa7-4b74-bf02-f7ea57b0a221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086661286-172.17.0.7-1597347211796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-9afdb639-a029-4dc0-b8ce-03c99865d632,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c8791d73-dc06-41df-8327-7e25354d1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-a1d5aca2-3f3d-4d98-9efa-5a39587f81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4827ce2c-3fd2-4a1b-bd2c-57edbd144cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-7dd048a6-2534-4527-99d8-9dec08e7d316,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-0a8dc7bf-7101-47af-b73b-28cf5b712673,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-0e561945-4737-4e78-8811-d2cda438bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-81b01666-890e-4616-823b-c8c73655010e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086661286-172.17.0.7-1597347211796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-9afdb639-a029-4dc0-b8ce-03c99865d632,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c8791d73-dc06-41df-8327-7e25354d1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-a1d5aca2-3f3d-4d98-9efa-5a39587f81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4827ce2c-3fd2-4a1b-bd2c-57edbd144cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-7dd048a6-2534-4527-99d8-9dec08e7d316,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-0a8dc7bf-7101-47af-b73b-28cf5b712673,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-0e561945-4737-4e78-8811-d2cda438bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-81b01666-890e-4616-823b-c8c73655010e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5726
