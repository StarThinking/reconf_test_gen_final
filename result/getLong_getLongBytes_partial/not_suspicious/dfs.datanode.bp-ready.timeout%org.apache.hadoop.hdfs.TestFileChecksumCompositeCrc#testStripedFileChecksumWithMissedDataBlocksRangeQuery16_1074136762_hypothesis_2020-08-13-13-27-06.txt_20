reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363071247-172.17.0.17-1597325700430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-79a10b99-b8ff-4978-9b34-75373e3e1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-b0d31ac6-dc2d-406b-9a69-3591cec28021,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-36445f97-fe7d-4151-b685-a99cc83299d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-8a0a4ddc-da05-4fa7-8c20-2da86de8ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-98855363-f790-4663-8c5d-2773e8a6fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-b4b1ddb7-7af4-44df-a139-31272a1175e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d06c682e-edb8-453f-8348-f2eb27577bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a01f9660-a188-404e-af49-7608db3e7d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363071247-172.17.0.17-1597325700430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-79a10b99-b8ff-4978-9b34-75373e3e1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-b0d31ac6-dc2d-406b-9a69-3591cec28021,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-36445f97-fe7d-4151-b685-a99cc83299d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-8a0a4ddc-da05-4fa7-8c20-2da86de8ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-98855363-f790-4663-8c5d-2773e8a6fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-b4b1ddb7-7af4-44df-a139-31272a1175e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d06c682e-edb8-453f-8348-f2eb27577bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a01f9660-a188-404e-af49-7608db3e7d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804182522-172.17.0.17-1597326094388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-89ba3d0a-473b-4465-b4d6-9880317b4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-863846c8-fcc0-4144-9012-43ae88b85bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-1cb66744-d15c-4d74-9dba-8aba43d97d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-7578f3eb-2c6b-4296-ad72-52aacb9b6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-e38802c6-f7e4-432e-957e-74d4582d92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-97b3c6c8-79fe-40b3-aeb6-178c176cb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-7293d8ce-75b5-4a5e-90aa-81b2690f264c,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-130d91f6-2221-41c3-9669-d3468b50844f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804182522-172.17.0.17-1597326094388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-89ba3d0a-473b-4465-b4d6-9880317b4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-863846c8-fcc0-4144-9012-43ae88b85bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-1cb66744-d15c-4d74-9dba-8aba43d97d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-7578f3eb-2c6b-4296-ad72-52aacb9b6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-e38802c6-f7e4-432e-957e-74d4582d92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-97b3c6c8-79fe-40b3-aeb6-178c176cb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-7293d8ce-75b5-4a5e-90aa-81b2690f264c,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-130d91f6-2221-41c3-9669-d3468b50844f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308738207-172.17.0.17-1597326675785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-693159a8-ea57-40e8-8d8b-d7f9680de53a,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-bbfb8130-1e8c-4db6-b400-e510c54412ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-5587d712-3610-44e5-90a9-1155543b2260,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-cb69f6e8-44d1-4a2e-909f-8b0da6ecfa94,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-d3d5d964-ff6d-4e7d-8776-bb83a49d0877,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-0d9ee32e-c431-4969-9e69-0b20c21692f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-f6440e92-6fa2-4b8f-a079-54eafd354438,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-9c886646-1368-4ea7-97ec-a2bc036b8503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308738207-172.17.0.17-1597326675785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-693159a8-ea57-40e8-8d8b-d7f9680de53a,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-bbfb8130-1e8c-4db6-b400-e510c54412ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-5587d712-3610-44e5-90a9-1155543b2260,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-cb69f6e8-44d1-4a2e-909f-8b0da6ecfa94,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-d3d5d964-ff6d-4e7d-8776-bb83a49d0877,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-0d9ee32e-c431-4969-9e69-0b20c21692f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-f6440e92-6fa2-4b8f-a079-54eafd354438,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-9c886646-1368-4ea7-97ec-a2bc036b8503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779369525-172.17.0.17-1597327869459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-3ff2ada8-dcec-476d-9a94-d52bd33900b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2948e1fb-079d-4a85-9d7d-4854f260cdac,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-e82b8a20-d9ad-4e66-8f27-44297540c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-215462be-1704-4416-86c7-7863c8b0bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-8d756723-9e03-49d3-a281-e302d13d826f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-79c66d72-fb29-498c-afe0-d6ca8651068e,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-c4a4cf6c-4b9e-4cca-9e58-79a76db869ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-efe65355-0cf5-4242-a05c-f177358b5bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779369525-172.17.0.17-1597327869459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-3ff2ada8-dcec-476d-9a94-d52bd33900b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2948e1fb-079d-4a85-9d7d-4854f260cdac,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-e82b8a20-d9ad-4e66-8f27-44297540c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-215462be-1704-4416-86c7-7863c8b0bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-8d756723-9e03-49d3-a281-e302d13d826f,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-79c66d72-fb29-498c-afe0-d6ca8651068e,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-c4a4cf6c-4b9e-4cca-9e58-79a76db869ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-efe65355-0cf5-4242-a05c-f177358b5bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105984368-172.17.0.17-1597328064264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0f0c9b81-bbd8-4987-917e-1efb1f034886,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-908df68d-3cf4-44bd-892e-8fdd4c9f1169,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-2febc1a3-f6b6-46a5-92c5-5cdb96bd012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-2ee5c5ca-effd-4d1d-a897-fa2c940c4495,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-6a73a2db-4fc2-4f37-ab17-ea3841d943ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-0732e4ed-4e60-43b5-bfb5-6e26591630ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-f78a5766-9a83-4ffb-857c-c39bf3b84f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-eeeba393-1a06-498f-8372-54eadfafa2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105984368-172.17.0.17-1597328064264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0f0c9b81-bbd8-4987-917e-1efb1f034886,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-908df68d-3cf4-44bd-892e-8fdd4c9f1169,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-2febc1a3-f6b6-46a5-92c5-5cdb96bd012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-2ee5c5ca-effd-4d1d-a897-fa2c940c4495,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-6a73a2db-4fc2-4f37-ab17-ea3841d943ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-0732e4ed-4e60-43b5-bfb5-6e26591630ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-f78a5766-9a83-4ffb-857c-c39bf3b84f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-eeeba393-1a06-498f-8372-54eadfafa2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598416146-172.17.0.17-1597328296797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-1682d510-7b21-4985-9e50-bdf774f2df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1e798819-4c62-45a9-aadf-a4a417428de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-6b356e16-b44c-4356-af0a-270860752707,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-00f8814e-2a0d-4e43-ac66-4f2d7c854864,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-d18318ae-3a91-4480-971e-0a89627dac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-3403b7a9-11b8-416c-b67d-f186ebfaf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-719f0bb9-63cd-4dcc-8fbf-c61efb787f69,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-efa7fb14-1679-45ac-a055-596c91752834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598416146-172.17.0.17-1597328296797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-1682d510-7b21-4985-9e50-bdf774f2df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1e798819-4c62-45a9-aadf-a4a417428de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-6b356e16-b44c-4356-af0a-270860752707,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-00f8814e-2a0d-4e43-ac66-4f2d7c854864,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-d18318ae-3a91-4480-971e-0a89627dac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-3403b7a9-11b8-416c-b67d-f186ebfaf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-719f0bb9-63cd-4dcc-8fbf-c61efb787f69,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-efa7fb14-1679-45ac-a055-596c91752834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502194899-172.17.0.17-1597328347270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-4eb6895d-0046-4fc0-877c-34f9d75fd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-8d215241-ba4d-4bcb-86bc-20a1d4c296d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-d41ba57d-353f-4f10-a582-3a65b3e642ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cdbae1c7-c35a-460c-beee-c66e57a392f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-47906409-8357-4165-9f67-6dc5b0d9a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-0085a719-1d7e-4149-8f20-bf9a3cf282c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-a3ee52ce-f5b3-4247-80d2-8fe44e5c9665,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-e6c9f70f-9521-4982-9abb-b4db220af9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502194899-172.17.0.17-1597328347270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-4eb6895d-0046-4fc0-877c-34f9d75fd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-8d215241-ba4d-4bcb-86bc-20a1d4c296d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-d41ba57d-353f-4f10-a582-3a65b3e642ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cdbae1c7-c35a-460c-beee-c66e57a392f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-47906409-8357-4165-9f67-6dc5b0d9a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-0085a719-1d7e-4149-8f20-bf9a3cf282c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-a3ee52ce-f5b3-4247-80d2-8fe44e5c9665,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-e6c9f70f-9521-4982-9abb-b4db220af9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144397376-172.17.0.17-1597328796081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-3dc44dbe-ef65-4d60-b988-530017a8b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-a51bc989-1c0e-4c4b-8615-3371b1e654e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-239e96b8-f9a7-4204-a11d-17b9035c736e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-87282f8f-35a5-4f88-af94-d75b2ce98db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-5059f6b8-1684-4dce-b28c-d698e49cc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-4cf5adc5-ee60-4f9c-8995-7dd1a674f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-36375f0f-222e-4e27-ab52-13533f93c1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-a54f46e2-a1c6-470d-8710-04815ef9bf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144397376-172.17.0.17-1597328796081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-3dc44dbe-ef65-4d60-b988-530017a8b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-a51bc989-1c0e-4c4b-8615-3371b1e654e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-239e96b8-f9a7-4204-a11d-17b9035c736e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-87282f8f-35a5-4f88-af94-d75b2ce98db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-5059f6b8-1684-4dce-b28c-d698e49cc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-4cf5adc5-ee60-4f9c-8995-7dd1a674f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-36375f0f-222e-4e27-ab52-13533f93c1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-a54f46e2-a1c6-470d-8710-04815ef9bf01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133806243-172.17.0.17-1597329232703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-6678fe3f-0074-4311-8fc7-111680060676,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-399bbd47-7dd8-4720-83a9-906faa2798ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-cff1b1ce-c031-4129-9e4f-50982d1e0876,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-f762e1d3-0954-4d53-80a6-eaf10c781ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-1ec64dbc-8a8a-4791-8fee-cfb1f89a045c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-1cf9bcb4-0e6f-4b5d-8893-ce2f9e218228,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-25f18dd9-b451-4e81-87cc-e87647439005,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-79620655-47e5-4eec-b4d3-a47cb25347f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133806243-172.17.0.17-1597329232703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-6678fe3f-0074-4311-8fc7-111680060676,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-399bbd47-7dd8-4720-83a9-906faa2798ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-cff1b1ce-c031-4129-9e4f-50982d1e0876,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-f762e1d3-0954-4d53-80a6-eaf10c781ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-1ec64dbc-8a8a-4791-8fee-cfb1f89a045c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-1cf9bcb4-0e6f-4b5d-8893-ce2f9e218228,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-25f18dd9-b451-4e81-87cc-e87647439005,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-79620655-47e5-4eec-b4d3-a47cb25347f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987250073-172.17.0.17-1597329776962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-18253bc5-6d98-4759-b2d4-dfecb188aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-c27f2793-ce4e-46fa-b36f-63285fb149c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1b028a09-7419-4191-9c99-b271416051ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-73f31da9-bf09-46e0-b187-4805bac80002,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-b7c48df8-8e14-4695-bd8a-6fc4c9d2c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-e08cee26-e0ab-4aad-ae68-9da961e621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-3b6ccef0-79fe-4ec1-a378-5b984e08e572,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-57d050e7-4780-445c-a428-eb3d1608c756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987250073-172.17.0.17-1597329776962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-18253bc5-6d98-4759-b2d4-dfecb188aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-c27f2793-ce4e-46fa-b36f-63285fb149c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1b028a09-7419-4191-9c99-b271416051ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-73f31da9-bf09-46e0-b187-4805bac80002,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-b7c48df8-8e14-4695-bd8a-6fc4c9d2c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-e08cee26-e0ab-4aad-ae68-9da961e621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-3b6ccef0-79fe-4ec1-a378-5b984e08e572,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-57d050e7-4780-445c-a428-eb3d1608c756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886016812-172.17.0.17-1597329896362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-c2b91341-1675-40cb-a93a-c1949eca87fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-0afc51c0-9d06-45dc-91f1-7ec39d46866c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-b3c2c5f3-1636-4b51-96ee-c80a929be1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-70d70996-dabc-4af0-be45-87ff7050f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-935f7efe-68e9-4d12-87a3-857fc878c752,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-a93793eb-779a-4fad-9cdb-f33d51782d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-342ac04e-9b83-420a-ad8b-e953505bc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-db1c8f32-7918-4a22-8661-81275754e910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886016812-172.17.0.17-1597329896362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-c2b91341-1675-40cb-a93a-c1949eca87fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-0afc51c0-9d06-45dc-91f1-7ec39d46866c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-b3c2c5f3-1636-4b51-96ee-c80a929be1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-70d70996-dabc-4af0-be45-87ff7050f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-935f7efe-68e9-4d12-87a3-857fc878c752,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-a93793eb-779a-4fad-9cdb-f33d51782d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-342ac04e-9b83-420a-ad8b-e953505bc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-db1c8f32-7918-4a22-8661-81275754e910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115644174-172.17.0.17-1597330276090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-387466f9-7678-4918-9f59-46a8c4733986,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-c3b4e4d2-1ab5-433a-81e4-dc6c32e4da61,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-8de45b1a-d98c-466f-8f3f-298e724c911f,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-e845d28c-1534-49f4-9eac-f8af4d1c414e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-33377403-79e1-40f1-a061-ffe18cb5301a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c6cd3b95-081b-4264-9f00-de706272495b,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-077841ba-e38c-4732-8c8e-620e8717dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-94595080-1c9c-4d77-b2a7-71468cf7c452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115644174-172.17.0.17-1597330276090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-387466f9-7678-4918-9f59-46a8c4733986,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-c3b4e4d2-1ab5-433a-81e4-dc6c32e4da61,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-8de45b1a-d98c-466f-8f3f-298e724c911f,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-e845d28c-1534-49f4-9eac-f8af4d1c414e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-33377403-79e1-40f1-a061-ffe18cb5301a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c6cd3b95-081b-4264-9f00-de706272495b,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-077841ba-e38c-4732-8c8e-620e8717dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-94595080-1c9c-4d77-b2a7-71468cf7c452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103569359-172.17.0.17-1597330463981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-48bf0f3a-40a5-4b07-9c70-a7c6b7802a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-f0770c8f-9354-42ad-a6c8-17452cbb8104,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-80c43d8c-87ea-4b55-9983-ba941f6ecb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-6ffbced7-e29c-403e-97a7-43a8e503fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-e23289c4-6e8f-41e3-8e53-239e3a263134,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-9a798f68-90e5-4167-9f85-4cdf334f6916,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-615d20c5-d9da-4ebf-970b-1ccaa928e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-3434bad1-8aaa-4bbd-9bca-5d15cf4e343e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103569359-172.17.0.17-1597330463981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-48bf0f3a-40a5-4b07-9c70-a7c6b7802a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-f0770c8f-9354-42ad-a6c8-17452cbb8104,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-80c43d8c-87ea-4b55-9983-ba941f6ecb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-6ffbced7-e29c-403e-97a7-43a8e503fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-e23289c4-6e8f-41e3-8e53-239e3a263134,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-9a798f68-90e5-4167-9f85-4cdf334f6916,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-615d20c5-d9da-4ebf-970b-1ccaa928e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-3434bad1-8aaa-4bbd-9bca-5d15cf4e343e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426877428-172.17.0.17-1597331281286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-47ec1382-c24b-4e4b-a8f0-1b8d22115fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d9124896-b106-4d2a-82b7-efc51c1f251d,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f8f8d0fc-c5b0-4425-9472-cc35f07d0d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c3414079-62c0-4e4f-a47f-334b2c888d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-3ded1b8e-b994-43fd-8ac9-8c4a86b1c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-3795c9da-8d1b-43a2-86b0-badf43b53559,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-b43a46a0-aa43-4997-8676-e5ff5b470c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-f13cbd97-1021-4984-b3c3-bfb290fefd43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426877428-172.17.0.17-1597331281286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-47ec1382-c24b-4e4b-a8f0-1b8d22115fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d9124896-b106-4d2a-82b7-efc51c1f251d,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f8f8d0fc-c5b0-4425-9472-cc35f07d0d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c3414079-62c0-4e4f-a47f-334b2c888d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-3ded1b8e-b994-43fd-8ac9-8c4a86b1c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-3795c9da-8d1b-43a2-86b0-badf43b53559,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-b43a46a0-aa43-4997-8676-e5ff5b470c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-f13cbd97-1021-4984-b3c3-bfb290fefd43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6826
