reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651992250-172.17.0.20-1597660094890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34877,DS-55b15d57-fdeb-4536-ba5b-52241554573d,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-2c51a657-1c7c-4fce-abdb-e90e35337aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-bef5689b-4ab8-4aec-a16c-0fda615406bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-e7edc113-aeb0-4ae5-8376-d93ae646fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-d8953bc4-7de1-4b6d-af01-0c1c2c8fed10,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-52cfbb79-5463-495e-bf0f-95629a63eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-54da12f1-7592-4919-932a-774938f09367,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-3be09f6a-bb84-4c73-8780-17254f144a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651992250-172.17.0.20-1597660094890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34877,DS-55b15d57-fdeb-4536-ba5b-52241554573d,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-2c51a657-1c7c-4fce-abdb-e90e35337aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-bef5689b-4ab8-4aec-a16c-0fda615406bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-e7edc113-aeb0-4ae5-8376-d93ae646fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-d8953bc4-7de1-4b6d-af01-0c1c2c8fed10,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-52cfbb79-5463-495e-bf0f-95629a63eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-54da12f1-7592-4919-932a-774938f09367,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-3be09f6a-bb84-4c73-8780-17254f144a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052971290-172.17.0.20-1597660314702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-3557c0cf-2f7e-4954-afc3-95dfb97af368,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-08dbf7b5-a092-4eae-9c01-bd153abd9eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-11a7cf85-9e1b-465b-931d-a55ca5d97394,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-07e18447-b1ea-4ad2-96b4-b08af5ee4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-12e5a620-49be-4384-be0f-18bf72c304ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4ee56e00-1d33-4545-b54a-c2c3cc197bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-d5d6fb0f-dcbe-42e6-b00d-f5d439a20f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-14d0c4f6-c909-4690-ad13-88d379a5a8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052971290-172.17.0.20-1597660314702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-3557c0cf-2f7e-4954-afc3-95dfb97af368,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-08dbf7b5-a092-4eae-9c01-bd153abd9eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-11a7cf85-9e1b-465b-931d-a55ca5d97394,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-07e18447-b1ea-4ad2-96b4-b08af5ee4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-12e5a620-49be-4384-be0f-18bf72c304ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-4ee56e00-1d33-4545-b54a-c2c3cc197bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-d5d6fb0f-dcbe-42e6-b00d-f5d439a20f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-14d0c4f6-c909-4690-ad13-88d379a5a8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676707834-172.17.0.20-1597660358806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-6afa1e6d-4534-4561-a0e4-c30ee6f5ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-c58f377b-3f59-4165-8c3b-fdaa2d84bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-544cdd20-6eb4-4f8a-9e7a-a4a4c74163a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-3ac76a0a-d7de-4b6d-91d0-80a6eb81c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-e9a69615-d52d-4f2f-ad28-3fde31abf2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-ca6f75cc-67d4-47c7-81c6-4f16395b4b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-4593075a-2f43-477e-9759-88db2bd3a625,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-7cdfc3cf-6d78-4a7c-b032-86fad88a7ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676707834-172.17.0.20-1597660358806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-6afa1e6d-4534-4561-a0e4-c30ee6f5ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-c58f377b-3f59-4165-8c3b-fdaa2d84bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-544cdd20-6eb4-4f8a-9e7a-a4a4c74163a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-3ac76a0a-d7de-4b6d-91d0-80a6eb81c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-e9a69615-d52d-4f2f-ad28-3fde31abf2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-ca6f75cc-67d4-47c7-81c6-4f16395b4b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-4593075a-2f43-477e-9759-88db2bd3a625,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-7cdfc3cf-6d78-4a7c-b032-86fad88a7ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768811872-172.17.0.20-1597660670684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-a612f921-2fe9-4a1a-9ea0-59b65ea49f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-49de9cf0-e585-4af0-860d-f4abe3732f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-bb4010bd-874b-43c8-bcd5-968316f42c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-662768fc-382b-4d2f-81bd-e993a8e25f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-6e6579f0-ca4b-4c3b-9664-adf6b6c0f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-f7a5c896-3ffe-4fb8-8fd6-62200bc8ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-c07a017a-84b5-4def-bed8-f73974618c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-9432709d-92b1-4a3e-8f1c-30f423666bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768811872-172.17.0.20-1597660670684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-a612f921-2fe9-4a1a-9ea0-59b65ea49f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-49de9cf0-e585-4af0-860d-f4abe3732f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-bb4010bd-874b-43c8-bcd5-968316f42c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-662768fc-382b-4d2f-81bd-e993a8e25f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-6e6579f0-ca4b-4c3b-9664-adf6b6c0f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-f7a5c896-3ffe-4fb8-8fd6-62200bc8ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-c07a017a-84b5-4def-bed8-f73974618c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-9432709d-92b1-4a3e-8f1c-30f423666bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307374455-172.17.0.20-1597661116384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40563,DS-dde846a8-9942-40bc-b012-befadd4c8ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-6f4b797f-f801-4821-8beb-ae0eb906bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-13ac92bc-f475-4eef-a6f5-0dcb4ece9f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-9e2b37e4-e08d-4faa-a151-d7154c3e1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-3851db1e-2a9a-4c88-bd25-7afad360e270,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-5efd4e95-42eb-45f8-bbb9-18c9bead64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-b3c72513-0f4b-4236-93b7-97b36fc7e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4963a47b-6cd9-4a54-ac7c-2119d16bbb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307374455-172.17.0.20-1597661116384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40563,DS-dde846a8-9942-40bc-b012-befadd4c8ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-6f4b797f-f801-4821-8beb-ae0eb906bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-13ac92bc-f475-4eef-a6f5-0dcb4ece9f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-9e2b37e4-e08d-4faa-a151-d7154c3e1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-3851db1e-2a9a-4c88-bd25-7afad360e270,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-5efd4e95-42eb-45f8-bbb9-18c9bead64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-b3c72513-0f4b-4236-93b7-97b36fc7e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4963a47b-6cd9-4a54-ac7c-2119d16bbb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218340150-172.17.0.20-1597661952780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42767,DS-8410e5fe-5a84-4ce5-b688-80256388016f,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-6189c242-4a38-456b-aca2-87bc7659491a,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-68c63d34-7e2a-469d-ba70-07f8d226d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b4bf0de6-8a89-4761-8e32-0f30e7f8b176,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-e42d8d3a-f6f8-4bb2-8915-410dbedf7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6688ef7d-d995-47d6-887f-81f080b67828,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a6d0b590-a3a1-480d-987e-09c885bd45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-b6a3dfa1-875c-4c5b-bcd7-8a07a6aa8341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218340150-172.17.0.20-1597661952780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42767,DS-8410e5fe-5a84-4ce5-b688-80256388016f,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-6189c242-4a38-456b-aca2-87bc7659491a,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-68c63d34-7e2a-469d-ba70-07f8d226d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b4bf0de6-8a89-4761-8e32-0f30e7f8b176,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-e42d8d3a-f6f8-4bb2-8915-410dbedf7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6688ef7d-d995-47d6-887f-81f080b67828,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a6d0b590-a3a1-480d-987e-09c885bd45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-b6a3dfa1-875c-4c5b-bcd7-8a07a6aa8341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645711105-172.17.0.20-1597662228613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-8555d3f4-c29e-4f52-a14e-9dd1a32363ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6e0462ed-4088-4e38-89f1-251949663d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-56faf7c2-23fd-41a9-9180-cd1fb4df2df7,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-2cd6cb16-3eb3-4737-a281-6aed01d15eef,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b21638db-7fef-48fe-8a5e-948ed0011f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-2ee61150-486f-4f27-9276-ad292753490b,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-c311b5a0-3fb2-4344-989a-3089cb431e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-044792bb-38ec-48a8-8efa-56b74fb16a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645711105-172.17.0.20-1597662228613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-8555d3f4-c29e-4f52-a14e-9dd1a32363ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6e0462ed-4088-4e38-89f1-251949663d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-56faf7c2-23fd-41a9-9180-cd1fb4df2df7,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-2cd6cb16-3eb3-4737-a281-6aed01d15eef,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b21638db-7fef-48fe-8a5e-948ed0011f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-2ee61150-486f-4f27-9276-ad292753490b,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-c311b5a0-3fb2-4344-989a-3089cb431e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-044792bb-38ec-48a8-8efa-56b74fb16a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064155426-172.17.0.20-1597663123765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-6521e5c4-d3ee-4826-863b-ee367c4cbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-b1b800b1-b06b-4c23-b01a-a499e0926004,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-4e486b7b-15d4-46d6-b7d9-6d543eb1f912,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-9b615270-bf2a-405d-be41-68298fe41b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-a625069c-2802-458c-9518-b6319ec718ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-b6c72b30-7cdc-46c3-aa2f-f3f866a41b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-f45f857d-8bcd-4974-8229-5ac16923d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-6e7c4434-5bd3-47e6-99c7-fbc0df40ffe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064155426-172.17.0.20-1597663123765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-6521e5c4-d3ee-4826-863b-ee367c4cbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-b1b800b1-b06b-4c23-b01a-a499e0926004,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-4e486b7b-15d4-46d6-b7d9-6d543eb1f912,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-9b615270-bf2a-405d-be41-68298fe41b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-a625069c-2802-458c-9518-b6319ec718ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-b6c72b30-7cdc-46c3-aa2f-f3f866a41b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-f45f857d-8bcd-4974-8229-5ac16923d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-6e7c4434-5bd3-47e6-99c7-fbc0df40ffe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42168318-172.17.0.20-1597663833588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-d541f1da-f6f6-40d3-ac17-af7127fd5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-2dc1ed9d-84ec-48ef-a254-4aa8d5431cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-adc79785-a504-47f3-b312-12cd5dc47101,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-6d380e57-2fd5-4bd4-9b16-436bb6b92c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-77c0d1b6-203a-4634-8bd7-67cd48a1329b,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-feb8c5f4-8b3f-4f2f-ba03-fc34a8e8d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-4568e530-8473-44ab-84f7-02f815316fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cd104dc2-e568-46eb-99b9-3ac5bbfc4cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42168318-172.17.0.20-1597663833588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-d541f1da-f6f6-40d3-ac17-af7127fd5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-2dc1ed9d-84ec-48ef-a254-4aa8d5431cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-adc79785-a504-47f3-b312-12cd5dc47101,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-6d380e57-2fd5-4bd4-9b16-436bb6b92c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-77c0d1b6-203a-4634-8bd7-67cd48a1329b,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-feb8c5f4-8b3f-4f2f-ba03-fc34a8e8d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-4568e530-8473-44ab-84f7-02f815316fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cd104dc2-e568-46eb-99b9-3ac5bbfc4cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720862451-172.17.0.20-1597664060539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-396e4406-2bda-4ae4-887a-9e10dee22d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-9436bba6-224c-49e4-bc0e-575c3dee1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d880311a-79ec-4a68-b90c-50f630d6d878,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-4ad100ac-c71f-4ba5-9d63-fb2f2a52ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-dc983154-21c3-4d9f-9cb3-eb5074c5cf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-9def0996-24a3-483f-9272-f7ae2e63ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-019627f8-ce0a-451b-9193-16546fecf437,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-6c9a9ed2-9451-4ffb-be15-af084802e783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720862451-172.17.0.20-1597664060539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-396e4406-2bda-4ae4-887a-9e10dee22d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-9436bba6-224c-49e4-bc0e-575c3dee1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d880311a-79ec-4a68-b90c-50f630d6d878,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-4ad100ac-c71f-4ba5-9d63-fb2f2a52ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-dc983154-21c3-4d9f-9cb3-eb5074c5cf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-9def0996-24a3-483f-9272-f7ae2e63ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-019627f8-ce0a-451b-9193-16546fecf437,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-6c9a9ed2-9451-4ffb-be15-af084802e783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869955887-172.17.0.20-1597664366545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-a02911c5-79bf-494e-8340-c951d9f5f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-778c846e-52b1-4e78-af6e-c6f7870ab8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-b7ffddae-2078-4992-abad-7535fdffa6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-8cdca246-5dbd-4455-8cd7-c9cbc58fc0de,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ca6bb2d8-9792-4daf-a5fa-93a7e156e172,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-a84e78d7-033e-4ae9-aca6-bf997841cb25,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-26b1b2a2-c7a5-4b76-a842-6febf8ee1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f3a0b507-f710-41bb-9aca-df411e4b68b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869955887-172.17.0.20-1597664366545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-a02911c5-79bf-494e-8340-c951d9f5f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-778c846e-52b1-4e78-af6e-c6f7870ab8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-b7ffddae-2078-4992-abad-7535fdffa6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-8cdca246-5dbd-4455-8cd7-c9cbc58fc0de,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ca6bb2d8-9792-4daf-a5fa-93a7e156e172,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-a84e78d7-033e-4ae9-aca6-bf997841cb25,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-26b1b2a2-c7a5-4b76-a842-6febf8ee1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f3a0b507-f710-41bb-9aca-df411e4b68b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852979399-172.17.0.20-1597664481901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-e9e49bfa-b336-4720-bfee-4703638b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-904bcfda-73a7-4905-bf6b-5f4dc3682e54,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-1d3b7eaa-b36a-42c5-8b50-7eb4ffd9cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-926f95ad-796c-4931-afec-1da9cf92b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-27d135a1-bb78-48d3-8fb1-377fa32d2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-36720448-d30d-4c6c-9e45-cd0c056c0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-63765eff-342c-4e08-97b7-06b178f6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-4a02c0fe-5073-4339-8ca7-415566e22e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852979399-172.17.0.20-1597664481901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-e9e49bfa-b336-4720-bfee-4703638b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-904bcfda-73a7-4905-bf6b-5f4dc3682e54,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-1d3b7eaa-b36a-42c5-8b50-7eb4ffd9cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-926f95ad-796c-4931-afec-1da9cf92b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-27d135a1-bb78-48d3-8fb1-377fa32d2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-36720448-d30d-4c6c-9e45-cd0c056c0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-63765eff-342c-4e08-97b7-06b178f6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-4a02c0fe-5073-4339-8ca7-415566e22e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098579647-172.17.0.20-1597665022209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-6aae9838-a475-4fa8-bab2-d8b2620255d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-0b712c79-8b36-4f72-b833-82c8231d4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-7422a085-fb0c-471d-8681-f969ecfd1432,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-b9c0a4d7-2e10-4b5a-bbad-3e3da17ca15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-db125ffb-2ce2-4110-a459-7abb67631a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-a730626e-0be6-4f1b-9134-0194673bc041,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-495e1421-4701-4a6e-8144-cf8c7d26c057,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-4154c568-b8a0-4da6-b599-f68e6f024df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098579647-172.17.0.20-1597665022209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-6aae9838-a475-4fa8-bab2-d8b2620255d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-0b712c79-8b36-4f72-b833-82c8231d4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-7422a085-fb0c-471d-8681-f969ecfd1432,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-b9c0a4d7-2e10-4b5a-bbad-3e3da17ca15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-db125ffb-2ce2-4110-a459-7abb67631a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-a730626e-0be6-4f1b-9134-0194673bc041,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-495e1421-4701-4a6e-8144-cf8c7d26c057,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-4154c568-b8a0-4da6-b599-f68e6f024df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089000227-172.17.0.20-1597665432453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-9750a5ad-f813-43b1-9906-e56aa8e12a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0f56e2e1-884f-457e-b347-927c84389c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-95aa9e46-29ea-4cfa-b6ca-050b87ce96c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-0716c39b-a228-4e5b-9462-d775f42f0c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-92aee813-081a-454d-b75a-638c2b8ebe89,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-104cd251-4faa-4c1e-a3a2-a5d350558127,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-28ad7267-3e68-4f36-adcd-4707e9878712,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-983170ef-c044-46ff-a61f-ddc8dfc2140d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089000227-172.17.0.20-1597665432453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-9750a5ad-f813-43b1-9906-e56aa8e12a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0f56e2e1-884f-457e-b347-927c84389c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-95aa9e46-29ea-4cfa-b6ca-050b87ce96c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-0716c39b-a228-4e5b-9462-d775f42f0c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-92aee813-081a-454d-b75a-638c2b8ebe89,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-104cd251-4faa-4c1e-a3a2-a5d350558127,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-28ad7267-3e68-4f36-adcd-4707e9878712,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-983170ef-c044-46ff-a61f-ddc8dfc2140d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5515
