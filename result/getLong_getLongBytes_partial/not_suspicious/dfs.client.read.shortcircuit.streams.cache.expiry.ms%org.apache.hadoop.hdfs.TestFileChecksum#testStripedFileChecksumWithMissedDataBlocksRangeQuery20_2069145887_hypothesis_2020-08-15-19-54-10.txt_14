reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166440322-172.17.0.15-1597521265483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-bd4486f3-4dad-495d-9d4b-3180ab6a0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-980d53b6-8948-486a-8019-c326dd1c3231,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-22c611dd-f426-4dbd-a8ed-d5057163c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-04e7548e-b797-46b3-9e75-bbeb35f0e597,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-9fb3cc46-6d1e-45f4-b967-49df5ed58146,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-9044e48f-0784-4a70-bcdf-a4bdd8e541ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-449070d8-6920-47fd-8bad-1e38aa317006,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-9bd6a603-798e-40a3-8c23-54778e6ec5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166440322-172.17.0.15-1597521265483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-bd4486f3-4dad-495d-9d4b-3180ab6a0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-980d53b6-8948-486a-8019-c326dd1c3231,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-22c611dd-f426-4dbd-a8ed-d5057163c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-04e7548e-b797-46b3-9e75-bbeb35f0e597,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-9fb3cc46-6d1e-45f4-b967-49df5ed58146,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-9044e48f-0784-4a70-bcdf-a4bdd8e541ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-449070d8-6920-47fd-8bad-1e38aa317006,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-9bd6a603-798e-40a3-8c23-54778e6ec5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165453643-172.17.0.15-1597521430953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45664,DS-1500154a-8207-4c02-a20f-7dff5d89bc76,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-00af70e3-1cef-44fa-a114-ed261c7266d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-49097e86-a27f-4c80-a475-a0af12795253,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-7bed11f5-d498-41b4-8f7e-f46fdfff39b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-0b6ea0c6-7006-42b2-9b5c-a4963c0d33fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-32bca0d1-bddf-4bb7-8aea-fe50ce185d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-5cd4f735-1c73-4ec0-9405-83d97a76594b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-14ab2b8d-46ab-4efd-b0e1-4d342e0abbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165453643-172.17.0.15-1597521430953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45664,DS-1500154a-8207-4c02-a20f-7dff5d89bc76,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-00af70e3-1cef-44fa-a114-ed261c7266d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-49097e86-a27f-4c80-a475-a0af12795253,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-7bed11f5-d498-41b4-8f7e-f46fdfff39b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-0b6ea0c6-7006-42b2-9b5c-a4963c0d33fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-32bca0d1-bddf-4bb7-8aea-fe50ce185d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-5cd4f735-1c73-4ec0-9405-83d97a76594b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-14ab2b8d-46ab-4efd-b0e1-4d342e0abbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384069223-172.17.0.15-1597521566572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-9e6167aa-b0ac-44c6-a094-d3c64fa2eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-e7ddf033-3061-4fba-9da6-725398256e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-3f05c0fc-05ca-45d0-b25b-8a15842c5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5026f43a-7942-4330-ad02-c481968af03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-48a0dd31-249d-47da-984a-8c412964c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-761b6ad3-0f90-4417-ad9e-e8e7b891cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-28da39ac-54a8-4919-bb0e-5d59501a48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-eeab4ad2-a06c-43bc-a82b-7c768fdd798c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384069223-172.17.0.15-1597521566572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-9e6167aa-b0ac-44c6-a094-d3c64fa2eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-e7ddf033-3061-4fba-9da6-725398256e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-3f05c0fc-05ca-45d0-b25b-8a15842c5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5026f43a-7942-4330-ad02-c481968af03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-48a0dd31-249d-47da-984a-8c412964c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-761b6ad3-0f90-4417-ad9e-e8e7b891cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-28da39ac-54a8-4919-bb0e-5d59501a48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-eeab4ad2-a06c-43bc-a82b-7c768fdd798c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426188292-172.17.0.15-1597521814731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-ec7f4a97-464e-491d-b07d-1b3ec9f91f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0014eaa4-669f-47ee-9b2e-ea6dc90aaecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a16346b0-57d8-4c83-b1f3-b675c1ff64f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-6a90929f-fcff-4c05-95a9-98abf35f6a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-5b7b8d30-075c-4761-8cbb-856cdb5623ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-310d21b1-cb74-4674-b66f-dad06fe28a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-7b47b1f0-1e89-4711-a6d2-93c0e995d400,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-ba96c6ef-76ab-4713-97e5-b62261d877e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426188292-172.17.0.15-1597521814731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-ec7f4a97-464e-491d-b07d-1b3ec9f91f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0014eaa4-669f-47ee-9b2e-ea6dc90aaecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a16346b0-57d8-4c83-b1f3-b675c1ff64f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-6a90929f-fcff-4c05-95a9-98abf35f6a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-5b7b8d30-075c-4761-8cbb-856cdb5623ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-310d21b1-cb74-4674-b66f-dad06fe28a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-7b47b1f0-1e89-4711-a6d2-93c0e995d400,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-ba96c6ef-76ab-4713-97e5-b62261d877e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772571276-172.17.0.15-1597522909526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37419,DS-78b8f9c5-fa49-4dbd-97f7-53d2a071c408,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-ef41e930-fa8e-4a7c-9e0a-8b510f58a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-88141a44-2823-44aa-9995-b8caff0da994,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-bd1a93b3-cdae-482a-81a1-aa1a9244a67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-07e2d69e-d1be-469e-b2d8-c383f805ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-56bd17eb-ac2d-4bcd-90aa-c7f5a1b6b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-d29929b0-b018-49ee-9811-82205578d401,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-038fc129-42c5-4dbc-95bf-2736342c9d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772571276-172.17.0.15-1597522909526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37419,DS-78b8f9c5-fa49-4dbd-97f7-53d2a071c408,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-ef41e930-fa8e-4a7c-9e0a-8b510f58a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-88141a44-2823-44aa-9995-b8caff0da994,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-bd1a93b3-cdae-482a-81a1-aa1a9244a67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-07e2d69e-d1be-469e-b2d8-c383f805ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-56bd17eb-ac2d-4bcd-90aa-c7f5a1b6b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-d29929b0-b018-49ee-9811-82205578d401,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-038fc129-42c5-4dbc-95bf-2736342c9d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643712690-172.17.0.15-1597522943312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-54a23635-c0de-4e7f-b0bd-e18467ff839e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-19cefb61-e1af-4a74-9b1f-2c5ad227a226,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0fd1c5fd-1233-4b0e-9236-aee1a0ef8357,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-277a9a51-9180-4d06-b107-889c2264b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-92ac357b-c520-4aaf-8cff-40c7cb621d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-c0350f40-c30b-4c47-88d4-dc1efd712e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-0c089e87-96a9-4cbd-ab88-6a16a6207539,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-faa72638-23e9-4f5a-bdae-fcae1c9547c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643712690-172.17.0.15-1597522943312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-54a23635-c0de-4e7f-b0bd-e18467ff839e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-19cefb61-e1af-4a74-9b1f-2c5ad227a226,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0fd1c5fd-1233-4b0e-9236-aee1a0ef8357,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-277a9a51-9180-4d06-b107-889c2264b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-92ac357b-c520-4aaf-8cff-40c7cb621d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-c0350f40-c30b-4c47-88d4-dc1efd712e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-0c089e87-96a9-4cbd-ab88-6a16a6207539,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-faa72638-23e9-4f5a-bdae-fcae1c9547c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714483269-172.17.0.15-1597523439383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-92adffdc-b4fa-45f4-a871-234ffa1ddac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-1bee60a1-a0f1-4df4-9591-67e9909ed64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-7ac17eb1-3cf4-4f5e-ae00-fbcc0f40cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-c6a045fc-3343-47ac-b589-c1b432acc926,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7a516700-6c8d-4a83-aa74-55ad587e52f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7a69d471-0ede-40aa-976a-d60231def1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-3abe69b2-d3d5-48e9-a5f1-d032081b618d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-ecf14698-e6cc-4145-9c56-c72224fb2d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714483269-172.17.0.15-1597523439383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-92adffdc-b4fa-45f4-a871-234ffa1ddac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-1bee60a1-a0f1-4df4-9591-67e9909ed64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-7ac17eb1-3cf4-4f5e-ae00-fbcc0f40cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-c6a045fc-3343-47ac-b589-c1b432acc926,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7a516700-6c8d-4a83-aa74-55ad587e52f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7a69d471-0ede-40aa-976a-d60231def1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-3abe69b2-d3d5-48e9-a5f1-d032081b618d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-ecf14698-e6cc-4145-9c56-c72224fb2d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409499435-172.17.0.15-1597523565858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-1f3a139e-d83e-4c18-91bc-d5c05173734a,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-1249d239-7495-45c3-aee1-14c0682cea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-434cae3e-66af-4740-91d3-257119197d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-f2ff8b0d-b902-4b75-b5e0-8a80d8a0086e,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-a9a08cc5-f27a-4ccd-8dc0-fcc557bafa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-91ffcaec-ab48-4e0a-9fda-8e32df16ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-1cfd687f-1202-4061-b7b2-093e94a95434,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-a0aab199-0bd7-4c17-90ba-99583d01dfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409499435-172.17.0.15-1597523565858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-1f3a139e-d83e-4c18-91bc-d5c05173734a,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-1249d239-7495-45c3-aee1-14c0682cea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-434cae3e-66af-4740-91d3-257119197d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-f2ff8b0d-b902-4b75-b5e0-8a80d8a0086e,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-a9a08cc5-f27a-4ccd-8dc0-fcc557bafa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-91ffcaec-ab48-4e0a-9fda-8e32df16ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-1cfd687f-1202-4061-b7b2-093e94a95434,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-a0aab199-0bd7-4c17-90ba-99583d01dfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217105052-172.17.0.15-1597523906546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-6b62df1c-d103-4412-81da-e3abb83a6882,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-17b3ae1f-6573-43cb-85b6-11408efe1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-4b019255-0cd7-43dc-b940-c40cea26574d,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-d45b9ab0-4cdf-46c6-9e4d-ea8fbbdec173,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-41476088-8ade-40fa-86af-fbb5c88301c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-5a6b7920-90d3-41e1-ac47-9b9fe7ddfac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-cd051f8a-5e13-4f56-9f05-4d5ff7d7168a,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-dcf0cdba-1299-43b8-86e3-9645df9a8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217105052-172.17.0.15-1597523906546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-6b62df1c-d103-4412-81da-e3abb83a6882,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-17b3ae1f-6573-43cb-85b6-11408efe1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-4b019255-0cd7-43dc-b940-c40cea26574d,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-d45b9ab0-4cdf-46c6-9e4d-ea8fbbdec173,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-41476088-8ade-40fa-86af-fbb5c88301c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-5a6b7920-90d3-41e1-ac47-9b9fe7ddfac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-cd051f8a-5e13-4f56-9f05-4d5ff7d7168a,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-dcf0cdba-1299-43b8-86e3-9645df9a8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482023412-172.17.0.15-1597524483672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-cc95be51-2dfa-48a6-9113-687d28eee9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-98087b2e-7789-49e8-9528-7a0917b2126d,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-319c18bf-b0ed-49fa-aa30-1786f23f57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5ba145f2-0223-425f-a551-ef5b02412a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-067ad1d8-6a6b-4848-a9a4-2912cd6e7af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-a3e481f9-69f7-468f-bbab-d6ca21951cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-2158096e-37c9-43be-ac96-88a6d151d520,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-17d1833e-4e2a-41bd-ae31-f34ef9320c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482023412-172.17.0.15-1597524483672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-cc95be51-2dfa-48a6-9113-687d28eee9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-98087b2e-7789-49e8-9528-7a0917b2126d,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-319c18bf-b0ed-49fa-aa30-1786f23f57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5ba145f2-0223-425f-a551-ef5b02412a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-067ad1d8-6a6b-4848-a9a4-2912cd6e7af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-a3e481f9-69f7-468f-bbab-d6ca21951cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-2158096e-37c9-43be-ac96-88a6d151d520,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-17d1833e-4e2a-41bd-ae31-f34ef9320c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88528377-172.17.0.15-1597526346059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ede03225-9d5b-404d-8ebf-7dcb3f6210c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-dff39eff-45bf-4840-8933-3083c8a41206,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-55f27b07-e7bb-4387-91d3-64528856f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-900e2bbd-4f43-4593-b609-39719be60453,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-e7a0b376-a3c6-4cb5-9eaf-384faa38ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-17dcde61-e451-412b-82b6-5b8c57761b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-b20771ce-7564-43f5-9f65-8d831efdfcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-246f5e2e-148e-4785-87d7-e10479bf2e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88528377-172.17.0.15-1597526346059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ede03225-9d5b-404d-8ebf-7dcb3f6210c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-dff39eff-45bf-4840-8933-3083c8a41206,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-55f27b07-e7bb-4387-91d3-64528856f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-900e2bbd-4f43-4593-b609-39719be60453,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-e7a0b376-a3c6-4cb5-9eaf-384faa38ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-17dcde61-e451-412b-82b6-5b8c57761b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-b20771ce-7564-43f5-9f65-8d831efdfcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-246f5e2e-148e-4785-87d7-e10479bf2e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5186
