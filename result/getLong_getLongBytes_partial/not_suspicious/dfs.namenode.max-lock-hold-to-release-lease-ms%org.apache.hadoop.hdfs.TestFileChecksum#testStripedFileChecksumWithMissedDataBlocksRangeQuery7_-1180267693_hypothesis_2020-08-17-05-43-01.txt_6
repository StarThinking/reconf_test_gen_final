reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253839135-172.17.0.9-1597642995696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-711942d6-7502-49f5-a99c-eefb20b496f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-8c8f452d-1532-43d8-9a68-192f106541f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-8bf39f96-871b-4bca-93d1-30bbaf320a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-0d5a0ba0-3b4e-4ad7-88ce-6aeeed27313c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0f7b13e2-8374-4055-aa55-1a519b21bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e0e30b01-69a1-4c06-9531-31a32efe749a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-233874ff-0cca-45ba-b759-ac539c98e257,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-14806630-d87f-4404-80e1-c706b52ea00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253839135-172.17.0.9-1597642995696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-711942d6-7502-49f5-a99c-eefb20b496f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-8c8f452d-1532-43d8-9a68-192f106541f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-8bf39f96-871b-4bca-93d1-30bbaf320a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-0d5a0ba0-3b4e-4ad7-88ce-6aeeed27313c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0f7b13e2-8374-4055-aa55-1a519b21bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e0e30b01-69a1-4c06-9531-31a32efe749a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-233874ff-0cca-45ba-b759-ac539c98e257,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-14806630-d87f-4404-80e1-c706b52ea00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036988985-172.17.0.9-1597643174124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-d9ab868d-f57f-4ac0-abaf-41a03eb67c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-f0cb04d8-b12f-4985-8343-2162a12b4022,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e556de63-2033-471b-bbe8-6d6c353d6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-05cd7984-08c2-4033-849b-db3f9e5c8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-9c685ae3-7b1d-4a80-a38c-e7b53e3cf534,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0091366a-fcb4-47fb-9ba0-b8a9b564f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-76d2f1c6-80ea-4fdf-988e-c4248a12c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-66ed6621-3765-49be-afb1-72c1e963e2f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036988985-172.17.0.9-1597643174124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-d9ab868d-f57f-4ac0-abaf-41a03eb67c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-f0cb04d8-b12f-4985-8343-2162a12b4022,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e556de63-2033-471b-bbe8-6d6c353d6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-05cd7984-08c2-4033-849b-db3f9e5c8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-9c685ae3-7b1d-4a80-a38c-e7b53e3cf534,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0091366a-fcb4-47fb-9ba0-b8a9b564f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-76d2f1c6-80ea-4fdf-988e-c4248a12c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-66ed6621-3765-49be-afb1-72c1e963e2f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068608721-172.17.0.9-1597643361454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-d29a3ec4-d5eb-45d7-9016-db3baa272a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-0ea8ac89-a685-4e51-a80a-86ec2a4646e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-3d52ee83-4df8-4955-bd53-066df59e6feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-297c82a4-0e03-4faa-bcd2-ca10e6d2d381,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5387c2db-c7de-4d7d-91f2-82b56314ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-2fcabd8f-9bc4-4bfc-be23-ec2613848b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-55506c24-2b1d-4105-8407-c77e34ab92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-182a3010-1de0-4ff8-9450-2ce488cde954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068608721-172.17.0.9-1597643361454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-d29a3ec4-d5eb-45d7-9016-db3baa272a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-0ea8ac89-a685-4e51-a80a-86ec2a4646e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-3d52ee83-4df8-4955-bd53-066df59e6feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-297c82a4-0e03-4faa-bcd2-ca10e6d2d381,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5387c2db-c7de-4d7d-91f2-82b56314ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-2fcabd8f-9bc4-4bfc-be23-ec2613848b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-55506c24-2b1d-4105-8407-c77e34ab92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-182a3010-1de0-4ff8-9450-2ce488cde954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103648574-172.17.0.9-1597643475343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-45299be9-f0d1-4f8e-a94b-0b65116d42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fb8b2742-069b-42af-a1b3-db35b4195b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-64717daf-151f-42a7-a178-323dc5385874,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-f0f52209-15d7-46cd-8a2c-4fe4d64187c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-fa8512d0-8a78-4589-9877-df8a3b89e344,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-7ca0ef87-18a0-4433-bc96-86b8604bd930,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-5cade607-9f38-4f4b-8dd5-194d5443ce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-99a31266-be57-4d59-b95e-189ef1cd1ffa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103648574-172.17.0.9-1597643475343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-45299be9-f0d1-4f8e-a94b-0b65116d42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fb8b2742-069b-42af-a1b3-db35b4195b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-64717daf-151f-42a7-a178-323dc5385874,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-f0f52209-15d7-46cd-8a2c-4fe4d64187c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-fa8512d0-8a78-4589-9877-df8a3b89e344,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-7ca0ef87-18a0-4433-bc96-86b8604bd930,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-5cade607-9f38-4f4b-8dd5-194d5443ce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-99a31266-be57-4d59-b95e-189ef1cd1ffa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074322308-172.17.0.9-1597643851967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-30551645-68b1-46a3-ba44-0a16b9f7f63f,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-74b13009-f840-47ec-8f9e-b9f65d65dd25,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-1a5e4afd-f57e-4875-a42c-87a50ed61aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-64a064a4-86f2-4b28-8e84-876157d7bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-c9f55ae6-744e-442d-a367-21b24727999d,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-348cfaf3-cc78-4e2b-9ab8-a2a48d240dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-35d44710-bd4a-4f91-9848-b341b68ebc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-9746f24e-19da-4751-ba24-b08e660b2c14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074322308-172.17.0.9-1597643851967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-30551645-68b1-46a3-ba44-0a16b9f7f63f,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-74b13009-f840-47ec-8f9e-b9f65d65dd25,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-1a5e4afd-f57e-4875-a42c-87a50ed61aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-64a064a4-86f2-4b28-8e84-876157d7bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-c9f55ae6-744e-442d-a367-21b24727999d,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-348cfaf3-cc78-4e2b-9ab8-a2a48d240dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-35d44710-bd4a-4f91-9848-b341b68ebc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-9746f24e-19da-4751-ba24-b08e660b2c14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600856154-172.17.0.9-1597644627400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-6f221678-ef4d-41bf-9b6b-b20a99e98c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-04cbed21-e926-4d9c-9e25-7383cbfb281c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-e4c3ff1d-bdb5-49f5-9cd4-d6cedeb20d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-94b5732d-d2b9-43dd-b201-deb949405299,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-4dfa16cc-b69a-4511-8712-685333678e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-d6a6ea62-c9c0-4805-bb3f-454da6b6123d,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7e4e5336-1100-4b16-9117-b8176dd06007,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-643f935f-69e2-483d-8430-a022341fbfb5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600856154-172.17.0.9-1597644627400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-6f221678-ef4d-41bf-9b6b-b20a99e98c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-04cbed21-e926-4d9c-9e25-7383cbfb281c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-e4c3ff1d-bdb5-49f5-9cd4-d6cedeb20d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-94b5732d-d2b9-43dd-b201-deb949405299,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-4dfa16cc-b69a-4511-8712-685333678e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-d6a6ea62-c9c0-4805-bb3f-454da6b6123d,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7e4e5336-1100-4b16-9117-b8176dd06007,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-643f935f-69e2-483d-8430-a022341fbfb5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278840188-172.17.0.9-1597644659821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-1139cd79-7ed5-4e8a-857b-186377678604,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-a4400299-219d-4314-9961-13ea7886055b,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-483f005c-9b77-41c5-93df-65804e2d6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-74005bbb-c129-4919-ac1f-30ff1a5dc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-89d58549-d2df-4bce-8033-4a5b291037c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-c1522fb2-0834-490a-b6de-61e3f85e90a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-b41a45c8-eb51-4ae9-a86f-e9b3f923bb62,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-18ac02ea-9225-4ebd-9f28-ae7c8ce6a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278840188-172.17.0.9-1597644659821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-1139cd79-7ed5-4e8a-857b-186377678604,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-a4400299-219d-4314-9961-13ea7886055b,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-483f005c-9b77-41c5-93df-65804e2d6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-74005bbb-c129-4919-ac1f-30ff1a5dc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-89d58549-d2df-4bce-8033-4a5b291037c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-c1522fb2-0834-490a-b6de-61e3f85e90a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-b41a45c8-eb51-4ae9-a86f-e9b3f923bb62,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-18ac02ea-9225-4ebd-9f28-ae7c8ce6a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317945501-172.17.0.9-1597644774831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-abf67a4f-cb38-4e56-bd28-75a08450fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-940a62a6-667b-4f5f-8f0f-618ba85e1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-8ce7f6b7-e1a0-4432-8a7e-e21dfa87dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8f937f4c-4632-4539-bd8a-a8d595f3c489,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-33faaf2a-d831-4d76-b99d-e082921c91e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-775902a9-ebb7-49ab-b285-1bb241b49ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-9b13235f-aabb-4a2d-bb6c-92558d941100,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-fd20451d-c72e-4af6-a530-ea6c59d12c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317945501-172.17.0.9-1597644774831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-abf67a4f-cb38-4e56-bd28-75a08450fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-940a62a6-667b-4f5f-8f0f-618ba85e1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-8ce7f6b7-e1a0-4432-8a7e-e21dfa87dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8f937f4c-4632-4539-bd8a-a8d595f3c489,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-33faaf2a-d831-4d76-b99d-e082921c91e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-775902a9-ebb7-49ab-b285-1bb241b49ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-9b13235f-aabb-4a2d-bb6c-92558d941100,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-fd20451d-c72e-4af6-a530-ea6c59d12c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630275830-172.17.0.9-1597644887129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-9c1b5b4e-b4be-49ed-99ca-c7aa6159638d,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-741285f4-2757-44d0-a431-23a0a18b0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-5659c136-b809-4791-8c7a-db2072468d98,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-2d1edf7d-50e7-4bda-88b2-02b4b592412e,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c64113c8-dead-4814-b759-ff6f06a53633,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-4e6840fc-0d37-4adf-bee7-ead69fcaab86,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-7128a8c4-dad6-4857-b5e7-0efa09b49751,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-c3e27a6c-8474-4945-97d5-77fdb3efddea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630275830-172.17.0.9-1597644887129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-9c1b5b4e-b4be-49ed-99ca-c7aa6159638d,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-741285f4-2757-44d0-a431-23a0a18b0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-5659c136-b809-4791-8c7a-db2072468d98,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-2d1edf7d-50e7-4bda-88b2-02b4b592412e,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c64113c8-dead-4814-b759-ff6f06a53633,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-4e6840fc-0d37-4adf-bee7-ead69fcaab86,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-7128a8c4-dad6-4857-b5e7-0efa09b49751,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-c3e27a6c-8474-4945-97d5-77fdb3efddea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728012849-172.17.0.9-1597645185013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-fc7d4b37-4f0e-4eb4-8a9b-914264d8d0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-316c86e0-8ea5-472d-b2ab-8d3a144d477e,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-8cd5723b-aa19-4c37-a333-d4a6623445a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b1cff121-56ad-449f-9dbc-0fc34164dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-2131698d-4e28-4c82-afdb-5c37f6b8cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-4bee043b-5c24-4fbf-8543-725149fdb598,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b3385ef2-381c-401f-aff4-988cb928ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-0d91b14a-ea5e-40ad-a43e-de8baa94c306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728012849-172.17.0.9-1597645185013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-fc7d4b37-4f0e-4eb4-8a9b-914264d8d0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-316c86e0-8ea5-472d-b2ab-8d3a144d477e,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-8cd5723b-aa19-4c37-a333-d4a6623445a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b1cff121-56ad-449f-9dbc-0fc34164dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-2131698d-4e28-4c82-afdb-5c37f6b8cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-4bee043b-5c24-4fbf-8543-725149fdb598,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b3385ef2-381c-401f-aff4-988cb928ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-0d91b14a-ea5e-40ad-a43e-de8baa94c306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501501278-172.17.0.9-1597645330113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-d98686f6-2a10-411c-9533-d5baeb401032,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-58dfe6cb-aba4-4dec-8398-dd43068b9397,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-738779c9-eaef-42fc-ba21-d65af4542fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-eef2c8e5-ea72-4054-8ab7-2eec3e66cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-0a8d4fc5-06e2-4455-b97f-7d938446aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-a47774c4-9162-4729-bc05-cf5b50c3dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-9458eb6a-39b8-400e-842e-4151e3e1b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-aae7479b-ff98-4f88-bb3a-45165b251015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501501278-172.17.0.9-1597645330113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-d98686f6-2a10-411c-9533-d5baeb401032,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-58dfe6cb-aba4-4dec-8398-dd43068b9397,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-738779c9-eaef-42fc-ba21-d65af4542fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-eef2c8e5-ea72-4054-8ab7-2eec3e66cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-0a8d4fc5-06e2-4455-b97f-7d938446aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-a47774c4-9162-4729-bc05-cf5b50c3dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-9458eb6a-39b8-400e-842e-4151e3e1b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-aae7479b-ff98-4f88-bb3a-45165b251015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622884477-172.17.0.9-1597645642044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40999,DS-d19f142f-6600-4b92-a460-5decf2dae4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-3ff21f98-35a4-47c6-9f27-188e36196833,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-2604bc96-d504-4b98-8781-f6d2bd0ab2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-4a7b7e4d-ea7a-4fd6-b58e-f48c411f57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-483548cf-b4f1-4bab-ae7c-1dcecfd3b48c,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-d7274fb3-2c0a-43d2-a6e5-fee65fb9e669,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3565c956-0c95-4cf9-add9-9c149a1e9001,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-95a228ae-9e4e-46cd-b0e2-49753a558296,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622884477-172.17.0.9-1597645642044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40999,DS-d19f142f-6600-4b92-a460-5decf2dae4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-3ff21f98-35a4-47c6-9f27-188e36196833,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-2604bc96-d504-4b98-8781-f6d2bd0ab2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-4a7b7e4d-ea7a-4fd6-b58e-f48c411f57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-483548cf-b4f1-4bab-ae7c-1dcecfd3b48c,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-d7274fb3-2c0a-43d2-a6e5-fee65fb9e669,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3565c956-0c95-4cf9-add9-9c149a1e9001,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-95a228ae-9e4e-46cd-b0e2-49753a558296,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110065467-172.17.0.9-1597645786890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44513,DS-1bd7931e-26a7-441a-bc0d-43accacd0642,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7adf48a0-3f0a-4c5f-a518-b6cdcf4711c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-b01aa4d0-5214-484a-800d-825d42999e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-927e1019-489d-456a-8142-2897ab16b304,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-3383858a-16c6-4078-8d9c-15f51db2a755,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-233a1e8c-7932-44ea-a613-263d48581e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-eec441eb-161c-429e-b5ce-32dbb0ac6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-f5a33424-50ce-4f4e-91de-d7302f78496e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110065467-172.17.0.9-1597645786890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44513,DS-1bd7931e-26a7-441a-bc0d-43accacd0642,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7adf48a0-3f0a-4c5f-a518-b6cdcf4711c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-b01aa4d0-5214-484a-800d-825d42999e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-927e1019-489d-456a-8142-2897ab16b304,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-3383858a-16c6-4078-8d9c-15f51db2a755,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-233a1e8c-7932-44ea-a613-263d48581e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-eec441eb-161c-429e-b5ce-32dbb0ac6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-f5a33424-50ce-4f4e-91de-d7302f78496e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259774492-172.17.0.9-1597645865341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36074,DS-02c5af07-1926-48c2-ab9a-61e4abff0bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-8f3fc49d-40bc-4b4a-87aa-e1ec71d7fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-98929737-f773-4aa3-8a87-775b1b2900f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-758c6cc4-bf3d-491d-b58b-72e1f077c867,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-97bb60b6-2a95-4601-9fc8-d34ceb62420d,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-9b593c40-e3b4-4d7c-a5b6-7e93f83bf827,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-dcf6174b-8930-48d9-af3a-0d74161da053,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-a13a7d1c-54db-4a31-ae52-4008180be2b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259774492-172.17.0.9-1597645865341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36074,DS-02c5af07-1926-48c2-ab9a-61e4abff0bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-8f3fc49d-40bc-4b4a-87aa-e1ec71d7fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-98929737-f773-4aa3-8a87-775b1b2900f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-758c6cc4-bf3d-491d-b58b-72e1f077c867,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-97bb60b6-2a95-4601-9fc8-d34ceb62420d,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-9b593c40-e3b4-4d7c-a5b6-7e93f83bf827,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-dcf6174b-8930-48d9-af3a-0d74161da053,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-a13a7d1c-54db-4a31-ae52-4008180be2b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048627717-172.17.0.9-1597645903683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-9ae8b602-5b81-4019-a102-3965ab23aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-6d7f9307-f7ea-4c3f-a5da-d52fa96a75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-9703bfd6-6e35-4459-8fa7-153ad32eaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-5301fd05-11c0-40e6-b00e-55b5127cc6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-f7e889aa-7707-4ca3-8f13-5f6b1bcbc430,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-938a82df-5bab-48de-87fe-c6ea96676093,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-982903e8-cb01-4b54-a6a3-b1bf45cc94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-08692369-a8f1-4641-8ab3-b4fb303f3db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048627717-172.17.0.9-1597645903683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-9ae8b602-5b81-4019-a102-3965ab23aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-6d7f9307-f7ea-4c3f-a5da-d52fa96a75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-9703bfd6-6e35-4459-8fa7-153ad32eaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-5301fd05-11c0-40e6-b00e-55b5127cc6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-f7e889aa-7707-4ca3-8f13-5f6b1bcbc430,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-938a82df-5bab-48de-87fe-c6ea96676093,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-982903e8-cb01-4b54-a6a3-b1bf45cc94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-08692369-a8f1-4641-8ab3-b4fb303f3db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108623706-172.17.0.9-1597646260166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-65ad6010-bdbe-4316-89dc-f1225a9a1e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-1980386e-35f6-4b0f-a1e0-b825d25fedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-15cf9b8b-a89b-41ba-be2e-09b06d67eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2b454eae-f009-4388-b0e6-b6c6788e4597,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-882b83d6-1dcc-4507-af11-3b5e937e0359,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-a1441076-9e8e-4040-9b4c-d0fb265acdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-4a5f5462-2e61-46ff-9542-f4bf303616fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-5f5c03a4-02d0-4dd0-b98c-afa0c7a94dc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108623706-172.17.0.9-1597646260166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-65ad6010-bdbe-4316-89dc-f1225a9a1e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-1980386e-35f6-4b0f-a1e0-b825d25fedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-15cf9b8b-a89b-41ba-be2e-09b06d67eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2b454eae-f009-4388-b0e6-b6c6788e4597,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-882b83d6-1dcc-4507-af11-3b5e937e0359,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-a1441076-9e8e-4040-9b4c-d0fb265acdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-4a5f5462-2e61-46ff-9542-f4bf303616fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-5f5c03a4-02d0-4dd0-b98c-afa0c7a94dc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130177336-172.17.0.9-1597646304291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-53fd1fbe-8119-4347-ab1b-9575261bf329,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-e37a9b00-cc03-4a43-b7b5-353bf817a612,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-371d8941-9d0f-4cb4-a93e-1287220e95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cf9de6a8-6e2f-41a6-8606-a942194a3315,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-43bc4369-ba9e-4f2c-bcdb-3736ced5571b,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-ad374d36-1007-4139-968d-6deef02d6005,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f53657ec-b4bc-4b3e-9a10-a401dc311ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-38c91ff5-8706-4845-9d90-2e95266513ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130177336-172.17.0.9-1597646304291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-53fd1fbe-8119-4347-ab1b-9575261bf329,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-e37a9b00-cc03-4a43-b7b5-353bf817a612,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-371d8941-9d0f-4cb4-a93e-1287220e95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cf9de6a8-6e2f-41a6-8606-a942194a3315,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-43bc4369-ba9e-4f2c-bcdb-3736ced5571b,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-ad374d36-1007-4139-968d-6deef02d6005,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f53657ec-b4bc-4b3e-9a10-a401dc311ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-38c91ff5-8706-4845-9d90-2e95266513ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529922803-172.17.0.9-1597646377572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-f0ec1105-12f5-4460-8e5e-1b56f6aa8b50,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-43b60b9c-c903-4aa0-842c-b408f862b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-2365af65-a396-42d9-a37f-054d1908daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-069cb026-911b-4f59-8de1-45b7a552d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-0faf79a8-24a3-43e0-a786-e23cb869af72,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-ac0bcff5-1bb1-43c7-ace3-aa363dc7984b,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-dc6e519a-21b5-4db9-93dd-f7754369a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-81d3051a-c91d-462d-8286-48ba60250af9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529922803-172.17.0.9-1597646377572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-f0ec1105-12f5-4460-8e5e-1b56f6aa8b50,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-43b60b9c-c903-4aa0-842c-b408f862b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-2365af65-a396-42d9-a37f-054d1908daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-069cb026-911b-4f59-8de1-45b7a552d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-0faf79a8-24a3-43e0-a786-e23cb869af72,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-ac0bcff5-1bb1-43c7-ace3-aa363dc7984b,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-dc6e519a-21b5-4db9-93dd-f7754369a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-81d3051a-c91d-462d-8286-48ba60250af9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98285511-172.17.0.9-1597646793209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-36b72a16-93f4-47cc-b44d-b1c706e85c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-33bc0bca-8ff2-4e91-9192-75a03b290d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-4bf6b934-19a7-4542-b7ca-aff148c4b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-5f1e89e7-32e8-48e6-93e1-0d0532eeeece,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-4760a96d-f700-4c43-81ed-fd121aa6c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-8ba244c1-8bad-4a7d-9997-947c32a97790,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-50c0c277-563a-4857-8127-66d21fc6a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-0a351927-944d-42d4-a34a-4025c54671d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98285511-172.17.0.9-1597646793209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-36b72a16-93f4-47cc-b44d-b1c706e85c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-33bc0bca-8ff2-4e91-9192-75a03b290d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-4bf6b934-19a7-4542-b7ca-aff148c4b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-5f1e89e7-32e8-48e6-93e1-0d0532eeeece,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-4760a96d-f700-4c43-81ed-fd121aa6c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-8ba244c1-8bad-4a7d-9997-947c32a97790,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-50c0c277-563a-4857-8127-66d21fc6a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-0a351927-944d-42d4-a34a-4025c54671d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154915892-172.17.0.9-1597647041662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41159,DS-fb5b0388-fbbc-4d27-8d0f-a0639984fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-ee0ccfbc-9db7-4b60-afb9-86f4adb010b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-32007484-d731-4ec8-9644-2092dd2e925a,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1a43f98b-748c-4059-9783-f14afc81c028,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-031b138a-88ae-41ab-b5cc-a1e2e35069d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-eeaf0d8b-4fcd-42bf-b96b-4757365eb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-60a2cc0c-37ee-4dd2-a937-2b48cabb297e,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-899251ae-d62e-4554-a25f-0906f19deae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154915892-172.17.0.9-1597647041662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41159,DS-fb5b0388-fbbc-4d27-8d0f-a0639984fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-ee0ccfbc-9db7-4b60-afb9-86f4adb010b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-32007484-d731-4ec8-9644-2092dd2e925a,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1a43f98b-748c-4059-9783-f14afc81c028,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-031b138a-88ae-41ab-b5cc-a1e2e35069d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-eeaf0d8b-4fcd-42bf-b96b-4757365eb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-60a2cc0c-37ee-4dd2-a937-2b48cabb297e,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-899251ae-d62e-4554-a25f-0906f19deae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981269702-172.17.0.9-1597647109832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-8cf8e953-b275-41b9-96e8-4e772ccec832,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-9fb5bc71-88e7-4af7-9355-27ddb29f4355,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-48ec69c7-35aa-4565-b282-b4196d116b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-967a8aee-971e-4dcf-827a-d4ab5fcdbd50,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-db1fc0f4-7963-4291-8aec-499bf583da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-c5a06e08-bbd8-426f-870c-b5b3762749c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-20d8546a-9265-4dee-b669-ac7d038be24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-c701621d-8ddd-40f0-8b34-54149bc0c0e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981269702-172.17.0.9-1597647109832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-8cf8e953-b275-41b9-96e8-4e772ccec832,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-9fb5bc71-88e7-4af7-9355-27ddb29f4355,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-48ec69c7-35aa-4565-b282-b4196d116b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-967a8aee-971e-4dcf-827a-d4ab5fcdbd50,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-db1fc0f4-7963-4291-8aec-499bf583da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-c5a06e08-bbd8-426f-870c-b5b3762749c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-20d8546a-9265-4dee-b669-ac7d038be24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-c701621d-8ddd-40f0-8b34-54149bc0c0e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729120299-172.17.0.9-1597647178359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-9d7f0ccc-7095-4b76-b9ce-3f8d6b8c62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-854ec867-4bfc-43b5-9543-892aface1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-b0cbb452-03be-494f-ad6e-861023fe8c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-ba254547-c43f-4007-8730-f3d38fbd7e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-9d373d83-e7ca-4520-ba4c-80e0c70e9d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-df4b5d8f-6ba7-47dc-9e7a-358a0764481d,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-61e59533-14d9-41d3-8ad6-e65ae00fa9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3c09aa36-4d20-415c-ad6e-18960e5c80d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729120299-172.17.0.9-1597647178359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-9d7f0ccc-7095-4b76-b9ce-3f8d6b8c62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-854ec867-4bfc-43b5-9543-892aface1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-b0cbb452-03be-494f-ad6e-861023fe8c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-ba254547-c43f-4007-8730-f3d38fbd7e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-9d373d83-e7ca-4520-ba4c-80e0c70e9d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-df4b5d8f-6ba7-47dc-9e7a-358a0764481d,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-61e59533-14d9-41d3-8ad6-e65ae00fa9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3c09aa36-4d20-415c-ad6e-18960e5c80d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388024938-172.17.0.9-1597647341891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-579936cf-a8ee-4ac7-a0b5-058edc67fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-f2ee03b9-ef31-4296-b882-2145e0d719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-ebeb8bcf-701c-41d4-b25a-c285b5dbe390,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-65ea5610-5d53-4e28-b7ea-68b4df172a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-87f8d992-26d7-463e-9241-f9b87ea0ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ff105fd9-90b1-4e70-b075-b58ebdb6267b,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-2c2de9f1-cd52-4617-8f0c-98b2f96f63d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-9ea77037-acb6-4526-97d0-75df5b37e350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388024938-172.17.0.9-1597647341891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-579936cf-a8ee-4ac7-a0b5-058edc67fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-f2ee03b9-ef31-4296-b882-2145e0d719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-ebeb8bcf-701c-41d4-b25a-c285b5dbe390,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-65ea5610-5d53-4e28-b7ea-68b4df172a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-87f8d992-26d7-463e-9241-f9b87ea0ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ff105fd9-90b1-4e70-b075-b58ebdb6267b,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-2c2de9f1-cd52-4617-8f0c-98b2f96f63d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-9ea77037-acb6-4526-97d0-75df5b37e350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774186010-172.17.0.9-1597647521546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-44e77259-276f-472d-8bb1-1024d19ba9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-ef18b2be-41bd-435b-a93f-c3d2b9ebde64,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-cbbf7cf7-48d1-4d81-95e6-718fdb2c23a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-3221b01c-e78d-4c5b-8e5d-b321bdcd4094,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-aaf0bba2-601c-4c80-9161-c1daef68e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-04f65e79-8834-4d54-9440-ef5938a3a499,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4c505588-825c-434c-89ec-2e7609bb6164,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-6fed3c11-1dda-4da4-b481-09c098a032c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774186010-172.17.0.9-1597647521546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-44e77259-276f-472d-8bb1-1024d19ba9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-ef18b2be-41bd-435b-a93f-c3d2b9ebde64,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-cbbf7cf7-48d1-4d81-95e6-718fdb2c23a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-3221b01c-e78d-4c5b-8e5d-b321bdcd4094,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-aaf0bba2-601c-4c80-9161-c1daef68e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-04f65e79-8834-4d54-9440-ef5938a3a499,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4c505588-825c-434c-89ec-2e7609bb6164,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-6fed3c11-1dda-4da4-b481-09c098a032c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082481843-172.17.0.9-1597647600343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-54432efe-8550-4427-8d52-51f04865b73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-e27473f4-d81c-4e02-8981-03c333e00e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-57a37e07-0bec-40b3-8396-39660f4baa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-6e69ea1d-0041-47e2-a3fc-ba88899cd173,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-6f89cfc4-c4ea-4dfe-a84d-67970d7e2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-45de0feb-696a-4d62-a836-df9df9d9e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-7f5683f1-70e0-458f-bd42-546bc7a3c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-143de54b-4a4a-4484-ab8f-8850a0f9ab54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082481843-172.17.0.9-1597647600343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-54432efe-8550-4427-8d52-51f04865b73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-e27473f4-d81c-4e02-8981-03c333e00e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-57a37e07-0bec-40b3-8396-39660f4baa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-6e69ea1d-0041-47e2-a3fc-ba88899cd173,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-6f89cfc4-c4ea-4dfe-a84d-67970d7e2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-45de0feb-696a-4d62-a836-df9df9d9e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-7f5683f1-70e0-458f-bd42-546bc7a3c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-143de54b-4a4a-4484-ab8f-8850a0f9ab54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667859968-172.17.0.9-1597648016145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-0b3c287b-90d6-4a96-adbe-d670ba426fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-7aee4893-4809-4f95-9c5c-72204e0a4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-c04f8d4c-f88f-40bf-9b0e-f6beb6679cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-402da983-51e4-4127-bf4a-c2b07395c720,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-69e59d83-0502-42cc-beec-39ced793b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-be6926e6-ac33-42c1-b723-b66d9afaaf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-571940e6-5240-460f-99cf-3e1d9b166292,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-243feae9-5abd-49ab-a543-c9216f804d92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667859968-172.17.0.9-1597648016145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-0b3c287b-90d6-4a96-adbe-d670ba426fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-7aee4893-4809-4f95-9c5c-72204e0a4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-c04f8d4c-f88f-40bf-9b0e-f6beb6679cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-402da983-51e4-4127-bf4a-c2b07395c720,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-69e59d83-0502-42cc-beec-39ced793b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-be6926e6-ac33-42c1-b723-b66d9afaaf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-571940e6-5240-460f-99cf-3e1d9b166292,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-243feae9-5abd-49ab-a543-c9216f804d92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891816485-172.17.0.9-1597648169473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-56f4c78a-3fbc-4bfb-90c0-848cdd030db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e56a753c-b770-40c5-bf24-dcef19bf2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-908ab0d8-065c-4ba9-8ee9-9e33a8de29f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-8cde30ef-9f13-40d9-aa3c-2950d3d9d834,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-0e7e6948-f1d5-400d-aad8-fb9cbc31f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-1c66b5d8-2cb3-4961-92c3-28ec088449d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c8fbfa5a-6c7b-4305-8339-208a744afcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-61bb3245-b70e-45cd-8c8c-6196992a4392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891816485-172.17.0.9-1597648169473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-56f4c78a-3fbc-4bfb-90c0-848cdd030db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e56a753c-b770-40c5-bf24-dcef19bf2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-908ab0d8-065c-4ba9-8ee9-9e33a8de29f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-8cde30ef-9f13-40d9-aa3c-2950d3d9d834,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-0e7e6948-f1d5-400d-aad8-fb9cbc31f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-1c66b5d8-2cb3-4961-92c3-28ec088449d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c8fbfa5a-6c7b-4305-8339-208a744afcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-61bb3245-b70e-45cd-8c8c-6196992a4392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5568
