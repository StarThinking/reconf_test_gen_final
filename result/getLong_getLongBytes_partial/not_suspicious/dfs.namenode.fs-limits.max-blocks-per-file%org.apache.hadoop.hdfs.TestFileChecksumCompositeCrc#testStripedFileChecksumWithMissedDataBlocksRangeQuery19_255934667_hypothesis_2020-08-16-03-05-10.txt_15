reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974736794-172.17.0.9-1597547305840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-ed97746a-a21c-4a8f-9f15-45eb73b97658,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-03a52e6a-7e64-484c-aa5e-a9528ca469c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-6bb0cdd3-2526-4d92-a22c-9ae7831aaaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-780e94ad-99d5-405e-a5b8-5891dce0a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-da2663c8-761a-4c50-b456-e061db2218cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-5db38893-c880-4e7e-8d35-b02873a17270,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-52a7ffc2-dc6c-44a9-82cd-299bd62def7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-79e4e05b-c505-402d-8cbf-999beebe0114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974736794-172.17.0.9-1597547305840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-ed97746a-a21c-4a8f-9f15-45eb73b97658,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-03a52e6a-7e64-484c-aa5e-a9528ca469c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-6bb0cdd3-2526-4d92-a22c-9ae7831aaaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-780e94ad-99d5-405e-a5b8-5891dce0a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-da2663c8-761a-4c50-b456-e061db2218cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-5db38893-c880-4e7e-8d35-b02873a17270,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-52a7ffc2-dc6c-44a9-82cd-299bd62def7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-79e4e05b-c505-402d-8cbf-999beebe0114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871562034-172.17.0.9-1597547478088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-1101d286-d6b9-4eaf-bd4b-869912a28a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-bf6eb3d6-51a6-49e5-a10a-56ed2b9cbb89,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-d55f21f6-8dd8-4e1a-ba80-6ecac137b546,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-9e3883da-c278-46c2-9f1c-eba524680a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0e22ce04-329e-46b4-ae22-b48d654d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-1a588cfe-cd2a-40c6-9d57-4a33aa34fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7dd41283-2a2c-4465-9eb2-33aa7e847d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-29c2396e-58d5-4192-8052-e91d75338613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871562034-172.17.0.9-1597547478088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-1101d286-d6b9-4eaf-bd4b-869912a28a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-bf6eb3d6-51a6-49e5-a10a-56ed2b9cbb89,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-d55f21f6-8dd8-4e1a-ba80-6ecac137b546,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-9e3883da-c278-46c2-9f1c-eba524680a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0e22ce04-329e-46b4-ae22-b48d654d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-1a588cfe-cd2a-40c6-9d57-4a33aa34fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7dd41283-2a2c-4465-9eb2-33aa7e847d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-29c2396e-58d5-4192-8052-e91d75338613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245716499-172.17.0.9-1597548715671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33487,DS-5900be77-06f6-4397-9214-c682ab510b23,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-a72bc7ac-3c07-4d9c-9d7d-55c808b93b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-9ffe0229-701e-4753-a004-b08f3dd24563,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-3ae58c57-71c8-42ab-93e8-436a34e345ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-b791dcf2-5afa-4374-bdd7-be86d84a918e,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-2d535c59-8c28-4617-a761-f0fd426ba132,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-ec7cc279-294c-4e15-bfd6-0e163e524a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-58db4314-90a2-4eb2-b3d0-2b5c37689d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245716499-172.17.0.9-1597548715671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33487,DS-5900be77-06f6-4397-9214-c682ab510b23,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-a72bc7ac-3c07-4d9c-9d7d-55c808b93b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-9ffe0229-701e-4753-a004-b08f3dd24563,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-3ae58c57-71c8-42ab-93e8-436a34e345ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-b791dcf2-5afa-4374-bdd7-be86d84a918e,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-2d535c59-8c28-4617-a761-f0fd426ba132,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-ec7cc279-294c-4e15-bfd6-0e163e524a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-58db4314-90a2-4eb2-b3d0-2b5c37689d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487040469-172.17.0.9-1597549013096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-be89bb59-0109-4041-9285-0122e58a544d,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-5a2ea503-c4a2-4a0c-b7bf-8d145c0a37db,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-10bee13b-d77b-40e9-9b12-e315c4c6b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-178c3487-3c44-4014-a768-342dc64d927f,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-6245a7ef-82c9-42e8-b55d-b9e2f360ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-2e221bba-67d5-4d83-a076-3fe76d29118a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-fabe3548-f44c-409a-b305-84efe267eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-59ab4b54-92cc-40cf-813b-12794b788061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487040469-172.17.0.9-1597549013096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-be89bb59-0109-4041-9285-0122e58a544d,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-5a2ea503-c4a2-4a0c-b7bf-8d145c0a37db,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-10bee13b-d77b-40e9-9b12-e315c4c6b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-178c3487-3c44-4014-a768-342dc64d927f,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-6245a7ef-82c9-42e8-b55d-b9e2f360ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-2e221bba-67d5-4d83-a076-3fe76d29118a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-fabe3548-f44c-409a-b305-84efe267eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-59ab4b54-92cc-40cf-813b-12794b788061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699381117-172.17.0.9-1597549383486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-1d74b170-2932-42bd-849d-dc6b65e1e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3e140863-e5f5-40b2-8581-aa76fad7a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-3cb6ec24-55ae-4596-82b9-793bdce4569b,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-2870aab2-3521-4181-9d33-ac4e4f0a5d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d9c61d73-1f06-4c4e-af83-4fd92d59dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-025909ed-6b87-4d37-b211-3db4360db072,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-bb7f8f6f-eef5-4d4c-846f-b01efb68c265,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-70eb1314-173e-4407-8bf6-9f2cc6ae1bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699381117-172.17.0.9-1597549383486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-1d74b170-2932-42bd-849d-dc6b65e1e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3e140863-e5f5-40b2-8581-aa76fad7a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-3cb6ec24-55ae-4596-82b9-793bdce4569b,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-2870aab2-3521-4181-9d33-ac4e4f0a5d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d9c61d73-1f06-4c4e-af83-4fd92d59dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-025909ed-6b87-4d37-b211-3db4360db072,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-bb7f8f6f-eef5-4d4c-846f-b01efb68c265,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-70eb1314-173e-4407-8bf6-9f2cc6ae1bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81174984-172.17.0.9-1597549493625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-a2530e20-9f77-4c4a-8168-e1df33d4e61e,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-7abc410a-7820-4c0f-bdc4-59b940c45a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-ba6e1b90-a04c-4a1a-863f-da7f640305b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-09595a74-c9b6-4109-9357-a3ee0d128a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-743ebe34-c9e2-4bfe-983c-bd821be9d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-36fc833e-542b-41a8-b2f9-20597afe2190,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-a33ceaee-5175-42ac-b0a0-dd386909f120,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-136d53f1-a676-43bb-89be-c0e8190a2034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81174984-172.17.0.9-1597549493625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-a2530e20-9f77-4c4a-8168-e1df33d4e61e,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-7abc410a-7820-4c0f-bdc4-59b940c45a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-ba6e1b90-a04c-4a1a-863f-da7f640305b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-09595a74-c9b6-4109-9357-a3ee0d128a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-743ebe34-c9e2-4bfe-983c-bd821be9d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-36fc833e-542b-41a8-b2f9-20597afe2190,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-a33ceaee-5175-42ac-b0a0-dd386909f120,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-136d53f1-a676-43bb-89be-c0e8190a2034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137297510-172.17.0.9-1597550507771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-ef415ade-b6e2-4fdf-a934-50ce80c2f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-b5e6bd54-d209-4920-bc86-d0692212a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-83a69037-7b21-473b-9bcc-555566281666,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-0f46db53-98b0-4f66-b149-226601ac4d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-13ea78a9-66b0-469d-944b-e5e337b9bb49,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-039e762f-022c-4386-a474-f43227437442,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-d1ff383a-78f3-4567-854c-dc5963ce8efb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-a826814a-1276-4359-9e19-70e9fa4384fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137297510-172.17.0.9-1597550507771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-ef415ade-b6e2-4fdf-a934-50ce80c2f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-b5e6bd54-d209-4920-bc86-d0692212a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-83a69037-7b21-473b-9bcc-555566281666,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-0f46db53-98b0-4f66-b149-226601ac4d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-13ea78a9-66b0-469d-944b-e5e337b9bb49,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-039e762f-022c-4386-a474-f43227437442,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-d1ff383a-78f3-4567-854c-dc5963ce8efb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-a826814a-1276-4359-9e19-70e9fa4384fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967106166-172.17.0.9-1597551233220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-8148d4d2-de72-4f42-89e6-66c0f197b768,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-6e999ead-6139-4e4b-8d84-0486fac64a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-2ad7e0fe-0f1a-4d78-b62d-63a1904c6339,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-d791e11e-848a-4f96-9303-9a685a53dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-e4ab664f-ee78-42ee-8df8-43deaffe59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4fb09df1-4f5f-4dc9-b0af-b453e5d64a29,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-572989e0-e42d-486d-97b8-57c36e722044,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-b73df24d-eb27-4495-b80f-1d4f30ec8ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967106166-172.17.0.9-1597551233220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-8148d4d2-de72-4f42-89e6-66c0f197b768,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-6e999ead-6139-4e4b-8d84-0486fac64a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-2ad7e0fe-0f1a-4d78-b62d-63a1904c6339,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-d791e11e-848a-4f96-9303-9a685a53dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-e4ab664f-ee78-42ee-8df8-43deaffe59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4fb09df1-4f5f-4dc9-b0af-b453e5d64a29,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-572989e0-e42d-486d-97b8-57c36e722044,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-b73df24d-eb27-4495-b80f-1d4f30ec8ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280598486-172.17.0.9-1597551447225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-39c9ed24-aca2-4b0e-861d-13350d4e7f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-4c3603fd-07c2-4fda-82cf-122805af9610,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-465a9d43-2326-4e92-952e-44166b1465b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-e5382818-5f51-4acc-a2f5-7ae9c647a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-50b9f115-fde1-4afd-b7f0-631e8c4dadb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-8ce36130-c8e7-4a00-b265-069667430f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-35300ef6-8d4a-4ad3-ad9f-39191c7d14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-50eb9a29-0226-43ca-a411-065ca0ed5936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280598486-172.17.0.9-1597551447225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-39c9ed24-aca2-4b0e-861d-13350d4e7f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-4c3603fd-07c2-4fda-82cf-122805af9610,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-465a9d43-2326-4e92-952e-44166b1465b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-e5382818-5f51-4acc-a2f5-7ae9c647a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-50b9f115-fde1-4afd-b7f0-631e8c4dadb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-8ce36130-c8e7-4a00-b265-069667430f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-35300ef6-8d4a-4ad3-ad9f-39191c7d14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-50eb9a29-0226-43ca-a411-065ca0ed5936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553794615-172.17.0.9-1597551589171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-bedb37ff-e5f9-4d29-91a6-d2e8b0b120a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-62374785-58b7-420a-9ee7-1b24b2dfc190,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-df39e1e3-ba8f-409e-a3ae-293226b2c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-738df1be-aecb-4a72-8984-cfaa54816f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-e87381b3-3be7-4e97-8fc9-55f139bc6784,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d5d5b81c-f6c2-4e48-abf7-48052d2ae285,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e7d85b24-45f0-497a-8fc8-e1176353cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c31258be-ca8c-41d6-b406-10fe0e2342a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553794615-172.17.0.9-1597551589171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-bedb37ff-e5f9-4d29-91a6-d2e8b0b120a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-62374785-58b7-420a-9ee7-1b24b2dfc190,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-df39e1e3-ba8f-409e-a3ae-293226b2c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-738df1be-aecb-4a72-8984-cfaa54816f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-e87381b3-3be7-4e97-8fc9-55f139bc6784,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d5d5b81c-f6c2-4e48-abf7-48052d2ae285,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e7d85b24-45f0-497a-8fc8-e1176353cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c31258be-ca8c-41d6-b406-10fe0e2342a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609206169-172.17.0.9-1597552228394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37360,DS-fcd08ed5-60ea-4be9-b83b-3d1a0f0f84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-3f47f03b-d7c5-4250-9552-8cc0622812eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-eac9b75f-feee-4ab8-b198-b62489727925,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-7f24601a-7daa-4869-bc4e-f4f018917ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-ba3c4868-046a-43cc-a4c5-16a8a7c9495d,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-21c95c5c-dee2-418a-aa23-f47ca07d7a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-bdd05918-5f72-4636-a561-6bdb61231a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-36a15739-115c-4f16-a007-f0be0770198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609206169-172.17.0.9-1597552228394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37360,DS-fcd08ed5-60ea-4be9-b83b-3d1a0f0f84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-3f47f03b-d7c5-4250-9552-8cc0622812eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-eac9b75f-feee-4ab8-b198-b62489727925,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-7f24601a-7daa-4869-bc4e-f4f018917ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-ba3c4868-046a-43cc-a4c5-16a8a7c9495d,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-21c95c5c-dee2-418a-aa23-f47ca07d7a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-bdd05918-5f72-4636-a561-6bdb61231a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-36a15739-115c-4f16-a007-f0be0770198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287436406-172.17.0.9-1597552522278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34229,DS-aebb7544-2919-46ac-9649-c1d7dccb6e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-643e1328-d7e4-4be3-892d-f1a26649b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-a1131966-d2ab-48f7-b74a-830684039d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e8acb8fd-11bb-4d92-8089-b8c53ef56ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bf8a80e0-a61b-4567-a7e4-f4e815cdaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-a1ee7af8-961f-43b8-af74-13eaa1b0ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f38828ec-c316-45b0-adb1-37a04537cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-283b7582-320e-4eda-b84f-43d6e5007e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287436406-172.17.0.9-1597552522278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34229,DS-aebb7544-2919-46ac-9649-c1d7dccb6e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-643e1328-d7e4-4be3-892d-f1a26649b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-a1131966-d2ab-48f7-b74a-830684039d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e8acb8fd-11bb-4d92-8089-b8c53ef56ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bf8a80e0-a61b-4567-a7e4-f4e815cdaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-a1ee7af8-961f-43b8-af74-13eaa1b0ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f38828ec-c316-45b0-adb1-37a04537cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-283b7582-320e-4eda-b84f-43d6e5007e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5431
