reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449357518-172.17.0.19-1597584901902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-c220368a-fcbb-4ea3-8c09-8ab3643d9bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-1ca8b5cc-d391-412b-9888-d407753802a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-298fb206-5dc3-4c70-92d3-5c3d64b1486e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-789d9722-93a6-463f-a9b2-370be7e6e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-584ed44f-c757-45f0-84c3-9430924c9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-e385cce7-4325-491a-98cb-2ba4c0827823,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e145a46a-bbba-48a2-b465-16fc6b040ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-f8c2b7bb-3076-4739-85e1-e5d422f3fb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449357518-172.17.0.19-1597584901902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-c220368a-fcbb-4ea3-8c09-8ab3643d9bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-1ca8b5cc-d391-412b-9888-d407753802a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-298fb206-5dc3-4c70-92d3-5c3d64b1486e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-789d9722-93a6-463f-a9b2-370be7e6e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-584ed44f-c757-45f0-84c3-9430924c9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-e385cce7-4325-491a-98cb-2ba4c0827823,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e145a46a-bbba-48a2-b465-16fc6b040ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-f8c2b7bb-3076-4739-85e1-e5d422f3fb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446116843-172.17.0.19-1597585253231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-229070a5-c8ec-49f5-b785-f86bf1dff000,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-d6dbb3a9-5224-49ed-ace4-65fefa9947ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-aa19c24b-590e-43b8-852e-9c80910f6d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-b84a2089-3902-4e61-b040-b6cf0196970b,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e3379dec-e7c0-4549-9466-c8302fd9c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-7c54ebde-bff0-4a4d-82c2-6389a0930193,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-3476a543-6fc7-4f04-a7e1-553ff5d7211c,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-065ececd-06e0-4735-b702-f836f4d3e6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446116843-172.17.0.19-1597585253231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-229070a5-c8ec-49f5-b785-f86bf1dff000,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-d6dbb3a9-5224-49ed-ace4-65fefa9947ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-aa19c24b-590e-43b8-852e-9c80910f6d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-b84a2089-3902-4e61-b040-b6cf0196970b,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e3379dec-e7c0-4549-9466-c8302fd9c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-7c54ebde-bff0-4a4d-82c2-6389a0930193,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-3476a543-6fc7-4f04-a7e1-553ff5d7211c,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-065ececd-06e0-4735-b702-f836f4d3e6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421353488-172.17.0.19-1597585449734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-3adfd0e9-bccd-42f0-b6ae-e9db5808f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-3c6b668c-4148-48c7-b529-417a4a6c0459,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-81761f7f-2970-41ed-a3a8-059a1dbb3a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-492de675-a117-4bc0-a8c4-67bead21fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-b356ee60-a0c8-4387-a25d-c7db721de5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-70268d77-d6ce-42ca-b64b-507af48c2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-e3365e77-5ec7-4417-88c4-27908465748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d935269c-1b49-4917-8c23-0b42ff1943f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421353488-172.17.0.19-1597585449734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-3adfd0e9-bccd-42f0-b6ae-e9db5808f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-3c6b668c-4148-48c7-b529-417a4a6c0459,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-81761f7f-2970-41ed-a3a8-059a1dbb3a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-492de675-a117-4bc0-a8c4-67bead21fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-b356ee60-a0c8-4387-a25d-c7db721de5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-70268d77-d6ce-42ca-b64b-507af48c2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-e3365e77-5ec7-4417-88c4-27908465748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d935269c-1b49-4917-8c23-0b42ff1943f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184540252-172.17.0.19-1597585559287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42829,DS-ff44003f-3738-4e84-aa47-f99ac975b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-dd315d45-ec44-4314-9fbb-703a1de94b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-7a532fbc-1608-4f83-8c86-cb57ff9eb86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-f2ad4d86-d0cc-4f21-aeb2-048770abe6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-fd5c1974-99e0-4584-b0cf-369169e8de27,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-adc3a131-c38f-46f4-8c32-49ddf6ec8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e5ee6e4f-2fa7-49e9-a2f2-d96ac2340a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-68ad7589-9e47-4808-9d2a-858bcc573864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184540252-172.17.0.19-1597585559287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42829,DS-ff44003f-3738-4e84-aa47-f99ac975b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-dd315d45-ec44-4314-9fbb-703a1de94b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-7a532fbc-1608-4f83-8c86-cb57ff9eb86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-f2ad4d86-d0cc-4f21-aeb2-048770abe6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-fd5c1974-99e0-4584-b0cf-369169e8de27,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-adc3a131-c38f-46f4-8c32-49ddf6ec8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e5ee6e4f-2fa7-49e9-a2f2-d96ac2340a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-68ad7589-9e47-4808-9d2a-858bcc573864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311171701-172.17.0.19-1597586137104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42345,DS-3c18d457-ee19-4088-af31-74a5bacb9986,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-bbffeb77-1536-4c8f-8892-02970d477695,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d622104d-74ce-4bd5-9180-7c6950532130,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-d0dea143-a6bd-4bd2-9875-9202f4a31df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a058c96b-323d-4f23-ab7d-2716d0bee795,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-45aeccbc-6b62-4179-a08c-3cdf9013e800,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-6611a409-5129-4ef3-8e96-33ae21a5dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-82330885-274b-429e-903c-d79966e2a658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311171701-172.17.0.19-1597586137104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42345,DS-3c18d457-ee19-4088-af31-74a5bacb9986,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-bbffeb77-1536-4c8f-8892-02970d477695,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d622104d-74ce-4bd5-9180-7c6950532130,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-d0dea143-a6bd-4bd2-9875-9202f4a31df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a058c96b-323d-4f23-ab7d-2716d0bee795,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-45aeccbc-6b62-4179-a08c-3cdf9013e800,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-6611a409-5129-4ef3-8e96-33ae21a5dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-82330885-274b-429e-903c-d79966e2a658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084311607-172.17.0.19-1597586409273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-b0c1eec9-6213-434f-9c14-34d486fdcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-37abe768-06b6-48b1-ab7f-85e6fa3d142a,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-307148e6-bf0f-43c4-ad20-8580f3ee56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-d7f898a4-0cb1-4f4c-abf9-4179a17a92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-ad6df29c-620e-4112-8d34-6c1f35bdfbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-3c9e4a48-85e8-4ff8-9e7f-2924299483d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-52d5c9ad-f02f-4235-b506-8c80634d3eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-2fbab209-996a-4e03-a96c-e1376e034a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084311607-172.17.0.19-1597586409273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-b0c1eec9-6213-434f-9c14-34d486fdcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-37abe768-06b6-48b1-ab7f-85e6fa3d142a,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-307148e6-bf0f-43c4-ad20-8580f3ee56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-d7f898a4-0cb1-4f4c-abf9-4179a17a92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-ad6df29c-620e-4112-8d34-6c1f35bdfbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-3c9e4a48-85e8-4ff8-9e7f-2924299483d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-52d5c9ad-f02f-4235-b506-8c80634d3eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-2fbab209-996a-4e03-a96c-e1376e034a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669700343-172.17.0.19-1597587147678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-de1443c0-f52e-4eea-9e14-62ad110083d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-9c463205-99de-4f54-9868-8091d5eddb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-ee8dfe23-5a7d-40e4-b6a2-c460a5206bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-232b7643-8414-4b7e-9da0-3ef5e5c2efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ddf4d01d-798d-4333-9f92-b2c515cb6459,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-f2218124-3191-4422-85a4-c6e8944cb330,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-f7d1a7ed-ce8e-4b2f-b8b9-1a4c54f97397,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-2dc15029-bba7-4204-9e2c-a6525810d106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669700343-172.17.0.19-1597587147678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-de1443c0-f52e-4eea-9e14-62ad110083d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-9c463205-99de-4f54-9868-8091d5eddb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-ee8dfe23-5a7d-40e4-b6a2-c460a5206bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-232b7643-8414-4b7e-9da0-3ef5e5c2efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ddf4d01d-798d-4333-9f92-b2c515cb6459,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-f2218124-3191-4422-85a4-c6e8944cb330,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-f7d1a7ed-ce8e-4b2f-b8b9-1a4c54f97397,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-2dc15029-bba7-4204-9e2c-a6525810d106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141471372-172.17.0.19-1597587493847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-6ca8f403-27fc-4d71-91c1-fc3fa9f10fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-27bb5268-9012-4960-803d-c5844cc7e20c,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-64f76e86-be29-488c-a547-f9fd1b1b2ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-603ce714-bde3-42d2-8a78-2316988b6571,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e94e3b43-be24-4380-80b9-b18bb5ec21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-26f95051-d732-4d76-9078-4b4c190ce8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-4ea8f4d5-68ae-4894-bd40-5079c54694e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-fb58cd56-fa39-4315-b94f-3a67b3c00cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141471372-172.17.0.19-1597587493847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-6ca8f403-27fc-4d71-91c1-fc3fa9f10fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-27bb5268-9012-4960-803d-c5844cc7e20c,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-64f76e86-be29-488c-a547-f9fd1b1b2ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-603ce714-bde3-42d2-8a78-2316988b6571,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-e94e3b43-be24-4380-80b9-b18bb5ec21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-26f95051-d732-4d76-9078-4b4c190ce8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-4ea8f4d5-68ae-4894-bd40-5079c54694e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-fb58cd56-fa39-4315-b94f-3a67b3c00cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162988986-172.17.0.19-1597588145614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-e8b42770-f6e7-42ab-9d1e-28e8ebbd1fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-5014f483-a957-4433-92f6-b18def711e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fad0e2aa-f107-45d5-85f5-1956218425c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-85b10535-a73d-46b0-bdff-358f74ba035c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-7d383dcd-f9b1-4ca2-bb16-a60219af6c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-4233b5d3-c8d3-4e27-a9b6-c1a507bb6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-d3364916-da83-43b0-9e1f-928adc8a6634,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-259a43c3-dc7c-4048-9b31-a43c9db17d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162988986-172.17.0.19-1597588145614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-e8b42770-f6e7-42ab-9d1e-28e8ebbd1fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-5014f483-a957-4433-92f6-b18def711e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fad0e2aa-f107-45d5-85f5-1956218425c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-85b10535-a73d-46b0-bdff-358f74ba035c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-7d383dcd-f9b1-4ca2-bb16-a60219af6c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-4233b5d3-c8d3-4e27-a9b6-c1a507bb6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-d3364916-da83-43b0-9e1f-928adc8a6634,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-259a43c3-dc7c-4048-9b31-a43c9db17d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042677895-172.17.0.19-1597588347165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-5d9087a6-3596-48ed-97cb-9924cb289d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-b5c52040-372a-4c28-9e3b-2b3656dfa9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-22485c50-38ac-4b87-b060-2813b1f10f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-4d28a475-fb94-4d2b-a4ad-e759fe0f2b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-bdcc5c43-871d-4755-86ec-1940f7dcfbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-de9bbceb-7b91-46a6-a904-ed00612f8218,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-b29f841a-2095-4d6e-a73a-d8afd5b61a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-a73642db-18af-45b7-a056-116216b6e032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042677895-172.17.0.19-1597588347165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-5d9087a6-3596-48ed-97cb-9924cb289d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-b5c52040-372a-4c28-9e3b-2b3656dfa9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-22485c50-38ac-4b87-b060-2813b1f10f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-4d28a475-fb94-4d2b-a4ad-e759fe0f2b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-bdcc5c43-871d-4755-86ec-1940f7dcfbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-de9bbceb-7b91-46a6-a904-ed00612f8218,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-b29f841a-2095-4d6e-a73a-d8afd5b61a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-a73642db-18af-45b7-a056-116216b6e032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316951954-172.17.0.19-1597588498593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44386,DS-51a69f2d-a3cc-435a-a826-d14d550b82fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-562317fc-56de-470c-94da-0e52e3373423,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-059f1e0e-3013-4f25-a8ee-f62e0a50c078,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d01e1ada-baaa-403d-94eb-2d41a54f808e,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-6360d2bf-dccf-48db-9eb2-722068830288,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6fe44485-1b39-4bc2-8360-df2e47ecdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-34680027-c734-431a-b2d7-7baa66859c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-82b872fa-5831-4ed7-a045-7707a169f8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316951954-172.17.0.19-1597588498593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44386,DS-51a69f2d-a3cc-435a-a826-d14d550b82fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-562317fc-56de-470c-94da-0e52e3373423,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-059f1e0e-3013-4f25-a8ee-f62e0a50c078,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d01e1ada-baaa-403d-94eb-2d41a54f808e,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-6360d2bf-dccf-48db-9eb2-722068830288,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6fe44485-1b39-4bc2-8360-df2e47ecdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-34680027-c734-431a-b2d7-7baa66859c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-82b872fa-5831-4ed7-a045-7707a169f8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669017087-172.17.0.19-1597588613030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-31b7ffc0-27d1-4ae5-9f14-28c6c63cbb90,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-bae1788f-3e6b-425d-9a98-514ab759064c,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-f168b5a7-d7ba-4199-af63-46f611088d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-95546410-db4e-4e12-ac4b-61a56bff04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-611aa141-4de8-44a0-b6d8-6734ba016e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-78c169c4-3c26-4ade-969d-caa9f07ea50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-71a0bf5c-8dbc-4113-8c23-3b836a534bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-29a8b951-8a9d-4199-af53-dcd8721a4bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669017087-172.17.0.19-1597588613030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-31b7ffc0-27d1-4ae5-9f14-28c6c63cbb90,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-bae1788f-3e6b-425d-9a98-514ab759064c,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-f168b5a7-d7ba-4199-af63-46f611088d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-95546410-db4e-4e12-ac4b-61a56bff04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-611aa141-4de8-44a0-b6d8-6734ba016e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-78c169c4-3c26-4ade-969d-caa9f07ea50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-71a0bf5c-8dbc-4113-8c23-3b836a534bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-29a8b951-8a9d-4199-af53-dcd8721a4bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975178751-172.17.0.19-1597588766937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-43499a60-8beb-4690-8cb2-8cd6fd3a5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-535ca8ea-a7ec-4c38-ba9c-16224f62d025,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-d9050022-2c42-4f47-8b9e-773639b8c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-c40eb70a-02ee-465a-8ad6-2bf00ad98b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e66869aa-5525-459b-84f9-a52f387e8a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-506aa832-2719-454c-953a-9d246fd7fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-1ba83bae-4c62-4bb0-a870-17bd47113947,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1ed589e6-7c56-4f04-a7e0-270f678ac85c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975178751-172.17.0.19-1597588766937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-43499a60-8beb-4690-8cb2-8cd6fd3a5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-535ca8ea-a7ec-4c38-ba9c-16224f62d025,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-d9050022-2c42-4f47-8b9e-773639b8c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-c40eb70a-02ee-465a-8ad6-2bf00ad98b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e66869aa-5525-459b-84f9-a52f387e8a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-506aa832-2719-454c-953a-9d246fd7fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-1ba83bae-4c62-4bb0-a870-17bd47113947,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1ed589e6-7c56-4f04-a7e0-270f678ac85c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960998398-172.17.0.19-1597589480609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-4182be50-20ed-4fef-b22b-b2ec347395b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-6326f186-efd0-4c03-819c-8a1bdf2bb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a1b69a30-e042-4a76-9729-73097b5569cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-2486609d-0c22-48ad-94c4-5457ffbedf80,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-1a778a52-511f-4fac-9b14-02fbd52b8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-39c1cabb-0d50-4499-962a-3492e5574635,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-88990561-f8be-491c-a41d-959829dd5581,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-3d8225d3-89f0-4cbc-a653-c8f0af20c5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960998398-172.17.0.19-1597589480609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-4182be50-20ed-4fef-b22b-b2ec347395b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-6326f186-efd0-4c03-819c-8a1bdf2bb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a1b69a30-e042-4a76-9729-73097b5569cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-2486609d-0c22-48ad-94c4-5457ffbedf80,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-1a778a52-511f-4fac-9b14-02fbd52b8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-39c1cabb-0d50-4499-962a-3492e5574635,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-88990561-f8be-491c-a41d-959829dd5581,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-3d8225d3-89f0-4cbc-a653-c8f0af20c5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872048412-172.17.0.19-1597589873494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-95730288-83cd-4f2d-87f4-ee7f9fe248c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-adbf7450-c254-4995-8fb2-be7f81b2855e,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-b7a638eb-65ec-4ae9-906f-3975df51fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-8ac55e3b-86d4-4154-b088-e311e0e1a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f4e99ef2-55e0-4dc0-ac70-d0b7adc1b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3ed4a66d-54c8-4cf9-9592-2185c85b1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-36ea0c40-26e0-4a40-9b7b-ede9d067ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3093907d-9677-45f5-bc36-7e740338a1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872048412-172.17.0.19-1597589873494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-95730288-83cd-4f2d-87f4-ee7f9fe248c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-adbf7450-c254-4995-8fb2-be7f81b2855e,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-b7a638eb-65ec-4ae9-906f-3975df51fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-8ac55e3b-86d4-4154-b088-e311e0e1a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f4e99ef2-55e0-4dc0-ac70-d0b7adc1b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3ed4a66d-54c8-4cf9-9592-2185c85b1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-36ea0c40-26e0-4a40-9b7b-ede9d067ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3093907d-9677-45f5-bc36-7e740338a1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898121704-172.17.0.19-1597590142013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35549,DS-3cc72ed7-946b-4f0f-a46a-f9571057cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-0798449f-84b4-4984-9a1c-bc28e51c251e,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-55c182b7-d5d7-499b-b229-f3b41f6f86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-5109d997-0871-4aa9-a411-17620aca9506,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-7a32d566-38ee-4a9b-b933-45fe9a6b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-883b9961-7495-4a1e-8d78-4e438fd22921,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-fc1ef157-f6d6-48b7-8e1b-df25961f6cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-2a2a6103-43db-400d-82e8-15d694607fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898121704-172.17.0.19-1597590142013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35549,DS-3cc72ed7-946b-4f0f-a46a-f9571057cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-0798449f-84b4-4984-9a1c-bc28e51c251e,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-55c182b7-d5d7-499b-b229-f3b41f6f86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-5109d997-0871-4aa9-a411-17620aca9506,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-7a32d566-38ee-4a9b-b933-45fe9a6b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-883b9961-7495-4a1e-8d78-4e438fd22921,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-fc1ef157-f6d6-48b7-8e1b-df25961f6cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-2a2a6103-43db-400d-82e8-15d694607fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5800
