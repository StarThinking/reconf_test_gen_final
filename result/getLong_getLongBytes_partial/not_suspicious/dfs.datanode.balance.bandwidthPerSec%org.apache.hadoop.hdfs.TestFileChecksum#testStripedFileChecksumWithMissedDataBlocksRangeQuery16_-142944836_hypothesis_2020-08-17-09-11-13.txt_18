reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333390036-172.17.0.20-1597655756442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-59c90216-2a95-44c4-885b-92527ce55978,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-81019a89-a86d-4463-b948-271bd557dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-02b98447-8940-4205-b40b-5bf7f837aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-f65e5ad2-b735-4371-8f6c-e2adfc1869cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-c336ca5f-0f65-42ce-9d4e-015d9f7e668c,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-c8038071-a73c-4e8d-adb7-a76d7d656cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-c0c137f5-9bfc-4c89-9d13-554460c3970e,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-67b379c5-3e65-4ec2-be78-c792e3e50b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333390036-172.17.0.20-1597655756442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-59c90216-2a95-44c4-885b-92527ce55978,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-81019a89-a86d-4463-b948-271bd557dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-02b98447-8940-4205-b40b-5bf7f837aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-f65e5ad2-b735-4371-8f6c-e2adfc1869cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-c336ca5f-0f65-42ce-9d4e-015d9f7e668c,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-c8038071-a73c-4e8d-adb7-a76d7d656cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-c0c137f5-9bfc-4c89-9d13-554460c3970e,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-67b379c5-3e65-4ec2-be78-c792e3e50b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823798291-172.17.0.20-1597656026979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-34263e3c-de54-45c6-bea0-744ae27b5748,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-e6c592d1-a4c4-4ef7-8871-e5453864fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-c888d9e8-ddb2-4be6-99c7-1306ca5ac16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-9c50b3c3-593a-4747-89c9-0e3b587d0157,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-48996ab6-513d-4645-90d1-c2668f09282b,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-0d8c166f-4c42-4885-bd1c-85e39da67039,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-a2525d30-d11a-4ac2-8a6f-bdbf5b4c9bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-6bf63dc8-3496-483d-a243-3aca6bc25fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823798291-172.17.0.20-1597656026979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-34263e3c-de54-45c6-bea0-744ae27b5748,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-e6c592d1-a4c4-4ef7-8871-e5453864fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-c888d9e8-ddb2-4be6-99c7-1306ca5ac16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-9c50b3c3-593a-4747-89c9-0e3b587d0157,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-48996ab6-513d-4645-90d1-c2668f09282b,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-0d8c166f-4c42-4885-bd1c-85e39da67039,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-a2525d30-d11a-4ac2-8a6f-bdbf5b4c9bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-6bf63dc8-3496-483d-a243-3aca6bc25fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604538345-172.17.0.20-1597656348745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-6f7b4483-9f98-4742-815a-f217310220be,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f1cc1038-b5de-4173-912b-5cf68636957c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ebcbc97f-16f9-45c9-81c6-540955d72ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1ed24114-3988-47de-81a0-65abd2fbfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a1d41c37-94a8-4e0f-bf6e-d9d2e1e176fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-48ce7fa1-d7a7-4267-b934-26400cf6f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-ee75e8d7-615f-4d17-a2a8-6c2c2b1f0740,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-f4112027-6f26-47b6-b8b2-5b23018ced4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604538345-172.17.0.20-1597656348745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-6f7b4483-9f98-4742-815a-f217310220be,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f1cc1038-b5de-4173-912b-5cf68636957c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ebcbc97f-16f9-45c9-81c6-540955d72ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1ed24114-3988-47de-81a0-65abd2fbfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a1d41c37-94a8-4e0f-bf6e-d9d2e1e176fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-48ce7fa1-d7a7-4267-b934-26400cf6f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-ee75e8d7-615f-4d17-a2a8-6c2c2b1f0740,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-f4112027-6f26-47b6-b8b2-5b23018ced4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264583600-172.17.0.20-1597656442383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-97e81df7-db3c-4a48-ac4b-a4b53c65689b,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-7663c941-79b2-4db4-8bd7-fc96d06834dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-5463c060-469a-428f-a1ad-74a4452fe494,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ce548c8a-c637-4ba5-8ff3-e2da47888986,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-fc80bb48-9cdd-456d-afd4-6ad970f7d468,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-36162bf8-2c05-423d-a6a8-2f5dcea8c211,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-79fd30ed-e3ed-4e00-8288-9da09cdd532b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-668e4773-991a-48ae-8739-6c09a23e1101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264583600-172.17.0.20-1597656442383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-97e81df7-db3c-4a48-ac4b-a4b53c65689b,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-7663c941-79b2-4db4-8bd7-fc96d06834dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-5463c060-469a-428f-a1ad-74a4452fe494,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ce548c8a-c637-4ba5-8ff3-e2da47888986,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-fc80bb48-9cdd-456d-afd4-6ad970f7d468,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-36162bf8-2c05-423d-a6a8-2f5dcea8c211,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-79fd30ed-e3ed-4e00-8288-9da09cdd532b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-668e4773-991a-48ae-8739-6c09a23e1101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581184264-172.17.0.20-1597656487333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43541,DS-b88fb2ef-1b15-4c9b-b84d-c284318b2264,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-039770ff-24c6-4e54-9fb2-12d0a320d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-faae5995-1ebf-4f84-a03b-8d190cfba9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-4c700e64-b873-403b-807c-dfa633fcbb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-1ec621d7-376a-42c0-ab14-14ac92a8b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-68e43183-025b-4680-920c-b68c36c4eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-741d0931-b3a8-41ee-871c-300fbfe6801c,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-4d0c7d6c-d658-4f2b-9ff7-bd74909c5e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581184264-172.17.0.20-1597656487333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43541,DS-b88fb2ef-1b15-4c9b-b84d-c284318b2264,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-039770ff-24c6-4e54-9fb2-12d0a320d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-faae5995-1ebf-4f84-a03b-8d190cfba9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-4c700e64-b873-403b-807c-dfa633fcbb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-1ec621d7-376a-42c0-ab14-14ac92a8b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-68e43183-025b-4680-920c-b68c36c4eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-741d0931-b3a8-41ee-871c-300fbfe6801c,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-4d0c7d6c-d658-4f2b-9ff7-bd74909c5e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046545543-172.17.0.20-1597656609155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-c1227846-fe41-49da-a036-e0aea2919691,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-cded8829-1d84-42d3-88d7-92c83978be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-316e3148-c18b-4146-986c-35ee1bd1b4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-76840d6f-15d8-44e4-8d5f-f905f221cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-6b34a169-947b-452c-80e1-a89a1698605e,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-7a8b6743-c07a-43f7-b792-9482d061ba23,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-2e0acb27-7ccd-4b92-bf42-dd11bc08757f,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-88ebad7f-e5ea-46eb-9a09-89ef864de363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046545543-172.17.0.20-1597656609155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-c1227846-fe41-49da-a036-e0aea2919691,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-cded8829-1d84-42d3-88d7-92c83978be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-316e3148-c18b-4146-986c-35ee1bd1b4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-76840d6f-15d8-44e4-8d5f-f905f221cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-6b34a169-947b-452c-80e1-a89a1698605e,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-7a8b6743-c07a-43f7-b792-9482d061ba23,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-2e0acb27-7ccd-4b92-bf42-dd11bc08757f,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-88ebad7f-e5ea-46eb-9a09-89ef864de363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889867227-172.17.0.20-1597656961406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-9326b79c-57b4-4169-842a-b01d5a0e64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-db923a9e-db37-40c8-a7a2-5fc289628037,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-237ca8e8-6b44-40a7-ba64-145adbce2255,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-f33d51ea-ea91-48ac-ab40-aaaf3ad67b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-b2e9bfa6-119f-4d93-9369-35039c6af307,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-6d132f99-631a-417d-ac8d-72bd9e465aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-768b0499-e5a7-4732-8763-3671e1112bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-131c73e6-6642-4c47-a119-970319e91ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889867227-172.17.0.20-1597656961406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-9326b79c-57b4-4169-842a-b01d5a0e64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-db923a9e-db37-40c8-a7a2-5fc289628037,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-237ca8e8-6b44-40a7-ba64-145adbce2255,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-f33d51ea-ea91-48ac-ab40-aaaf3ad67b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-b2e9bfa6-119f-4d93-9369-35039c6af307,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-6d132f99-631a-417d-ac8d-72bd9e465aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-768b0499-e5a7-4732-8763-3671e1112bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-131c73e6-6642-4c47-a119-970319e91ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498809834-172.17.0.20-1597657010827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-88e0771f-4a42-4f09-a7b5-9711e76f2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-52becca7-fc11-4d12-a4ca-e647cb9f3917,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-3b2d4b78-5814-40ac-b3d0-f3f07e9dddad,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-fa84d9bb-36a9-46bf-a564-865d5a9ce6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-2e4312b3-c430-4c29-bfc6-a1091352483e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-9705f5ad-b3d3-4a67-b8cf-2299e5503974,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-9ce65a22-2ab2-4b6f-8e91-ed0e4a8a5764,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-deda15f5-0d41-40be-9926-870d543f80dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498809834-172.17.0.20-1597657010827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-88e0771f-4a42-4f09-a7b5-9711e76f2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-52becca7-fc11-4d12-a4ca-e647cb9f3917,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-3b2d4b78-5814-40ac-b3d0-f3f07e9dddad,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-fa84d9bb-36a9-46bf-a564-865d5a9ce6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-2e4312b3-c430-4c29-bfc6-a1091352483e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-9705f5ad-b3d3-4a67-b8cf-2299e5503974,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-9ce65a22-2ab2-4b6f-8e91-ed0e4a8a5764,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-deda15f5-0d41-40be-9926-870d543f80dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666796170-172.17.0.20-1597657512778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46731,DS-b6696ec4-27ec-4085-a67a-c252fbb94d94,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-5490d977-6677-43a8-80e5-0f37b0381946,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-e29f169c-f088-4b9f-b8be-611c05757238,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-8dd68463-93aa-47cd-9b8e-4800a56e30b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3e96375f-b8e0-445a-9c06-6a0fbb598786,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-13589751-6b28-4edd-b1b4-bb3a5a46d144,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-ef14385f-0b47-41d8-b1c4-358b5e6b155a,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-e6696ba1-753b-4394-b462-7ce1f0e55a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666796170-172.17.0.20-1597657512778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46731,DS-b6696ec4-27ec-4085-a67a-c252fbb94d94,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-5490d977-6677-43a8-80e5-0f37b0381946,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-e29f169c-f088-4b9f-b8be-611c05757238,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-8dd68463-93aa-47cd-9b8e-4800a56e30b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3e96375f-b8e0-445a-9c06-6a0fbb598786,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-13589751-6b28-4edd-b1b4-bb3a5a46d144,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-ef14385f-0b47-41d8-b1c4-358b5e6b155a,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-e6696ba1-753b-4394-b462-7ce1f0e55a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085153914-172.17.0.20-1597658059847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43330,DS-bef3cb25-1378-438c-8a08-1a04c5c76e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d16d20ff-7f0a-4540-aafe-6a0853b0df92,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-ea9bf06f-545d-4b7c-bcf0-7532b724ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-c7b48039-a81e-4446-845f-6e3b99d7b58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-820c43b1-e030-466a-873a-92f554e2e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-05d54a23-27bb-438c-abae-8fb89e8dd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-99248544-7329-4b8b-b1be-3251c81e4084,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-27812f97-6b71-4f5c-909d-476437b1277a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085153914-172.17.0.20-1597658059847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43330,DS-bef3cb25-1378-438c-8a08-1a04c5c76e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d16d20ff-7f0a-4540-aafe-6a0853b0df92,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-ea9bf06f-545d-4b7c-bcf0-7532b724ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-c7b48039-a81e-4446-845f-6e3b99d7b58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-820c43b1-e030-466a-873a-92f554e2e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-05d54a23-27bb-438c-abae-8fb89e8dd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-99248544-7329-4b8b-b1be-3251c81e4084,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-27812f97-6b71-4f5c-909d-476437b1277a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-329590636-172.17.0.20-1597658435904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-6557ad6d-01e5-4971-b402-76c38f66ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-ea19d90d-1799-4c52-bbec-c9ba23ab100c,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2a5f505f-0c04-402e-8282-2f233ee97e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-f3d8d5c7-e2c4-437b-9852-1fb1b7f8c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-36f5576e-8728-4f5e-8dcf-01a74dc2ea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-b0c108ff-d023-42d6-a190-452695f7d9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-fe1cc2e3-f94a-44bd-a972-9c3819483db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-3b8e469b-712f-4ccc-af92-b0c822354e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-329590636-172.17.0.20-1597658435904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-6557ad6d-01e5-4971-b402-76c38f66ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-ea19d90d-1799-4c52-bbec-c9ba23ab100c,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2a5f505f-0c04-402e-8282-2f233ee97e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-f3d8d5c7-e2c4-437b-9852-1fb1b7f8c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-36f5576e-8728-4f5e-8dcf-01a74dc2ea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-b0c108ff-d023-42d6-a190-452695f7d9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-fe1cc2e3-f94a-44bd-a972-9c3819483db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-3b8e469b-712f-4ccc-af92-b0c822354e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650043302-172.17.0.20-1597658672129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-f98b78be-58d3-438a-8822-f0c4f42ed686,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-774bbea0-912f-439b-a1e0-78b2950c5996,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d7039497-878d-4f8e-9cd3-702ea56cf16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-c52b6afc-4c0e-4472-b07c-e8b46f60246a,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-c188d390-b501-4764-b19f-43ef0111a408,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-bc736523-436a-49df-9f25-ed1723a2b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-80eef693-e775-4a7d-b64f-c75eead3f858,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-ee19203f-81f5-4f49-a2d8-ec2c8234a84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650043302-172.17.0.20-1597658672129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-f98b78be-58d3-438a-8822-f0c4f42ed686,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-774bbea0-912f-439b-a1e0-78b2950c5996,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d7039497-878d-4f8e-9cd3-702ea56cf16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-c52b6afc-4c0e-4472-b07c-e8b46f60246a,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-c188d390-b501-4764-b19f-43ef0111a408,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-bc736523-436a-49df-9f25-ed1723a2b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-80eef693-e775-4a7d-b64f-c75eead3f858,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-ee19203f-81f5-4f49-a2d8-ec2c8234a84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637367845-172.17.0.20-1597659614646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-1b7a6eba-3000-4ed5-aceb-6455896c5c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2f0e3a5b-c2f7-4d1d-8bda-43cf5aa20fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-b298a413-7de4-4a89-827f-0a032fee3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-d2255830-27ad-40ad-b4c8-91f781732d06,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-197d37fc-f074-424e-baa6-3974476b2e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-4c0f3e35-ae69-4817-bd65-7509ece6cfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-0150e149-b2ac-445d-af8a-98946d68a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-922b7c13-a3a4-442e-8752-4917aa5469a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637367845-172.17.0.20-1597659614646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-1b7a6eba-3000-4ed5-aceb-6455896c5c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2f0e3a5b-c2f7-4d1d-8bda-43cf5aa20fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-b298a413-7de4-4a89-827f-0a032fee3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-d2255830-27ad-40ad-b4c8-91f781732d06,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-197d37fc-f074-424e-baa6-3974476b2e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-4c0f3e35-ae69-4817-bd65-7509ece6cfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-0150e149-b2ac-445d-af8a-98946d68a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-922b7c13-a3a4-442e-8752-4917aa5469a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940404763-172.17.0.20-1597659710802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-e6addaa7-c815-4575-bfe9-17e943dfc27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-965445ab-2c7a-4ba0-9e6d-0aa8bff98b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-4bcbec1c-133e-410d-9741-b6196b48222f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-b897ccb2-7079-4cc9-b4f2-974d59992021,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-8ee221a3-3027-4c23-9132-21875ad57737,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e2e325e7-9742-4d17-a8f8-a2f0c550540b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-3ec5a133-8b25-41e7-b575-51abbdcd4488,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-c5554708-a065-4b79-89d0-6ca4a9560756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940404763-172.17.0.20-1597659710802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-e6addaa7-c815-4575-bfe9-17e943dfc27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-965445ab-2c7a-4ba0-9e6d-0aa8bff98b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-4bcbec1c-133e-410d-9741-b6196b48222f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-b897ccb2-7079-4cc9-b4f2-974d59992021,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-8ee221a3-3027-4c23-9132-21875ad57737,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e2e325e7-9742-4d17-a8f8-a2f0c550540b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-3ec5a133-8b25-41e7-b575-51abbdcd4488,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-c5554708-a065-4b79-89d0-6ca4a9560756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595709137-172.17.0.20-1597660040737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-f8830baf-9573-4227-955f-4f8c78287f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-df5053e9-ae8e-489d-bf5e-d0238f6de456,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-395784fc-7dce-4fb3-af4e-15d4c435301c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-52c3d76c-dfc1-487d-90be-98afab627d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-472d5140-de54-47bd-8f31-4c018c9f0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-021a4f33-264f-494d-9534-a3f312a23e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-51425c16-837f-45ac-b3cc-e69c7a09d3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-940659e7-08fc-4870-a198-131a9b445ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595709137-172.17.0.20-1597660040737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-f8830baf-9573-4227-955f-4f8c78287f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-df5053e9-ae8e-489d-bf5e-d0238f6de456,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-395784fc-7dce-4fb3-af4e-15d4c435301c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-52c3d76c-dfc1-487d-90be-98afab627d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-472d5140-de54-47bd-8f31-4c018c9f0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-021a4f33-264f-494d-9534-a3f312a23e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-51425c16-837f-45ac-b3cc-e69c7a09d3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-940659e7-08fc-4870-a198-131a9b445ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521633843-172.17.0.20-1597660081900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-a5d8bcf4-7458-4dca-8932-958b5732e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-21391f47-b598-41e0-ad78-b26ad3cedc95,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-632fffba-3332-4cf4-8bf2-ada25326f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-b18233ef-9acf-4d15-95d8-2f408c70ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-1e1383f9-15a2-48bf-92cc-74e2109ef9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-c8625a1f-2737-4682-b9be-d06a971b4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-d6e8df68-76fa-48d6-ada0-6bc309e704b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-6ce8a4f0-b5a3-4e6c-b2a4-7af89a58d367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521633843-172.17.0.20-1597660081900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-a5d8bcf4-7458-4dca-8932-958b5732e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-21391f47-b598-41e0-ad78-b26ad3cedc95,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-632fffba-3332-4cf4-8bf2-ada25326f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-b18233ef-9acf-4d15-95d8-2f408c70ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-1e1383f9-15a2-48bf-92cc-74e2109ef9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-c8625a1f-2737-4682-b9be-d06a971b4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-d6e8df68-76fa-48d6-ada0-6bc309e704b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-6ce8a4f0-b5a3-4e6c-b2a4-7af89a58d367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033922517-172.17.0.20-1597660396804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-91f6c9ed-cc1c-41bf-80d9-586571985fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-f111f20b-9272-4f2c-b20b-dba278274b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-42c26d89-e4c4-447c-9693-8dbe01e614e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-eda7a6fa-d24b-4ad3-8ffb-c0460ad7c437,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-1ff8f2f3-3e46-48ad-aef3-4f689ee87780,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-cb63a79c-23a6-4a81-859c-f9a496879081,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-76cc2070-c61d-4f95-8932-8f154791c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-33c960b3-2fab-45a7-8f17-6d02404fa9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033922517-172.17.0.20-1597660396804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-91f6c9ed-cc1c-41bf-80d9-586571985fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-f111f20b-9272-4f2c-b20b-dba278274b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-42c26d89-e4c4-447c-9693-8dbe01e614e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-eda7a6fa-d24b-4ad3-8ffb-c0460ad7c437,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-1ff8f2f3-3e46-48ad-aef3-4f689ee87780,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-cb63a79c-23a6-4a81-859c-f9a496879081,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-76cc2070-c61d-4f95-8932-8f154791c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-33c960b3-2fab-45a7-8f17-6d02404fa9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691813357-172.17.0.20-1597660674968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-772257aa-5a8c-4f2c-b299-3fcee4b63541,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-fbc645ed-0d17-455c-b4b0-1c962e2beaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ef163080-a011-4c04-b29b-6326e2d91026,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-8b97091d-d75f-491c-9661-ef87d982e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-c9ed6568-cc4c-4828-8971-f9689138653c,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-d849db99-9eea-4371-8a4d-f6fe5d716f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-cfe4bbc0-c42b-4bfa-b053-2503443e1149,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8ce23dab-e75d-4c5b-9549-ac9f8600f289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691813357-172.17.0.20-1597660674968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-772257aa-5a8c-4f2c-b299-3fcee4b63541,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-fbc645ed-0d17-455c-b4b0-1c962e2beaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ef163080-a011-4c04-b29b-6326e2d91026,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-8b97091d-d75f-491c-9661-ef87d982e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-c9ed6568-cc4c-4828-8971-f9689138653c,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-d849db99-9eea-4371-8a4d-f6fe5d716f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-cfe4bbc0-c42b-4bfa-b053-2503443e1149,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8ce23dab-e75d-4c5b-9549-ac9f8600f289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989413544-172.17.0.20-1597661104658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-0f63941f-f1ec-4b37-8022-20e6c8b50a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7c2f411b-8210-475b-9f38-2248ff866aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c5b54947-2dc2-4e55-a3d8-cd253eb9f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-ae760242-1a3b-4045-9fdc-42082efd11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-7598d28f-5f31-4e23-ade5-e5232be68992,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-2058702d-4ea0-4d13-80d2-592c7d0d83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5e58d0bd-75ac-4637-97e7-62113a27bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-dd461862-ac79-4bbd-8688-76cd75309b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989413544-172.17.0.20-1597661104658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-0f63941f-f1ec-4b37-8022-20e6c8b50a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7c2f411b-8210-475b-9f38-2248ff866aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-c5b54947-2dc2-4e55-a3d8-cd253eb9f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-ae760242-1a3b-4045-9fdc-42082efd11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-7598d28f-5f31-4e23-ade5-e5232be68992,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-2058702d-4ea0-4d13-80d2-592c7d0d83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5e58d0bd-75ac-4637-97e7-62113a27bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-dd461862-ac79-4bbd-8688-76cd75309b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605725784-172.17.0.20-1597661293783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-95ab6f28-e1ed-439d-b4ef-3a974c881afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7f9652b9-0222-4a3a-8f21-510dde92c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-089a2da2-5472-429d-ae46-5d1c00d25188,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-8dca00a1-4092-40fd-a3e8-f78cd3cb49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-704eb4fc-d8ea-40e4-b944-759389dfe7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7f5a627d-6307-4ebd-94f3-883658d4ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-cc6a2d59-68f3-4070-b69c-3be0bc95b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-b4a9c5bc-51ac-4fd2-9de0-3488a85008e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605725784-172.17.0.20-1597661293783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-95ab6f28-e1ed-439d-b4ef-3a974c881afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7f9652b9-0222-4a3a-8f21-510dde92c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-089a2da2-5472-429d-ae46-5d1c00d25188,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-8dca00a1-4092-40fd-a3e8-f78cd3cb49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-704eb4fc-d8ea-40e4-b944-759389dfe7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7f5a627d-6307-4ebd-94f3-883658d4ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-cc6a2d59-68f3-4070-b69c-3be0bc95b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-b4a9c5bc-51ac-4fd2-9de0-3488a85008e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281180832-172.17.0.20-1597661427933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-2872e5c3-91cb-4a85-a53a-1043f24e3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-3fbcc136-4c0d-43ea-850f-585b1a230700,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-ab8f5f3e-0b3d-4299-b9f8-24574fb2fa18,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-ef1c19fc-267c-4fbd-b6d5-a9a414890a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-83cc818b-4d97-412e-b037-1e3104954dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-5fd92326-7467-4d03-827e-72795eb09861,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-ddd1e19f-d435-4a03-919d-66c746dd2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-4cf5891c-5755-4e7b-a484-5a4bd82dfcb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281180832-172.17.0.20-1597661427933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-2872e5c3-91cb-4a85-a53a-1043f24e3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-3fbcc136-4c0d-43ea-850f-585b1a230700,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-ab8f5f3e-0b3d-4299-b9f8-24574fb2fa18,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-ef1c19fc-267c-4fbd-b6d5-a9a414890a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-83cc818b-4d97-412e-b037-1e3104954dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-5fd92326-7467-4d03-827e-72795eb09861,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-ddd1e19f-d435-4a03-919d-66c746dd2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-4cf5891c-5755-4e7b-a484-5a4bd82dfcb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167255491-172.17.0.20-1597661532182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-d49d0178-0c72-4666-a628-ee2895c25f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-529fe07b-43c6-424f-b9f6-879386f84efb,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-328c3178-f073-45d1-b3cd-9ea529036a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-21588674-1bcf-4a45-8fa2-932f08d4c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-40262cb5-4009-48e1-8b1c-a6221efa5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-66149822-cdb1-4519-a18f-51c3a6b62ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-30849362-eaaa-4fa3-bfe4-efac194d830a,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-73588b33-02d3-4c8e-9d7b-a4941ffdd35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167255491-172.17.0.20-1597661532182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-d49d0178-0c72-4666-a628-ee2895c25f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-529fe07b-43c6-424f-b9f6-879386f84efb,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-328c3178-f073-45d1-b3cd-9ea529036a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-21588674-1bcf-4a45-8fa2-932f08d4c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-40262cb5-4009-48e1-8b1c-a6221efa5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-66149822-cdb1-4519-a18f-51c3a6b62ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-30849362-eaaa-4fa3-bfe4-efac194d830a,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-73588b33-02d3-4c8e-9d7b-a4941ffdd35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533427849-172.17.0.20-1597662095911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-c3587e27-2f39-4286-8d17-b8fab2ebb950,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-a1848e68-9ece-4995-83d6-0d0f4f033ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-0fbdb7e3-9ac8-4294-b7a2-a179911d2813,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-e864c509-a780-4368-bc9b-1f5338faab88,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-4febad34-5ae4-414c-8fde-0c9180dfc318,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-79b58970-8500-4ed2-bfca-0f6427641693,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-9597864d-3b52-4163-8403-7b09bfb53bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8b3b3733-7192-42aa-90f4-c266c4376dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533427849-172.17.0.20-1597662095911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-c3587e27-2f39-4286-8d17-b8fab2ebb950,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-a1848e68-9ece-4995-83d6-0d0f4f033ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-0fbdb7e3-9ac8-4294-b7a2-a179911d2813,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-e864c509-a780-4368-bc9b-1f5338faab88,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-4febad34-5ae4-414c-8fde-0c9180dfc318,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-79b58970-8500-4ed2-bfca-0f6427641693,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-9597864d-3b52-4163-8403-7b09bfb53bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8b3b3733-7192-42aa-90f4-c266c4376dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110570741-172.17.0.20-1597662323716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-cf3308fd-2164-43e6-9f1a-67ad64724cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b95de206-ee5c-4039-8f04-4d9ee2bd7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a500cfdd-b886-4473-8bfe-fd8e57f52185,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-b9cdad22-d57c-4298-9e3e-41cb46e962e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-b070b5f6-42f8-4151-846f-1358304e575d,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-8094dc72-2512-44db-8267-f323a77318da,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-7a993f06-8d64-44d5-8afd-b7c31d290f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-b081086b-a47b-4eef-966e-3ed03df9741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110570741-172.17.0.20-1597662323716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-cf3308fd-2164-43e6-9f1a-67ad64724cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b95de206-ee5c-4039-8f04-4d9ee2bd7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-a500cfdd-b886-4473-8bfe-fd8e57f52185,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-b9cdad22-d57c-4298-9e3e-41cb46e962e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-b070b5f6-42f8-4151-846f-1358304e575d,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-8094dc72-2512-44db-8267-f323a77318da,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-7a993f06-8d64-44d5-8afd-b7c31d290f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-b081086b-a47b-4eef-966e-3ed03df9741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: might be true error
Total execution time in seconds : 6875
