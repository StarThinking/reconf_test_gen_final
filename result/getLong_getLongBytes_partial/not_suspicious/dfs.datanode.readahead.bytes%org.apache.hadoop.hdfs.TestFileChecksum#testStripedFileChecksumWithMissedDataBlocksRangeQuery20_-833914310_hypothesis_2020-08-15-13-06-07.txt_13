reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757518913-172.17.0.20-1597497182270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-eb36572a-efad-4a5a-96f5-b090c3bd70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-c22b25e8-2544-4de2-9619-c90dcda5f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-97111a60-78f6-419e-a738-82a7210ad50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-6f98f46d-abe7-4568-96bf-eceb5e431dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-783cda96-3b9c-4e7f-b30c-bf9a3ba7f325,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-24b4ca8d-60b5-4abc-91c4-62324fbd41d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-3105ba5e-d65d-404c-92a5-c4f847718c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-aecb3dda-37e9-460a-a163-6cd6dc067475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757518913-172.17.0.20-1597497182270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-eb36572a-efad-4a5a-96f5-b090c3bd70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-c22b25e8-2544-4de2-9619-c90dcda5f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-97111a60-78f6-419e-a738-82a7210ad50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-6f98f46d-abe7-4568-96bf-eceb5e431dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-783cda96-3b9c-4e7f-b30c-bf9a3ba7f325,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-24b4ca8d-60b5-4abc-91c4-62324fbd41d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-3105ba5e-d65d-404c-92a5-c4f847718c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-aecb3dda-37e9-460a-a163-6cd6dc067475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269652156-172.17.0.20-1597497378321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-e4dae271-eb74-4cdf-9837-8fc58e92dcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-c90a9c6d-7e23-440c-a87f-0e1e0837f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3b1b46cd-cd6f-42c0-bb03-b6e4dfb8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-ad927937-0764-401e-93d3-76eadca05706,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-75655e65-e624-4881-be07-ba7d483aa5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-cc1976e3-d2b1-46fe-bb15-65b24bd2ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-eb8d9c34-b57e-4615-9b41-ceee747af417,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-e45f4ee4-0b17-4e76-9f5d-d14de4f48832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269652156-172.17.0.20-1597497378321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-e4dae271-eb74-4cdf-9837-8fc58e92dcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-c90a9c6d-7e23-440c-a87f-0e1e0837f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3b1b46cd-cd6f-42c0-bb03-b6e4dfb8855b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-ad927937-0764-401e-93d3-76eadca05706,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-75655e65-e624-4881-be07-ba7d483aa5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-cc1976e3-d2b1-46fe-bb15-65b24bd2ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-eb8d9c34-b57e-4615-9b41-ceee747af417,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-e45f4ee4-0b17-4e76-9f5d-d14de4f48832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677365406-172.17.0.20-1597497722294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-90f98d41-4e0c-402d-b5c0-10ecbee945f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-59fa3d71-5175-42eb-aeb0-2b8f280f3a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-402b1d89-f0a1-4265-9f02-145797443077,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57d37e05-6f96-43c1-b84f-ecc464700ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-826d2a48-f3cb-416c-b4fb-121d3fa4f128,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-dad38d84-ec8b-416e-b436-712f6929e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f7110711-8951-458a-96bf-2870eb7f9293,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9edfa0c5-ff01-4979-aff3-679e0eecf8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677365406-172.17.0.20-1597497722294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-90f98d41-4e0c-402d-b5c0-10ecbee945f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-59fa3d71-5175-42eb-aeb0-2b8f280f3a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-402b1d89-f0a1-4265-9f02-145797443077,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57d37e05-6f96-43c1-b84f-ecc464700ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-826d2a48-f3cb-416c-b4fb-121d3fa4f128,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-dad38d84-ec8b-416e-b436-712f6929e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f7110711-8951-458a-96bf-2870eb7f9293,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9edfa0c5-ff01-4979-aff3-679e0eecf8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298260351-172.17.0.20-1597498003307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-b8f72dd4-724e-48ce-aa08-a664d397dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-213293f8-555b-4d33-8b60-e938d4bf31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-4638ee49-4b8d-4384-a687-2716cc769b83,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-b02bbc5d-cd97-4736-aa88-027a4a221241,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-2c8e89dd-53d2-4eca-b6b7-f6438748573d,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-17eab7e7-bd10-4d6f-8cf6-d0dcd68b159a,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-fe61e9fb-0d1a-4c90-aef2-09f6faaa501f,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-bbb89c5c-d88e-42ec-ab84-05b3693adca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298260351-172.17.0.20-1597498003307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-b8f72dd4-724e-48ce-aa08-a664d397dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-213293f8-555b-4d33-8b60-e938d4bf31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-4638ee49-4b8d-4384-a687-2716cc769b83,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-b02bbc5d-cd97-4736-aa88-027a4a221241,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-2c8e89dd-53d2-4eca-b6b7-f6438748573d,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-17eab7e7-bd10-4d6f-8cf6-d0dcd68b159a,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-fe61e9fb-0d1a-4c90-aef2-09f6faaa501f,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-bbb89c5c-d88e-42ec-ab84-05b3693adca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560578656-172.17.0.20-1597498205711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-1d3cd7d4-ece3-4207-8625-312408e07034,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-56285e7f-3921-4178-a1f9-e586bf94684a,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-69dedc5c-2814-47fc-b08d-c4a3347ffa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-08820181-b537-490d-95d1-4a8bcb2d684d,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-2b89ffe8-9e13-4029-88c4-79f37b8b7705,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-fee5d6fe-fce7-4ea2-bbc6-cf2da299a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0201dd6e-fabe-462f-8fc1-915dd1e30b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-bebb2c90-ed06-4158-be3a-ac639bd3a08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560578656-172.17.0.20-1597498205711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-1d3cd7d4-ece3-4207-8625-312408e07034,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-56285e7f-3921-4178-a1f9-e586bf94684a,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-69dedc5c-2814-47fc-b08d-c4a3347ffa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-08820181-b537-490d-95d1-4a8bcb2d684d,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-2b89ffe8-9e13-4029-88c4-79f37b8b7705,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-fee5d6fe-fce7-4ea2-bbc6-cf2da299a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0201dd6e-fabe-462f-8fc1-915dd1e30b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-bebb2c90-ed06-4158-be3a-ac639bd3a08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541077009-172.17.0.20-1597498437342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-f0609e7f-6b8f-4a50-846f-77020fd6bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-b2a91a41-32a8-4be1-8add-4a23055e6207,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-8a00cd66-6407-4e63-b73a-cd45f713dd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-275be1f7-8f87-4c44-893c-1091e167b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-09e42003-df55-47e1-9c68-f46d0f492c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-6970856b-7cd1-496e-90cc-0a54d5c7920c,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-602f1725-4992-412f-9ab1-85a7ff724f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-357cd507-21ee-44f5-b089-0af8965529bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541077009-172.17.0.20-1597498437342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-f0609e7f-6b8f-4a50-846f-77020fd6bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-b2a91a41-32a8-4be1-8add-4a23055e6207,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-8a00cd66-6407-4e63-b73a-cd45f713dd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-275be1f7-8f87-4c44-893c-1091e167b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-09e42003-df55-47e1-9c68-f46d0f492c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-6970856b-7cd1-496e-90cc-0a54d5c7920c,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-602f1725-4992-412f-9ab1-85a7ff724f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-357cd507-21ee-44f5-b089-0af8965529bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668038985-172.17.0.20-1597498768237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-adc687e6-07a3-4f85-b902-46833405f716,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-20951ea2-5cbe-4859-9b57-039680c02f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-1a7045cf-1dfe-4df4-bed4-93d18ba12d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-dc6ffe16-9513-4543-a7a0-868ef31324f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-d6f22951-48a2-4f03-8259-57747bacf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-6c29ab45-799f-45da-856b-615affa5cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-413abf31-2d11-424a-9c65-f706d9378bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-8a42ccbe-ba3f-4697-854d-a1d0b05ee892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668038985-172.17.0.20-1597498768237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-adc687e6-07a3-4f85-b902-46833405f716,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-20951ea2-5cbe-4859-9b57-039680c02f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-1a7045cf-1dfe-4df4-bed4-93d18ba12d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-dc6ffe16-9513-4543-a7a0-868ef31324f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-d6f22951-48a2-4f03-8259-57747bacf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-6c29ab45-799f-45da-856b-615affa5cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-413abf31-2d11-424a-9c65-f706d9378bde,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-8a42ccbe-ba3f-4697-854d-a1d0b05ee892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738110264-172.17.0.20-1597498846067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-6bfd57bf-5f2a-4fc9-816d-9898a27c5952,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-894f5ef5-8b9e-4059-9744-3b8e867bc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-494f2d86-fe26-4ac1-b878-e194088617b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-1ce4f88e-ee7a-49d5-a188-2d87f70134e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d90d9f52-0d8f-4d7a-83d0-6610e01fbf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-d0383279-0a77-4b24-97fd-89b62c033761,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-c0902ce2-3f2e-4c74-8d77-3d8c00654287,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-d9354b22-c5a0-4ea5-92f3-6cb194b5fddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738110264-172.17.0.20-1597498846067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-6bfd57bf-5f2a-4fc9-816d-9898a27c5952,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-894f5ef5-8b9e-4059-9744-3b8e867bc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-494f2d86-fe26-4ac1-b878-e194088617b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-1ce4f88e-ee7a-49d5-a188-2d87f70134e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d90d9f52-0d8f-4d7a-83d0-6610e01fbf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-d0383279-0a77-4b24-97fd-89b62c033761,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-c0902ce2-3f2e-4c74-8d77-3d8c00654287,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-d9354b22-c5a0-4ea5-92f3-6cb194b5fddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542555104-172.17.0.20-1597500103414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-4238e529-bc8f-49f4-bc93-e6eb1b468d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-c306c722-387c-4283-a431-b8775d09d218,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-8613d113-d18c-4c78-80f7-6d9cddc1d769,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-cdfd6724-f20f-4cf5-9ff0-6f4276487472,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-696441ae-4210-4b70-b0e9-502f90bc25d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-93dc7d36-0500-40c0-b2ff-ae76c222585a,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-1dabbcf0-3b86-45fc-bdc5-4422e6fa18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-904c5471-2018-4d43-8e86-7dee2585c5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542555104-172.17.0.20-1597500103414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-4238e529-bc8f-49f4-bc93-e6eb1b468d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-c306c722-387c-4283-a431-b8775d09d218,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-8613d113-d18c-4c78-80f7-6d9cddc1d769,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-cdfd6724-f20f-4cf5-9ff0-6f4276487472,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-696441ae-4210-4b70-b0e9-502f90bc25d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-93dc7d36-0500-40c0-b2ff-ae76c222585a,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-1dabbcf0-3b86-45fc-bdc5-4422e6fa18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-904c5471-2018-4d43-8e86-7dee2585c5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569515706-172.17.0.20-1597500406024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-7582a7c1-bbc6-4164-b6de-2aee4f3a5f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-a7b4788e-6e43-4a4c-aef5-98ac434961ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fbdabadd-bab8-40d8-8c49-41f63dbda570,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f6aa700c-2a1c-4c69-8c8a-83034bbca565,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-70863719-b4cc-41b2-950c-143a10f21b19,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-7cb7ac83-6654-484f-a560-4d40b1545cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-672b47ea-0fb9-4ec6-a326-adbe04cada59,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-dfb4b566-841a-426d-92dd-a158efb6811e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569515706-172.17.0.20-1597500406024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-7582a7c1-bbc6-4164-b6de-2aee4f3a5f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-a7b4788e-6e43-4a4c-aef5-98ac434961ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fbdabadd-bab8-40d8-8c49-41f63dbda570,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f6aa700c-2a1c-4c69-8c8a-83034bbca565,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-70863719-b4cc-41b2-950c-143a10f21b19,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-7cb7ac83-6654-484f-a560-4d40b1545cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-672b47ea-0fb9-4ec6-a326-adbe04cada59,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-dfb4b566-841a-426d-92dd-a158efb6811e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381161070-172.17.0.20-1597501680928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-0859c616-96b9-4c2f-ae2e-d1a65e3015b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-320b518a-72e6-4ae4-8b0f-284396552de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0d517e80-0c6a-4bf2-96ff-9e562cbeb792,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-46d93c41-cbc2-4b50-86d4-da08f7cd1da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-46be7cf6-ac4c-4329-a746-0b923f949deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-9554cfab-768d-406c-8fcc-60cac931ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-aeb902d9-a6be-4671-a2c0-5b7356e7dcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-88f5060b-7118-4f17-a7d4-78e32fc5f8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381161070-172.17.0.20-1597501680928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-0859c616-96b9-4c2f-ae2e-d1a65e3015b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-320b518a-72e6-4ae4-8b0f-284396552de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0d517e80-0c6a-4bf2-96ff-9e562cbeb792,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-46d93c41-cbc2-4b50-86d4-da08f7cd1da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-46be7cf6-ac4c-4329-a746-0b923f949deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-9554cfab-768d-406c-8fcc-60cac931ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-aeb902d9-a6be-4671-a2c0-5b7356e7dcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-88f5060b-7118-4f17-a7d4-78e32fc5f8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978339023-172.17.0.20-1597502179795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-eae021d4-b9cb-4c1a-b429-7c7a78fd10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-93a3fca5-8acf-43f4-89a7-e762e30f7abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-98ffefbf-20b4-4d2b-897a-351cc86cbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-67005ba3-86a0-4417-aa42-271c9278a283,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-54d0c7bb-06e7-4b2d-9d4a-b40758f84c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-368ec256-365c-4a50-890a-bec339a99c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-fb7138de-39e8-426e-957e-3b8a449a92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-29174443-6eaa-4526-9b1b-59026bb71e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978339023-172.17.0.20-1597502179795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-eae021d4-b9cb-4c1a-b429-7c7a78fd10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-93a3fca5-8acf-43f4-89a7-e762e30f7abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-98ffefbf-20b4-4d2b-897a-351cc86cbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-67005ba3-86a0-4417-aa42-271c9278a283,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-54d0c7bb-06e7-4b2d-9d4a-b40758f84c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-368ec256-365c-4a50-890a-bec339a99c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-fb7138de-39e8-426e-957e-3b8a449a92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-29174443-6eaa-4526-9b1b-59026bb71e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5623
