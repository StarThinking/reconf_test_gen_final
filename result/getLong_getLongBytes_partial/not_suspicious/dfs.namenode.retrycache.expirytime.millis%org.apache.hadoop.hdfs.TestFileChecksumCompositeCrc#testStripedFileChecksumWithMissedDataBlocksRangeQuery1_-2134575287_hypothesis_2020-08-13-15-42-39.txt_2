reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747903636-172.17.0.20-1597333452161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-8f534697-e444-42ce-bc37-30c6326ba892,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-a2e92aa7-d27c-4b81-b191-c3d75c8f60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-dbb954fe-228d-47c3-ac72-d6a202ad48bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-995e1e08-2aab-4a80-9f4b-6ac561779907,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-84ec4f05-7159-4655-b8ed-713cde95ce62,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-dc00befb-1409-4071-8858-74cb8378d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-f95ab162-fb54-4b68-a215-0a6d562f72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-2b50884f-ea96-42c5-9881-c4af68b529de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747903636-172.17.0.20-1597333452161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-8f534697-e444-42ce-bc37-30c6326ba892,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-a2e92aa7-d27c-4b81-b191-c3d75c8f60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-dbb954fe-228d-47c3-ac72-d6a202ad48bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-995e1e08-2aab-4a80-9f4b-6ac561779907,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-84ec4f05-7159-4655-b8ed-713cde95ce62,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-dc00befb-1409-4071-8858-74cb8378d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-f95ab162-fb54-4b68-a215-0a6d562f72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-2b50884f-ea96-42c5-9881-c4af68b529de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880870604-172.17.0.20-1597333739504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-3d8bfc92-9c5a-43dc-a560-312670818a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-ffc68f1a-ff98-436a-9bb0-c78a2404ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-0c74347c-4ce5-46b6-9cb7-3897b77da9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-a0d9e48c-57f6-48e6-b8b9-ebf23175ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-8ee33240-8d81-452c-a259-293da4a7d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-bdcd2f05-d31b-4d6d-bd5c-a27285c60355,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-bed572e9-63d2-4e91-a42b-c5393a7224af,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e8f5b1bd-c9a8-4534-bdcf-4c60fb3f663a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880870604-172.17.0.20-1597333739504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-3d8bfc92-9c5a-43dc-a560-312670818a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-ffc68f1a-ff98-436a-9bb0-c78a2404ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-0c74347c-4ce5-46b6-9cb7-3897b77da9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-a0d9e48c-57f6-48e6-b8b9-ebf23175ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-8ee33240-8d81-452c-a259-293da4a7d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-bdcd2f05-d31b-4d6d-bd5c-a27285c60355,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-bed572e9-63d2-4e91-a42b-c5393a7224af,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e8f5b1bd-c9a8-4534-bdcf-4c60fb3f663a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111412524-172.17.0.20-1597333889085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-806c4c9b-f14f-4afc-90d7-00467f5560d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-24516597-9c15-4cd0-aa7a-0de69073826e,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-96dc0461-f7d1-43b1-b237-5cccae0af28e,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-cf12d433-4d43-453f-a9f2-9eb8b28a8679,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-cf125194-cf7e-494f-aec7-5b142a3f738a,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-51212134-7166-4691-922c-662f237f2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-df921a4a-1f4a-48ed-a5d0-d52aa4d5cacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-e2172584-e08e-432b-b574-199d67f909dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111412524-172.17.0.20-1597333889085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-806c4c9b-f14f-4afc-90d7-00467f5560d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-24516597-9c15-4cd0-aa7a-0de69073826e,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-96dc0461-f7d1-43b1-b237-5cccae0af28e,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-cf12d433-4d43-453f-a9f2-9eb8b28a8679,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-cf125194-cf7e-494f-aec7-5b142a3f738a,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-51212134-7166-4691-922c-662f237f2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-df921a4a-1f4a-48ed-a5d0-d52aa4d5cacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-e2172584-e08e-432b-b574-199d67f909dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582878211-172.17.0.20-1597334251242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-f9fee5b7-3d09-44de-8930-5d2b209a9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-4f282f84-41c4-4656-bfbb-ad0696cb8417,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3a219709-021b-4eb6-9ade-9f830e80b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-a1a95b95-57d5-4ce1-9be0-c1e06b37f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-d02c4e6e-1bbe-438a-99d2-7f1df9eb5163,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-f7a8e293-f2da-4fbb-9aa3-d52e35c3acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b4bc9d79-bf3f-4b4b-90e5-4b07ca5ccf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-1a4e99a6-86e9-499a-913b-3df220572bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582878211-172.17.0.20-1597334251242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-f9fee5b7-3d09-44de-8930-5d2b209a9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-4f282f84-41c4-4656-bfbb-ad0696cb8417,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3a219709-021b-4eb6-9ade-9f830e80b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-a1a95b95-57d5-4ce1-9be0-c1e06b37f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-d02c4e6e-1bbe-438a-99d2-7f1df9eb5163,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-f7a8e293-f2da-4fbb-9aa3-d52e35c3acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b4bc9d79-bf3f-4b4b-90e5-4b07ca5ccf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-1a4e99a6-86e9-499a-913b-3df220572bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588262850-172.17.0.20-1597334507517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-ab063053-28e4-4d8b-ba56-7f2ac9406678,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-ea5d0c49-cb40-42b7-992a-e13621e4d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-2e61c6a6-8755-48a2-b48e-37424754e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-7a7ffbd9-5dc9-463c-8592-209cfedf56cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-f9e7ecbe-5e6a-4e74-9989-11711f2d3548,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-60d77827-cc5a-4a74-a134-8f4fcd75a600,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1f08755c-7a39-4acc-b960-a98e2290677f,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d0525760-4bcc-4e76-966f-ad0466d1d6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588262850-172.17.0.20-1597334507517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-ab063053-28e4-4d8b-ba56-7f2ac9406678,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-ea5d0c49-cb40-42b7-992a-e13621e4d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-2e61c6a6-8755-48a2-b48e-37424754e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-7a7ffbd9-5dc9-463c-8592-209cfedf56cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-f9e7ecbe-5e6a-4e74-9989-11711f2d3548,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-60d77827-cc5a-4a74-a134-8f4fcd75a600,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1f08755c-7a39-4acc-b960-a98e2290677f,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d0525760-4bcc-4e76-966f-ad0466d1d6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965080820-172.17.0.20-1597334779362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-4528847a-1bb1-4957-bccb-93554aec3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-4cba7971-f554-49a2-900e-c06d5ad1c069,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d2fad1b1-2a28-4152-b80a-5331dd650513,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-814f1ae7-decc-41b7-ba22-f7f1a5e8b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-834527bc-7d12-4ae6-b8b4-8dab93fdaa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-c9004be3-8cce-4517-8ff9-c05b5a447f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-c3f2458c-2f27-44fe-b52e-245895177374,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-6607f4ff-8f96-422d-8e8d-775e68639678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965080820-172.17.0.20-1597334779362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-4528847a-1bb1-4957-bccb-93554aec3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-4cba7971-f554-49a2-900e-c06d5ad1c069,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d2fad1b1-2a28-4152-b80a-5331dd650513,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-814f1ae7-decc-41b7-ba22-f7f1a5e8b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-834527bc-7d12-4ae6-b8b4-8dab93fdaa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-c9004be3-8cce-4517-8ff9-c05b5a447f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-c3f2458c-2f27-44fe-b52e-245895177374,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-6607f4ff-8f96-422d-8e8d-775e68639678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444470884-172.17.0.20-1597334939886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-2637ef92-4117-438c-9a36-2fb4d9047f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-eba5aca5-ffe5-4ef5-b142-a0746b93f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-553d529e-759c-4f4a-b13a-b3c75f4c16d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-38a6ba9e-6451-450d-ab31-b8e0dab85854,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-7f4c9342-77af-4ec6-8ee8-11e65251f9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-3e86b4e5-af6a-4b66-8e55-db10b1420e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-a18d99f5-de44-464a-b22a-ae6ac43790b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-996cba26-c80a-4cc6-973a-2db934edbf37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444470884-172.17.0.20-1597334939886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-2637ef92-4117-438c-9a36-2fb4d9047f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-eba5aca5-ffe5-4ef5-b142-a0746b93f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-553d529e-759c-4f4a-b13a-b3c75f4c16d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-38a6ba9e-6451-450d-ab31-b8e0dab85854,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-7f4c9342-77af-4ec6-8ee8-11e65251f9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-3e86b4e5-af6a-4b66-8e55-db10b1420e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-a18d99f5-de44-464a-b22a-ae6ac43790b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-996cba26-c80a-4cc6-973a-2db934edbf37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411675543-172.17.0.20-1597335053782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-ac57a463-c5e0-49f0-a2ff-b45ace272e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-33845c20-bd04-41a3-bff7-ce787862d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8052d474-ff01-4a29-82ec-7c5b0f7055d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-66eb67a3-340d-4084-be79-e5024019f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-0281ebac-abc7-498f-85e7-fc5b4bbb817f,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-ac7e9834-82d8-45bd-993a-523ab37bb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-8a2ad04d-35e2-4f34-9fbb-8ab8fe959189,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-a00f93fc-8122-4557-bfd9-2b2e53b46e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411675543-172.17.0.20-1597335053782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-ac57a463-c5e0-49f0-a2ff-b45ace272e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-33845c20-bd04-41a3-bff7-ce787862d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8052d474-ff01-4a29-82ec-7c5b0f7055d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-66eb67a3-340d-4084-be79-e5024019f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-0281ebac-abc7-498f-85e7-fc5b4bbb817f,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-ac7e9834-82d8-45bd-993a-523ab37bb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-8a2ad04d-35e2-4f34-9fbb-8ab8fe959189,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-a00f93fc-8122-4557-bfd9-2b2e53b46e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040293776-172.17.0.20-1597335175396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-51648d81-96bd-4cc0-9699-5c49185f4318,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6a7bf05e-5977-47b9-9b81-0d6eafd4b33c,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b978900a-0ce4-4614-8638-67ce63eba1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-d1b71f04-b895-4ace-804e-05179bdd5d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-ade0f86a-dde1-4584-838e-44488d9d729f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-600435ed-f882-47a4-8099-10387d29d590,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-5f8faf3f-0e51-4102-914e-be67734cdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-9221166a-0690-43e5-8bfa-49a25dd4a313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040293776-172.17.0.20-1597335175396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-51648d81-96bd-4cc0-9699-5c49185f4318,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6a7bf05e-5977-47b9-9b81-0d6eafd4b33c,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b978900a-0ce4-4614-8638-67ce63eba1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-d1b71f04-b895-4ace-804e-05179bdd5d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-ade0f86a-dde1-4584-838e-44488d9d729f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-600435ed-f882-47a4-8099-10387d29d590,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-5f8faf3f-0e51-4102-914e-be67734cdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-9221166a-0690-43e5-8bfa-49a25dd4a313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000984667-172.17.0.20-1597336101246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-37bf0034-2dce-4ad4-ba81-9067b7b47b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ab302222-8948-49d6-9c4f-03dac1bfa398,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-5d820ec8-5077-4a49-9970-d1ca5dc44687,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-86065de5-bdb9-4859-b27d-570ab2f7a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2791947f-08c2-4128-a1f7-5fcb1889d765,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4a9557e1-e9bb-401d-a7d9-0151a3d09813,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-e167cc5f-4b71-49f3-9095-5098850f901f,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-b8918a64-3b9c-43dc-ac58-9e8c1f3e209a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000984667-172.17.0.20-1597336101246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-37bf0034-2dce-4ad4-ba81-9067b7b47b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ab302222-8948-49d6-9c4f-03dac1bfa398,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-5d820ec8-5077-4a49-9970-d1ca5dc44687,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-86065de5-bdb9-4859-b27d-570ab2f7a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2791947f-08c2-4128-a1f7-5fcb1889d765,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4a9557e1-e9bb-401d-a7d9-0151a3d09813,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-e167cc5f-4b71-49f3-9095-5098850f901f,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-b8918a64-3b9c-43dc-ac58-9e8c1f3e209a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310554756-172.17.0.20-1597336426112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-31a691fe-d585-42bf-8f5c-e9b80222af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-44ffbf3e-5829-46b4-9236-a0acce6b4b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-4054bd2e-e1bd-4672-974a-67d17338882c,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ef6311be-e940-4568-b3be-0b5b6d03e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-2dbdbe63-3fe5-421e-b06b-c9aac4045081,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b38e8bd0-b0d6-4f50-ba44-152969347ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-7780bb8c-8ad6-4ee9-8af9-70e6e9e47cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-a8556e12-689f-4bc2-b9dd-9f4828051dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310554756-172.17.0.20-1597336426112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-31a691fe-d585-42bf-8f5c-e9b80222af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-44ffbf3e-5829-46b4-9236-a0acce6b4b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-4054bd2e-e1bd-4672-974a-67d17338882c,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ef6311be-e940-4568-b3be-0b5b6d03e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-2dbdbe63-3fe5-421e-b06b-c9aac4045081,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b38e8bd0-b0d6-4f50-ba44-152969347ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-7780bb8c-8ad6-4ee9-8af9-70e6e9e47cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-a8556e12-689f-4bc2-b9dd-9f4828051dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964375809-172.17.0.20-1597336974425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-8502ae15-9af6-409d-a827-796ba61ac7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-ad3873d4-7104-4a94-8509-4cf8fc425515,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-7ec51856-85cf-4ae7-844a-2c12937c1990,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-c757e865-c38c-4a16-8e40-3ed2ec01aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-4c8b2da8-b503-4a8a-a24e-ab07c413c66f,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5e311d7b-8726-4b99-b42f-9db2f488ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-06a596ef-1b95-47a0-b091-388c9068f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-ec084a40-c969-4cbd-a2fb-d7497bceaacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964375809-172.17.0.20-1597336974425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-8502ae15-9af6-409d-a827-796ba61ac7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-ad3873d4-7104-4a94-8509-4cf8fc425515,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-7ec51856-85cf-4ae7-844a-2c12937c1990,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-c757e865-c38c-4a16-8e40-3ed2ec01aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-4c8b2da8-b503-4a8a-a24e-ab07c413c66f,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5e311d7b-8726-4b99-b42f-9db2f488ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-06a596ef-1b95-47a0-b091-388c9068f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-ec084a40-c969-4cbd-a2fb-d7497bceaacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007226168-172.17.0.20-1597337010669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-109f3950-3ee5-47f3-acd6-6687a2d15659,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-b150a1a8-e270-4c2b-beb7-935c90301ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-c4eb0205-808f-4692-99e2-66ec421b6fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-00f72953-e5a5-4d3f-9b71-9018cd8a4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-de833802-8496-4b51-aaae-0c279df27665,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-1111367b-eeb0-41bc-9f71-e8cc0fa37246,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-5dc6ac09-5a89-4349-b7f3-de8f779c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-f44fc6fb-207f-4ac8-afe6-7b8c06c1f773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007226168-172.17.0.20-1597337010669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-109f3950-3ee5-47f3-acd6-6687a2d15659,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-b150a1a8-e270-4c2b-beb7-935c90301ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-c4eb0205-808f-4692-99e2-66ec421b6fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-00f72953-e5a5-4d3f-9b71-9018cd8a4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-de833802-8496-4b51-aaae-0c279df27665,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-1111367b-eeb0-41bc-9f71-e8cc0fa37246,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-5dc6ac09-5a89-4349-b7f3-de8f779c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-f44fc6fb-207f-4ac8-afe6-7b8c06c1f773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919247216-172.17.0.20-1597337090185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-fe365a32-ca5f-4726-8940-a22d59839433,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1642df88-106c-4e6e-bd12-9ab41be61b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-aaa1ffda-faba-441c-8e7f-4461239ab985,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-f7848e72-980f-43b2-8130-bc009176f010,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-f35967e2-942f-47df-befd-412a6241a157,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-fdf7b174-a340-49a4-9253-4f3eefa6e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-126bc3ba-c649-4b86-bec9-b66fb33961a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2ba34ec3-aabf-4c44-bd8f-3c29c1c0acf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919247216-172.17.0.20-1597337090185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-fe365a32-ca5f-4726-8940-a22d59839433,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1642df88-106c-4e6e-bd12-9ab41be61b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-aaa1ffda-faba-441c-8e7f-4461239ab985,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-f7848e72-980f-43b2-8130-bc009176f010,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-f35967e2-942f-47df-befd-412a6241a157,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-fdf7b174-a340-49a4-9253-4f3eefa6e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-126bc3ba-c649-4b86-bec9-b66fb33961a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2ba34ec3-aabf-4c44-bd8f-3c29c1c0acf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723247555-172.17.0.20-1597337748410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-886edabd-a2e4-49fd-85be-e955fbb41714,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cb31cd8a-a9f9-4804-bffc-9aa4a6810c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-e8c5ea7a-21d5-444b-80c0-2ba8d742178f,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ce538398-add8-4b24-9ab5-f45e750f2c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-8163d326-3793-43df-aa27-e46830a4fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-b83d1b30-d113-4659-8797-86dda4a91900,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1b779ea5-79f1-4044-9274-870e7665fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-4bd324f3-c95b-40ae-a636-7672131ffcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723247555-172.17.0.20-1597337748410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-886edabd-a2e4-49fd-85be-e955fbb41714,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cb31cd8a-a9f9-4804-bffc-9aa4a6810c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-e8c5ea7a-21d5-444b-80c0-2ba8d742178f,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ce538398-add8-4b24-9ab5-f45e750f2c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-8163d326-3793-43df-aa27-e46830a4fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-b83d1b30-d113-4659-8797-86dda4a91900,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1b779ea5-79f1-4044-9274-870e7665fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-4bd324f3-c95b-40ae-a636-7672131ffcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422010190-172.17.0.20-1597337828502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44568,DS-81736d50-9821-4fe6-917c-3d9a9d7a56b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-d15b3995-926c-4048-9aa9-a77aa46e2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-4dec8390-dd48-4ee1-bd52-fdf591450eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0a106154-e79a-435b-9a57-a5d6074cac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-911924f0-3e36-4d59-9089-e3c9bb458d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-7560810c-fc07-48b7-8c9d-29e1e5d2746a,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-f2578611-1802-4fbd-af64-c7cb58591eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-09ece31b-9be3-4fdf-b901-6a5cf9a84f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422010190-172.17.0.20-1597337828502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44568,DS-81736d50-9821-4fe6-917c-3d9a9d7a56b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-d15b3995-926c-4048-9aa9-a77aa46e2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-4dec8390-dd48-4ee1-bd52-fdf591450eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0a106154-e79a-435b-9a57-a5d6074cac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-911924f0-3e36-4d59-9089-e3c9bb458d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-7560810c-fc07-48b7-8c9d-29e1e5d2746a,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-f2578611-1802-4fbd-af64-c7cb58591eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-09ece31b-9be3-4fdf-b901-6a5cf9a84f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165472610-172.17.0.20-1597338778271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-053f87b4-90c1-4201-9e0f-6c1045948161,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-a8734d05-46fe-4414-8290-a424bbf767ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-84922af1-328d-4774-b80f-a70b851c3b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ace673b5-727f-45f9-a2d2-bf54fed95844,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-3971a5cf-32cf-4151-b55a-93ab0f347bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-1e394bf9-a6b5-49d4-b9b6-1ac1bc2ffa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-1a8e1c10-51b6-4dd2-a495-57807f5c3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-0320b01d-2a13-432f-b090-ba6a4933739e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165472610-172.17.0.20-1597338778271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-053f87b4-90c1-4201-9e0f-6c1045948161,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-a8734d05-46fe-4414-8290-a424bbf767ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-84922af1-328d-4774-b80f-a70b851c3b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ace673b5-727f-45f9-a2d2-bf54fed95844,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-3971a5cf-32cf-4151-b55a-93ab0f347bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-1e394bf9-a6b5-49d4-b9b6-1ac1bc2ffa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-1a8e1c10-51b6-4dd2-a495-57807f5c3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-0320b01d-2a13-432f-b090-ba6a4933739e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5651
