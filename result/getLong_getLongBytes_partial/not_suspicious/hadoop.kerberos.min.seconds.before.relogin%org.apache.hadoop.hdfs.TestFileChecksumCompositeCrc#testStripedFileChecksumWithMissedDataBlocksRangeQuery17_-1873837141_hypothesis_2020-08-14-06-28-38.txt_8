reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143882625-172.17.0.6-1597387311922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-05965352-383a-4b25-86f7-cd5de5888f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-e08f7977-a86d-4448-adc8-7ebb82138473,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-da514773-be0b-4b63-b68e-b231e3b186fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-d7969a1c-bf0f-4a36-9ae6-817cd9a1eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-f1877436-99ca-4330-abe2-a439a3957ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f1322d13-955f-4c78-a7c3-916f0546ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-7c31b1f7-c50b-4507-985a-137cba728cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-cc5fcc59-2562-4439-88cb-12023b8a84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143882625-172.17.0.6-1597387311922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-05965352-383a-4b25-86f7-cd5de5888f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-e08f7977-a86d-4448-adc8-7ebb82138473,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-da514773-be0b-4b63-b68e-b231e3b186fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-d7969a1c-bf0f-4a36-9ae6-817cd9a1eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-f1877436-99ca-4330-abe2-a439a3957ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f1322d13-955f-4c78-a7c3-916f0546ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-7c31b1f7-c50b-4507-985a-137cba728cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-cc5fcc59-2562-4439-88cb-12023b8a84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761385019-172.17.0.6-1597387580595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-fc723d20-4ac3-43ac-b64b-cd80455ba72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-0439590c-602b-4887-9545-749fb6394abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-fd9e3954-6339-4e83-8d8f-accfcf3f80c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-9763b633-c9a6-4f83-a2a6-42263bd8fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-3a953a1a-8e65-4331-b3ed-216be2424322,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-193c8ebb-a111-4c83-937c-f5785f1eae45,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-3b804687-b44b-420f-bf74-77e8092ad36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-6f30c2e4-3383-4fde-9792-6d0f9f5fccd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761385019-172.17.0.6-1597387580595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-fc723d20-4ac3-43ac-b64b-cd80455ba72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-0439590c-602b-4887-9545-749fb6394abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-fd9e3954-6339-4e83-8d8f-accfcf3f80c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-9763b633-c9a6-4f83-a2a6-42263bd8fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-3a953a1a-8e65-4331-b3ed-216be2424322,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-193c8ebb-a111-4c83-937c-f5785f1eae45,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-3b804687-b44b-420f-bf74-77e8092ad36c,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-6f30c2e4-3383-4fde-9792-6d0f9f5fccd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145263553-172.17.0.6-1597388142798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-8b8f1935-f448-4e89-8128-a0a7e228ee09,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-68899f37-9e8b-418e-adc2-6fe6a5518735,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-add71e02-4280-4bb9-b1c3-e420c95bb866,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-433391f2-ac5a-413c-a35a-64233d8083ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-5cda21f8-5334-4e89-9a64-6bfb04fcb6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-69da5d9a-0dcb-4669-a797-ce182d340b52,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-28b93fba-4039-4a3d-bec3-b6f1b4854f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4f04e15c-32b6-4a7b-beef-379ff0a7bc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145263553-172.17.0.6-1597388142798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-8b8f1935-f448-4e89-8128-a0a7e228ee09,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-68899f37-9e8b-418e-adc2-6fe6a5518735,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-add71e02-4280-4bb9-b1c3-e420c95bb866,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-433391f2-ac5a-413c-a35a-64233d8083ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-5cda21f8-5334-4e89-9a64-6bfb04fcb6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-69da5d9a-0dcb-4669-a797-ce182d340b52,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-28b93fba-4039-4a3d-bec3-b6f1b4854f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4f04e15c-32b6-4a7b-beef-379ff0a7bc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483630062-172.17.0.6-1597388483300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-75259714-1b03-424b-a761-68c957dcf056,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-0ee3b4a3-749e-46c8-95ec-f0b5f1eb1648,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-2e0ba6da-11ac-4449-b36b-4f864ae69c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-d818733f-eb53-497c-9e95-f693b2e7b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-6cd12317-7b84-47e3-b7c9-7dfdc9c8e19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-63624808-f929-4210-a6bd-56acf68d0dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-2d6ca11e-3a3d-44d8-b586-13438bef7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-7609c0ca-b7e2-4a8f-a373-b70685d78e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483630062-172.17.0.6-1597388483300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-75259714-1b03-424b-a761-68c957dcf056,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-0ee3b4a3-749e-46c8-95ec-f0b5f1eb1648,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-2e0ba6da-11ac-4449-b36b-4f864ae69c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-d818733f-eb53-497c-9e95-f693b2e7b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-6cd12317-7b84-47e3-b7c9-7dfdc9c8e19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-63624808-f929-4210-a6bd-56acf68d0dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-2d6ca11e-3a3d-44d8-b586-13438bef7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-7609c0ca-b7e2-4a8f-a373-b70685d78e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380688122-172.17.0.6-1597388625686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-7f0dbd9e-4cb9-455a-aec4-6e2d0a91881c,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c6203f38-2d45-4bc0-8ed5-4c292ae3e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-66ff42d5-a450-4251-9cd1-a900c96ebe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-6bb5515c-89cb-4f27-a08e-fe9236f3fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-f9939979-71c1-4a8f-b155-35c6b5b52e15,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-12c8d3a0-7faa-4bd2-ae1a-9b8a7c6fa506,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-d5d71211-57a1-4fca-be6d-9f156dd26ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-dbb83703-f8b1-4f61-bc65-5af6ae409a83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380688122-172.17.0.6-1597388625686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-7f0dbd9e-4cb9-455a-aec4-6e2d0a91881c,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c6203f38-2d45-4bc0-8ed5-4c292ae3e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-66ff42d5-a450-4251-9cd1-a900c96ebe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-6bb5515c-89cb-4f27-a08e-fe9236f3fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-f9939979-71c1-4a8f-b155-35c6b5b52e15,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-12c8d3a0-7faa-4bd2-ae1a-9b8a7c6fa506,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-d5d71211-57a1-4fca-be6d-9f156dd26ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-dbb83703-f8b1-4f61-bc65-5af6ae409a83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877716052-172.17.0.6-1597388663516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-a7a4917d-dd17-4d22-94c1-5606d45a8f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-998ae159-a2d1-491b-8a84-07bc8186cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f1eaaa5f-79b3-4be8-b443-2e8f34b60091,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-0f4821ef-0546-406a-8526-9eaa8b91b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-b575a039-d487-453e-90ae-b90748118347,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f59fe364-53c6-4607-8315-f5ec986ee6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-3caf50b1-bb5d-44f1-8ad1-21b81e42947f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-86f8eced-4ec2-49a5-842a-129d519f30fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877716052-172.17.0.6-1597388663516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-a7a4917d-dd17-4d22-94c1-5606d45a8f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-998ae159-a2d1-491b-8a84-07bc8186cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f1eaaa5f-79b3-4be8-b443-2e8f34b60091,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-0f4821ef-0546-406a-8526-9eaa8b91b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-b575a039-d487-453e-90ae-b90748118347,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f59fe364-53c6-4607-8315-f5ec986ee6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-3caf50b1-bb5d-44f1-8ad1-21b81e42947f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-86f8eced-4ec2-49a5-842a-129d519f30fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715031613-172.17.0.6-1597388760613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-3eab2578-59ba-4742-9a76-795cb187837f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-c6035a09-94f0-4e1d-a925-1ba67d962bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-51307906-e3bc-4c0b-aa97-8d8998875d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-f35f1bd1-3769-4cc9-8090-e72bed075721,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3e4325ba-f48b-446c-9c30-6f81d53fb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-19484010-cb98-484d-b5d3-0f45113de0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-4999c0a9-07c2-4d2f-bff0-2ed5a6aeeb56,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-126eedc1-a142-4a2a-9912-04f477237aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715031613-172.17.0.6-1597388760613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-3eab2578-59ba-4742-9a76-795cb187837f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-c6035a09-94f0-4e1d-a925-1ba67d962bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-51307906-e3bc-4c0b-aa97-8d8998875d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-f35f1bd1-3769-4cc9-8090-e72bed075721,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3e4325ba-f48b-446c-9c30-6f81d53fb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-19484010-cb98-484d-b5d3-0f45113de0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-4999c0a9-07c2-4d2f-bff0-2ed5a6aeeb56,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-126eedc1-a142-4a2a-9912-04f477237aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727109787-172.17.0.6-1597389110914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-ce358ad4-03f4-4427-890c-a5b8ead7cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5bbdcb8d-d6d0-41fe-bf8a-0bf2bc0ba0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-a75343d7-0809-47ab-9ec9-61a585bb11dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-ca4ba9ca-27de-4c2b-8ca7-a7e9b4bce865,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-eb0636ed-2d06-4717-9ce1-7b3a9f8bc745,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-2fe6fe12-5619-4df4-9c30-9538abc16a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8e3943d8-47ff-42f6-97b0-186b634c8e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-47b690c0-f6f7-4273-94f4-deace30f75ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727109787-172.17.0.6-1597389110914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-ce358ad4-03f4-4427-890c-a5b8ead7cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5bbdcb8d-d6d0-41fe-bf8a-0bf2bc0ba0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-a75343d7-0809-47ab-9ec9-61a585bb11dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-ca4ba9ca-27de-4c2b-8ca7-a7e9b4bce865,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-eb0636ed-2d06-4717-9ce1-7b3a9f8bc745,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-2fe6fe12-5619-4df4-9c30-9538abc16a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8e3943d8-47ff-42f6-97b0-186b634c8e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-47b690c0-f6f7-4273-94f4-deace30f75ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644563986-172.17.0.6-1597389183138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-cd1ee477-d690-418d-a120-8ba2de334f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e319b618-30d7-42c9-bb93-f55eb54c8f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-f0e6f388-d1c7-441b-8978-e0ee279bdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-9f3117ae-167c-4441-8b3c-389b944a806c,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f5635c02-dddc-4279-bba1-35dfcf666cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-f609dfd9-b729-4da5-981c-a5f4527f8327,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-33d5197e-1d13-4af6-b03c-f0f7bf42da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-cf26227f-04a0-4e87-a8d2-32f13f45fe8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644563986-172.17.0.6-1597389183138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-cd1ee477-d690-418d-a120-8ba2de334f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e319b618-30d7-42c9-bb93-f55eb54c8f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-f0e6f388-d1c7-441b-8978-e0ee279bdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-9f3117ae-167c-4441-8b3c-389b944a806c,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f5635c02-dddc-4279-bba1-35dfcf666cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-f609dfd9-b729-4da5-981c-a5f4527f8327,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-33d5197e-1d13-4af6-b03c-f0f7bf42da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-cf26227f-04a0-4e87-a8d2-32f13f45fe8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774190975-172.17.0.6-1597389582533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-d98ea79a-cbb9-48d4-a5a7-958bd79702d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-66a62acd-243b-4afd-a3e3-7de1833c23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-b94c06a9-a560-4131-bda2-12d5b67f5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-9f6817fe-ef69-4ff0-99b9-14c5ac510db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-1bfb45b1-c7e9-4e0f-a56d-ee87cd0decae,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-f9969c02-1d19-480a-852d-e03c225854ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-692625a6-276e-4a2b-afe5-4e4321051988,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-a820a74f-c10c-4ddd-866f-85fea0fba8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774190975-172.17.0.6-1597389582533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-d98ea79a-cbb9-48d4-a5a7-958bd79702d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-66a62acd-243b-4afd-a3e3-7de1833c23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-b94c06a9-a560-4131-bda2-12d5b67f5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-9f6817fe-ef69-4ff0-99b9-14c5ac510db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-1bfb45b1-c7e9-4e0f-a56d-ee87cd0decae,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-f9969c02-1d19-480a-852d-e03c225854ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-692625a6-276e-4a2b-afe5-4e4321051988,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-a820a74f-c10c-4ddd-866f-85fea0fba8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181805000-172.17.0.6-1597389979771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-30df4d6e-0289-4015-bece-a1d6fffdc698,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-891fdb32-f59d-4d7f-a3b0-55751bd1b642,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-0ff19b55-e491-4a16-a6be-7a353724f478,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-50327cc8-382c-493b-943a-29b35ee010bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7b8891e3-6219-4f87-bc90-ff12f1bf2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-cbdf0789-faed-4066-a8da-9c35bb675763,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-43971b3f-c11e-4d26-be43-b50f36b72285,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-6e472edc-0b77-495d-8e86-253cd1886743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181805000-172.17.0.6-1597389979771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-30df4d6e-0289-4015-bece-a1d6fffdc698,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-891fdb32-f59d-4d7f-a3b0-55751bd1b642,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-0ff19b55-e491-4a16-a6be-7a353724f478,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-50327cc8-382c-493b-943a-29b35ee010bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7b8891e3-6219-4f87-bc90-ff12f1bf2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-cbdf0789-faed-4066-a8da-9c35bb675763,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-43971b3f-c11e-4d26-be43-b50f36b72285,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-6e472edc-0b77-495d-8e86-253cd1886743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600168247-172.17.0.6-1597390223206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-9c062c03-8de2-4b15-8d81-ae502f396ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-961fef46-97ba-40b5-a95d-0aab8f22cd86,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-d5d03fa1-e586-4456-b5b8-c3d1ccde1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-25a24507-82f4-408d-8db8-16a014d390f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-49f4bd05-6228-4008-896c-253328562f67,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-639dc11c-507a-4f1c-ac1a-05a0924f5a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-e081e553-4913-4f07-bcc8-409b20c268be,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-bb1ba62b-12cd-40b3-9125-74774e616537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600168247-172.17.0.6-1597390223206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-9c062c03-8de2-4b15-8d81-ae502f396ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-961fef46-97ba-40b5-a95d-0aab8f22cd86,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-d5d03fa1-e586-4456-b5b8-c3d1ccde1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-25a24507-82f4-408d-8db8-16a014d390f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-49f4bd05-6228-4008-896c-253328562f67,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-639dc11c-507a-4f1c-ac1a-05a0924f5a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-e081e553-4913-4f07-bcc8-409b20c268be,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-bb1ba62b-12cd-40b3-9125-74774e616537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642201034-172.17.0.6-1597390935807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-0e0cd39f-7750-4325-93b8-b2ed8555145a,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-59e1d9c3-77d8-411b-bddb-598e913901f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-2b4d7e08-95de-4ed3-a822-bb0cd7bc09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-728ab98c-26f3-4d8b-b86a-009fdd3a844a,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-538f3eff-a8e3-4dec-8e0b-59d7a96d5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-e7ea06de-9cf5-4ec8-89e6-d69dcfda30de,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-b7c39171-1dbe-4394-9ad9-387fff04dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-7e7e54c0-8fa7-4a42-b456-823b31f8079a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642201034-172.17.0.6-1597390935807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-0e0cd39f-7750-4325-93b8-b2ed8555145a,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-59e1d9c3-77d8-411b-bddb-598e913901f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-2b4d7e08-95de-4ed3-a822-bb0cd7bc09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-728ab98c-26f3-4d8b-b86a-009fdd3a844a,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-538f3eff-a8e3-4dec-8e0b-59d7a96d5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-e7ea06de-9cf5-4ec8-89e6-d69dcfda30de,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-b7c39171-1dbe-4394-9ad9-387fff04dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-7e7e54c0-8fa7-4a42-b456-823b31f8079a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569350811-172.17.0.6-1597390972580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42360,DS-5f779206-603f-40f4-ae31-d41cfb700b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-f77f629d-ef69-4e25-88a6-63935a8beb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-7b946b83-7b1d-4f5c-b502-68c0ade1e5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-5f280cac-15d2-40a3-a73a-92e098181fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-df716353-fdf9-44b5-82ae-69195c403454,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d2625a18-d312-4512-b352-3bfdea258e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-f4dd62ee-1efd-4a5c-b943-4e94e6b28fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-7c2931cb-bd36-4796-bf90-1e3cf5392847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569350811-172.17.0.6-1597390972580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42360,DS-5f779206-603f-40f4-ae31-d41cfb700b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-f77f629d-ef69-4e25-88a6-63935a8beb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-7b946b83-7b1d-4f5c-b502-68c0ade1e5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-5f280cac-15d2-40a3-a73a-92e098181fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-df716353-fdf9-44b5-82ae-69195c403454,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d2625a18-d312-4512-b352-3bfdea258e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-f4dd62ee-1efd-4a5c-b943-4e94e6b28fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-7c2931cb-bd36-4796-bf90-1e3cf5392847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5213
