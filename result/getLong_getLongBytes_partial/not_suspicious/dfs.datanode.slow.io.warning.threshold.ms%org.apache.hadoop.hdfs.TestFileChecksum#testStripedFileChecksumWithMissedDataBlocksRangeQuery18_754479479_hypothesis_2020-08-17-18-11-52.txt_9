reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142022129-172.17.0.2-1597687925859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-d218cb44-0efc-4ff1-b1ec-42d97de6f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-81c1dec3-284b-4d81-920f-36379e0a93db,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-7404faca-cbbc-4751-93b2-eeb5816a2694,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-495322d9-023c-4639-a6a7-9e6b0a79c0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-dc49e496-d3d1-471f-a28e-35a0e97995c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-b6f395d2-162d-4d63-bdc2-5dc46c8fe0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-48195d16-dc08-4c81-95d5-a5d67bf50f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-e6f1dbfc-3ae1-4914-965b-3bd847011a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142022129-172.17.0.2-1597687925859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-d218cb44-0efc-4ff1-b1ec-42d97de6f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-81c1dec3-284b-4d81-920f-36379e0a93db,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-7404faca-cbbc-4751-93b2-eeb5816a2694,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-495322d9-023c-4639-a6a7-9e6b0a79c0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-dc49e496-d3d1-471f-a28e-35a0e97995c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-b6f395d2-162d-4d63-bdc2-5dc46c8fe0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-48195d16-dc08-4c81-95d5-a5d67bf50f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-e6f1dbfc-3ae1-4914-965b-3bd847011a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362137995-172.17.0.2-1597687958637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-1e38c7f8-9eed-4b93-b5b3-3c736b6ba44f,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-f7f0aa96-a9c9-463f-a74e-bed550576c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-8f5b633e-6205-4bb7-ac98-9573016c6604,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-d173761c-9ee1-4d48-8b04-b3c4baec52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-e3d3c235-fbd7-4587-b16d-a548013817ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-eadd04fc-2bca-425d-9615-79c2eed095eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-132d7bc9-7e06-4409-b54a-b05e55797746,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-30af29cb-969a-4da0-8613-fdb5f8a56724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362137995-172.17.0.2-1597687958637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-1e38c7f8-9eed-4b93-b5b3-3c736b6ba44f,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-f7f0aa96-a9c9-463f-a74e-bed550576c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-8f5b633e-6205-4bb7-ac98-9573016c6604,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-d173761c-9ee1-4d48-8b04-b3c4baec52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-e3d3c235-fbd7-4587-b16d-a548013817ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-eadd04fc-2bca-425d-9615-79c2eed095eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-132d7bc9-7e06-4409-b54a-b05e55797746,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-30af29cb-969a-4da0-8613-fdb5f8a56724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414914036-172.17.0.2-1597688065363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-372dba8e-ee2e-49d5-a9f1-2492a5d6d742,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-41d7003a-0350-4139-af69-77cc5f254467,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-04280b2b-4206-4aac-a81e-7d829726dc29,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-76b245b8-964f-46c6-8cb5-968dd3827ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-81fc31a6-6823-4633-8cab-18ff9920afce,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-b97d4b1a-97c0-40e5-86a5-3c2542a225ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-0b8d2a9e-ccb7-4ef2-b6ed-6dfc199b5223,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-eed0858c-4a01-46cf-9304-8c11eb111a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414914036-172.17.0.2-1597688065363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-372dba8e-ee2e-49d5-a9f1-2492a5d6d742,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-41d7003a-0350-4139-af69-77cc5f254467,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-04280b2b-4206-4aac-a81e-7d829726dc29,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-76b245b8-964f-46c6-8cb5-968dd3827ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-81fc31a6-6823-4633-8cab-18ff9920afce,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-b97d4b1a-97c0-40e5-86a5-3c2542a225ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-0b8d2a9e-ccb7-4ef2-b6ed-6dfc199b5223,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-eed0858c-4a01-46cf-9304-8c11eb111a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729612676-172.17.0.2-1597688101236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-81f9669d-fa69-4f51-96d9-22c24f609ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-7966bac1-f734-462f-bff6-6e38fad625af,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0e589458-ac17-43c3-a625-8818a6d13517,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-f4171eab-70a2-46de-beb8-8c3211e85ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-32578c92-3ab9-4d18-a1a3-5109b7bd43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-a3734d56-5981-44c7-9937-9cbb3fef1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-573d240b-ab82-4fc6-bb55-07b58874c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-6d9ea249-15bb-4d1d-a4b5-49c0f1531107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729612676-172.17.0.2-1597688101236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-81f9669d-fa69-4f51-96d9-22c24f609ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-7966bac1-f734-462f-bff6-6e38fad625af,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0e589458-ac17-43c3-a625-8818a6d13517,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-f4171eab-70a2-46de-beb8-8c3211e85ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-32578c92-3ab9-4d18-a1a3-5109b7bd43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-a3734d56-5981-44c7-9937-9cbb3fef1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-573d240b-ab82-4fc6-bb55-07b58874c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-6d9ea249-15bb-4d1d-a4b5-49c0f1531107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197340944-172.17.0.2-1597688188903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-b24440ef-5fbf-4392-9e52-f0ca56eb2c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-56dd8056-12da-4fbc-b590-1045daab62ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-4d49e3a7-2c99-4c6d-a188-19b2c1844047,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-32b1eb76-095e-49ed-aeb6-cc9d6e059ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0c650fda-31be-4a91-a842-e01f47531241,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-7816b80f-7e37-4935-a7ca-59c4dace4e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-5bc3db10-0bd2-45a2-b6c8-a043ad75c447,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-aa8c2e79-583c-4d7d-b1f5-c36ee69e19a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197340944-172.17.0.2-1597688188903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-b24440ef-5fbf-4392-9e52-f0ca56eb2c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-56dd8056-12da-4fbc-b590-1045daab62ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-4d49e3a7-2c99-4c6d-a188-19b2c1844047,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-32b1eb76-095e-49ed-aeb6-cc9d6e059ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0c650fda-31be-4a91-a842-e01f47531241,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-7816b80f-7e37-4935-a7ca-59c4dace4e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-5bc3db10-0bd2-45a2-b6c8-a043ad75c447,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-aa8c2e79-583c-4d7d-b1f5-c36ee69e19a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974889146-172.17.0.2-1597688379697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-7025a946-9c30-4b8c-a372-f2a39c63f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-0c85155b-a3df-4df4-83df-0c1bff1fc5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-509a520b-faf7-4be2-ac2c-98d62c4dc13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-a7207a76-179c-41e1-828d-eea70716ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-8bad2387-502e-436a-9eac-79cdb123bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-5b440ebf-671c-4f70-a701-811475a41284,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-9c8cdaac-8faa-42d0-a284-f1c0bbe9e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-464c89fb-3011-4c18-a1ce-c7dcc399658b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974889146-172.17.0.2-1597688379697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-7025a946-9c30-4b8c-a372-f2a39c63f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-0c85155b-a3df-4df4-83df-0c1bff1fc5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-509a520b-faf7-4be2-ac2c-98d62c4dc13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-a7207a76-179c-41e1-828d-eea70716ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-8bad2387-502e-436a-9eac-79cdb123bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-5b440ebf-671c-4f70-a701-811475a41284,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-9c8cdaac-8faa-42d0-a284-f1c0bbe9e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-464c89fb-3011-4c18-a1ce-c7dcc399658b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828627-172.17.0.2-1597688840959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-7b02e4f9-a03d-4079-85cb-6b838df14d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-4d8e6d39-1951-4796-865a-ffa605ddae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-b8a21414-cd44-47d8-91e4-f4b45279b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-71baa022-a282-4a0f-acf4-2753e83aa91a,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-ebd922cd-4547-4e00-a86c-860cefaa3f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-5fb8bd50-eae7-40f6-9dca-f02142d1eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-ba3d9565-fd28-4817-9e54-048197ef74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-bc0b8621-ef98-4655-a279-f4154bb417a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828627-172.17.0.2-1597688840959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-7b02e4f9-a03d-4079-85cb-6b838df14d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-4d8e6d39-1951-4796-865a-ffa605ddae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-b8a21414-cd44-47d8-91e4-f4b45279b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-71baa022-a282-4a0f-acf4-2753e83aa91a,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-ebd922cd-4547-4e00-a86c-860cefaa3f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-5fb8bd50-eae7-40f6-9dca-f02142d1eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-ba3d9565-fd28-4817-9e54-048197ef74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-bc0b8621-ef98-4655-a279-f4154bb417a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585581685-172.17.0.2-1597688915180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-ff9781cb-cb1d-4394-96c0-9cf8cbfc0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5678b194-17e7-480b-88c4-f0ab34d140a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9ba26065-7f15-48bb-964e-b8aa3eaacb82,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-4e023486-7215-4dee-9819-9e67fc7398cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-9d90c408-df15-4b71-ba7c-1ec1819499ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-92e9dad3-0d06-4cb9-b292-0591a8021375,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-edafc0ea-4bd2-4fa0-b10f-0c4d144af6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-8bd91f8b-851d-4eeb-b616-592d76f9d314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585581685-172.17.0.2-1597688915180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-ff9781cb-cb1d-4394-96c0-9cf8cbfc0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5678b194-17e7-480b-88c4-f0ab34d140a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9ba26065-7f15-48bb-964e-b8aa3eaacb82,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-4e023486-7215-4dee-9819-9e67fc7398cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-9d90c408-df15-4b71-ba7c-1ec1819499ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-92e9dad3-0d06-4cb9-b292-0591a8021375,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-edafc0ea-4bd2-4fa0-b10f-0c4d144af6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-8bd91f8b-851d-4eeb-b616-592d76f9d314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713066697-172.17.0.2-1597689022249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-d848a566-507f-4549-a24a-0863c61efad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-42cde81d-326b-4e2d-9cf1-7a5b527fd38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c40e3b3e-c37a-4e7b-9ba5-92fbd5679c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-6ba88abc-f2ed-4c05-9e25-5699dda15a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-e6d214da-4e32-467f-9e30-2a0bcbd37248,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-ecee48fa-8b5f-4237-a5c7-8e043dc25a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-68e4cffd-cc7f-45bc-85f0-bbef8cd17c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-471a75f5-f4f7-4b0b-80dc-2d9407338783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713066697-172.17.0.2-1597689022249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-d848a566-507f-4549-a24a-0863c61efad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-42cde81d-326b-4e2d-9cf1-7a5b527fd38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c40e3b3e-c37a-4e7b-9ba5-92fbd5679c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-6ba88abc-f2ed-4c05-9e25-5699dda15a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-e6d214da-4e32-467f-9e30-2a0bcbd37248,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-ecee48fa-8b5f-4237-a5c7-8e043dc25a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-68e4cffd-cc7f-45bc-85f0-bbef8cd17c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-471a75f5-f4f7-4b0b-80dc-2d9407338783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471536595-172.17.0.2-1597689063815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-303ca2f4-5d00-4888-9a39-c8cad44881d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-654b9255-81b6-4a80-89ad-9f9e9539841e,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-2a527dca-6b56-473f-9b8c-09a7026064c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-016ed246-a426-4615-b02e-dcc9454ceea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-745eea83-d3dc-4572-b7ac-299a7fb1b270,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-8b9c6858-5e08-45d7-8ae1-916e0c6f57c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-faa08cee-376a-425c-ae9c-148ac4c5a29d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3d26b865-2a8f-4376-99ab-6698f0e5e85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471536595-172.17.0.2-1597689063815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-303ca2f4-5d00-4888-9a39-c8cad44881d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-654b9255-81b6-4a80-89ad-9f9e9539841e,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-2a527dca-6b56-473f-9b8c-09a7026064c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-016ed246-a426-4615-b02e-dcc9454ceea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-745eea83-d3dc-4572-b7ac-299a7fb1b270,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-8b9c6858-5e08-45d7-8ae1-916e0c6f57c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-faa08cee-376a-425c-ae9c-148ac4c5a29d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3d26b865-2a8f-4376-99ab-6698f0e5e85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145510159-172.17.0.2-1597690644926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-41371819-cc79-49e5-885e-171e9343eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-2db8e2c0-31b7-4f34-83cb-7fc5b6eb3818,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-7e0b053c-0404-4df3-b905-ac69af558a84,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-ddc49bdc-6b75-4676-b649-eb69c7d9f648,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-5bef552c-9d9a-477d-992c-20980755e250,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-2c556ae8-d0a8-4a09-b0af-ef9f91b03361,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-dbc6d3ec-b1f9-4570-9400-8cd8af7c8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-90f8deec-596a-4f52-8db5-519dc042c7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145510159-172.17.0.2-1597690644926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-41371819-cc79-49e5-885e-171e9343eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-2db8e2c0-31b7-4f34-83cb-7fc5b6eb3818,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-7e0b053c-0404-4df3-b905-ac69af558a84,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-ddc49bdc-6b75-4676-b649-eb69c7d9f648,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-5bef552c-9d9a-477d-992c-20980755e250,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-2c556ae8-d0a8-4a09-b0af-ef9f91b03361,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-dbc6d3ec-b1f9-4570-9400-8cd8af7c8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-90f8deec-596a-4f52-8db5-519dc042c7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776161423-172.17.0.2-1597690717625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-fdd9f229-88b0-4361-a195-95bbd09b7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-579c53a2-871c-4f68-8a2b-0e5b6053beae,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-150c4fa1-c0f7-4fa4-9e44-d41e4e1c7852,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-96f14756-0d6f-48cd-a12d-76a500a1b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-80757b55-5db8-4a9a-9081-3d3a7ba5c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-0cd4ff2f-61b4-4208-a5a5-5ad35fa05ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-4794d1f4-f6fc-4f87-a5d5-f22df7e1783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-9455291a-177f-4744-b983-8da15b5f4aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776161423-172.17.0.2-1597690717625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-fdd9f229-88b0-4361-a195-95bbd09b7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-579c53a2-871c-4f68-8a2b-0e5b6053beae,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-150c4fa1-c0f7-4fa4-9e44-d41e4e1c7852,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-96f14756-0d6f-48cd-a12d-76a500a1b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-80757b55-5db8-4a9a-9081-3d3a7ba5c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-0cd4ff2f-61b4-4208-a5a5-5ad35fa05ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-4794d1f4-f6fc-4f87-a5d5-f22df7e1783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-9455291a-177f-4744-b983-8da15b5f4aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260440880-172.17.0.2-1597690747219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-5527468d-4afb-4dac-9f07-0e4dad3fc1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-bfb6e5a3-9671-4551-9643-33d7f586f919,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-36f693b1-26c9-486d-93cf-2cbd867cfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-7e09e189-acf7-495f-979c-a64d77c8b880,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-a79230ed-eed3-4cf5-84c1-d205853508b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-aa140f4a-4207-4150-b2e3-d827d55ed6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bf7f3b41-dba2-477d-9a9b-d98cbb316e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-16df2355-94b5-4838-94c8-45d0dfdd4919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260440880-172.17.0.2-1597690747219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-5527468d-4afb-4dac-9f07-0e4dad3fc1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-bfb6e5a3-9671-4551-9643-33d7f586f919,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-36f693b1-26c9-486d-93cf-2cbd867cfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-7e09e189-acf7-495f-979c-a64d77c8b880,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-a79230ed-eed3-4cf5-84c1-d205853508b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-aa140f4a-4207-4150-b2e3-d827d55ed6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bf7f3b41-dba2-477d-9a9b-d98cbb316e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-16df2355-94b5-4838-94c8-45d0dfdd4919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558769656-172.17.0.2-1597691135243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-6ca30260-cf67-43b6-9b38-ba3ce8d52e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-1fd5e62d-1270-4ab0-a546-566fe1770870,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-88f39698-9749-4116-899d-20af6897275a,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-6ea0d708-d9df-4191-aeb2-ec81f2364bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-9c497fea-7dc9-412d-be9b-2530d7c3690c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-6ac3d4cb-2ee5-46f8-857a-b3d8e2e1edef,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4bbf1b9a-d5a9-4b29-aea1-718065afbb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-cb52fa2d-ece3-4981-9d3d-e895f44cb1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558769656-172.17.0.2-1597691135243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-6ca30260-cf67-43b6-9b38-ba3ce8d52e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-1fd5e62d-1270-4ab0-a546-566fe1770870,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-88f39698-9749-4116-899d-20af6897275a,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-6ea0d708-d9df-4191-aeb2-ec81f2364bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-9c497fea-7dc9-412d-be9b-2530d7c3690c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-6ac3d4cb-2ee5-46f8-857a-b3d8e2e1edef,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4bbf1b9a-d5a9-4b29-aea1-718065afbb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-cb52fa2d-ece3-4981-9d3d-e895f44cb1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727697685-172.17.0.2-1597691429481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-558ebaef-d17c-45ff-a3cd-4957902ed053,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-18826dcd-b53d-4e59-8f60-a9c6bf1cdbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a9291185-9c7d-478f-aa14-7110d38d9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-2d11e767-176c-4558-92ea-9feb495d6cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-f271ad8d-ba94-4c33-bfc7-d2db2570ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-20cde87b-7403-4571-9c5f-6a6ce48c66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-72deb789-310b-49de-9d6b-006bfb50bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-20ce0957-2c7c-44a3-8ace-b0758525cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727697685-172.17.0.2-1597691429481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-558ebaef-d17c-45ff-a3cd-4957902ed053,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-18826dcd-b53d-4e59-8f60-a9c6bf1cdbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a9291185-9c7d-478f-aa14-7110d38d9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-2d11e767-176c-4558-92ea-9feb495d6cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-f271ad8d-ba94-4c33-bfc7-d2db2570ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-20cde87b-7403-4571-9c5f-6a6ce48c66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-72deb789-310b-49de-9d6b-006bfb50bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-20ce0957-2c7c-44a3-8ace-b0758525cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487751853-172.17.0.2-1597692246354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-b8be04f3-fe30-443b-a7dc-c7b587a4f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-60b92c60-b0f6-4aaf-8540-1566477b5334,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ffa7da17-49aa-4c5c-bac5-1b6cccfb09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-3f08c787-7b94-4e12-8427-805089c1d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-d4c05b08-9cd5-4ee8-ad6a-120958321361,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-c8d64dfa-e03b-4bf7-8f24-71d387164a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-8132f1b9-cf4d-4eab-a4f0-a7c3a822a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-bf0621aa-0370-41c9-a29a-adc4790f0206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487751853-172.17.0.2-1597692246354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-b8be04f3-fe30-443b-a7dc-c7b587a4f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-60b92c60-b0f6-4aaf-8540-1566477b5334,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ffa7da17-49aa-4c5c-bac5-1b6cccfb09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-3f08c787-7b94-4e12-8427-805089c1d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-d4c05b08-9cd5-4ee8-ad6a-120958321361,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-c8d64dfa-e03b-4bf7-8f24-71d387164a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-8132f1b9-cf4d-4eab-a4f0-a7c3a822a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-bf0621aa-0370-41c9-a29a-adc4790f0206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272770478-172.17.0.2-1597692624474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-2f2750d9-29b2-4906-ba07-9e290d2138d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-0ca0749d-1dfc-4341-a393-be6fdc55f702,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-cd1b6376-7c3b-4746-903a-af58aa5e47fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-4c0be93b-0972-476e-adc0-3e84f6d0ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-7bbc56ec-61f7-460d-8491-8a1703b6d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f5b37e25-3ce7-4334-88f6-5e01057696f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-f9148d2f-25d7-4802-9128-efaea6651853,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-88470fab-0132-4590-8620-d38402a657e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272770478-172.17.0.2-1597692624474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-2f2750d9-29b2-4906-ba07-9e290d2138d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-0ca0749d-1dfc-4341-a393-be6fdc55f702,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-cd1b6376-7c3b-4746-903a-af58aa5e47fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-4c0be93b-0972-476e-adc0-3e84f6d0ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-7bbc56ec-61f7-460d-8491-8a1703b6d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f5b37e25-3ce7-4334-88f6-5e01057696f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-f9148d2f-25d7-4802-9128-efaea6651853,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-88470fab-0132-4590-8620-d38402a657e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065299315-172.17.0.2-1597692943551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-e60253f7-130f-4d09-9078-edf08b86195a,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-88099670-b7b9-4fea-90ff-cc33bef43b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-525e73b5-e121-41e3-8e20-54191a539361,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f8ec84c3-952a-44da-a911-8d5cf1e86493,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-c35d8601-11de-4444-a7fa-8eacf9df53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-75c8d0f8-93da-488b-a1e7-4c63fbfe703b,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-cc56ebd1-7e4e-4833-a82c-5d13efd5b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-f53c67bb-31a6-42a1-866a-de4fc180b075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065299315-172.17.0.2-1597692943551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-e60253f7-130f-4d09-9078-edf08b86195a,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-88099670-b7b9-4fea-90ff-cc33bef43b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-525e73b5-e121-41e3-8e20-54191a539361,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f8ec84c3-952a-44da-a911-8d5cf1e86493,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-c35d8601-11de-4444-a7fa-8eacf9df53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-75c8d0f8-93da-488b-a1e7-4c63fbfe703b,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-cc56ebd1-7e4e-4833-a82c-5d13efd5b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-f53c67bb-31a6-42a1-866a-de4fc180b075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5264
