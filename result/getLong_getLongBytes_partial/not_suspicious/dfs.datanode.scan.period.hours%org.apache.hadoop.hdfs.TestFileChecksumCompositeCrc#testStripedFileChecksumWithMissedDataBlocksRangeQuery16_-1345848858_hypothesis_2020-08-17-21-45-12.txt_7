reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055887301-172.17.0.16-1597700842812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38464,DS-12de47f0-ae00-4145-95d4-eff2fdaa60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-cae0aa3d-17b4-41b7-b2ef-2115f5768dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-93cadfb2-4637-4ac0-8603-d6fb4e54cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-5a5f5653-3fab-4611-a417-811ce158abbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d37c0149-a0ee-49eb-b4eb-ef93d7251edf,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-73beddf3-7cdd-4c08-872e-b28a4a8cb731,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-86a33d1b-a610-44ff-96d7-0770188b47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-a051f2b5-f4a9-407b-b665-b7ac1200ec91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055887301-172.17.0.16-1597700842812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38464,DS-12de47f0-ae00-4145-95d4-eff2fdaa60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-cae0aa3d-17b4-41b7-b2ef-2115f5768dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-93cadfb2-4637-4ac0-8603-d6fb4e54cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-5a5f5653-3fab-4611-a417-811ce158abbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d37c0149-a0ee-49eb-b4eb-ef93d7251edf,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-73beddf3-7cdd-4c08-872e-b28a4a8cb731,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-86a33d1b-a610-44ff-96d7-0770188b47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-a051f2b5-f4a9-407b-b665-b7ac1200ec91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259604104-172.17.0.16-1597700924566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-2d93baf0-11db-456d-a131-da8d5571b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-07a94ebc-c5b7-4381-9768-282cf17a6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-4ee45168-6aa4-45f9-abc1-7e62acb8bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-145fd3fd-1938-4911-b582-6118d9e30bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-4dbd3837-558d-4786-95cb-c71d3b0ab7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-44fcc59b-4312-473d-9e28-c61121764906,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-95da839a-d6c0-474a-b4a9-2b2f6e869139,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-eaef1caf-8af8-4e47-8bca-ce97f0b7b5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259604104-172.17.0.16-1597700924566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-2d93baf0-11db-456d-a131-da8d5571b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-07a94ebc-c5b7-4381-9768-282cf17a6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-4ee45168-6aa4-45f9-abc1-7e62acb8bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-145fd3fd-1938-4911-b582-6118d9e30bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-4dbd3837-558d-4786-95cb-c71d3b0ab7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-44fcc59b-4312-473d-9e28-c61121764906,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-95da839a-d6c0-474a-b4a9-2b2f6e869139,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-eaef1caf-8af8-4e47-8bca-ce97f0b7b5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936795558-172.17.0.16-1597701203087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46446,DS-97176d51-2dcd-468f-8ddb-944407bccec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-190209ba-f889-4af7-b754-4d095c77b6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-c6d4b05c-93ea-474d-985b-0be07140a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-0e775bdc-c6fc-4636-b815-f95a1b3f4577,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-2c03b473-916a-4a4c-9b3b-eabb36f1557d,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-0db91450-e2f0-4a21-bf93-c304cf0a8009,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-28f1be47-ff93-4563-9c20-1ab505100e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2d70f5ea-8678-4517-81ab-ab300835da95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936795558-172.17.0.16-1597701203087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46446,DS-97176d51-2dcd-468f-8ddb-944407bccec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-190209ba-f889-4af7-b754-4d095c77b6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-c6d4b05c-93ea-474d-985b-0be07140a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-0e775bdc-c6fc-4636-b815-f95a1b3f4577,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-2c03b473-916a-4a4c-9b3b-eabb36f1557d,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-0db91450-e2f0-4a21-bf93-c304cf0a8009,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-28f1be47-ff93-4563-9c20-1ab505100e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2d70f5ea-8678-4517-81ab-ab300835da95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869252469-172.17.0.16-1597701900328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46114,DS-48155e96-e0c8-4b98-b3aa-df6dc31d5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-0dba4a63-3e55-49d4-8195-ae8fa58413e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-4ffbc173-4125-4cef-8058-5f7f858dcb96,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-36c2dd1e-ed90-4879-9793-ca340173bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-3908ce00-f30b-4f61-895c-29cf9c7654f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f23d2b7a-39db-4721-aec0-2fe60d60cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-f05aa1f0-d1c7-4520-83a4-e1f277838c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-8d674b37-b66b-46d1-9533-4504b3b28140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869252469-172.17.0.16-1597701900328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46114,DS-48155e96-e0c8-4b98-b3aa-df6dc31d5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-0dba4a63-3e55-49d4-8195-ae8fa58413e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-4ffbc173-4125-4cef-8058-5f7f858dcb96,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-36c2dd1e-ed90-4879-9793-ca340173bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-3908ce00-f30b-4f61-895c-29cf9c7654f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f23d2b7a-39db-4721-aec0-2fe60d60cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-f05aa1f0-d1c7-4520-83a4-e1f277838c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-8d674b37-b66b-46d1-9533-4504b3b28140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729808281-172.17.0.16-1597702359404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-c1811425-46b1-481a-a107-3340cf82def1,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-8b45d133-adad-47e1-acc2-cb8ad522e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-96f04b32-8d60-48ff-8d00-bc9f59612403,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-7d7b14e5-c87a-4a8b-a6dd-1bb7b937d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-048e74f1-fe5b-478a-b6ba-c64b86975459,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-7429aa07-b4d4-4691-b313-f613e3ec4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-8caeefae-aeb6-4647-926d-71b44c18b056,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-043fa064-3031-4f2d-a0a7-4e5a33193d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729808281-172.17.0.16-1597702359404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-c1811425-46b1-481a-a107-3340cf82def1,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-8b45d133-adad-47e1-acc2-cb8ad522e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-96f04b32-8d60-48ff-8d00-bc9f59612403,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-7d7b14e5-c87a-4a8b-a6dd-1bb7b937d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-048e74f1-fe5b-478a-b6ba-c64b86975459,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-7429aa07-b4d4-4691-b313-f613e3ec4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-8caeefae-aeb6-4647-926d-71b44c18b056,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-043fa064-3031-4f2d-a0a7-4e5a33193d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962073453-172.17.0.16-1597702867448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-40623d12-daeb-4578-8a17-826ab16d4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-07f3d627-337b-4bb6-a1a3-690e16a24d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-97fa0f8b-6554-4239-acac-969b43db014f,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-846f8c5e-7c36-4fb3-b861-672ba5db6396,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-585ae1d7-b95f-4f07-8c52-824173f307db,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-9544f0c2-af67-4010-ace9-65a5fd781835,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-686ff9b4-8c60-4dff-9663-2f7037eddf78,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-9790ca3d-f3cf-4ee4-84b7-dd408d1c0ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962073453-172.17.0.16-1597702867448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-40623d12-daeb-4578-8a17-826ab16d4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-07f3d627-337b-4bb6-a1a3-690e16a24d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-97fa0f8b-6554-4239-acac-969b43db014f,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-846f8c5e-7c36-4fb3-b861-672ba5db6396,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-585ae1d7-b95f-4f07-8c52-824173f307db,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-9544f0c2-af67-4010-ace9-65a5fd781835,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-686ff9b4-8c60-4dff-9663-2f7037eddf78,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-9790ca3d-f3cf-4ee4-84b7-dd408d1c0ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195497475-172.17.0.16-1597702896112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-608a873d-a619-4e2e-b01c-f76ef80ec868,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-1c23d3bd-f439-456a-8ebd-0eb8c5b99248,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6d87bed0-0c30-421e-9253-454a03220241,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-d2e64959-b64d-463b-89a4-49c5ad70f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-daa84a6b-2c5d-41d3-8d74-79284824c971,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-2d029e0a-1f34-4f4c-a47f-8215421117b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-b77916cd-43a5-46de-bde3-fd9a758c9944,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-e0d596bb-3392-4325-9c43-e42002421578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195497475-172.17.0.16-1597702896112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-608a873d-a619-4e2e-b01c-f76ef80ec868,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-1c23d3bd-f439-456a-8ebd-0eb8c5b99248,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6d87bed0-0c30-421e-9253-454a03220241,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-d2e64959-b64d-463b-89a4-49c5ad70f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-daa84a6b-2c5d-41d3-8d74-79284824c971,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-2d029e0a-1f34-4f4c-a47f-8215421117b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-b77916cd-43a5-46de-bde3-fd9a758c9944,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-e0d596bb-3392-4325-9c43-e42002421578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958192657-172.17.0.16-1597703621393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-096c8879-9267-449a-9190-cf6a149558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-a442acb7-5e6e-47a7-9d3b-33f9e02233f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a76f2a7f-fcf4-468f-8156-0e80d5da07ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-4940c8ec-b7a7-4380-9fd9-7ca33eb67a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-58921d5b-631a-4373-a47b-029149af42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-fa1c2f6a-5e26-4f16-b076-347cabda8eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-6f062b27-f6ed-46e2-a2db-40ac2090ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-63d391c2-3b0a-47b6-a271-82da2d84cf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958192657-172.17.0.16-1597703621393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-096c8879-9267-449a-9190-cf6a149558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-a442acb7-5e6e-47a7-9d3b-33f9e02233f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a76f2a7f-fcf4-468f-8156-0e80d5da07ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-4940c8ec-b7a7-4380-9fd9-7ca33eb67a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-58921d5b-631a-4373-a47b-029149af42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-fa1c2f6a-5e26-4f16-b076-347cabda8eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-6f062b27-f6ed-46e2-a2db-40ac2090ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-63d391c2-3b0a-47b6-a271-82da2d84cf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548357946-172.17.0.16-1597703805259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-549eaffb-3573-461d-a0ee-c99edd911132,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9039161e-2a92-49db-aa0d-160a9cb6605e,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-26b0b7e8-e07e-4949-a5a3-127e19ba5bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-2f792cc1-56e4-4d09-83cd-a502187b3885,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-810f9f59-f127-4afa-bf1f-bd4843c4ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-e6aceaf1-5f6c-418f-aa16-dc18953185cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-c4e2cbc7-f0cb-4428-9cc5-8a792086f264,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-bbcf3d7f-624e-4801-a66b-a607ba520994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548357946-172.17.0.16-1597703805259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-549eaffb-3573-461d-a0ee-c99edd911132,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9039161e-2a92-49db-aa0d-160a9cb6605e,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-26b0b7e8-e07e-4949-a5a3-127e19ba5bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-2f792cc1-56e4-4d09-83cd-a502187b3885,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-810f9f59-f127-4afa-bf1f-bd4843c4ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-e6aceaf1-5f6c-418f-aa16-dc18953185cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-c4e2cbc7-f0cb-4428-9cc5-8a792086f264,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-bbcf3d7f-624e-4801-a66b-a607ba520994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074585583-172.17.0.16-1597703873091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-76f3eca9-cf24-4a16-b876-759f75a84a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-3ebeccb7-a4f5-4af2-890f-49c30fea0592,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6c7061d5-c490-4337-8c80-91321439a637,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-a6f3b591-953c-42c8-bdfe-77357264363a,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-a4bef28c-0355-430c-958b-db08da3003fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-832a3cbd-25d8-4a30-ba2a-a73cc488c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-ca694696-2e61-4a9d-b339-07d70efe78e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d300c6ba-f49d-45da-b860-18ac13c9a406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074585583-172.17.0.16-1597703873091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-76f3eca9-cf24-4a16-b876-759f75a84a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-3ebeccb7-a4f5-4af2-890f-49c30fea0592,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6c7061d5-c490-4337-8c80-91321439a637,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-a6f3b591-953c-42c8-bdfe-77357264363a,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-a4bef28c-0355-430c-958b-db08da3003fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-832a3cbd-25d8-4a30-ba2a-a73cc488c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-ca694696-2e61-4a9d-b339-07d70efe78e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d300c6ba-f49d-45da-b860-18ac13c9a406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443341024-172.17.0.16-1597704202060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-e9cddb1e-a1ed-4bae-9cb4-a66cf5fb1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-09d367ec-e3dc-4a37-ac0b-db3018c87b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-08bf7c0e-fb3a-45a7-a25b-5c339a881fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-17c7d40a-097a-476e-a27a-7c2d16baf065,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-43549948-3d89-4093-b7ea-d4af78b43d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-e26977f5-ef06-4aad-ae5a-e091bc715ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-d04bb365-7f34-43c5-81af-7484a03f4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-8e917561-689d-4091-a94f-e888e1e042fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443341024-172.17.0.16-1597704202060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-e9cddb1e-a1ed-4bae-9cb4-a66cf5fb1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-09d367ec-e3dc-4a37-ac0b-db3018c87b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-08bf7c0e-fb3a-45a7-a25b-5c339a881fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-17c7d40a-097a-476e-a27a-7c2d16baf065,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-43549948-3d89-4093-b7ea-d4af78b43d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-e26977f5-ef06-4aad-ae5a-e091bc715ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-d04bb365-7f34-43c5-81af-7484a03f4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-8e917561-689d-4091-a94f-e888e1e042fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726731438-172.17.0.16-1597704689820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-aa257206-d44e-4d3e-a58e-d3ebc1e2ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-132876a5-50a9-4d0b-9e7d-a41dee5e91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-b98aad2e-262b-4666-81d5-32e12626de80,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-9dff01e3-632b-4bf0-a2b9-2d851e581a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-4af59b8b-ff6e-4bfc-94a0-5b312705afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-b2bbde14-9ee5-482b-9937-468b655cf110,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-6ab19e87-d8c8-43d2-ac6d-6a44be085557,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e26120d0-1afe-48cb-aa5e-2a3b3c06ec39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726731438-172.17.0.16-1597704689820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-aa257206-d44e-4d3e-a58e-d3ebc1e2ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-132876a5-50a9-4d0b-9e7d-a41dee5e91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-b98aad2e-262b-4666-81d5-32e12626de80,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-9dff01e3-632b-4bf0-a2b9-2d851e581a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-4af59b8b-ff6e-4bfc-94a0-5b312705afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-b2bbde14-9ee5-482b-9937-468b655cf110,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-6ab19e87-d8c8-43d2-ac6d-6a44be085557,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e26120d0-1afe-48cb-aa5e-2a3b3c06ec39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079443302-172.17.0.16-1597704721873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-1ac26dac-2b43-4ce0-97bd-ad7fa9a8d8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-36e1442a-1f51-41a3-a870-095a1ba73419,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-21eb6a2e-2bb4-483c-bcfa-e5c4284a90ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-9f91e7ed-96b8-4e52-9003-86705af6d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-9ae39b61-7dd2-4f54-9c2e-1ca934efbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-e0dffcec-b78c-40fb-85b8-3f6318cd565e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-fd51d2c0-2c45-4ea0-b04e-a2921051b5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-711a0557-5d8f-4135-a51f-f0a33ec72201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079443302-172.17.0.16-1597704721873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-1ac26dac-2b43-4ce0-97bd-ad7fa9a8d8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-36e1442a-1f51-41a3-a870-095a1ba73419,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-21eb6a2e-2bb4-483c-bcfa-e5c4284a90ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-9f91e7ed-96b8-4e52-9003-86705af6d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-9ae39b61-7dd2-4f54-9c2e-1ca934efbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-e0dffcec-b78c-40fb-85b8-3f6318cd565e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-fd51d2c0-2c45-4ea0-b04e-a2921051b5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-711a0557-5d8f-4135-a51f-f0a33ec72201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555357624-172.17.0.16-1597704831712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-e675688b-b866-4fc1-ab2a-0cfef7d7e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-1d066dfb-9143-4108-82e3-14339f9156c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-d57d02cc-36e0-46bd-b4fb-044fc27f862b,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e6538523-4c3c-4799-bd4f-dc91ad40757b,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c3b60cff-8d5c-4f93-9ecd-876478f924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-613ba9fc-e0d5-4c81-b8bf-cae246774562,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-bb4a28a6-9887-42a3-9604-9aa836fa5328,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-277d1432-ae2a-4b9c-a94a-dc874930f56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555357624-172.17.0.16-1597704831712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-e675688b-b866-4fc1-ab2a-0cfef7d7e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-1d066dfb-9143-4108-82e3-14339f9156c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-d57d02cc-36e0-46bd-b4fb-044fc27f862b,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e6538523-4c3c-4799-bd4f-dc91ad40757b,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c3b60cff-8d5c-4f93-9ecd-876478f924b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-613ba9fc-e0d5-4c81-b8bf-cae246774562,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-bb4a28a6-9887-42a3-9604-9aa836fa5328,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-277d1432-ae2a-4b9c-a94a-dc874930f56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003022995-172.17.0.16-1597705218314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41138,DS-b733ed49-6a2c-4081-8cdb-ac91d27c1886,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f10fd950-ecd1-4e70-8423-f3aee73a5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c9509d35-05f7-4ddf-bbe0-1b8fcc74a611,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-071e5b36-8919-4988-8581-704ee95226e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-0313aa66-b8eb-4bc4-b9d3-d1668c6ecc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f9b293c2-8362-4613-b182-e892c024ea20,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3ea1bbb2-8e64-4786-acf3-487aae144a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-02d3b7fd-19d6-4d5f-8868-1e8e53a2c3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003022995-172.17.0.16-1597705218314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41138,DS-b733ed49-6a2c-4081-8cdb-ac91d27c1886,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f10fd950-ecd1-4e70-8423-f3aee73a5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c9509d35-05f7-4ddf-bbe0-1b8fcc74a611,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-071e5b36-8919-4988-8581-704ee95226e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-0313aa66-b8eb-4bc4-b9d3-d1668c6ecc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f9b293c2-8362-4613-b182-e892c024ea20,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3ea1bbb2-8e64-4786-acf3-487aae144a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-02d3b7fd-19d6-4d5f-8868-1e8e53a2c3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362800887-172.17.0.16-1597705441212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-409d4fa3-e1cc-4a0a-801a-29f93a41c647,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-26f5c614-34fa-4a7d-be53-d4699253a1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-994cb29d-715b-417e-ba8b-b27d58f5b415,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-5cd6176a-7307-4470-bc64-4876af2efd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-7b5a96cc-11b2-49c8-b0a6-f0f73cc165d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b0e7efde-b780-4b19-ad44-1567bf663fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-90e0054b-452a-4db8-a8b7-65b09d02319e,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-8aa2046f-09f6-4546-8219-42dea16b4aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362800887-172.17.0.16-1597705441212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-409d4fa3-e1cc-4a0a-801a-29f93a41c647,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-26f5c614-34fa-4a7d-be53-d4699253a1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-994cb29d-715b-417e-ba8b-b27d58f5b415,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-5cd6176a-7307-4470-bc64-4876af2efd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-7b5a96cc-11b2-49c8-b0a6-f0f73cc165d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b0e7efde-b780-4b19-ad44-1567bf663fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-90e0054b-452a-4db8-a8b7-65b09d02319e,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-8aa2046f-09f6-4546-8219-42dea16b4aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141441047-172.17.0.16-1597705797717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-d7115de0-eeea-4aa2-a970-958738172939,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-3ab07a33-71ef-461f-8329-83819f2221cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-53263e3d-938a-4973-9ffd-d91877860bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-77ea89c4-3b2b-4f94-a428-bb00735c82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-3967a95c-e3b4-4a6f-bda0-2bcbea0660a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-412043cc-58b4-41fd-b083-1437eb6f16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-c8b51285-017c-4758-8c77-7f91b7fee910,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-66125d0b-bdaa-48e6-89f5-220dc36175e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141441047-172.17.0.16-1597705797717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-d7115de0-eeea-4aa2-a970-958738172939,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-3ab07a33-71ef-461f-8329-83819f2221cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-53263e3d-938a-4973-9ffd-d91877860bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-77ea89c4-3b2b-4f94-a428-bb00735c82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-3967a95c-e3b4-4a6f-bda0-2bcbea0660a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-412043cc-58b4-41fd-b083-1437eb6f16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-c8b51285-017c-4758-8c77-7f91b7fee910,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-66125d0b-bdaa-48e6-89f5-220dc36175e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136813204-172.17.0.16-1597705902821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-804f1d0e-dc50-4e2c-88a4-d3727b668955,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-ac44e3a8-5256-42fd-afe6-b17d35926e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-8127e3c2-982e-4b9f-854d-7091f9d29b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-a2a5a820-e81a-4016-95ea-f92033738d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-13912e6e-90f3-487d-9e9a-0406be2fb823,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-c275600d-9cca-4d6d-8bc4-be94e8c518d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-a769790c-f5bb-47b6-ab47-1d3e8e3d3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a6c207e0-bd03-4bb5-b517-19071d5beac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136813204-172.17.0.16-1597705902821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-804f1d0e-dc50-4e2c-88a4-d3727b668955,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-ac44e3a8-5256-42fd-afe6-b17d35926e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-8127e3c2-982e-4b9f-854d-7091f9d29b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-a2a5a820-e81a-4016-95ea-f92033738d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-13912e6e-90f3-487d-9e9a-0406be2fb823,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-c275600d-9cca-4d6d-8bc4-be94e8c518d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-a769790c-f5bb-47b6-ab47-1d3e8e3d3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a6c207e0-bd03-4bb5-b517-19071d5beac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5390
