reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952315979-172.17.0.12-1597682511566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-c29e6cf0-9b8f-45dd-853d-0b721aa76f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-c38797eb-3467-4c27-8615-082b0ac8e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b0fdd684-de98-4cb0-86a0-1d552f159128,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-de8b19e3-84e0-4cbf-8005-cf69dadcb014,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-f91ee7b7-d2d3-4347-a31e-e640903191c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-03706877-eed1-4f2b-b6de-cc47f96fcf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-12c4f9eb-b678-4120-b0fa-4d935e0b4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c0508c07-63cf-40c3-a75a-6c8cb925cb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952315979-172.17.0.12-1597682511566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-c29e6cf0-9b8f-45dd-853d-0b721aa76f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-c38797eb-3467-4c27-8615-082b0ac8e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b0fdd684-de98-4cb0-86a0-1d552f159128,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-de8b19e3-84e0-4cbf-8005-cf69dadcb014,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-f91ee7b7-d2d3-4347-a31e-e640903191c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-03706877-eed1-4f2b-b6de-cc47f96fcf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-12c4f9eb-b678-4120-b0fa-4d935e0b4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c0508c07-63cf-40c3-a75a-6c8cb925cb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187408541-172.17.0.12-1597682652060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-683bc077-56d3-478d-a6f2-9846d9a6f7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-664b259e-8f14-4eaf-a146-2eb7e103032d,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-02e99e3c-4f7e-47fa-9ba6-5cedc645874f,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-6dd99997-fb7d-4cbf-9711-80051f2c0383,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-bfc24b3f-60ef-40b8-a640-54b8cbb2e149,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-ce15866c-900a-47b3-8b70-a4a533afff30,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-c47475d4-2fb1-421c-90d3-ec954e359023,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-88944a7e-0fd2-4294-9db0-1ccd3f92a2df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187408541-172.17.0.12-1597682652060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-683bc077-56d3-478d-a6f2-9846d9a6f7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-664b259e-8f14-4eaf-a146-2eb7e103032d,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-02e99e3c-4f7e-47fa-9ba6-5cedc645874f,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-6dd99997-fb7d-4cbf-9711-80051f2c0383,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-bfc24b3f-60ef-40b8-a640-54b8cbb2e149,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-ce15866c-900a-47b3-8b70-a4a533afff30,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-c47475d4-2fb1-421c-90d3-ec954e359023,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-88944a7e-0fd2-4294-9db0-1ccd3f92a2df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931792785-172.17.0.12-1597683288213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-adad7959-e2f4-4c23-a7c0-926257896df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-c8a08720-bbdf-46f1-8bb1-587729b15c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-830ef7a2-1735-473d-9d90-541cbe2b2327,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-f85f3e90-dfa7-4091-ab64-5c08a7340439,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-25c804d3-c858-48e8-8287-b7a49d793fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-08dc8fcb-585d-4dd6-a497-40e74327dc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-eead5789-37eb-44fd-be57-57cd66e08a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-54670163-d736-4664-9416-d2158753754e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931792785-172.17.0.12-1597683288213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-adad7959-e2f4-4c23-a7c0-926257896df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-c8a08720-bbdf-46f1-8bb1-587729b15c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-830ef7a2-1735-473d-9d90-541cbe2b2327,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-f85f3e90-dfa7-4091-ab64-5c08a7340439,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-25c804d3-c858-48e8-8287-b7a49d793fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-08dc8fcb-585d-4dd6-a497-40e74327dc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-eead5789-37eb-44fd-be57-57cd66e08a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-54670163-d736-4664-9416-d2158753754e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145740693-172.17.0.12-1597684075867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38206,DS-1e3b7388-37dc-4d9c-9aa8-019147694b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-952eec51-bc56-4aba-af94-fa4ba7d6a744,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-b32e4411-3b1b-4f33-8e29-9a58fd65f0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-5ba04d96-5c92-4323-81ab-00c91c603d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-067faa24-5d8b-421c-a3ed-f207dda6246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-adc8b347-9bbe-4835-8545-47c36dbd1790,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-ee4bda1c-83d0-42ff-9531-6f382a39593c,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-6afc6c80-7b8e-42cc-a89f-3116d2f683bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145740693-172.17.0.12-1597684075867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38206,DS-1e3b7388-37dc-4d9c-9aa8-019147694b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-952eec51-bc56-4aba-af94-fa4ba7d6a744,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-b32e4411-3b1b-4f33-8e29-9a58fd65f0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-5ba04d96-5c92-4323-81ab-00c91c603d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-067faa24-5d8b-421c-a3ed-f207dda6246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-adc8b347-9bbe-4835-8545-47c36dbd1790,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-ee4bda1c-83d0-42ff-9531-6f382a39593c,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-6afc6c80-7b8e-42cc-a89f-3116d2f683bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22559294-172.17.0.12-1597684116451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-91cb2758-d08a-4608-ba72-b1f45d147871,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-6bf36b49-959b-411e-b399-00e59bd5b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-ecd64296-9f30-4799-8455-3cb91741d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-4d1c49bc-5cc3-4915-b45a-da46cd877df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-038ece3b-d34b-44e5-a6ba-39f4b51bfccd,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-ae36ff5e-e85b-465b-a919-67af10aeb7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9fe4422a-e894-4bef-b944-24902e5ff9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-fb2a52a5-fd06-450c-98a1-7b07969ba3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22559294-172.17.0.12-1597684116451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-91cb2758-d08a-4608-ba72-b1f45d147871,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-6bf36b49-959b-411e-b399-00e59bd5b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-ecd64296-9f30-4799-8455-3cb91741d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-4d1c49bc-5cc3-4915-b45a-da46cd877df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-038ece3b-d34b-44e5-a6ba-39f4b51bfccd,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-ae36ff5e-e85b-465b-a919-67af10aeb7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9fe4422a-e894-4bef-b944-24902e5ff9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-fb2a52a5-fd06-450c-98a1-7b07969ba3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411920627-172.17.0.12-1597684536664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-5138dcbc-e99b-4569-8325-58aaa80b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-2eaac809-7bda-440c-b472-2900d640faaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-f61f5d48-8c6f-49cc-a659-c0d448194041,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-977771e1-675f-42c3-8b52-9425c7c1037f,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-b551cae8-d28d-4000-a8e7-da50615b4f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e7ce16ca-25e1-47a8-a84a-040010c8bf42,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-eb226dc9-0983-4966-952f-e6f68c1e4895,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bd07f0f3-b157-41c2-a6c0-264546befe0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411920627-172.17.0.12-1597684536664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-5138dcbc-e99b-4569-8325-58aaa80b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-2eaac809-7bda-440c-b472-2900d640faaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-f61f5d48-8c6f-49cc-a659-c0d448194041,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-977771e1-675f-42c3-8b52-9425c7c1037f,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-b551cae8-d28d-4000-a8e7-da50615b4f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e7ce16ca-25e1-47a8-a84a-040010c8bf42,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-eb226dc9-0983-4966-952f-e6f68c1e4895,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bd07f0f3-b157-41c2-a6c0-264546befe0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053198390-172.17.0.12-1597685682566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46406,DS-d55e300c-3210-4a4d-8671-ba76b9e8153e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-1c008cab-93fa-4353-a672-834be30a912c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-d22325f9-461d-4fbb-9a9d-3ea66d96db91,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-3accfcfa-52be-4f32-a880-8ed3678b68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c0754cc1-7cbd-4ecc-b2dc-753242c01d32,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-f106060f-8af7-4a92-ab79-9a096ccb01c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-11bb2bad-ddbf-4905-89cf-3bed759521e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-f870e008-4af8-465d-a046-7f9fb4afa295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053198390-172.17.0.12-1597685682566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46406,DS-d55e300c-3210-4a4d-8671-ba76b9e8153e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-1c008cab-93fa-4353-a672-834be30a912c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-d22325f9-461d-4fbb-9a9d-3ea66d96db91,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-3accfcfa-52be-4f32-a880-8ed3678b68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c0754cc1-7cbd-4ecc-b2dc-753242c01d32,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-f106060f-8af7-4a92-ab79-9a096ccb01c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-11bb2bad-ddbf-4905-89cf-3bed759521e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-f870e008-4af8-465d-a046-7f9fb4afa295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905757857-172.17.0.12-1597686123012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-c4e030a2-eb24-4ee2-84a1-d56c3d5a60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e6c0d1c4-4828-4c1f-86f0-15726c2d1123,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-92e45e40-5112-4b95-b3dd-177f30307fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2117a4b3-4b80-4500-8719-508e73eeb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-2deab78e-cf7f-4cee-bdf6-7292785c1a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-296b9f60-b45d-45c1-be25-abb187c2a957,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-d3ccfe12-4044-469d-9b1b-8477ed0bccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-4d929711-33db-4b1a-a8bc-8cd4cbb29f18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905757857-172.17.0.12-1597686123012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-c4e030a2-eb24-4ee2-84a1-d56c3d5a60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e6c0d1c4-4828-4c1f-86f0-15726c2d1123,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-92e45e40-5112-4b95-b3dd-177f30307fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2117a4b3-4b80-4500-8719-508e73eeb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-2deab78e-cf7f-4cee-bdf6-7292785c1a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-296b9f60-b45d-45c1-be25-abb187c2a957,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-d3ccfe12-4044-469d-9b1b-8477ed0bccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-4d929711-33db-4b1a-a8bc-8cd4cbb29f18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977144241-172.17.0.12-1597686264653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-950aca1c-98f7-4b3d-977b-9a8cb9a76a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-93c7df8e-a4d8-483c-bd0e-c5ec8b6026b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-3c9221d1-4209-46f1-a107-9858e68406c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-e1de735d-0406-4555-a5a6-c34cfd60b531,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-0e0da94f-afb6-4389-9a43-c27991b1a529,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-65edede8-935b-4a56-9290-2e17774f00db,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d0c405da-417c-40ef-9e7f-436ee5c38a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-e510ae1c-6914-4c7f-8132-512dafd7cc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977144241-172.17.0.12-1597686264653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-950aca1c-98f7-4b3d-977b-9a8cb9a76a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-93c7df8e-a4d8-483c-bd0e-c5ec8b6026b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-3c9221d1-4209-46f1-a107-9858e68406c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-e1de735d-0406-4555-a5a6-c34cfd60b531,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-0e0da94f-afb6-4389-9a43-c27991b1a529,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-65edede8-935b-4a56-9290-2e17774f00db,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d0c405da-417c-40ef-9e7f-436ee5c38a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-e510ae1c-6914-4c7f-8132-512dafd7cc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619843986-172.17.0.12-1597686357749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-9822fa28-07a3-43a6-b636-778e37b4bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-8207216f-56c8-4663-aa17-6e8e480783c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-776ad0c7-53a8-4170-b9f3-c2beae12f989,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-cba3c97c-b1f3-4e97-9fa3-f0e9965944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-7694eb83-f1df-4a9e-8e7e-bf07776714a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-42cb7bfa-5fd5-4566-91e7-58afa0f354f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-46c1d107-6080-4a60-a8ad-55360f19833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-d1910118-4ee8-4ade-81d6-dc9fb66ef6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619843986-172.17.0.12-1597686357749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-9822fa28-07a3-43a6-b636-778e37b4bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-8207216f-56c8-4663-aa17-6e8e480783c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-776ad0c7-53a8-4170-b9f3-c2beae12f989,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-cba3c97c-b1f3-4e97-9fa3-f0e9965944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-7694eb83-f1df-4a9e-8e7e-bf07776714a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-42cb7bfa-5fd5-4566-91e7-58afa0f354f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-46c1d107-6080-4a60-a8ad-55360f19833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-d1910118-4ee8-4ade-81d6-dc9fb66ef6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579964413-172.17.0.12-1597686643977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-ed459dcd-8938-4148-bff0-73a79f1cc68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-c1da9a66-4f52-4d33-9506-144f4685ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-76d8790b-913b-46b0-aebb-28cf2f885ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-95a4b212-3f12-44bf-ae4d-3410a1ea312f,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a92cb465-a68e-4699-82a3-16c9c2305872,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-95e329cd-60a1-488a-918d-a370fd63b616,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-1a659ea2-588a-4cd2-8693-aad6ce01d701,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-18c5fae6-4ffd-41aa-b675-884d43dabef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579964413-172.17.0.12-1597686643977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-ed459dcd-8938-4148-bff0-73a79f1cc68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-c1da9a66-4f52-4d33-9506-144f4685ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-76d8790b-913b-46b0-aebb-28cf2f885ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-95a4b212-3f12-44bf-ae4d-3410a1ea312f,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a92cb465-a68e-4699-82a3-16c9c2305872,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-95e329cd-60a1-488a-918d-a370fd63b616,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-1a659ea2-588a-4cd2-8693-aad6ce01d701,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-18c5fae6-4ffd-41aa-b675-884d43dabef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342957070-172.17.0.12-1597687468929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42827,DS-00f284b9-c6f1-4987-af15-07fb09e83753,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-7a906027-3aca-4ee7-a611-ecb2db9499b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4abc764d-126d-4c97-a461-67488564b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c62ffa16-536a-46e4-b837-5675225cc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-3a69db42-b75f-44af-ad99-3249e114c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-29d2170f-a909-441f-a266-2c32526e2229,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-df487816-a613-4b95-bd9b-46003fc5f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-763014a3-0c13-415e-a501-7d6749e795cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342957070-172.17.0.12-1597687468929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42827,DS-00f284b9-c6f1-4987-af15-07fb09e83753,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-7a906027-3aca-4ee7-a611-ecb2db9499b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4abc764d-126d-4c97-a461-67488564b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c62ffa16-536a-46e4-b837-5675225cc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-3a69db42-b75f-44af-ad99-3249e114c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-29d2170f-a909-441f-a266-2c32526e2229,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-df487816-a613-4b95-bd9b-46003fc5f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-763014a3-0c13-415e-a501-7d6749e795cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7060
