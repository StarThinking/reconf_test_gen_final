reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=2, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-2139920362-172.17.0.11-1597426986592:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-599706da-715a-4a9b-a033-08b2d2074a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-42f054e5-ed75-408b-95d2-380b6c852629,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-59ba8638-72cf-420f-ad6e-0fae1f2d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-76c1570b-f0a0-403f-aa4b-c3f1b2b8c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b5321322-79c1-476e-9ba7-4d5e251fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4139e1c0-757b-47a5-8d0f-a0fc46efec38,DISK]]; indices=[0, 1, 2, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-2139920362-172.17.0.11-1597426986592:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-599706da-715a-4a9b-a033-08b2d2074a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-42f054e5-ed75-408b-95d2-380b6c852629,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-59ba8638-72cf-420f-ad6e-0fae1f2d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-76c1570b-f0a0-403f-aa4b-c3f1b2b8c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b5321322-79c1-476e-9ba7-4d5e251fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4139e1c0-757b-47a5-8d0f-a0fc46efec38,DISK]]; indices=[0, 1, 2, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=2, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-2139920362-172.17.0.11-1597426986592:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-599706da-715a-4a9b-a033-08b2d2074a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-42f054e5-ed75-408b-95d2-380b6c852629,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-59ba8638-72cf-420f-ad6e-0fae1f2d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-76c1570b-f0a0-403f-aa4b-c3f1b2b8c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b5321322-79c1-476e-9ba7-4d5e251fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4139e1c0-757b-47a5-8d0f-a0fc46efec38,DISK]]; indices=[0, 1, 2, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-2139920362-172.17.0.11-1597426986592:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-599706da-715a-4a9b-a033-08b2d2074a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-42f054e5-ed75-408b-95d2-380b6c852629,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-59ba8638-72cf-420f-ad6e-0fae1f2d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-76c1570b-f0a0-403f-aa4b-c3f1b2b8c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-b5321322-79c1-476e-9ba7-4d5e251fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4139e1c0-757b-47a5-8d0f-a0fc46efec38,DISK]]; indices=[0, 1, 2, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:375)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
reconfPoint: -1
result: -1
failureMessage: No enough valid inputs are provided, not recoverable
stackTrace: org.apache.hadoop.HadoopIllegalArgumentException: No enough valid inputs are provided, not recoverable
	at org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState.checkInputBuffers(ByteBufferDecodingState.java:119)
	at org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState.<init>(ByteBufferDecodingState.java:47)
	at org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder.decode(RawErasureDecoder.java:86)
	at org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder.decode(RawErasureDecoder.java:170)
	at org.apache.hadoop.hdfs.StripeReader.decodeAndFillBuffer(StripeReader.java:433)
	at org.apache.hadoop.hdfs.StatefulStripeReader.decode(StatefulStripeReader.java:94)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:390)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyStatefulRead(StripedFileTestUtil.java:126)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:141)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1321342955-172.17.0.11-1597428825638:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0136361f-ab19-4480-8a1a-b55c81cb47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-dc0cec98-857b-43ec-aacd-9b9007473aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-1fe16111-528e-4843-abfb-63281a252abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3dfdccc1-58e8-4dcf-8a95-f7200103b060,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-c7eb96fb-c4ab-4adc-8ed6-2dff83a833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-74df9a99-d1cf-436a-b0a8-b006d12057c2,DISK]]; indices=[0, 1, 2, 3, 4, 6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1321342955-172.17.0.11-1597428825638:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0136361f-ab19-4480-8a1a-b55c81cb47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-dc0cec98-857b-43ec-aacd-9b9007473aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-1fe16111-528e-4843-abfb-63281a252abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3dfdccc1-58e8-4dcf-8a95-f7200103b060,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-c7eb96fb-c4ab-4adc-8ed6-2dff83a833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-74df9a99-d1cf-436a-b0a8-b006d12057c2,DISK]]; indices=[0, 1, 2, 3, 4, 6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1321342955-172.17.0.11-1597428825638:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0136361f-ab19-4480-8a1a-b55c81cb47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-dc0cec98-857b-43ec-aacd-9b9007473aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-1fe16111-528e-4843-abfb-63281a252abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3dfdccc1-58e8-4dcf-8a95-f7200103b060,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-c7eb96fb-c4ab-4adc-8ed6-2dff83a833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-74df9a99-d1cf-436a-b0a8-b006d12057c2,DISK]]; indices=[0, 1, 2, 3, 4, 6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1321342955-172.17.0.11-1597428825638:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0136361f-ab19-4480-8a1a-b55c81cb47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-dc0cec98-857b-43ec-aacd-9b9007473aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-1fe16111-528e-4843-abfb-63281a252abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3dfdccc1-58e8-4dcf-8a95-f7200103b060,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-c7eb96fb-c4ab-4adc-8ed6-2dff83a833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-74df9a99-d1cf-436a-b0a8-b006d12057c2,DISK]]; indices=[0, 1, 2, 3, 4, 6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:378)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 1 out of 50
result: might be true error
Total execution time in seconds : 7364
