reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510128851-172.17.0.2-1597288120010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37360,DS-3de515b9-0dc4-477b-931b-eb0f8b4096c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-0ad285f0-f744-4744-847f-1a88e24b8f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8a971c28-2d5c-4794-9cfb-7a47b305d647,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3fc20a36-6cd1-4c87-83a9-5c102867f302,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f6572f38-0025-46a3-9805-05c26b935845,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-6bfccd25-127f-4690-8830-dec6e10e3792,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-2e046c6c-e7ea-46b5-b799-c169559a47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-333e7c62-8151-4426-b2b5-be8ec2aeecb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510128851-172.17.0.2-1597288120010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37360,DS-3de515b9-0dc4-477b-931b-eb0f8b4096c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-0ad285f0-f744-4744-847f-1a88e24b8f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8a971c28-2d5c-4794-9cfb-7a47b305d647,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3fc20a36-6cd1-4c87-83a9-5c102867f302,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f6572f38-0025-46a3-9805-05c26b935845,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-6bfccd25-127f-4690-8830-dec6e10e3792,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-2e046c6c-e7ea-46b5-b799-c169559a47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-333e7c62-8151-4426-b2b5-be8ec2aeecb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127995595-172.17.0.2-1597288402230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34571,DS-5b2552cf-c3c8-4f20-aea8-418be1cc04e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-9b739cc7-7347-409f-a191-c7622b1f259a,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7c99a958-3cc2-46ad-a5ca-e66c7e9318f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-aabb96a2-83b7-46b8-be18-e997ed235cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-a76cb00f-b329-47fe-b020-a618784f3002,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-2140614c-7ca0-464c-b9cd-5e91c7922aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ef799950-67de-4635-9335-db61dfc7fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-885de0e9-f3d8-4f98-a415-4b628ca8bc85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127995595-172.17.0.2-1597288402230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34571,DS-5b2552cf-c3c8-4f20-aea8-418be1cc04e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-9b739cc7-7347-409f-a191-c7622b1f259a,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7c99a958-3cc2-46ad-a5ca-e66c7e9318f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-aabb96a2-83b7-46b8-be18-e997ed235cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-a76cb00f-b329-47fe-b020-a618784f3002,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-2140614c-7ca0-464c-b9cd-5e91c7922aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ef799950-67de-4635-9335-db61dfc7fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-885de0e9-f3d8-4f98-a415-4b628ca8bc85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187218661-172.17.0.2-1597288690134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-2f1c1021-509e-48ac-97a0-2a298a8f5374,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-69890e68-d894-4390-ba3a-6a74a05a4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-179c3572-8d76-4d46-9f44-13453d50da88,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-473f6cba-82cf-450e-adeb-cd8199804333,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-2d13e55f-152e-4e7d-935f-e6181a00648c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9dcaf54b-6190-4530-b58b-8054689df470,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-489a3123-7a49-4012-81a7-57cab3a690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-77f68e2c-b550-4cb6-975f-c8acd8b4c790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187218661-172.17.0.2-1597288690134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-2f1c1021-509e-48ac-97a0-2a298a8f5374,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-69890e68-d894-4390-ba3a-6a74a05a4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-179c3572-8d76-4d46-9f44-13453d50da88,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-473f6cba-82cf-450e-adeb-cd8199804333,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-2d13e55f-152e-4e7d-935f-e6181a00648c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9dcaf54b-6190-4530-b58b-8054689df470,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-489a3123-7a49-4012-81a7-57cab3a690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-77f68e2c-b550-4cb6-975f-c8acd8b4c790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450961759-172.17.0.2-1597289361355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-14ca59f5-f9fe-4b12-b9e7-bbfd654741aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-ac8f2d4c-6678-4625-aa19-1a3c48dac5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-771c9243-ba64-4da8-b77d-ade900f58105,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-80589824-76fa-47a0-a67d-34017a062a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-73c0515a-5bcb-4ab0-b59e-b0ff679e06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-0f2baf3d-0988-458a-9a4a-9be3f0b653e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f3a9892d-061d-4ee8-bfb5-e54e73af1959,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-39501fd6-8b90-4789-ad07-7bb344422abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450961759-172.17.0.2-1597289361355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-14ca59f5-f9fe-4b12-b9e7-bbfd654741aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-ac8f2d4c-6678-4625-aa19-1a3c48dac5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-771c9243-ba64-4da8-b77d-ade900f58105,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-80589824-76fa-47a0-a67d-34017a062a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-73c0515a-5bcb-4ab0-b59e-b0ff679e06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-0f2baf3d-0988-458a-9a4a-9be3f0b653e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f3a9892d-061d-4ee8-bfb5-e54e73af1959,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-39501fd6-8b90-4789-ad07-7bb344422abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309705768-172.17.0.2-1597289471277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-86e24ba0-6261-4789-85fb-38e1812cc3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-593dd26c-a43d-47e5-a601-53543cf7cf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-10505049-dec5-4c38-9a6e-2960f26c54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-c938b9f9-25c5-4ed1-8412-e91c35b207e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-8f7e43fd-9c8d-4719-a1f5-5e7cd75ab61e,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-b38204ee-8b0c-42cb-ad12-643d3f5e1862,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-c183699b-d601-4dac-abd8-d576821a782f,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-948990d5-0a8f-4876-b4f5-2690862e1e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309705768-172.17.0.2-1597289471277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-86e24ba0-6261-4789-85fb-38e1812cc3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-593dd26c-a43d-47e5-a601-53543cf7cf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-10505049-dec5-4c38-9a6e-2960f26c54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-c938b9f9-25c5-4ed1-8412-e91c35b207e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-8f7e43fd-9c8d-4719-a1f5-5e7cd75ab61e,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-b38204ee-8b0c-42cb-ad12-643d3f5e1862,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-c183699b-d601-4dac-abd8-d576821a782f,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-948990d5-0a8f-4876-b4f5-2690862e1e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773369541-172.17.0.2-1597290355942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-ead5325e-046a-431c-a862-ca7d8453ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-62a2940f-5504-4022-9422-925f16332249,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-c4f89b41-61b5-4f6a-9a09-81df330251c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-19806afb-12f0-438d-9446-2591ff1c0243,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-d286c797-5ddb-4786-ab2c-cc8365193224,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-b30b4988-4e1c-4775-a60e-02c2ca48269b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-d62e1c10-192b-4ba4-af30-96468e9b9335,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-06a93434-b920-47f1-a3ff-01fdb26ca6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773369541-172.17.0.2-1597290355942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-ead5325e-046a-431c-a862-ca7d8453ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-62a2940f-5504-4022-9422-925f16332249,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-c4f89b41-61b5-4f6a-9a09-81df330251c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-19806afb-12f0-438d-9446-2591ff1c0243,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-d286c797-5ddb-4786-ab2c-cc8365193224,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-b30b4988-4e1c-4775-a60e-02c2ca48269b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-d62e1c10-192b-4ba4-af30-96468e9b9335,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-06a93434-b920-47f1-a3ff-01fdb26ca6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804758129-172.17.0.2-1597291035595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-515af42e-0890-42cf-abc0-74dbb555bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-490d7f46-7eda-4576-ab40-9fd7de284e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bb008962-e5d5-4bf5-a6b5-1cc426423960,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-7ea33b9f-8d37-4d96-bb4d-d2826ac183f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-126da874-ebff-4976-82f8-1de7ff452d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-95b38f4c-5a0d-4f8a-ba23-a66e511fdde9,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-58234ec3-b2ac-43de-b040-7045327c9212,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a0d203e0-68de-43c4-92a4-482542177495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804758129-172.17.0.2-1597291035595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-515af42e-0890-42cf-abc0-74dbb555bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-490d7f46-7eda-4576-ab40-9fd7de284e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bb008962-e5d5-4bf5-a6b5-1cc426423960,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-7ea33b9f-8d37-4d96-bb4d-d2826ac183f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-126da874-ebff-4976-82f8-1de7ff452d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-95b38f4c-5a0d-4f8a-ba23-a66e511fdde9,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-58234ec3-b2ac-43de-b040-7045327c9212,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a0d203e0-68de-43c4-92a4-482542177495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931657848-172.17.0.2-1597291117107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-2bac7ad2-735a-466f-97f7-9166ca7bea11,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2308c1e4-5de0-45b2-b13d-926d94594e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-adc91f93-a93c-4f30-b452-2cf90789ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-832c768f-17dd-4909-b50f-3ff19d08f001,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-46e17d02-fbba-462d-9e11-5e57ac0c3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-3a11fd3c-76ba-400b-8bfc-096cee8c0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-84812603-f588-49a3-87f2-ca7ecc1d2354,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-fabe4409-2f1d-4f93-a086-cfe6be50e443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931657848-172.17.0.2-1597291117107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-2bac7ad2-735a-466f-97f7-9166ca7bea11,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2308c1e4-5de0-45b2-b13d-926d94594e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-adc91f93-a93c-4f30-b452-2cf90789ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-832c768f-17dd-4909-b50f-3ff19d08f001,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-46e17d02-fbba-462d-9e11-5e57ac0c3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-3a11fd3c-76ba-400b-8bfc-096cee8c0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-84812603-f588-49a3-87f2-ca7ecc1d2354,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-fabe4409-2f1d-4f93-a086-cfe6be50e443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471966099-172.17.0.2-1597291152591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6ea24650-d677-4993-9fea-01692aab3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-a23a6e76-cc76-4d61-a8ea-264dfb5e6696,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-3300a289-0570-4ff7-96f3-067666dff120,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-282ab3a3-3cce-4c48-b6a3-3bf3aac31f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-242f595b-d51b-4b35-82c0-e42608d2f1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-d2de83e6-ac61-4827-9d78-8f5bfad42288,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-7bac4fd8-5600-4f2b-8e66-6aa0272d9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-75a1fc93-f372-46b2-91c6-949398b4c6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471966099-172.17.0.2-1597291152591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6ea24650-d677-4993-9fea-01692aab3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-a23a6e76-cc76-4d61-a8ea-264dfb5e6696,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-3300a289-0570-4ff7-96f3-067666dff120,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-282ab3a3-3cce-4c48-b6a3-3bf3aac31f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-242f595b-d51b-4b35-82c0-e42608d2f1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-d2de83e6-ac61-4827-9d78-8f5bfad42288,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-7bac4fd8-5600-4f2b-8e66-6aa0272d9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-75a1fc93-f372-46b2-91c6-949398b4c6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016115761-172.17.0.2-1597291404266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-699599cd-52f9-4bff-bae9-edf319fd7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-24216265-efbd-457c-9c61-7ebd1ee3151b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5cecea00-c12a-40a8-9af7-926ede78520a,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-2172a594-814a-49ad-878f-6cb14a08f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-a70d7530-c4e8-4ba4-9e50-7b31c6dcb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-7db4e1df-7bb5-4300-be4d-da1271df8ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-7399a6b8-a4ae-4dee-a42b-fde295511b84,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-709e62a6-87ac-4978-8555-db4f5ee1a983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016115761-172.17.0.2-1597291404266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-699599cd-52f9-4bff-bae9-edf319fd7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-24216265-efbd-457c-9c61-7ebd1ee3151b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5cecea00-c12a-40a8-9af7-926ede78520a,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-2172a594-814a-49ad-878f-6cb14a08f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-a70d7530-c4e8-4ba4-9e50-7b31c6dcb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-7db4e1df-7bb5-4300-be4d-da1271df8ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-7399a6b8-a4ae-4dee-a42b-fde295511b84,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-709e62a6-87ac-4978-8555-db4f5ee1a983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671667617-172.17.0.2-1597291598768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-3c7133e9-edc9-4787-b8b1-02ca2d8d8010,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-0204f18d-c953-4daf-985c-6f9d0a46c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a321071f-4ce7-48b8-a3ba-5f3172e14c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-693f6bfe-9841-4570-8965-c7c334c302e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-fa611549-7697-4f0e-8388-8779f0fe8cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-1a1788df-a096-43e2-9ea1-1b938f9cb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-b46f5913-17aa-4074-b231-8d2af340a638,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-a7744dcc-84c4-4ed7-9950-5ecaae73c5d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671667617-172.17.0.2-1597291598768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-3c7133e9-edc9-4787-b8b1-02ca2d8d8010,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-0204f18d-c953-4daf-985c-6f9d0a46c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a321071f-4ce7-48b8-a3ba-5f3172e14c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-693f6bfe-9841-4570-8965-c7c334c302e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-fa611549-7697-4f0e-8388-8779f0fe8cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-1a1788df-a096-43e2-9ea1-1b938f9cb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-b46f5913-17aa-4074-b231-8d2af340a638,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-a7744dcc-84c4-4ed7-9950-5ecaae73c5d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162456619-172.17.0.2-1597291757024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42466,DS-35ecbbb6-1dba-479d-9677-6bb3e43ec052,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-ecc6690e-296b-4caf-944a-bab6f2939b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-b37d633e-5e92-437a-ade4-0a02fc52e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-db5f7f8a-dcc9-4277-8636-f9812bd20d24,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-8e8f6650-fff2-4922-9dc9-2440e8c887ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-432d9494-a63b-45e8-bda5-bbeefae735da,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-5e0603e1-99ba-49bc-8434-a1ed2d2748cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-8106dffa-651f-4c38-9181-8bb6439915f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162456619-172.17.0.2-1597291757024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42466,DS-35ecbbb6-1dba-479d-9677-6bb3e43ec052,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-ecc6690e-296b-4caf-944a-bab6f2939b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-b37d633e-5e92-437a-ade4-0a02fc52e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-db5f7f8a-dcc9-4277-8636-f9812bd20d24,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-8e8f6650-fff2-4922-9dc9-2440e8c887ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-432d9494-a63b-45e8-bda5-bbeefae735da,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-5e0603e1-99ba-49bc-8434-a1ed2d2748cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-8106dffa-651f-4c38-9181-8bb6439915f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850099435-172.17.0.2-1597291790793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-3896b551-e24c-41b6-be0b-9e8c067a74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-cfffbfe8-d916-4e7e-a985-4f12731a5597,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-01950153-7d51-4297-bdbd-fe7ad60752b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-67e86f98-cbab-47e5-8965-444cc5c5149a,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-ed82f2de-59b8-4e68-89b2-a6ed1ea5a511,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-88d40ad0-4ea8-4115-b3c3-47fe85e34390,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-dcaf9230-eda4-4136-b0a3-e2f23d845907,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-f921adea-1263-46d3-a917-5bad2f305ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850099435-172.17.0.2-1597291790793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-3896b551-e24c-41b6-be0b-9e8c067a74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-cfffbfe8-d916-4e7e-a985-4f12731a5597,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-01950153-7d51-4297-bdbd-fe7ad60752b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-67e86f98-cbab-47e5-8965-444cc5c5149a,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-ed82f2de-59b8-4e68-89b2-a6ed1ea5a511,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-88d40ad0-4ea8-4115-b3c3-47fe85e34390,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-dcaf9230-eda4-4136-b0a3-e2f23d845907,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-f921adea-1263-46d3-a917-5bad2f305ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042338253-172.17.0.2-1597291859568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-f790d939-c8b5-4f56-9ce3-b81ae7fb23e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-be2aa803-307b-4d1f-8dfd-2bf562bfe0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-81f17ecb-7a61-4b16-99a1-242aec3c0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-30b832f1-d1de-4162-babb-c5f43205704d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-3b1e7c8d-3e90-48be-aad3-cf0328252b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-2a785c23-68ac-4920-8a00-4b7fe43a1424,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-6300f14e-ad62-4ea2-9b78-a9f59c3c182b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-7b0f50e3-12fc-4410-b8c6-c9800b4397d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042338253-172.17.0.2-1597291859568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-f790d939-c8b5-4f56-9ce3-b81ae7fb23e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-be2aa803-307b-4d1f-8dfd-2bf562bfe0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-81f17ecb-7a61-4b16-99a1-242aec3c0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-30b832f1-d1de-4162-babb-c5f43205704d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-3b1e7c8d-3e90-48be-aad3-cf0328252b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-2a785c23-68ac-4920-8a00-4b7fe43a1424,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-6300f14e-ad62-4ea2-9b78-a9f59c3c182b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-7b0f50e3-12fc-4410-b8c6-c9800b4397d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796664896-172.17.0.2-1597291893162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-f3750f2a-44b8-4999-8f64-ac6b9c6cc569,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-7917d83a-3d81-4d96-a60a-d66792abb80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d08d16b5-b446-4b68-8860-73b45fc1ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-6ea64a65-f9a8-4308-b4e2-667b1a865dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-594c6a07-1816-4acf-a872-58949606b55d,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-2d1201c2-55b5-4b9a-8fad-d96b82049f59,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-33713b2c-82f7-4ca2-a678-8a31a2eea272,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-e2d7d5be-1a37-4440-bd5e-9a8d2700d21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796664896-172.17.0.2-1597291893162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-f3750f2a-44b8-4999-8f64-ac6b9c6cc569,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-7917d83a-3d81-4d96-a60a-d66792abb80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d08d16b5-b446-4b68-8860-73b45fc1ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-6ea64a65-f9a8-4308-b4e2-667b1a865dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-594c6a07-1816-4acf-a872-58949606b55d,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-2d1201c2-55b5-4b9a-8fad-d96b82049f59,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-33713b2c-82f7-4ca2-a678-8a31a2eea272,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-e2d7d5be-1a37-4440-bd5e-9a8d2700d21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549375164-172.17.0.2-1597291960415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-78daea28-5779-4751-b0e8-11901220061c,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-d9cd93f4-1173-4559-9f1e-c5d1c219e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-d62320e1-a236-43d4-8dae-488855d600e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-eb85b5ca-6279-4a18-be1d-816f4b81569a,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f0b2c4bf-0d23-4715-bdc0-10d886b9a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-bf461ba7-24a2-4680-a7ea-508fad4ce3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-d1a2e93a-0c2b-41e6-a831-fffea4e2606c,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-05212079-0b0b-40f4-95a7-597b63e95525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549375164-172.17.0.2-1597291960415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-78daea28-5779-4751-b0e8-11901220061c,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-d9cd93f4-1173-4559-9f1e-c5d1c219e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-d62320e1-a236-43d4-8dae-488855d600e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-eb85b5ca-6279-4a18-be1d-816f4b81569a,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f0b2c4bf-0d23-4715-bdc0-10d886b9a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-bf461ba7-24a2-4680-a7ea-508fad4ce3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-d1a2e93a-0c2b-41e6-a831-fffea4e2606c,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-05212079-0b0b-40f4-95a7-597b63e95525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063852756-172.17.0.2-1597292055190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-ea4f6494-5068-4505-adc6-5cc3f56c9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0b666b44-f5bf-4f0c-80d2-683f644ddcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-a54897a1-eb30-4d4a-9ee1-a891ea045635,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-248b2376-0426-4103-8141-77044f346a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-411587d9-0e37-4526-bb65-7579d06c3013,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-309ddb85-db4c-4d7a-be0a-c41830c02739,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-257186c0-1519-4ea4-bb0c-938ef0a3ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-99a33535-bc3b-461c-8150-8789ee5b9e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063852756-172.17.0.2-1597292055190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-ea4f6494-5068-4505-adc6-5cc3f56c9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0b666b44-f5bf-4f0c-80d2-683f644ddcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-a54897a1-eb30-4d4a-9ee1-a891ea045635,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-248b2376-0426-4103-8141-77044f346a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-411587d9-0e37-4526-bb65-7579d06c3013,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-309ddb85-db4c-4d7a-be0a-c41830c02739,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-257186c0-1519-4ea4-bb0c-938ef0a3ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-99a33535-bc3b-461c-8150-8789ee5b9e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635241351-172.17.0.2-1597292213807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35545,DS-4ec66661-6a40-4e69-ab6b-b5a7857bc862,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-0c0cfe7f-f68d-4550-b450-95f57457f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-089f40f2-da99-47f7-9b57-5e1890f02e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-346f59b4-0a5c-4267-adca-67bc57af380e,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-7953205d-a9f2-42de-83f1-aff26801c304,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-9e8b3cd7-6f43-4710-9398-a27e7f7f0b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-32e9bb75-5eba-490f-9c07-f1f7c979d721,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-b47059c7-39ba-49cb-8fa6-aa0e1ef20272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635241351-172.17.0.2-1597292213807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35545,DS-4ec66661-6a40-4e69-ab6b-b5a7857bc862,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-0c0cfe7f-f68d-4550-b450-95f57457f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-089f40f2-da99-47f7-9b57-5e1890f02e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-346f59b4-0a5c-4267-adca-67bc57af380e,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-7953205d-a9f2-42de-83f1-aff26801c304,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-9e8b3cd7-6f43-4710-9398-a27e7f7f0b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-32e9bb75-5eba-490f-9c07-f1f7c979d721,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-b47059c7-39ba-49cb-8fa6-aa0e1ef20272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768730381-172.17.0.2-1597292409278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45391,DS-bb20d701-1854-4499-9f80-ba2781204204,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-de098b22-dd81-48f9-94a1-88c315b0cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-b21b0716-0fd4-4ba7-848f-031513c5a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f424bc63-8447-4ed0-968f-576bf502aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-1fe85b70-b7b5-4055-8d14-60cbad6022e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-ac41467a-ddae-450d-acd0-d541f3934d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a1c4d365-2ed2-4c78-aa16-f5ad9dc62e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-56dfc54c-c8c1-410b-945f-399ac2e94be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768730381-172.17.0.2-1597292409278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45391,DS-bb20d701-1854-4499-9f80-ba2781204204,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-de098b22-dd81-48f9-94a1-88c315b0cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-b21b0716-0fd4-4ba7-848f-031513c5a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f424bc63-8447-4ed0-968f-576bf502aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-1fe85b70-b7b5-4055-8d14-60cbad6022e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-ac41467a-ddae-450d-acd0-d541f3934d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a1c4d365-2ed2-4c78-aa16-f5ad9dc62e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-56dfc54c-c8c1-410b-945f-399ac2e94be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860819341-172.17.0.2-1597292769610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44034,DS-532a0bc1-11b6-4579-86dc-8aaf10894acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-1a4ada6a-4c2d-49cf-9689-716436089ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-36f3cb82-a15c-4c9f-9e5a-8923479d305b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0c650e77-136d-42cb-b83f-7f67350f100c,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-491ec247-b3d3-4fa2-8a72-ab2382d618b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-14218f17-9f0b-41ff-991a-cc80664124c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-ac96a0d1-de88-42a2-a020-aed9c96a3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-2eb4e485-fca2-477f-9719-9a16311f845a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860819341-172.17.0.2-1597292769610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44034,DS-532a0bc1-11b6-4579-86dc-8aaf10894acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-1a4ada6a-4c2d-49cf-9689-716436089ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-36f3cb82-a15c-4c9f-9e5a-8923479d305b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0c650e77-136d-42cb-b83f-7f67350f100c,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-491ec247-b3d3-4fa2-8a72-ab2382d618b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-14218f17-9f0b-41ff-991a-cc80664124c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-ac96a0d1-de88-42a2-a020-aed9c96a3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-2eb4e485-fca2-477f-9719-9a16311f845a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5286
