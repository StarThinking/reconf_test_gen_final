reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950482159-172.17.0.2-1597690503114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-781e891c-5860-4069-93aa-2bc0cb8818da,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5aba2a95-51b3-4fc1-9978-a3439451da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-3434cb3e-7ce7-4162-ae49-3e7a7c712f05,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-468c34da-d801-4461-9593-c253092a6316,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-79c0a1f9-7e28-43ce-8660-6292927a817f,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-51795bfc-1e30-448c-91d4-7f646edc4026,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-f3521498-8253-40a3-a66a-f04ba080b158,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-74d6aadd-cb4d-4a45-a820-9785062d139d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950482159-172.17.0.2-1597690503114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-781e891c-5860-4069-93aa-2bc0cb8818da,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5aba2a95-51b3-4fc1-9978-a3439451da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-3434cb3e-7ce7-4162-ae49-3e7a7c712f05,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-468c34da-d801-4461-9593-c253092a6316,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-79c0a1f9-7e28-43ce-8660-6292927a817f,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-51795bfc-1e30-448c-91d4-7f646edc4026,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-f3521498-8253-40a3-a66a-f04ba080b158,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-74d6aadd-cb4d-4a45-a820-9785062d139d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962416700-172.17.0.2-1597690635304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33904,DS-615a2bf3-47f2-410b-9f54-d50a672d88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-d4f103d6-731e-47f5-9562-8175e5682ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-8d4beba9-f12c-4e28-9059-140f0512d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-66fb999b-95b3-4bb3-9981-6e341ebbb795,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a941f9b7-2a97-4f30-8fba-dda533e751c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d8f67867-9c4b-4346-bcf5-87232f9e72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ade1c846-c20e-4ca6-9057-8d3556c826e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-efc85ef7-42af-4577-9c39-fb2611bda5f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962416700-172.17.0.2-1597690635304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33904,DS-615a2bf3-47f2-410b-9f54-d50a672d88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-d4f103d6-731e-47f5-9562-8175e5682ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-8d4beba9-f12c-4e28-9059-140f0512d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-66fb999b-95b3-4bb3-9981-6e341ebbb795,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a941f9b7-2a97-4f30-8fba-dda533e751c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d8f67867-9c4b-4346-bcf5-87232f9e72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ade1c846-c20e-4ca6-9057-8d3556c826e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-efc85ef7-42af-4577-9c39-fb2611bda5f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618555852-172.17.0.2-1597690704663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-1c26ace7-65db-4072-9ad2-d7b0274e3c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-07e38e2e-541f-4940-8af2-1e3d9c385553,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-66f69bae-1f5b-4c07-bdd1-2582383510b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-2f065cb1-4c8a-412c-b020-b8dc086b6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e3e865e9-0770-4005-bf1c-f52516880f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-837fcdf5-fa4a-41f0-9455-27b83bd959f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5499f253-3169-4ac6-9ffc-678030985639,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9248790d-2ada-4970-a219-8121d0c8c16c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618555852-172.17.0.2-1597690704663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-1c26ace7-65db-4072-9ad2-d7b0274e3c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-07e38e2e-541f-4940-8af2-1e3d9c385553,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-66f69bae-1f5b-4c07-bdd1-2582383510b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-2f065cb1-4c8a-412c-b020-b8dc086b6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e3e865e9-0770-4005-bf1c-f52516880f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-837fcdf5-fa4a-41f0-9455-27b83bd959f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5499f253-3169-4ac6-9ffc-678030985639,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9248790d-2ada-4970-a219-8121d0c8c16c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467045029-172.17.0.2-1597690741713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-9988ad92-1ecf-4b9d-a76b-1e713cace99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-17bbf7cf-06c6-43fe-b782-5f8d3dd47759,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-00a345ce-399f-4829-b7c4-a68c19daa3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-a47b2c7e-90ed-4003-bf60-abbdcc9df110,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f9eb02c2-4509-46ec-bafb-3b2883e892ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-c68ff52f-4377-4a30-becf-e52f713da5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-19c8fbbc-e344-4f48-ac61-7f94111d2c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-912946c9-aa93-4248-ba88-f6f49761d043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467045029-172.17.0.2-1597690741713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-9988ad92-1ecf-4b9d-a76b-1e713cace99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-17bbf7cf-06c6-43fe-b782-5f8d3dd47759,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-00a345ce-399f-4829-b7c4-a68c19daa3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-a47b2c7e-90ed-4003-bf60-abbdcc9df110,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f9eb02c2-4509-46ec-bafb-3b2883e892ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-c68ff52f-4377-4a30-becf-e52f713da5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-19c8fbbc-e344-4f48-ac61-7f94111d2c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-912946c9-aa93-4248-ba88-f6f49761d043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053064849-172.17.0.2-1597690821572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38103,DS-05bbe5bb-d5b4-48e9-a2ab-71b09313880f,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-334daa1d-db24-45c6-a663-0dc7f5f27b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-86116e85-c88c-425a-bc89-6e9c1b8d5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-4e347c28-6cb6-4f5d-97c7-eecb0510a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-ae72afbd-581b-49cf-b552-da04edf0d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-fcf84fc1-9555-4d87-88dc-f9c2fbdaabe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-a039589f-505c-489e-844e-d8ef8dc62f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-13011196-2d56-4e7e-8693-74adafb72cfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053064849-172.17.0.2-1597690821572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38103,DS-05bbe5bb-d5b4-48e9-a2ab-71b09313880f,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-334daa1d-db24-45c6-a663-0dc7f5f27b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-86116e85-c88c-425a-bc89-6e9c1b8d5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-4e347c28-6cb6-4f5d-97c7-eecb0510a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-ae72afbd-581b-49cf-b552-da04edf0d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-fcf84fc1-9555-4d87-88dc-f9c2fbdaabe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-a039589f-505c-489e-844e-d8ef8dc62f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-13011196-2d56-4e7e-8693-74adafb72cfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308237358-172.17.0.2-1597690938389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-1bd816ae-615f-4917-9d21-3b6914647784,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-62392a88-53f7-49b8-a7b1-13414f33e584,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-59e836fa-c7b9-4085-99cc-c90fe18cd83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-cc69cbed-6976-4c02-a996-019dbfe22985,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-374003f6-fc23-4dc9-997a-9f779f3ce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-74437a94-515d-4331-8608-d9b00e8e90e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-801378e3-c3c0-417d-b7d6-9e93b38487ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d303e343-5dff-460c-9e78-e349cb37cb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308237358-172.17.0.2-1597690938389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-1bd816ae-615f-4917-9d21-3b6914647784,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-62392a88-53f7-49b8-a7b1-13414f33e584,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-59e836fa-c7b9-4085-99cc-c90fe18cd83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-cc69cbed-6976-4c02-a996-019dbfe22985,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-374003f6-fc23-4dc9-997a-9f779f3ce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-74437a94-515d-4331-8608-d9b00e8e90e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-801378e3-c3c0-417d-b7d6-9e93b38487ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d303e343-5dff-460c-9e78-e349cb37cb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896580221-172.17.0.2-1597691021239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-b507633f-2e84-4189-97aa-40277acb83f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-43eda9d4-b3ce-4d39-98ea-c933b842d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-c447c021-0b98-4f37-9bdb-3e9c106e12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-0fd40ebf-b256-4ac2-b5a9-015ac4c436e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-983be24d-c86e-4153-b8bd-91fb5163e615,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-acbc3d1b-d28b-4eeb-98c9-41d7013a8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-d6024e36-af8d-417d-8627-2f825eee4f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-972272b4-1bee-480f-b4c9-ea594972f263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896580221-172.17.0.2-1597691021239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-b507633f-2e84-4189-97aa-40277acb83f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-43eda9d4-b3ce-4d39-98ea-c933b842d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-c447c021-0b98-4f37-9bdb-3e9c106e12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-0fd40ebf-b256-4ac2-b5a9-015ac4c436e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-983be24d-c86e-4153-b8bd-91fb5163e615,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-acbc3d1b-d28b-4eeb-98c9-41d7013a8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-d6024e36-af8d-417d-8627-2f825eee4f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-972272b4-1bee-480f-b4c9-ea594972f263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188208296-172.17.0.2-1597691270272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-cb6f896d-2e2f-435f-980d-da167d4a4153,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-b8cec547-a7bd-4516-a9bc-30b8a817f114,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-7d61717e-48f1-4e42-9fda-8d3b48c1e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-f06929fe-b461-4346-a29b-eadf8c06a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-75bfe482-6ff4-4d79-82df-0f6bde3e0326,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-b9d24ea9-ac2c-4e8b-b0d7-ec22ee4361ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-afb6f49a-b7db-4655-9c85-87f8a51d4676,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f5234e06-b95b-425b-a947-792a272957c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188208296-172.17.0.2-1597691270272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36921,DS-cb6f896d-2e2f-435f-980d-da167d4a4153,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-b8cec547-a7bd-4516-a9bc-30b8a817f114,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-7d61717e-48f1-4e42-9fda-8d3b48c1e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-f06929fe-b461-4346-a29b-eadf8c06a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-75bfe482-6ff4-4d79-82df-0f6bde3e0326,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-b9d24ea9-ac2c-4e8b-b0d7-ec22ee4361ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-afb6f49a-b7db-4655-9c85-87f8a51d4676,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f5234e06-b95b-425b-a947-792a272957c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934275830-172.17.0.2-1597691354886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-fc57eb50-1af1-4005-8899-48270dccc949,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-b9ec73c0-2065-45b5-9bf2-4db98409cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-888a9176-3c2c-496f-9809-bff74306e3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-9f56bd6e-1d75-4721-aba2-0778d0324ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-28d7e025-5069-47f0-9989-004a4a7a1b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-8d823cb8-53e2-4ed8-a496-a24d438d4503,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-fca0ec55-6163-4c52-bebf-e2cee39e841b,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-d7e18510-94c2-4f6b-a70f-487b917fe718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934275830-172.17.0.2-1597691354886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-fc57eb50-1af1-4005-8899-48270dccc949,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-b9ec73c0-2065-45b5-9bf2-4db98409cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-888a9176-3c2c-496f-9809-bff74306e3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-9f56bd6e-1d75-4721-aba2-0778d0324ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-28d7e025-5069-47f0-9989-004a4a7a1b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-8d823cb8-53e2-4ed8-a496-a24d438d4503,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-fca0ec55-6163-4c52-bebf-e2cee39e841b,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-d7e18510-94c2-4f6b-a70f-487b917fe718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450247112-172.17.0.2-1597691518006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-a5e7a479-f236-4ddb-bde3-b2534fd87b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-e903c8c4-a2ec-4cdd-89a7-3400d738302c,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-28981257-3b1b-4fff-946a-abd25fe17ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-216fd90a-8c1c-409a-8181-be2bbd710cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-ff232b44-0548-458d-b555-bdcd6e724ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-68ad64e2-5f20-40d3-93b1-0df4ee117821,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e3e98ef8-3b72-4e2b-a06b-69fe302ce64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-effe72e0-56b3-4383-b6aa-278a49640b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450247112-172.17.0.2-1597691518006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-a5e7a479-f236-4ddb-bde3-b2534fd87b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-e903c8c4-a2ec-4cdd-89a7-3400d738302c,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-28981257-3b1b-4fff-946a-abd25fe17ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-216fd90a-8c1c-409a-8181-be2bbd710cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-ff232b44-0548-458d-b555-bdcd6e724ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-68ad64e2-5f20-40d3-93b1-0df4ee117821,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e3e98ef8-3b72-4e2b-a06b-69fe302ce64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-effe72e0-56b3-4383-b6aa-278a49640b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880877010-172.17.0.2-1597691590688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-c560e7e9-1dd4-4fad-9840-31bf32e8db97,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-8226e385-ed90-4bb9-b42d-dff9ea6109fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f7921ed0-7c16-4649-b974-85bee329b377,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-798ff1bc-a758-4271-962a-89c2f302321d,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-1ec6f8a3-74f5-4f2a-b91f-a0aa72516ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-24b82051-092a-41ce-9a72-01863d136acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-cd66aa67-ddda-4ad6-9cf3-bb2249b5ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-9058100c-7106-4f80-89aa-1b8ec208ea64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880877010-172.17.0.2-1597691590688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-c560e7e9-1dd4-4fad-9840-31bf32e8db97,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-8226e385-ed90-4bb9-b42d-dff9ea6109fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f7921ed0-7c16-4649-b974-85bee329b377,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-798ff1bc-a758-4271-962a-89c2f302321d,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-1ec6f8a3-74f5-4f2a-b91f-a0aa72516ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-24b82051-092a-41ce-9a72-01863d136acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-cd66aa67-ddda-4ad6-9cf3-bb2249b5ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-9058100c-7106-4f80-89aa-1b8ec208ea64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480582802-172.17.0.2-1597691625189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41549,DS-54722383-a236-496d-a22a-d08488bb24c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-439a97eb-35d7-42f6-b34b-ddee187105b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-ad2cea2e-d16a-41bc-b744-2ec176556da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-aff5cf75-23ab-4d9a-ab19-e5800d856501,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2248bdde-e673-45d3-9d21-c0c1242208df,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8db468aa-972d-4291-8b46-05abac199aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-05283e39-e143-4cd6-a624-7fe0aab60538,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-91f96422-0af4-4340-b125-6884bc9688b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480582802-172.17.0.2-1597691625189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41549,DS-54722383-a236-496d-a22a-d08488bb24c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-439a97eb-35d7-42f6-b34b-ddee187105b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-ad2cea2e-d16a-41bc-b744-2ec176556da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-aff5cf75-23ab-4d9a-ab19-e5800d856501,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2248bdde-e673-45d3-9d21-c0c1242208df,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8db468aa-972d-4291-8b46-05abac199aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-05283e39-e143-4cd6-a624-7fe0aab60538,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-91f96422-0af4-4340-b125-6884bc9688b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701694822-172.17.0.2-1597691714497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-65247afd-ca5a-4857-9d75-d97cf1790206,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-314ee85d-10fd-4787-962b-b1e69753a049,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-1782d3f3-0bae-4398-9fba-63bab1d29b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-c8fca492-c0cd-48b8-bcfb-4a1e241329ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-05402036-f2d4-4360-a34d-35aa64cc7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-c9517227-0ebd-4238-92be-b3ca9f458ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-ed41982e-63c9-40d2-bd46-b9781acfceb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d704fd58-8757-447d-a8f0-be43a44f18c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701694822-172.17.0.2-1597691714497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-65247afd-ca5a-4857-9d75-d97cf1790206,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-314ee85d-10fd-4787-962b-b1e69753a049,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-1782d3f3-0bae-4398-9fba-63bab1d29b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-c8fca492-c0cd-48b8-bcfb-4a1e241329ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-05402036-f2d4-4360-a34d-35aa64cc7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-c9517227-0ebd-4238-92be-b3ca9f458ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-ed41982e-63c9-40d2-bd46-b9781acfceb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d704fd58-8757-447d-a8f0-be43a44f18c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070615117-172.17.0.2-1597691972437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44369,DS-7d795e07-1d04-466b-9763-7c2e5cc6264a,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-cba28f1a-3f19-4f0c-b6b8-6dc6b4c17c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-1c163461-d586-4422-8175-aca7a6367024,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-de72f4d9-e808-4023-bf3e-f5f412e3246c,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-dbb85dca-88c7-4079-913f-f43457c3bb96,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-edf74f78-2334-4d9b-95b4-ecfe5f060eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-da76c2f4-7a4d-4a1e-8f58-9238836d550e,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-ffc37d75-0024-422b-9df5-2cb740c4a1a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070615117-172.17.0.2-1597691972437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44369,DS-7d795e07-1d04-466b-9763-7c2e5cc6264a,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-cba28f1a-3f19-4f0c-b6b8-6dc6b4c17c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-1c163461-d586-4422-8175-aca7a6367024,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-de72f4d9-e808-4023-bf3e-f5f412e3246c,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-dbb85dca-88c7-4079-913f-f43457c3bb96,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-edf74f78-2334-4d9b-95b4-ecfe5f060eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-da76c2f4-7a4d-4a1e-8f58-9238836d550e,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-ffc37d75-0024-422b-9df5-2cb740c4a1a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474370110-172.17.0.2-1597692223744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-8bae2abe-fcf4-435c-ba32-a99499faac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-65c9a6f0-529e-4629-9b37-392e6eaff7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-c07da352-ad5e-438b-b43b-686493fa5828,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-134d6086-7168-4fd5-945e-9f1177a4cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-d14a4914-9f2d-4eee-8b6a-b4f76763362c,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-5b547a72-3e00-4943-bee5-b763702a4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-fbf04f32-969a-4d3b-b7b5-4b400c5603ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-f1764769-8b1e-4f7b-a246-d0c5886a97df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474370110-172.17.0.2-1597692223744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-8bae2abe-fcf4-435c-ba32-a99499faac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-65c9a6f0-529e-4629-9b37-392e6eaff7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-c07da352-ad5e-438b-b43b-686493fa5828,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-134d6086-7168-4fd5-945e-9f1177a4cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-d14a4914-9f2d-4eee-8b6a-b4f76763362c,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-5b547a72-3e00-4943-bee5-b763702a4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-fbf04f32-969a-4d3b-b7b5-4b400c5603ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-f1764769-8b1e-4f7b-a246-d0c5886a97df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752253489-172.17.0.2-1597692271419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-121c38cf-c8a7-401d-94dc-ae0ea0aefb81,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-23f5599a-5ee2-4bcf-a9ef-757997be4a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-ac90e9de-5e70-4e16-bd5c-4dc23cc95cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-8b76c026-9abf-4963-9f03-f744b6457e56,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-e6bc8c62-789a-41d9-81f1-18600bc776d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f7e7b665-cdb2-40eb-8f00-2d3e82a3ccc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-c11035e5-9959-4da7-b633-8d05c84642b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8815ceaa-6173-43d3-bf70-7e55dcf4e454,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752253489-172.17.0.2-1597692271419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-121c38cf-c8a7-401d-94dc-ae0ea0aefb81,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-23f5599a-5ee2-4bcf-a9ef-757997be4a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-ac90e9de-5e70-4e16-bd5c-4dc23cc95cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-8b76c026-9abf-4963-9f03-f744b6457e56,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-e6bc8c62-789a-41d9-81f1-18600bc776d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f7e7b665-cdb2-40eb-8f00-2d3e82a3ccc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-c11035e5-9959-4da7-b633-8d05c84642b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8815ceaa-6173-43d3-bf70-7e55dcf4e454,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455442736-172.17.0.2-1597692310889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-3b746d5b-2098-46a9-8420-800d483900a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-2092b56d-85c5-4089-b220-1c024606e207,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-965c374e-0ba4-4381-bd6c-b45319ff45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4518ce6c-fa3b-410c-8b6d-9bf3ff069903,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-02902bb8-eb2e-4bc8-84b0-5966948fbdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-cdf9077c-26b9-45fc-b1b0-a605679957ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1540b713-f621-44df-9a14-90a3d5f29870,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-454507f5-3163-48ec-b355-a8a1c1445220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455442736-172.17.0.2-1597692310889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-3b746d5b-2098-46a9-8420-800d483900a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-2092b56d-85c5-4089-b220-1c024606e207,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-965c374e-0ba4-4381-bd6c-b45319ff45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4518ce6c-fa3b-410c-8b6d-9bf3ff069903,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-02902bb8-eb2e-4bc8-84b0-5966948fbdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-cdf9077c-26b9-45fc-b1b0-a605679957ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1540b713-f621-44df-9a14-90a3d5f29870,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-454507f5-3163-48ec-b355-a8a1c1445220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548583143-172.17.0.2-1597692342982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-c79bdd69-09e0-4a9f-aed0-5bb509eeb412,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-e27434ac-e5ef-4ece-ba65-1ed98ff2ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b0857199-a28b-431d-8849-7f18e2cc00d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-1f8eccfc-99d1-4431-bbbe-91952a253ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d310f42c-64e1-44a3-b70f-85add40f947c,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-8b593470-8572-4261-87ba-8f28fec9be50,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-c88ef606-383a-4ae3-a374-3c660c6e53d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-1571092e-5fcf-4532-ad2f-4684f1b47364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548583143-172.17.0.2-1597692342982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-c79bdd69-09e0-4a9f-aed0-5bb509eeb412,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-e27434ac-e5ef-4ece-ba65-1ed98ff2ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b0857199-a28b-431d-8849-7f18e2cc00d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-1f8eccfc-99d1-4431-bbbe-91952a253ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d310f42c-64e1-44a3-b70f-85add40f947c,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-8b593470-8572-4261-87ba-8f28fec9be50,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-c88ef606-383a-4ae3-a374-3c660c6e53d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-1571092e-5fcf-4532-ad2f-4684f1b47364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132290388-172.17.0.2-1597692428721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45035,DS-7a135519-0cd0-4623-9f8d-43c182fe60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-7dc65f6d-918c-47e8-ac51-11ae0058fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-7e1f138e-0e62-4ab3-a1a8-b50c41320c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-6ce36375-6b43-4a4b-876d-fb4f8b0c610d,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-4ab5359d-9cb5-4377-950e-a90c5362c026,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1edbd62f-0c2e-4a05-be12-71c234849170,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8ea10427-3945-4625-91c4-ce7b4385da1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-a1f9da4b-3917-4e64-a851-a18ee419c5cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132290388-172.17.0.2-1597692428721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45035,DS-7a135519-0cd0-4623-9f8d-43c182fe60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-7dc65f6d-918c-47e8-ac51-11ae0058fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-7e1f138e-0e62-4ab3-a1a8-b50c41320c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-6ce36375-6b43-4a4b-876d-fb4f8b0c610d,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-4ab5359d-9cb5-4377-950e-a90c5362c026,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1edbd62f-0c2e-4a05-be12-71c234849170,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8ea10427-3945-4625-91c4-ce7b4385da1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-a1f9da4b-3917-4e64-a851-a18ee419c5cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199002398-172.17.0.2-1597692513678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33530,DS-6496acdd-a826-4e17-a95c-49710973b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f17eaf0d-c30f-4ed6-80c6-e45efc996010,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-5fdda46d-f2b4-4990-8546-50fad0d9435b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-0ff3a0de-64ce-47df-ace2-95cc8a2fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-20d01d77-b7f4-4fd9-abbc-9a09bfb44c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-6d312817-9ee2-4bf4-9be9-b5c0708ce9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-1bec8649-ed46-4fec-9bba-52bc1e0d577c,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-e3f23653-9e98-4448-82f4-ef0ea1f9b226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199002398-172.17.0.2-1597692513678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33530,DS-6496acdd-a826-4e17-a95c-49710973b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f17eaf0d-c30f-4ed6-80c6-e45efc996010,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-5fdda46d-f2b4-4990-8546-50fad0d9435b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-0ff3a0de-64ce-47df-ace2-95cc8a2fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-20d01d77-b7f4-4fd9-abbc-9a09bfb44c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-6d312817-9ee2-4bf4-9be9-b5c0708ce9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-1bec8649-ed46-4fec-9bba-52bc1e0d577c,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-e3f23653-9e98-4448-82f4-ef0ea1f9b226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75491602-172.17.0.2-1597692550478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-94548a09-d3a2-4741-b705-57cf2767c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c7c310e9-93dd-4da2-aac4-75213ab3d964,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-fef83725-a06f-4549-bd81-941e674d7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-5f65303c-29e4-4589-9d4b-be734a923fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-3b837dfa-de95-4491-8f82-0825d25712e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-25e37ea6-f59d-4b8e-8e4b-99e5f68543d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-5b3f40e1-199e-434e-9ff6-6b57fbc562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-5dc44418-ebf7-48a3-bf07-6b3e433b0670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75491602-172.17.0.2-1597692550478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-94548a09-d3a2-4741-b705-57cf2767c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c7c310e9-93dd-4da2-aac4-75213ab3d964,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-fef83725-a06f-4549-bd81-941e674d7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-5f65303c-29e4-4589-9d4b-be734a923fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-3b837dfa-de95-4491-8f82-0825d25712e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-25e37ea6-f59d-4b8e-8e4b-99e5f68543d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-5b3f40e1-199e-434e-9ff6-6b57fbc562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-5dc44418-ebf7-48a3-bf07-6b3e433b0670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892548040-172.17.0.2-1597692754187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35498,DS-f6d664ad-b42c-402a-a783-74fcb2fd6b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-4e14b48c-832e-4806-8ca2-1fb602404b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-0a9986f6-d606-49bf-b64b-016f75742cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-ca54973f-a3d0-4f42-83b4-cc01ba3e34df,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-fe98ad51-2eb7-4901-8322-935963ceb6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-9d1b42b4-8608-461b-90e0-86f1fbac8219,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-a39c0a3b-40d9-42f6-a257-0a631a2a67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3c6c829d-d121-45b1-9d6e-37d14492c9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892548040-172.17.0.2-1597692754187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35498,DS-f6d664ad-b42c-402a-a783-74fcb2fd6b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-4e14b48c-832e-4806-8ca2-1fb602404b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-0a9986f6-d606-49bf-b64b-016f75742cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-ca54973f-a3d0-4f42-83b4-cc01ba3e34df,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-fe98ad51-2eb7-4901-8322-935963ceb6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-9d1b42b4-8608-461b-90e0-86f1fbac8219,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-a39c0a3b-40d9-42f6-a257-0a631a2a67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3c6c829d-d121-45b1-9d6e-37d14492c9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241906236-172.17.0.2-1597692907573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-c8352eac-70d0-4036-b400-d53cbecc17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-1c28853e-d83a-49b3-94f7-e198c0be1231,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-c90ea188-8af6-4822-9595-9e0fe74d0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-49f9e318-ceae-4993-9a6b-59c075c2d935,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-67f91de6-0e2c-4a6f-9667-20aabf9233bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-aa682f58-b422-432a-b16e-fba33374f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-ec0b800b-51d1-4ec5-95d3-2a2bb963d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-9cf4279d-a01c-4c11-9d6a-b98fb332c7f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241906236-172.17.0.2-1597692907573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-c8352eac-70d0-4036-b400-d53cbecc17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-1c28853e-d83a-49b3-94f7-e198c0be1231,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-c90ea188-8af6-4822-9595-9e0fe74d0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-49f9e318-ceae-4993-9a6b-59c075c2d935,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-67f91de6-0e2c-4a6f-9667-20aabf9233bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-aa682f58-b422-432a-b16e-fba33374f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-ec0b800b-51d1-4ec5-95d3-2a2bb963d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-9cf4279d-a01c-4c11-9d6a-b98fb332c7f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369914131-172.17.0.2-1597692998350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-dda58254-fb7f-4c23-8ee8-41d2e98d63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-e4b51032-3182-479b-9f33-db41cfbfc3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4e85d6fc-f0cc-43b0-adbe-e653ed8408ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-68b28fac-988f-48dd-9ca0-ea8179a05995,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-6c2b6ce1-8752-4c51-bd47-8a9209a76246,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-4d07e344-f74b-42d4-b3b0-642c88f4e840,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-2abcaa60-c57d-4bb8-8131-356028501bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-442b0901-e549-49d3-b5c7-9ee15b449143,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369914131-172.17.0.2-1597692998350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-dda58254-fb7f-4c23-8ee8-41d2e98d63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-e4b51032-3182-479b-9f33-db41cfbfc3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4e85d6fc-f0cc-43b0-adbe-e653ed8408ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-68b28fac-988f-48dd-9ca0-ea8179a05995,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-6c2b6ce1-8752-4c51-bd47-8a9209a76246,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-4d07e344-f74b-42d4-b3b0-642c88f4e840,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-2abcaa60-c57d-4bb8-8131-356028501bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-442b0901-e549-49d3-b5c7-9ee15b449143,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082083821-172.17.0.2-1597693386644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-c031337c-b622-40c4-a513-4c4a736edcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-74621c86-15bc-43c0-b8c3-92342d210ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-838b75ec-4e14-473c-a4c4-bbe59942c5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-53ad9399-b2fb-484b-a8df-d5da947c1409,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-947deb71-95c1-478e-95fa-94232d895fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-65e5d446-94a8-4b7e-beb2-34ecd3e9179e,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-fd08e631-330e-422d-ab44-e2dd7e099241,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-ffe9c6d5-a327-4770-9020-cc3c9d0680d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082083821-172.17.0.2-1597693386644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-c031337c-b622-40c4-a513-4c4a736edcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-74621c86-15bc-43c0-b8c3-92342d210ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-838b75ec-4e14-473c-a4c4-bbe59942c5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-53ad9399-b2fb-484b-a8df-d5da947c1409,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-947deb71-95c1-478e-95fa-94232d895fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-65e5d446-94a8-4b7e-beb2-34ecd3e9179e,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-fd08e631-330e-422d-ab44-e2dd7e099241,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-ffe9c6d5-a327-4770-9020-cc3c9d0680d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386471725-172.17.0.2-1597693510262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-5288fa33-2816-4e8a-b579-818945a5edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-3e4b4508-5982-4eb9-bd49-35e313edaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-3b2231b1-20be-4f1b-8195-43b275c2b0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-a2a90d0c-7329-436c-ac4c-5f544a1f0f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-091991d0-34da-4ecc-bed6-38e3c48806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-1c3209fe-4045-4978-8305-0cacfa1bb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0f098fa8-48de-4d75-a65e-823d72d9b712,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-7b868d69-c973-4cc0-bbb8-f54e00f154c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386471725-172.17.0.2-1597693510262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-5288fa33-2816-4e8a-b579-818945a5edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-3e4b4508-5982-4eb9-bd49-35e313edaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-3b2231b1-20be-4f1b-8195-43b275c2b0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-a2a90d0c-7329-436c-ac4c-5f544a1f0f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-091991d0-34da-4ecc-bed6-38e3c48806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-1c3209fe-4045-4978-8305-0cacfa1bb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0f098fa8-48de-4d75-a65e-823d72d9b712,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-7b868d69-c973-4cc0-bbb8-f54e00f154c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036369853-172.17.0.2-1597693541194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-12d71dbc-2a39-452d-892b-c0cae20a3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7c98e3a4-b571-434c-92b4-a9063cc90d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-9e076faa-c240-4017-b04c-044471912084,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-ea87c34f-f5d7-42f3-a7a7-8c6c99e165f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-4765c75b-e37e-4d3e-afff-4b62feacfa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-f20c23f9-b240-4d05-9c70-bb77c9fd90e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-97065271-6958-4550-bc1b-1c96e774a2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-864adffd-be01-4c61-9586-f47bf7444c55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036369853-172.17.0.2-1597693541194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-12d71dbc-2a39-452d-892b-c0cae20a3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7c98e3a4-b571-434c-92b4-a9063cc90d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-9e076faa-c240-4017-b04c-044471912084,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-ea87c34f-f5d7-42f3-a7a7-8c6c99e165f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-4765c75b-e37e-4d3e-afff-4b62feacfa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-f20c23f9-b240-4d05-9c70-bb77c9fd90e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-97065271-6958-4550-bc1b-1c96e774a2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-864adffd-be01-4c61-9586-f47bf7444c55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826177893-172.17.0.2-1597693752601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-de32f7fb-53f7-42f7-953a-34ad2187dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-065383a1-1468-4b86-b586-8b26dc1f7142,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-5fc3b6fb-52e0-46bb-90ac-d96b27cb2259,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-71f31750-6f39-4429-b21d-a68d20e83ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-0a22cd0f-4cd1-42cb-a110-6ce642baa6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-6a39de52-9763-4a00-83c9-85de67c24f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-73d497e2-954f-45df-87e1-49618d7a4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-8dbd7dd9-4b9f-4046-adf1-8be434ca389a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826177893-172.17.0.2-1597693752601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-de32f7fb-53f7-42f7-953a-34ad2187dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-065383a1-1468-4b86-b586-8b26dc1f7142,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-5fc3b6fb-52e0-46bb-90ac-d96b27cb2259,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-71f31750-6f39-4429-b21d-a68d20e83ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-0a22cd0f-4cd1-42cb-a110-6ce642baa6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-6a39de52-9763-4a00-83c9-85de67c24f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-73d497e2-954f-45df-87e1-49618d7a4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-8dbd7dd9-4b9f-4046-adf1-8be434ca389a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769111266-172.17.0.2-1597693950403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-43286d9f-676a-417c-a631-909e3506b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-b74fa77c-585d-4e76-9f53-ce2fa46e83f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-53e88ae7-c219-4fb4-bd7f-fc5b52784a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4e265d70-113e-4eb3-9909-be408695040d,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-6c325caa-938f-4c9e-94cd-32298bf50e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b5d0ad51-45ea-4cbb-87a4-b63f0294b759,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-c4c2601b-eefa-49f4-84c1-07c4991f6297,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-d035aa8e-322a-45b6-ade8-958e403d551a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769111266-172.17.0.2-1597693950403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42914,DS-43286d9f-676a-417c-a631-909e3506b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-b74fa77c-585d-4e76-9f53-ce2fa46e83f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-53e88ae7-c219-4fb4-bd7f-fc5b52784a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4e265d70-113e-4eb3-9909-be408695040d,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-6c325caa-938f-4c9e-94cd-32298bf50e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b5d0ad51-45ea-4cbb-87a4-b63f0294b759,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-c4c2601b-eefa-49f4-84c1-07c4991f6297,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-d035aa8e-322a-45b6-ade8-958e403d551a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979693622-172.17.0.2-1597694116927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-18c39205-ddf0-4a19-b517-2fd38a8b4c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-6ca5ed41-969e-42b0-b8c9-f2e431df3992,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-dda4f3f8-1221-4d39-8953-128c9bba3567,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-4dea733c-6e83-4415-9ccf-96dae1c2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-1bf8eaf6-6d7d-4169-9a1f-51928460cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-64e2a56c-b6aa-4010-9af3-60e1e24446e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-19352f03-b5ff-44ff-b16f-355eee480f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6de63066-f924-4f77-81aa-c17c5516f1f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979693622-172.17.0.2-1597694116927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-18c39205-ddf0-4a19-b517-2fd38a8b4c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-6ca5ed41-969e-42b0-b8c9-f2e431df3992,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-dda4f3f8-1221-4d39-8953-128c9bba3567,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-4dea733c-6e83-4415-9ccf-96dae1c2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-1bf8eaf6-6d7d-4169-9a1f-51928460cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-64e2a56c-b6aa-4010-9af3-60e1e24446e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-19352f03-b5ff-44ff-b16f-355eee480f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6de63066-f924-4f77-81aa-c17c5516f1f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039700679-172.17.0.2-1597694245657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-d49fa670-3534-4b49-9275-df01cc389bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-5aeb27f8-3275-485f-95f8-1df2e4aeaa25,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-bc01fd23-a246-4655-8770-c993588045da,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-940ac41e-c9ff-4bfa-a2ad-1728f34c0c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-5b386dd7-84fb-42b1-93d6-3ed020a34982,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-86c95c9d-fab5-4904-bac4-5765d11c22cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-135cbf0b-0159-48c6-ba05-3bc6cf7c3b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-d5e5898f-981d-4adb-a4ee-51b87346d8a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039700679-172.17.0.2-1597694245657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-d49fa670-3534-4b49-9275-df01cc389bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-5aeb27f8-3275-485f-95f8-1df2e4aeaa25,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-bc01fd23-a246-4655-8770-c993588045da,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-940ac41e-c9ff-4bfa-a2ad-1728f34c0c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-5b386dd7-84fb-42b1-93d6-3ed020a34982,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-86c95c9d-fab5-4904-bac4-5765d11c22cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-135cbf0b-0159-48c6-ba05-3bc6cf7c3b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-d5e5898f-981d-4adb-a4ee-51b87346d8a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405558724-172.17.0.2-1597694373348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-3e9acf80-653c-4241-8573-325b4c0a2745,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3484962b-894b-4112-9920-5c6a0779588e,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d83cc252-820b-42f7-81b0-15d6b6d6a673,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-1777b2f9-3305-4498-9c03-5b99db13dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-f9970cbf-4412-4633-acb5-5f7e07ef8d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-ac6f821c-877d-4fd7-99dd-f4c7d0009792,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-12538f20-87eb-4e99-8bb8-55ad0e6f82fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ff74251d-cb62-4f31-b1f9-f3bc0452a036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405558724-172.17.0.2-1597694373348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-3e9acf80-653c-4241-8573-325b4c0a2745,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3484962b-894b-4112-9920-5c6a0779588e,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d83cc252-820b-42f7-81b0-15d6b6d6a673,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-1777b2f9-3305-4498-9c03-5b99db13dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-f9970cbf-4412-4633-acb5-5f7e07ef8d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-ac6f821c-877d-4fd7-99dd-f4c7d0009792,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-12538f20-87eb-4e99-8bb8-55ad0e6f82fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ff74251d-cb62-4f31-b1f9-f3bc0452a036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504137851-172.17.0.2-1597694579932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-8ed6700b-e019-4a64-bd21-7c84a2753873,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-64bdba49-0802-402b-88ca-e19e4ff31463,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-0e87199a-2fa7-4f1a-b241-0d35666485d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-54eb21b6-b9fc-407a-824a-f64d5cf1df31,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-321416f4-0517-4fdc-b655-e1a054faddde,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-e23d6286-9cbf-440e-92da-2a4db4752fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-a2249305-28d5-45ce-90c8-5cedfaa32e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-a79d9dc5-b7cb-4fb6-9b3e-519447adfdab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504137851-172.17.0.2-1597694579932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-8ed6700b-e019-4a64-bd21-7c84a2753873,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-64bdba49-0802-402b-88ca-e19e4ff31463,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-0e87199a-2fa7-4f1a-b241-0d35666485d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-54eb21b6-b9fc-407a-824a-f64d5cf1df31,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-321416f4-0517-4fdc-b655-e1a054faddde,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-e23d6286-9cbf-440e-92da-2a4db4752fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-a2249305-28d5-45ce-90c8-5cedfaa32e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-a79d9dc5-b7cb-4fb6-9b3e-519447adfdab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481379803-172.17.0.2-1597695254932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b0a2e6a5-a4fb-4428-be7b-20fea2b3fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1732854c-89b8-4827-b19a-226085af9c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-2b7776c2-10ee-44e9-9055-399eb1b85e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-9f56ff4f-c4f6-4c85-8c5f-b65a4e3209af,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-3d8163e0-99ac-4573-bb7a-4932e8a89c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-0f50c014-126a-4c43-982c-7fbd8e2dba31,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-fe8f6626-2ed6-4572-93a3-3e2ba94c3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-25338908-85c2-4f99-a765-a8f30a7c5fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481379803-172.17.0.2-1597695254932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b0a2e6a5-a4fb-4428-be7b-20fea2b3fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1732854c-89b8-4827-b19a-226085af9c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-2b7776c2-10ee-44e9-9055-399eb1b85e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-9f56ff4f-c4f6-4c85-8c5f-b65a4e3209af,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-3d8163e0-99ac-4573-bb7a-4932e8a89c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-0f50c014-126a-4c43-982c-7fbd8e2dba31,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-fe8f6626-2ed6-4572-93a3-3e2ba94c3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-25338908-85c2-4f99-a765-a8f30a7c5fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593428542-172.17.0.2-1597695506301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46093,DS-2e1b7af5-f0a8-4607-bf72-b6103eb297a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-30066323-e013-4783-8a8c-7efea40492d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-63e1936a-1110-4535-9d44-dbd08b491d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-616531d6-fa14-47f0-b266-ddd50ed45b25,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-fa8626c7-73ad-41c8-8571-fdef415ac446,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-3daa7716-c066-4c74-99a8-583573a53a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fe5541c6-163c-4ed1-95ed-9ce94568ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-39bf3afa-cd0c-474a-aa2a-0e2fe8660050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593428542-172.17.0.2-1597695506301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46093,DS-2e1b7af5-f0a8-4607-bf72-b6103eb297a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-30066323-e013-4783-8a8c-7efea40492d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-63e1936a-1110-4535-9d44-dbd08b491d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-616531d6-fa14-47f0-b266-ddd50ed45b25,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-fa8626c7-73ad-41c8-8571-fdef415ac446,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-3daa7716-c066-4c74-99a8-583573a53a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fe5541c6-163c-4ed1-95ed-9ce94568ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-39bf3afa-cd0c-474a-aa2a-0e2fe8660050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833397589-172.17.0.2-1597695624290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-2395f6a1-978f-44ef-8d90-01495c6661b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-aebf52f7-b572-4456-ac59-e3e4785f584c,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-e329d726-d4a7-4f52-a8a0-5ef156f085bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-d5e3af95-dfd5-40ce-810b-d8a1d02e1961,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-2e25ea57-109b-4c79-b7e5-a257449e83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-a9296ff7-f2cd-4f86-83b5-0c103660ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-93e13eaf-0b92-426a-9726-2c869bba175e,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-8ef2b306-6e3e-45de-9421-4d859abfbb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833397589-172.17.0.2-1597695624290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-2395f6a1-978f-44ef-8d90-01495c6661b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-aebf52f7-b572-4456-ac59-e3e4785f584c,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-e329d726-d4a7-4f52-a8a0-5ef156f085bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-d5e3af95-dfd5-40ce-810b-d8a1d02e1961,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-2e25ea57-109b-4c79-b7e5-a257449e83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-a9296ff7-f2cd-4f86-83b5-0c103660ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-93e13eaf-0b92-426a-9726-2c869bba175e,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-8ef2b306-6e3e-45de-9421-4d859abfbb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144454499-172.17.0.2-1597695958562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-69b675f2-222a-4cac-8378-3f5bc2f3c290,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-93c0ee78-8c9d-4403-a8ea-fad731de98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-eb0f9462-ad3b-4a5c-9bc5-04acd4eca1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-873acd22-5ce1-4385-8d55-44121acba3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-182b9b7e-aebe-4028-a1dc-c0fafd5e16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-34fde1de-5a94-403c-a1db-a49f5adbfea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ec0455d7-8dd5-404f-a732-b7c8a849ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-48eb1cba-e75a-441e-8830-ea1aa77e3993,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144454499-172.17.0.2-1597695958562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-69b675f2-222a-4cac-8378-3f5bc2f3c290,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-93c0ee78-8c9d-4403-a8ea-fad731de98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-eb0f9462-ad3b-4a5c-9bc5-04acd4eca1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-873acd22-5ce1-4385-8d55-44121acba3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-182b9b7e-aebe-4028-a1dc-c0fafd5e16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-34fde1de-5a94-403c-a1db-a49f5adbfea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ec0455d7-8dd5-404f-a732-b7c8a849ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-48eb1cba-e75a-441e-8830-ea1aa77e3993,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287970808-172.17.0.2-1597696130699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-5e553801-e721-4f4d-bc72-6e14aa7aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-86191f38-79ea-46dd-8373-362fdb448d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-a8acf4e2-cde5-41d1-a286-9987c8867696,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-857d513b-1559-4d2a-8711-00d34933a766,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-68752c1e-ac21-4bd3-806d-6a566d3d4ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-a48fe181-3f3a-4d4b-8cdd-bf30f0b4bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-1ee47145-4302-484f-891a-e3159ee10911,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-6cf8a9ed-b3aa-440c-b383-105dd7e55afd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287970808-172.17.0.2-1597696130699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-5e553801-e721-4f4d-bc72-6e14aa7aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-86191f38-79ea-46dd-8373-362fdb448d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-a8acf4e2-cde5-41d1-a286-9987c8867696,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-857d513b-1559-4d2a-8711-00d34933a766,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-68752c1e-ac21-4bd3-806d-6a566d3d4ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-a48fe181-3f3a-4d4b-8cdd-bf30f0b4bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-1ee47145-4302-484f-891a-e3159ee10911,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-6cf8a9ed-b3aa-440c-b383-105dd7e55afd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889433595-172.17.0.2-1597696611785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-51468f6c-c97b-426c-9e2b-cd5f97b830c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-9cc8f246-c4f7-42e8-bd1f-775c575c97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-006a35e0-1b88-4bff-bb28-640a1d00874c,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-7fc70ac7-2b7a-4db8-b5e1-e06d1f469d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-fb62e3e6-7961-4c8f-a847-7d3d9dadca03,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-bd5e05bb-ecc0-46ef-8110-7a39d2e4b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-cd6bcdae-e198-48fa-aba2-758c2ea4e423,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-2af97ddb-5880-4a61-9c9b-df19f731f902,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889433595-172.17.0.2-1597696611785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-51468f6c-c97b-426c-9e2b-cd5f97b830c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-9cc8f246-c4f7-42e8-bd1f-775c575c97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-006a35e0-1b88-4bff-bb28-640a1d00874c,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-7fc70ac7-2b7a-4db8-b5e1-e06d1f469d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-fb62e3e6-7961-4c8f-a847-7d3d9dadca03,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-bd5e05bb-ecc0-46ef-8110-7a39d2e4b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-cd6bcdae-e198-48fa-aba2-758c2ea4e423,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-2af97ddb-5880-4a61-9c9b-df19f731f902,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 6142
