reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205424390-172.17.0.6-1597730475945:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-57f169a1-8419-451d-974b-67d9e53abf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-593e2c3f-c8e1-488b-b682-03e7a1bdf499,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-e598318e-4b8b-4a42-a73e-393cb64b9112,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-a281a4f0-4192-4846-87d9-f4a4e5b794eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-44a8158d-5928-4ca0-9541-399786567786,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-56facdbf-95aa-40a7-91b2-bf2b40d8d475,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-bf31e03d-1361-4c0e-b24c-c939753829ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-7c9a794f-0369-49ae-8fb9-717f04bd09cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205424390-172.17.0.6-1597730475945:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-57f169a1-8419-451d-974b-67d9e53abf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-593e2c3f-c8e1-488b-b682-03e7a1bdf499,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-e598318e-4b8b-4a42-a73e-393cb64b9112,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-a281a4f0-4192-4846-87d9-f4a4e5b794eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-44a8158d-5928-4ca0-9541-399786567786,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-56facdbf-95aa-40a7-91b2-bf2b40d8d475,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-bf31e03d-1361-4c0e-b24c-c939753829ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-7c9a794f-0369-49ae-8fb9-717f04bd09cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82092815-172.17.0.6-1597730857062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-ea55cf52-960a-455b-bf38-9722f6341af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-1708d7cd-bf2d-4075-8a61-0b53c5cb8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-4c9f99d9-c9a6-4ee0-a397-73809acceb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-4a52ae42-6c5f-4193-83c4-4684c3df0653,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-58370579-be25-4a48-b0cd-d3973ff9c1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-d58882d0-8899-4327-b6fa-53c00de38aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-9b5bf082-fb4c-4635-b232-1ff0e273bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-e8f4d9d9-a5c2-4652-b401-40f05b87039f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82092815-172.17.0.6-1597730857062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-ea55cf52-960a-455b-bf38-9722f6341af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-1708d7cd-bf2d-4075-8a61-0b53c5cb8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-4c9f99d9-c9a6-4ee0-a397-73809acceb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-4a52ae42-6c5f-4193-83c4-4684c3df0653,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-58370579-be25-4a48-b0cd-d3973ff9c1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-d58882d0-8899-4327-b6fa-53c00de38aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-9b5bf082-fb4c-4635-b232-1ff0e273bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-e8f4d9d9-a5c2-4652-b401-40f05b87039f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309326053-172.17.0.6-1597731424914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-026d71d1-6d23-46b3-ab69-9ea4e15f083b,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-804f6d38-cf7c-43a4-b317-098255ee0dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-43825712-c88e-4db9-8239-2f8d9c04e2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-c08c3d4d-f174-48e3-af60-7334c9d61bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-6675f210-40d1-439e-b166-bfcdf81d2f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-e3f34f9d-aa3b-469b-9962-2d6ee48a2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-c84204b5-6f58-4507-ab4c-a158ac779065,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-5c8d18cf-7e2e-4e12-b7cd-9ab89b93e960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309326053-172.17.0.6-1597731424914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-026d71d1-6d23-46b3-ab69-9ea4e15f083b,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-804f6d38-cf7c-43a4-b317-098255ee0dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-43825712-c88e-4db9-8239-2f8d9c04e2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-c08c3d4d-f174-48e3-af60-7334c9d61bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-6675f210-40d1-439e-b166-bfcdf81d2f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-e3f34f9d-aa3b-469b-9962-2d6ee48a2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-c84204b5-6f58-4507-ab4c-a158ac779065,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-5c8d18cf-7e2e-4e12-b7cd-9ab89b93e960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893409974-172.17.0.6-1597732278135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-c39f4c80-cbbe-4f26-b130-9406a02525b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-16899b05-ae1e-46f5-8675-a2e674434e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-d0890b9b-f812-4ea2-a36b-e5a2090ee214,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fc317613-f407-4c55-9284-09ca1f3731eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-a7aa8a2f-1dc8-455d-ad4b-04a6f9b5fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-3387faef-c2af-4e44-b919-6ea422cee4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-79ac389d-c296-4172-900c-8066f06b2b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-57b3aacf-97b0-4323-a8bf-78d6174611b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893409974-172.17.0.6-1597732278135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-c39f4c80-cbbe-4f26-b130-9406a02525b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-16899b05-ae1e-46f5-8675-a2e674434e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-d0890b9b-f812-4ea2-a36b-e5a2090ee214,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fc317613-f407-4c55-9284-09ca1f3731eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-a7aa8a2f-1dc8-455d-ad4b-04a6f9b5fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-3387faef-c2af-4e44-b919-6ea422cee4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-79ac389d-c296-4172-900c-8066f06b2b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-57b3aacf-97b0-4323-a8bf-78d6174611b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030711248-172.17.0.6-1597732467285:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-f57ddee1-70fa-48fe-83ee-569845a05207,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-b4de6b6b-8023-4b2e-a970-b5cab6902959,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c4def18a-7aa3-440c-9e1c-b067e46ee1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-81646471-df32-4cd0-839d-26a08b55b538,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-ed9707ae-89c5-449f-b639-2446b35d4449,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-024af39e-b955-4f83-aac0-5d19bd2ef9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-b23654dd-812b-4cce-9d6a-a2e6d9a48289,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-371d5201-b4bf-4908-8187-94278e53329c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030711248-172.17.0.6-1597732467285:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-f57ddee1-70fa-48fe-83ee-569845a05207,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-b4de6b6b-8023-4b2e-a970-b5cab6902959,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c4def18a-7aa3-440c-9e1c-b067e46ee1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-81646471-df32-4cd0-839d-26a08b55b538,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-ed9707ae-89c5-449f-b639-2446b35d4449,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-024af39e-b955-4f83-aac0-5d19bd2ef9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-b23654dd-812b-4cce-9d6a-a2e6d9a48289,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-371d5201-b4bf-4908-8187-94278e53329c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148585621-172.17.0.6-1597732503923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-f2a61f53-ef54-48e0-9891-5940982345d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-d0cf4fe6-379d-4511-8d13-bc642cecd45c,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-424d6e3a-9193-4048-880f-bcc99d08862f,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-5bb520a0-e1e3-4f31-abdb-87a66207007f,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-f53b8c23-e384-415c-b0f7-f29e0be1764c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-42cd9470-53e7-4c5b-9405-13ab45002fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-a0342b41-9cd4-465a-968c-83f411f66ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-ef74cabc-ef2d-4e8c-ba52-f79394a53cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148585621-172.17.0.6-1597732503923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-f2a61f53-ef54-48e0-9891-5940982345d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-d0cf4fe6-379d-4511-8d13-bc642cecd45c,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-424d6e3a-9193-4048-880f-bcc99d08862f,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-5bb520a0-e1e3-4f31-abdb-87a66207007f,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-f53b8c23-e384-415c-b0f7-f29e0be1764c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-42cd9470-53e7-4c5b-9405-13ab45002fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-a0342b41-9cd4-465a-968c-83f411f66ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-ef74cabc-ef2d-4e8c-ba52-f79394a53cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-481642065-172.17.0.6-1597732539437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-5f03368f-8984-4b7e-b996-af233a3b38d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-10490d76-c4b6-4a44-ae1d-efc5cd9e4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-67bf8edc-e981-405b-85c2-1c81b5e40907,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-2101709c-dbf8-4c74-8b79-d3e0516d08db,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-3e5c3a01-5703-4a68-9fb5-749954551f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-aee466ae-f126-4093-9677-0845e2b07df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-aa72b54f-a277-497f-865c-926747bd4b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9fcd0ece-97a7-42a4-abfa-d3e80802c2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-481642065-172.17.0.6-1597732539437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-5f03368f-8984-4b7e-b996-af233a3b38d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-10490d76-c4b6-4a44-ae1d-efc5cd9e4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-67bf8edc-e981-405b-85c2-1c81b5e40907,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-2101709c-dbf8-4c74-8b79-d3e0516d08db,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-3e5c3a01-5703-4a68-9fb5-749954551f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-aee466ae-f126-4093-9677-0845e2b07df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-aa72b54f-a277-497f-865c-926747bd4b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9fcd0ece-97a7-42a4-abfa-d3e80802c2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677342145-172.17.0.6-1597732656227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-819b2e7d-572d-43d0-8656-41d9209cb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-119ee0a9-9b20-4318-9d78-ccbeadca42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-0b2e3153-72d9-4167-906d-25eecc41f921,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-84cad751-bcc5-46f8-a430-ad7d32d4cf86,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-837fe33f-938d-4a7e-8779-ff9243cba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-11a38ebe-42c4-40e1-91af-d39b48a89712,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-a03948df-1b8c-4b65-95b7-342a99a902ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-67e0ceff-761a-4b30-ae01-f3025861a75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677342145-172.17.0.6-1597732656227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-819b2e7d-572d-43d0-8656-41d9209cb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-119ee0a9-9b20-4318-9d78-ccbeadca42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-0b2e3153-72d9-4167-906d-25eecc41f921,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-84cad751-bcc5-46f8-a430-ad7d32d4cf86,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-837fe33f-938d-4a7e-8779-ff9243cba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-11a38ebe-42c4-40e1-91af-d39b48a89712,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-a03948df-1b8c-4b65-95b7-342a99a902ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-67e0ceff-761a-4b30-ae01-f3025861a75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510678362-172.17.0.6-1597733163407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-70f2221b-bec2-4be0-9ae2-c204e55ac2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-6b20ecb1-9f8d-48f5-b6a0-4022c4609c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-13dde6ce-539a-4a33-92cf-1e64fe07f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-0a8b9b12-f10b-4a08-a2a8-c139318e506c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-a627f2b6-3041-4c64-9a0f-6f47bf164c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-740ba54e-b16d-4b53-86b4-37e7837dda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-dcc47c99-2470-433c-8932-5c8fe319430e,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-20329c0d-5ac3-46aa-b1d2-342d24162c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510678362-172.17.0.6-1597733163407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-70f2221b-bec2-4be0-9ae2-c204e55ac2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-6b20ecb1-9f8d-48f5-b6a0-4022c4609c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-13dde6ce-539a-4a33-92cf-1e64fe07f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-0a8b9b12-f10b-4a08-a2a8-c139318e506c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-a627f2b6-3041-4c64-9a0f-6f47bf164c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-740ba54e-b16d-4b53-86b4-37e7837dda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-dcc47c99-2470-433c-8932-5c8fe319430e,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-20329c0d-5ac3-46aa-b1d2-342d24162c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536504999-172.17.0.6-1597733308916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39820,DS-06a48cd5-6075-4963-bd2b-875e902c11fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-c8efd6b3-9ab5-408f-bf1f-6112a98f2316,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-bd027ae9-d442-4775-b062-1f7f5a819d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c607c9d2-5ab1-4d89-8fee-5a6c12db5960,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e6ee97f1-2972-4acf-9fb4-a01b8a741e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-123fdb60-99cb-42a6-b76e-3708cb40800b,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-5280385c-3fa5-43b0-97fc-2062e9aa0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-435af463-b242-469d-9cc9-ce97ad72f080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536504999-172.17.0.6-1597733308916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39820,DS-06a48cd5-6075-4963-bd2b-875e902c11fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-c8efd6b3-9ab5-408f-bf1f-6112a98f2316,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-bd027ae9-d442-4775-b062-1f7f5a819d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c607c9d2-5ab1-4d89-8fee-5a6c12db5960,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e6ee97f1-2972-4acf-9fb4-a01b8a741e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-123fdb60-99cb-42a6-b76e-3708cb40800b,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-5280385c-3fa5-43b0-97fc-2062e9aa0bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-435af463-b242-469d-9cc9-ce97ad72f080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228598434-172.17.0.6-1597733380263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-a2e49eb5-045d-453c-a355-b304b205c113,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-599ea385-d13a-4eb1-a1d6-9debf69777db,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-d3b9a1e3-df6e-445e-8d25-ad2d9567b0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-128385d7-43be-4a18-9e94-8663ac6cd91d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-61bb5b33-f2ee-4bc3-b431-dfd8652becde,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-29bcef9f-0ea6-4131-954f-02e8548e5933,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-076127eb-87dc-436f-adb3-9dec4a634998,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-4f953dde-fb46-4979-84bc-c398ca17e9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228598434-172.17.0.6-1597733380263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-a2e49eb5-045d-453c-a355-b304b205c113,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-599ea385-d13a-4eb1-a1d6-9debf69777db,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-d3b9a1e3-df6e-445e-8d25-ad2d9567b0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-128385d7-43be-4a18-9e94-8663ac6cd91d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-61bb5b33-f2ee-4bc3-b431-dfd8652becde,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-29bcef9f-0ea6-4131-954f-02e8548e5933,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-076127eb-87dc-436f-adb3-9dec4a634998,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-4f953dde-fb46-4979-84bc-c398ca17e9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689481767-172.17.0.6-1597733548395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-a9af44d8-9adf-48c3-83c7-8d4d174cfdae,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c6f0f3e6-4dec-47f8-914a-78068dfd593b,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-8dd8ebf1-4fd6-42e4-8c97-ee9427ad8280,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ee6a8c39-a52b-4bb2-b3b5-a37df088048b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-ff187308-016b-4dfd-9e14-004794a11ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-cfeb82ac-c4b4-41e3-8c85-f37e66ccb903,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-b6b41d7f-b721-4d1b-9f79-ffafd4d0b38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-e83e348e-d2ca-4b7b-80db-d9600bc34851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689481767-172.17.0.6-1597733548395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-a9af44d8-9adf-48c3-83c7-8d4d174cfdae,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c6f0f3e6-4dec-47f8-914a-78068dfd593b,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-8dd8ebf1-4fd6-42e4-8c97-ee9427ad8280,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ee6a8c39-a52b-4bb2-b3b5-a37df088048b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-ff187308-016b-4dfd-9e14-004794a11ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-cfeb82ac-c4b4-41e3-8c85-f37e66ccb903,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-b6b41d7f-b721-4d1b-9f79-ffafd4d0b38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-e83e348e-d2ca-4b7b-80db-d9600bc34851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172216584-172.17.0.6-1597733747293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-599854c2-6af8-4845-a40f-957fab352e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-86975cc9-d33f-4f5a-8c34-70f8efd24f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-4d72a512-fccf-4828-8562-eb1a90d51aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-e62b7e9d-e049-4f6f-bcdc-ebd6b3ad6370,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-a173e252-f504-49bc-897b-2b6537f163b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-4f5ceaf3-8b01-4f1d-8853-8f4a9a3b24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-f90f8466-4cb3-44f2-aa4d-d4e68d9d4609,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-f75942c7-e9dd-456b-bdcd-e5432844206e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172216584-172.17.0.6-1597733747293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-599854c2-6af8-4845-a40f-957fab352e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-86975cc9-d33f-4f5a-8c34-70f8efd24f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-4d72a512-fccf-4828-8562-eb1a90d51aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-e62b7e9d-e049-4f6f-bcdc-ebd6b3ad6370,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-a173e252-f504-49bc-897b-2b6537f163b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-4f5ceaf3-8b01-4f1d-8853-8f4a9a3b24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-f90f8466-4cb3-44f2-aa4d-d4e68d9d4609,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-f75942c7-e9dd-456b-bdcd-e5432844206e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319718462-172.17.0.6-1597734349445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-029a495c-a8a4-4954-82f8-7e2fe6c24b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-bdcd9dbc-720f-4211-96d1-9391e1b340de,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6072e4a4-3556-40a4-8047-6338f87dce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b319e250-6233-421b-9734-0491efe1accd,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-c08a8ee2-30bc-4423-b5c9-19b299f39181,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-9433f7c0-ba29-4e51-b320-a1fb8ac7bf84,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-c15add6d-2314-4dd1-8411-6d17b39f832e,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9519bd79-c2fa-4944-b8f3-ba8f9c95fdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319718462-172.17.0.6-1597734349445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-029a495c-a8a4-4954-82f8-7e2fe6c24b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-bdcd9dbc-720f-4211-96d1-9391e1b340de,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6072e4a4-3556-40a4-8047-6338f87dce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b319e250-6233-421b-9734-0491efe1accd,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-c08a8ee2-30bc-4423-b5c9-19b299f39181,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-9433f7c0-ba29-4e51-b320-a1fb8ac7bf84,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-c15add6d-2314-4dd1-8411-6d17b39f832e,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9519bd79-c2fa-4944-b8f3-ba8f9c95fdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583460770-172.17.0.6-1597735271828:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-cf13fdee-3a42-44dd-a97c-62321d24a908,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-4b01ea51-4522-46fd-975e-48b6afd1667f,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-a8067f62-cd43-4934-a3b5-c9e1e5d7cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-77d06b5a-c32b-4f42-b67d-132902e24529,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-57cbe8e4-cb06-41ed-a742-7ff0fe9440a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-d09c51e4-234b-4f97-a99c-88b435555608,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-e2c5317a-c32e-4923-a8b9-97d52db22b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-906f3cf1-8dff-4e22-898a-449b4bb9becd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583460770-172.17.0.6-1597735271828:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-cf13fdee-3a42-44dd-a97c-62321d24a908,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-4b01ea51-4522-46fd-975e-48b6afd1667f,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-a8067f62-cd43-4934-a3b5-c9e1e5d7cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-77d06b5a-c32b-4f42-b67d-132902e24529,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-57cbe8e4-cb06-41ed-a742-7ff0fe9440a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-d09c51e4-234b-4f97-a99c-88b435555608,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-e2c5317a-c32e-4923-a8b9-97d52db22b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-906f3cf1-8dff-4e22-898a-449b4bb9becd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137822031-172.17.0.6-1597735901612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-7a451804-6fb7-4acc-8adb-610fd47e7080,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-434360f1-58f2-450f-96c0-0d7d67493c64,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-50c2bfc2-7ae9-492f-a6e5-51874de29c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-1bf56e06-721d-4e8a-97b3-f3058509275b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-735bca29-534b-4515-98c7-b77561e5425e,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-16c1398b-d77e-4e6e-bd56-045948cef8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-9b43a4e7-3460-45ba-90c4-e21de5281bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-9e9eb860-dd83-4a62-ae06-9f1fb7fcf598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137822031-172.17.0.6-1597735901612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-7a451804-6fb7-4acc-8adb-610fd47e7080,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-434360f1-58f2-450f-96c0-0d7d67493c64,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-50c2bfc2-7ae9-492f-a6e5-51874de29c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-1bf56e06-721d-4e8a-97b3-f3058509275b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-735bca29-534b-4515-98c7-b77561e5425e,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-16c1398b-d77e-4e6e-bd56-045948cef8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-9b43a4e7-3460-45ba-90c4-e21de5281bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-9e9eb860-dd83-4a62-ae06-9f1fb7fcf598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5864
