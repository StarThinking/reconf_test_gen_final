reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966827036-172.17.0.8-1597735652353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-6e4ff712-dd50-493c-99ec-5593766affde,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-6d4e3ba5-f549-4742-96c1-40e8e2d3b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-b7a78e72-ccb1-4270-9ff4-9be7d628f9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-999de116-a1b3-4944-b8a8-1c9650b16c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-798a93a5-2e3a-4587-a57b-311a84e20e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-8a566396-da32-449b-bc9c-461374fbfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-44637fd6-b367-4371-af93-b8ea3cf64464,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-2dd28c25-1505-4897-9cc5-1a27ae37b742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966827036-172.17.0.8-1597735652353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-6e4ff712-dd50-493c-99ec-5593766affde,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-6d4e3ba5-f549-4742-96c1-40e8e2d3b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-b7a78e72-ccb1-4270-9ff4-9be7d628f9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-999de116-a1b3-4944-b8a8-1c9650b16c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-798a93a5-2e3a-4587-a57b-311a84e20e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-8a566396-da32-449b-bc9c-461374fbfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-44637fd6-b367-4371-af93-b8ea3cf64464,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-2dd28c25-1505-4897-9cc5-1a27ae37b742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205163328-172.17.0.8-1597735688113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-c98f1f18-553b-42b5-9570-faaaeed36f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-be54b796-34e9-4d04-9779-6ee16c8430fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-e9175803-cb63-498c-a9fc-b68def987ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a1419b46-d201-4a53-9a30-a48f44a8e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-343ff30c-9fa9-4ec1-8421-6dbd26750c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-cb987822-e9e2-4c1f-9d22-6d76eb06ded5,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-9260ed6f-b4c1-42a9-9d17-fbaf8cb4babb,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-7e74b9c8-f07b-4ef2-aee5-e679e8105d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205163328-172.17.0.8-1597735688113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-c98f1f18-553b-42b5-9570-faaaeed36f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-be54b796-34e9-4d04-9779-6ee16c8430fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-e9175803-cb63-498c-a9fc-b68def987ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a1419b46-d201-4a53-9a30-a48f44a8e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-343ff30c-9fa9-4ec1-8421-6dbd26750c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-cb987822-e9e2-4c1f-9d22-6d76eb06ded5,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-9260ed6f-b4c1-42a9-9d17-fbaf8cb4babb,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-7e74b9c8-f07b-4ef2-aee5-e679e8105d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660251626-172.17.0.8-1597736021552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-7669328a-9f34-4a3f-b486-d7224b16b772,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-c8969bd5-c73d-4238-8a44-24bd60162cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-9d848863-ae14-48d2-90eb-d6b6f4f840ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-fe4012d5-d731-4a8b-aed7-6f95818dfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-43b25cf5-de70-46c3-9a2e-1b8630a17f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-4883e155-8cfa-41a5-975d-9e9217aa0b87,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-74b1028c-393c-4279-b518-b24b53566f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-0c86fafa-a1df-492f-9231-2da9ebaf9e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660251626-172.17.0.8-1597736021552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-7669328a-9f34-4a3f-b486-d7224b16b772,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-c8969bd5-c73d-4238-8a44-24bd60162cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-9d848863-ae14-48d2-90eb-d6b6f4f840ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-fe4012d5-d731-4a8b-aed7-6f95818dfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-43b25cf5-de70-46c3-9a2e-1b8630a17f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-4883e155-8cfa-41a5-975d-9e9217aa0b87,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-74b1028c-393c-4279-b518-b24b53566f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-0c86fafa-a1df-492f-9231-2da9ebaf9e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344307437-172.17.0.8-1597736058414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-454083fe-5ce5-4c51-9d3a-9c7625526003,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-db918800-df49-402f-a26e-3abbe7adfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-1df6e7d8-ad6e-4c44-88a1-ea8ecaebd991,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-4b79fa71-84f8-4286-93be-4cd7f71da9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-e140da17-c1fb-46de-a734-ad0b3c648eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-6057833e-d4a0-43ec-b688-ef11cb0fde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-ce39c567-fcfa-4aed-94aa-fefad4f2d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-60c1fc51-e364-4983-a1e5-22f06cafc46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344307437-172.17.0.8-1597736058414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-454083fe-5ce5-4c51-9d3a-9c7625526003,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-db918800-df49-402f-a26e-3abbe7adfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-1df6e7d8-ad6e-4c44-88a1-ea8ecaebd991,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-4b79fa71-84f8-4286-93be-4cd7f71da9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-e140da17-c1fb-46de-a734-ad0b3c648eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-6057833e-d4a0-43ec-b688-ef11cb0fde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-ce39c567-fcfa-4aed-94aa-fefad4f2d8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-60c1fc51-e364-4983-a1e5-22f06cafc46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846718229-172.17.0.8-1597736273519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-b6c22e26-a51e-4693-8b93-14f48e837f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-dc2ab7e4-8e80-45a1-89dd-91c2c5d29893,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-fb02a586-c6cb-40cd-9aac-e2fd7adcd8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-03fd71b8-a4c6-40c5-8c50-5528a151174f,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-d3a43482-673c-4cc0-a3d9-271df19f0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-dc1b3a9b-a6d9-45f2-b86f-4bf316396186,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c59c4224-178e-4118-8d0c-0430c13f6533,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-1ab191bd-c669-41d7-9d24-43c1fd007750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846718229-172.17.0.8-1597736273519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-b6c22e26-a51e-4693-8b93-14f48e837f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-dc2ab7e4-8e80-45a1-89dd-91c2c5d29893,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-fb02a586-c6cb-40cd-9aac-e2fd7adcd8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-03fd71b8-a4c6-40c5-8c50-5528a151174f,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-d3a43482-673c-4cc0-a3d9-271df19f0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-dc1b3a9b-a6d9-45f2-b86f-4bf316396186,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c59c4224-178e-4118-8d0c-0430c13f6533,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-1ab191bd-c669-41d7-9d24-43c1fd007750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823471944-172.17.0.8-1597736937188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-89594ca8-2c5f-467a-b79a-5a4f966a046d,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-58d3c654-664c-4fba-8ded-98971b4cff25,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-bdd92f5e-d8c3-4521-82fe-596a69b64b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-ef7ab284-fd28-4359-9109-c412374025dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-90a5ba61-283a-4941-b0e5-9e0adbaf5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-010977e5-03f2-4d91-b26c-9b98e9055f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-a6f553c7-e484-4e1e-847c-bae479726d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-c5b168ce-b475-4736-85d4-ecd42dc2da8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823471944-172.17.0.8-1597736937188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-89594ca8-2c5f-467a-b79a-5a4f966a046d,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-58d3c654-664c-4fba-8ded-98971b4cff25,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-bdd92f5e-d8c3-4521-82fe-596a69b64b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-ef7ab284-fd28-4359-9109-c412374025dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-90a5ba61-283a-4941-b0e5-9e0adbaf5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-010977e5-03f2-4d91-b26c-9b98e9055f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-a6f553c7-e484-4e1e-847c-bae479726d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-c5b168ce-b475-4736-85d4-ecd42dc2da8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649061126-172.17.0.8-1597737476377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-25263ffc-6bbf-4592-9940-c4d99ab289eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-258844a8-9d57-4814-bfbc-eb215c52db61,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-78236613-4395-4860-92f5-c4cdd15a8178,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-cf6b05b4-1789-4d4c-9f9b-a9090339e053,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-871b56e0-1b26-41f6-a39f-5054a33c27bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-5020d2c3-887d-405c-a24e-b0dd3f0eb355,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-2effe2f6-e9bd-4609-8bac-53678f2d7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-b4ccaf2c-e630-41fb-881a-e95d62bca913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649061126-172.17.0.8-1597737476377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-25263ffc-6bbf-4592-9940-c4d99ab289eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-258844a8-9d57-4814-bfbc-eb215c52db61,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-78236613-4395-4860-92f5-c4cdd15a8178,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-cf6b05b4-1789-4d4c-9f9b-a9090339e053,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-871b56e0-1b26-41f6-a39f-5054a33c27bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-5020d2c3-887d-405c-a24e-b0dd3f0eb355,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-2effe2f6-e9bd-4609-8bac-53678f2d7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-b4ccaf2c-e630-41fb-881a-e95d62bca913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487336803-172.17.0.8-1597737512942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-361dc483-cdda-4226-b3a0-d78957a14021,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-02a56a94-39c1-4bf2-9651-5958c39e3376,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-e7bdb053-8bf6-4b13-86ed-553e1af7810e,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-38a9a7d2-ad78-44d0-9871-50515c7e5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-62d0e76f-a4ff-4664-b3c1-b6d429a0a116,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-138366a7-9f5b-4bc5-9743-54bc650d66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-40bcef14-c4a0-4310-a517-0a6313937b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-1b6ee9b2-bfe4-4ea6-97e6-135c8242c749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487336803-172.17.0.8-1597737512942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-361dc483-cdda-4226-b3a0-d78957a14021,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-02a56a94-39c1-4bf2-9651-5958c39e3376,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-e7bdb053-8bf6-4b13-86ed-553e1af7810e,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-38a9a7d2-ad78-44d0-9871-50515c7e5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-62d0e76f-a4ff-4664-b3c1-b6d429a0a116,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-138366a7-9f5b-4bc5-9743-54bc650d66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-40bcef14-c4a0-4310-a517-0a6313937b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-1b6ee9b2-bfe4-4ea6-97e6-135c8242c749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123738703-172.17.0.8-1597737868385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-cee6dee7-430a-4d3d-8965-bd736deacae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-8fb31a36-ae1d-42d1-9c09-5691206bf786,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-6b6676a8-cec7-4223-917a-1ae9437020bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-37497195-7a53-4c06-b594-02a156b188f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-21ebd467-9771-47d8-8a06-9e84790a3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-0b5cf200-e38a-4f6e-b705-cd5e800c2208,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-aef7e146-4f05-4295-87dd-c5695e53bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-dde030ee-c725-43e5-b516-81e427758aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123738703-172.17.0.8-1597737868385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-cee6dee7-430a-4d3d-8965-bd736deacae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-8fb31a36-ae1d-42d1-9c09-5691206bf786,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-6b6676a8-cec7-4223-917a-1ae9437020bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-37497195-7a53-4c06-b594-02a156b188f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-21ebd467-9771-47d8-8a06-9e84790a3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-0b5cf200-e38a-4f6e-b705-cd5e800c2208,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-aef7e146-4f05-4295-87dd-c5695e53bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-dde030ee-c725-43e5-b516-81e427758aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012754808-172.17.0.8-1597737955108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-380f4ba9-64ec-4086-b4bf-bbebe2d727b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-dc7085c4-82b3-4866-9a8e-537d0d71fbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-b5dcfff4-0171-4209-a8ae-a20eacae2700,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-f921aa62-df63-4ddc-a77a-154eb9e524d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-1e30b7f0-c351-4db9-bb41-54439bb99672,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-e9347de4-8494-4d0f-ba3c-0ff3223c8244,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-5af07243-d57a-43ea-871d-239e0620675e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-6fdb6e5f-9694-4d9f-b865-d958e34067af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012754808-172.17.0.8-1597737955108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-380f4ba9-64ec-4086-b4bf-bbebe2d727b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-dc7085c4-82b3-4866-9a8e-537d0d71fbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-b5dcfff4-0171-4209-a8ae-a20eacae2700,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-f921aa62-df63-4ddc-a77a-154eb9e524d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-1e30b7f0-c351-4db9-bb41-54439bb99672,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-e9347de4-8494-4d0f-ba3c-0ff3223c8244,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-5af07243-d57a-43ea-871d-239e0620675e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-6fdb6e5f-9694-4d9f-b865-d958e34067af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058789977-172.17.0.8-1597738646989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-a44132b7-5cab-4096-9b9a-e545ba2c3eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-47573e42-42ef-4000-ac91-e03bee850495,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-d56925f5-43a8-4086-9bd5-255d1b1b4256,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-cc17de1b-1fdd-4a68-98e8-6dec63dbdd93,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-8c14d01f-5bf3-48c8-b5ae-978c8aae574c,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ddad2d1b-1f7c-4dfa-8d2d-5012a1ad58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5bdc2df2-6806-4abb-92eb-a574d2066bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-27f6ce5d-79e5-4194-8b79-6170ee65ed2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058789977-172.17.0.8-1597738646989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-a44132b7-5cab-4096-9b9a-e545ba2c3eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-47573e42-42ef-4000-ac91-e03bee850495,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-d56925f5-43a8-4086-9bd5-255d1b1b4256,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-cc17de1b-1fdd-4a68-98e8-6dec63dbdd93,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-8c14d01f-5bf3-48c8-b5ae-978c8aae574c,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ddad2d1b-1f7c-4dfa-8d2d-5012a1ad58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5bdc2df2-6806-4abb-92eb-a574d2066bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-27f6ce5d-79e5-4194-8b79-6170ee65ed2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298739198-172.17.0.8-1597738688760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-68d33761-c01e-4bb1-a410-524b561c3825,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-fba93cae-c571-4903-a49f-d1eeaeefcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-9a9a0c37-3a76-464e-b001-39f3bc34c721,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-69e9fad8-3a61-4dde-bb19-10a01d7e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-1aefbb03-c844-4741-81f0-d93e630c5bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-dfb39ff6-4a59-4185-83ae-e8065ca9aac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-57806e38-c005-499a-ae82-1d9897866f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-344cabaf-3bb9-4e54-882d-6eabfbdb6a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298739198-172.17.0.8-1597738688760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-68d33761-c01e-4bb1-a410-524b561c3825,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-fba93cae-c571-4903-a49f-d1eeaeefcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-9a9a0c37-3a76-464e-b001-39f3bc34c721,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-69e9fad8-3a61-4dde-bb19-10a01d7e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-1aefbb03-c844-4741-81f0-d93e630c5bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-dfb39ff6-4a59-4185-83ae-e8065ca9aac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-57806e38-c005-499a-ae82-1d9897866f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-344cabaf-3bb9-4e54-882d-6eabfbdb6a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634006468-172.17.0.8-1597738725911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-7cbe3664-ad35-4b21-a57f-9ebd5540a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-9d181dd1-d4c0-40c6-a435-4f9e9510ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-5601405f-f572-4637-82fa-f0f3cfd3dadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-55c4d3c8-65a5-4fcf-89d2-d4b0fbb8edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-e3892264-ebad-4a35-a4b2-79acb777c8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-5787e49e-a5e9-42d3-9135-62edd8d26926,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-e2a24983-6279-4821-a2d8-01b04f30020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-956f57bc-8cc0-4539-adba-00a5101a73db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634006468-172.17.0.8-1597738725911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-7cbe3664-ad35-4b21-a57f-9ebd5540a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-9d181dd1-d4c0-40c6-a435-4f9e9510ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-5601405f-f572-4637-82fa-f0f3cfd3dadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-55c4d3c8-65a5-4fcf-89d2-d4b0fbb8edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-e3892264-ebad-4a35-a4b2-79acb777c8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-5787e49e-a5e9-42d3-9135-62edd8d26926,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-e2a24983-6279-4821-a2d8-01b04f30020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-956f57bc-8cc0-4539-adba-00a5101a73db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208004038-172.17.0.8-1597739039611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-100147d9-fb04-4006-96ed-0e156d114546,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-dc909b0b-88c1-4b2a-9e50-ec02f8fa3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-b1fbce47-2345-43ac-bdc1-88115847bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-eae0c028-7587-4368-b3df-0ac5839db136,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-d2ec04f5-83aa-4b4c-a09d-0ccdbbe7a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-931909fe-beb7-4228-8b30-9b10d0a37df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-a2a204f2-e29a-4f06-89b7-338d52ad5226,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-f96001c2-34ea-464e-9c0c-ad248c3c577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208004038-172.17.0.8-1597739039611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-100147d9-fb04-4006-96ed-0e156d114546,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-dc909b0b-88c1-4b2a-9e50-ec02f8fa3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-b1fbce47-2345-43ac-bdc1-88115847bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-eae0c028-7587-4368-b3df-0ac5839db136,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-d2ec04f5-83aa-4b4c-a09d-0ccdbbe7a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-931909fe-beb7-4228-8b30-9b10d0a37df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-a2a204f2-e29a-4f06-89b7-338d52ad5226,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-f96001c2-34ea-464e-9c0c-ad248c3c577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757057979-172.17.0.8-1597739072259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-3fbe86f3-0ae5-4209-9a6c-398b88b49adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-05e8889e-a32a-425b-a35a-5700955c40f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-9dbf67e4-b649-4c3f-81ec-456af0103355,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-6b4ec3ae-0b75-484d-adaa-4fc7a76572f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-ea95a275-73a8-4e30-9253-cd2e2f2363bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-d9d1e50c-a935-4da0-ae4a-fb5862739c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-540db732-ab26-445c-99bc-e5b26b92ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-1091ea42-7d7b-4024-a638-40a8e616c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757057979-172.17.0.8-1597739072259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-3fbe86f3-0ae5-4209-9a6c-398b88b49adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-05e8889e-a32a-425b-a35a-5700955c40f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-9dbf67e4-b649-4c3f-81ec-456af0103355,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-6b4ec3ae-0b75-484d-adaa-4fc7a76572f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-ea95a275-73a8-4e30-9253-cd2e2f2363bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-d9d1e50c-a935-4da0-ae4a-fb5862739c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-540db732-ab26-445c-99bc-e5b26b92ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-1091ea42-7d7b-4024-a638-40a8e616c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310312181-172.17.0.8-1597739965313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-d272e2ba-d300-46a3-bd9a-2418954a7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-67f4693a-0e5c-4ec0-8fd0-29bc4caddfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-63031304-f508-4bf6-820b-cbc9c1f4a1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-79285404-8caa-4517-a680-8cfe0648d4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a4d2c974-ee1b-466f-a35d-7cc21563d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-63221c76-18ba-42d1-ba7a-6e21174fced1,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-3ef8d56f-67c6-4917-ad32-b743ff51457e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-03114c4b-3550-4fef-b003-d32b995c3acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310312181-172.17.0.8-1597739965313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-d272e2ba-d300-46a3-bd9a-2418954a7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-67f4693a-0e5c-4ec0-8fd0-29bc4caddfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-63031304-f508-4bf6-820b-cbc9c1f4a1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-79285404-8caa-4517-a680-8cfe0648d4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a4d2c974-ee1b-466f-a35d-7cc21563d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-63221c76-18ba-42d1-ba7a-6e21174fced1,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-3ef8d56f-67c6-4917-ad32-b743ff51457e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-03114c4b-3550-4fef-b003-d32b995c3acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241677247-172.17.0.8-1597740007361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-2c63a970-4ddf-489d-ae2d-877f6a24e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-43250056-9da2-472c-a8e1-a0bebe9e62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-13ffc0e2-d14d-4049-b6bd-0b6df844587c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-bb0dd7fb-38d8-49cf-b15d-d231e0c4baee,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-8df0c5eb-99cb-4b85-a88c-c5a8f3d13eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-229a0035-7691-4626-8edc-2220e51dba57,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-41982005-60e6-4ced-876e-63d08381a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-df85c5b1-fbbd-482c-9fe8-4c7ea59236fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241677247-172.17.0.8-1597740007361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-2c63a970-4ddf-489d-ae2d-877f6a24e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-43250056-9da2-472c-a8e1-a0bebe9e62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-13ffc0e2-d14d-4049-b6bd-0b6df844587c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-bb0dd7fb-38d8-49cf-b15d-d231e0c4baee,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-8df0c5eb-99cb-4b85-a88c-c5a8f3d13eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-229a0035-7691-4626-8edc-2220e51dba57,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-41982005-60e6-4ced-876e-63d08381a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-df85c5b1-fbbd-482c-9fe8-4c7ea59236fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136927874-172.17.0.8-1597740079739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-a1203420-928f-4834-a7bd-7fc1a794682e,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-2222a62d-7cfd-45db-b728-de983a4efb25,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d0ad45e9-293b-493f-9e49-2f16c21c317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-f45f8818-6f26-48ef-aeab-3459b733146e,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-685641b7-0816-4379-9db8-42b777c39be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-82ce6215-630f-47c1-bcd6-b3f0ac9c614f,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-2ab18a57-a2ab-4329-bc04-f0cf41e5024f,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-bcd8f6e4-189a-41cf-9dcf-f86fff8f0113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136927874-172.17.0.8-1597740079739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-a1203420-928f-4834-a7bd-7fc1a794682e,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-2222a62d-7cfd-45db-b728-de983a4efb25,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d0ad45e9-293b-493f-9e49-2f16c21c317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-f45f8818-6f26-48ef-aeab-3459b733146e,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-685641b7-0816-4379-9db8-42b777c39be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-82ce6215-630f-47c1-bcd6-b3f0ac9c614f,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-2ab18a57-a2ab-4329-bc04-f0cf41e5024f,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-bcd8f6e4-189a-41cf-9dcf-f86fff8f0113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945704826-172.17.0.8-1597740591310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-9a9e995b-958f-4e3d-b09c-2cdf102d3679,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-d109bd57-5990-4474-88d6-8a441136014c,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-81f83389-2615-44cb-97ec-33cc6fcf054b,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-7d64d441-8500-44d5-ad2b-2643d1e252f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-f75be396-7e45-40ec-9da7-0e70313a7057,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-fc240522-0665-4961-bbd6-0e650273acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-32c89ba2-34e0-4132-a67e-dfaa73b63c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-f4059ec8-be3b-4eee-a9e5-4ff509b6f032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945704826-172.17.0.8-1597740591310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-9a9e995b-958f-4e3d-b09c-2cdf102d3679,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-d109bd57-5990-4474-88d6-8a441136014c,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-81f83389-2615-44cb-97ec-33cc6fcf054b,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-7d64d441-8500-44d5-ad2b-2643d1e252f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-f75be396-7e45-40ec-9da7-0e70313a7057,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-fc240522-0665-4961-bbd6-0e650273acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-32c89ba2-34e0-4132-a67e-dfaa73b63c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-f4059ec8-be3b-4eee-a9e5-4ff509b6f032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858929076-172.17.0.8-1597740799103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-9035fb90-f93c-40ee-9f66-e7855f7ecbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-2b4ebd26-53a2-4c07-9d22-5258c6f5419f,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-eb346073-6ec0-4695-b120-8a279982adb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-8c3cb85d-dc1d-4bf1-a35e-36c4f55dcb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-70859be3-ca46-4756-a153-8bb0bc9242d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-51e78f28-ff85-4f8d-9583-519b06105b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-cdbecedc-7795-44a2-b1c3-3a8269f67290,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-469c17d4-66fb-4f8b-934e-da987b038a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858929076-172.17.0.8-1597740799103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-9035fb90-f93c-40ee-9f66-e7855f7ecbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-2b4ebd26-53a2-4c07-9d22-5258c6f5419f,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-eb346073-6ec0-4695-b120-8a279982adb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-8c3cb85d-dc1d-4bf1-a35e-36c4f55dcb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-70859be3-ca46-4756-a153-8bb0bc9242d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-51e78f28-ff85-4f8d-9583-519b06105b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-cdbecedc-7795-44a2-b1c3-3a8269f67290,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-469c17d4-66fb-4f8b-934e-da987b038a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895881266-172.17.0.8-1597740911334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-700d8f56-d10f-4865-9e41-12ec943ac777,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-9c70f685-5270-42ce-a766-28f81c3a01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-5e44083b-f04e-4d1f-93b4-11a997b83101,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c8973d90-139f-422f-97ba-0ad4c0522a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-3d56e2c3-46d5-457f-9c87-830335195285,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-59ce46a6-be54-4cb6-95d9-3d9886db82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-d88a55af-939c-4693-aff2-501d538eea81,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-0a3b6e7c-d1db-4d21-9568-69b5bf3b7502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895881266-172.17.0.8-1597740911334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-700d8f56-d10f-4865-9e41-12ec943ac777,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-9c70f685-5270-42ce-a766-28f81c3a01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-5e44083b-f04e-4d1f-93b4-11a997b83101,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c8973d90-139f-422f-97ba-0ad4c0522a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-3d56e2c3-46d5-457f-9c87-830335195285,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-59ce46a6-be54-4cb6-95d9-3d9886db82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-d88a55af-939c-4693-aff2-501d538eea81,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-0a3b6e7c-d1db-4d21-9568-69b5bf3b7502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301324703-172.17.0.8-1597740987976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41066,DS-86f77e65-4dde-426d-96ff-7c65effc206e,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-7c72e1dc-8765-4dd7-8ca2-820d05784b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-250e9514-92ad-4f18-8089-e80007fb30f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-80ca6700-e678-4642-9f4d-8b357957fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-1c3f60ed-684b-40c9-a744-caef60af27e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-a74ff2dc-c4ba-429f-8656-c41f0eb84d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-33ac047c-9eae-448d-b0d5-7a7570570bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a4cb54f0-99a3-414a-99b6-a630a276e22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301324703-172.17.0.8-1597740987976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41066,DS-86f77e65-4dde-426d-96ff-7c65effc206e,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-7c72e1dc-8765-4dd7-8ca2-820d05784b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-250e9514-92ad-4f18-8089-e80007fb30f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-80ca6700-e678-4642-9f4d-8b357957fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-1c3f60ed-684b-40c9-a744-caef60af27e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-a74ff2dc-c4ba-429f-8656-c41f0eb84d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-33ac047c-9eae-448d-b0d5-7a7570570bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a4cb54f0-99a3-414a-99b6-a630a276e22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5524
