reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612685350-172.17.0.21-1597642686547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-15566273-f95f-4c86-9773-b5ceed2ac57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-38acfd7c-c3ca-4d19-a3e4-f30e85e89946,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c4641efc-24cc-4b98-a9c0-27054f33fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ca39d41f-ed4f-4ed0-8ef8-1df76d4b38e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-81bcbb56-0cb8-49bb-86d8-6f1bee0bcb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-c3befc5d-2793-4072-8f1e-7deb6610a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bb054df6-686b-4609-abf9-022477ef3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-47af038f-47d0-495d-a95a-2ddae77951e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612685350-172.17.0.21-1597642686547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-15566273-f95f-4c86-9773-b5ceed2ac57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-38acfd7c-c3ca-4d19-a3e4-f30e85e89946,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c4641efc-24cc-4b98-a9c0-27054f33fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ca39d41f-ed4f-4ed0-8ef8-1df76d4b38e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-81bcbb56-0cb8-49bb-86d8-6f1bee0bcb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-c3befc5d-2793-4072-8f1e-7deb6610a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-bb054df6-686b-4609-abf9-022477ef3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-47af038f-47d0-495d-a95a-2ddae77951e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698310809-172.17.0.21-1597642755886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-346a5ce8-f395-4a3e-82b7-7b99e7d6155d,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-e620dcc2-1bea-43de-8fab-4ea63cbbc007,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-a85a51e0-cba7-4ea1-a6f0-106b1f92678f,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-69d69ea2-cb7f-4efe-a5ef-88145eea5470,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-76999fce-c3dc-4788-b4bc-fe4faa77baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-bb86e044-0e3b-43f5-82df-78de7c1dda09,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-264c9b0a-cb09-4217-b800-fd2888109106,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-0162984e-b025-43c7-95b8-fc53d45ccc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698310809-172.17.0.21-1597642755886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-346a5ce8-f395-4a3e-82b7-7b99e7d6155d,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-e620dcc2-1bea-43de-8fab-4ea63cbbc007,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-a85a51e0-cba7-4ea1-a6f0-106b1f92678f,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-69d69ea2-cb7f-4efe-a5ef-88145eea5470,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-76999fce-c3dc-4788-b4bc-fe4faa77baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-bb86e044-0e3b-43f5-82df-78de7c1dda09,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-264c9b0a-cb09-4217-b800-fd2888109106,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-0162984e-b025-43c7-95b8-fc53d45ccc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56225301-172.17.0.21-1597643092658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-5f8703fc-0066-4706-b1f3-032737250a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-e32c28ad-5aac-41bb-bf42-55283e64d539,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-c718c282-1508-4da2-a342-d76ba1be6345,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-10ff3957-7e01-4936-b01c-9a428d793545,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e48763d7-ac3c-4622-a318-5d56fe3742bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-3684ea66-a9aa-4bf2-9ca4-4a45dab58724,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-4de4d63a-7b1f-4e36-9817-f2a2040e51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-610eac6c-447e-4a08-950f-f783910dd442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56225301-172.17.0.21-1597643092658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-5f8703fc-0066-4706-b1f3-032737250a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-e32c28ad-5aac-41bb-bf42-55283e64d539,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-c718c282-1508-4da2-a342-d76ba1be6345,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-10ff3957-7e01-4936-b01c-9a428d793545,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e48763d7-ac3c-4622-a318-5d56fe3742bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-3684ea66-a9aa-4bf2-9ca4-4a45dab58724,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-4de4d63a-7b1f-4e36-9817-f2a2040e51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-610eac6c-447e-4a08-950f-f783910dd442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064578486-172.17.0.21-1597643443939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-34d924d7-8310-4f9c-ace1-342511457a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-fdc210b5-533b-47b9-a97f-0487993783e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-dabd2a2f-463d-4301-8c47-5e340b566934,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-1069f47c-652a-4380-9264-cf3b1010f554,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-a870d83e-66df-4932-8909-c71fba318aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-4f68566b-75dd-49d4-9434-9971f3aa22a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-5dd0d5c9-f0c3-4b2a-bde0-79a6ab572752,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e230d488-7df6-4bab-be7b-1874a5f4802d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064578486-172.17.0.21-1597643443939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-34d924d7-8310-4f9c-ace1-342511457a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-fdc210b5-533b-47b9-a97f-0487993783e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-dabd2a2f-463d-4301-8c47-5e340b566934,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-1069f47c-652a-4380-9264-cf3b1010f554,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-a870d83e-66df-4932-8909-c71fba318aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-4f68566b-75dd-49d4-9434-9971f3aa22a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-5dd0d5c9-f0c3-4b2a-bde0-79a6ab572752,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e230d488-7df6-4bab-be7b-1874a5f4802d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92161229-172.17.0.21-1597643480642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37285,DS-c4f736bd-e9eb-42a6-9c57-5a4452260e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-8a2f9d45-97c5-4639-af76-6c293c601446,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-7e446bbe-c7dd-4a30-9aea-d7fd5b9fd937,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-d455cb42-92b8-41fc-82f5-5259c09b992c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-840934c2-aa8d-456c-94b3-2e5e9eaa1a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-f7037be0-d8b4-4037-9582-a50027b79f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-78ca6c14-cd77-43f7-b8d1-76128975dbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-6354ab51-33c3-40b0-b512-8fdd098ab931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92161229-172.17.0.21-1597643480642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37285,DS-c4f736bd-e9eb-42a6-9c57-5a4452260e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-8a2f9d45-97c5-4639-af76-6c293c601446,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-7e446bbe-c7dd-4a30-9aea-d7fd5b9fd937,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-d455cb42-92b8-41fc-82f5-5259c09b992c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-840934c2-aa8d-456c-94b3-2e5e9eaa1a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-f7037be0-d8b4-4037-9582-a50027b79f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-78ca6c14-cd77-43f7-b8d1-76128975dbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-6354ab51-33c3-40b0-b512-8fdd098ab931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358206730-172.17.0.21-1597644101486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-d316d039-1076-4e10-ba02-705a7a03fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-13238a20-93f3-45dc-ae8f-60552a203ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-040a5193-55a2-44fd-bc6d-7b8db2dc8ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a7ae91d3-c986-4a28-8724-cc5e7b838a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-8af8b7af-5780-474e-8339-345b016f956e,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-a8e277e5-f305-460f-8555-7a13f3758dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-a87a7930-8a49-46a7-8337-89a74f72bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-54cbeff2-31d1-4b58-a194-60e72ba7a252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358206730-172.17.0.21-1597644101486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-d316d039-1076-4e10-ba02-705a7a03fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-13238a20-93f3-45dc-ae8f-60552a203ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-040a5193-55a2-44fd-bc6d-7b8db2dc8ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a7ae91d3-c986-4a28-8724-cc5e7b838a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-8af8b7af-5780-474e-8339-345b016f956e,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-a8e277e5-f305-460f-8555-7a13f3758dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-a87a7930-8a49-46a7-8337-89a74f72bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-54cbeff2-31d1-4b58-a194-60e72ba7a252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697261811-172.17.0.21-1597644395203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-dd4e48e1-85cf-4a21-ba24-158b60ca4d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-5cb09108-aab0-4f38-9df2-3c75ef6222da,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-3246adb8-239f-47a4-ab15-64512da6dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-827c5539-76c5-4a66-969f-def3c77c4e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-9cfd09bd-0cf2-436b-ac8e-fa707fc58791,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-826cef7c-d3bd-422c-826f-38f2e7f934d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-43e670f5-058b-479e-88a4-e9610321f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-08d82fab-292d-4e54-a995-c70f2b1388da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697261811-172.17.0.21-1597644395203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-dd4e48e1-85cf-4a21-ba24-158b60ca4d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-5cb09108-aab0-4f38-9df2-3c75ef6222da,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-3246adb8-239f-47a4-ab15-64512da6dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-827c5539-76c5-4a66-969f-def3c77c4e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-9cfd09bd-0cf2-436b-ac8e-fa707fc58791,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-826cef7c-d3bd-422c-826f-38f2e7f934d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-43e670f5-058b-479e-88a4-e9610321f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-08d82fab-292d-4e54-a995-c70f2b1388da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020182194-172.17.0.21-1597644902323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-8afe4aff-ce65-489a-bc28-b86841d49ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-daa8ab8b-c722-4bab-90ad-6c6ab4d466c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-cd8fd482-4359-40bd-8ae8-14046bfda000,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-922d0b42-01d9-48da-bc06-e658d6e664bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-4ac06254-27c6-45e0-bfc3-f74dc82967d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-08d3157e-2faa-40b3-9def-23a482abbec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c7ab0adc-3c09-4d1c-a59d-97806d64d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-d247476f-984e-48ff-9fbd-0942bcc2ac3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020182194-172.17.0.21-1597644902323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-8afe4aff-ce65-489a-bc28-b86841d49ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-daa8ab8b-c722-4bab-90ad-6c6ab4d466c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-cd8fd482-4359-40bd-8ae8-14046bfda000,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-922d0b42-01d9-48da-bc06-e658d6e664bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-4ac06254-27c6-45e0-bfc3-f74dc82967d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-08d3157e-2faa-40b3-9def-23a482abbec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c7ab0adc-3c09-4d1c-a59d-97806d64d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-d247476f-984e-48ff-9fbd-0942bcc2ac3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042212936-172.17.0.21-1597646034787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-3408c79c-ace5-496b-adf4-968644681b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6627fbcd-aa73-4eef-b794-6399944fa54c,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-a8c3b084-5d0d-4769-b3fe-422a81dac4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-ca4aab67-dfbd-4419-bea0-98de1cf807b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-2baa99c5-49ad-4eda-9d71-980e9b9026b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-728dab98-c5f2-43ca-aead-c8b415e2d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-e4b2a87c-90d5-495f-9d27-cc2a83cd092a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-d5dc154e-df94-4d47-8ce8-37bceb5156e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042212936-172.17.0.21-1597646034787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-3408c79c-ace5-496b-adf4-968644681b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6627fbcd-aa73-4eef-b794-6399944fa54c,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-a8c3b084-5d0d-4769-b3fe-422a81dac4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-ca4aab67-dfbd-4419-bea0-98de1cf807b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-2baa99c5-49ad-4eda-9d71-980e9b9026b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-728dab98-c5f2-43ca-aead-c8b415e2d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-e4b2a87c-90d5-495f-9d27-cc2a83cd092a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-d5dc154e-df94-4d47-8ce8-37bceb5156e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102371948-172.17.0.21-1597646338738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-aa6b39e2-89c3-40e9-abf9-ed3be01448f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-5d7e2201-aff1-43cc-b1f8-ca588a6c8993,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-f8162ae1-700f-460b-a9e9-d69b9f188fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-2b09d3b3-508c-409f-b9a6-b04accb53ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-78d401b7-7176-49b3-a520-3ac080661535,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-b0d8f743-4ac8-48b7-bfe4-cdd597f7681c,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-0611d3b6-bd66-4194-9645-3a7f75484c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-cf002033-d1eb-493c-b40d-172c4e66d650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102371948-172.17.0.21-1597646338738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-aa6b39e2-89c3-40e9-abf9-ed3be01448f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-5d7e2201-aff1-43cc-b1f8-ca588a6c8993,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-f8162ae1-700f-460b-a9e9-d69b9f188fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-2b09d3b3-508c-409f-b9a6-b04accb53ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-78d401b7-7176-49b3-a520-3ac080661535,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-b0d8f743-4ac8-48b7-bfe4-cdd597f7681c,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-0611d3b6-bd66-4194-9645-3a7f75484c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-cf002033-d1eb-493c-b40d-172c4e66d650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025152137-172.17.0.21-1597647016491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33732,DS-9ddc2851-1c4b-4d7a-8d89-ddda9fc2980d,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-970d4600-c61e-4b20-9657-2476f592d776,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-3f537f57-eba7-4e3a-b8ac-16b357fa56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-187005ce-17b5-4311-a644-8858ef6c1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-b191621e-069f-465c-9f30-3927c8b139bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-48cd9501-5a6c-475a-8ea0-32da4eb568b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-1e3d9a1f-43d2-465a-b472-e17622099975,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-bba1ea2a-6f50-48cd-aa6b-c145156422e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025152137-172.17.0.21-1597647016491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33732,DS-9ddc2851-1c4b-4d7a-8d89-ddda9fc2980d,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-970d4600-c61e-4b20-9657-2476f592d776,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-3f537f57-eba7-4e3a-b8ac-16b357fa56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-187005ce-17b5-4311-a644-8858ef6c1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-b191621e-069f-465c-9f30-3927c8b139bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-48cd9501-5a6c-475a-8ea0-32da4eb568b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-1e3d9a1f-43d2-465a-b472-e17622099975,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-bba1ea2a-6f50-48cd-aa6b-c145156422e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119478689-172.17.0.21-1597647343590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-a589a5da-258e-4ba4-b31d-379ddbfa1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-84424a86-5eaa-46c6-b43b-37f48453dad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-2a87c5af-4366-4e97-8a5a-7b6125ad5a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-2857c707-eb4e-49c4-ac11-ed56955b20a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-5d1f9275-aec9-434c-80ee-79db7c9ff1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-bd3b0363-46ca-4400-8e65-1d2f045a206a,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-c00813b6-2fb4-465e-9548-cadd4d346177,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-ac2ec227-52b1-4c8b-ae86-9be8f4e4cfb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119478689-172.17.0.21-1597647343590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-a589a5da-258e-4ba4-b31d-379ddbfa1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-84424a86-5eaa-46c6-b43b-37f48453dad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-2a87c5af-4366-4e97-8a5a-7b6125ad5a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-2857c707-eb4e-49c4-ac11-ed56955b20a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-5d1f9275-aec9-434c-80ee-79db7c9ff1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-bd3b0363-46ca-4400-8e65-1d2f045a206a,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-c00813b6-2fb4-465e-9548-cadd4d346177,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-ac2ec227-52b1-4c8b-ae86-9be8f4e4cfb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739846728-172.17.0.21-1597647482411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-da9eba62-7394-4890-9e94-7509490b2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-661def89-245b-4db6-a683-1da301d16997,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-9dd6ad76-06e4-4c2a-b1c2-4b4abb43edf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0379e1dc-c50f-4aff-ad79-84b7374ee328,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-20d7e77f-f8c4-4cf3-a678-8bab64066605,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-8eaf2fb5-6be8-4f65-bc84-f7929ba112fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-6128a98c-2a7a-4dcb-9bc3-b073c25e3784,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-3f6a129e-c44f-49e1-a202-9cedd43babbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739846728-172.17.0.21-1597647482411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-da9eba62-7394-4890-9e94-7509490b2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-661def89-245b-4db6-a683-1da301d16997,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-9dd6ad76-06e4-4c2a-b1c2-4b4abb43edf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0379e1dc-c50f-4aff-ad79-84b7374ee328,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-20d7e77f-f8c4-4cf3-a678-8bab64066605,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-8eaf2fb5-6be8-4f65-bc84-f7929ba112fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-6128a98c-2a7a-4dcb-9bc3-b073c25e3784,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-3f6a129e-c44f-49e1-a202-9cedd43babbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831819446-172.17.0.21-1597647633315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-5130033a-555a-45d5-bc40-eaeaac95a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-85922298-1dec-40af-b8ba-3a049b340f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-0e3c6c3c-0950-4094-8196-6a034812d211,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-83dbc6c6-478f-49ac-b1df-d5e74dabe79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-9a9a5dba-48a9-488b-9700-f95dbfaab607,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-d3c2e0ff-3cbe-4e0f-a259-bcb9c187bad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-24ee8017-e103-4b0f-a704-7bcd79a3e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-ee3ea1f6-1721-4557-aa88-f91c815d03f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831819446-172.17.0.21-1597647633315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-5130033a-555a-45d5-bc40-eaeaac95a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-85922298-1dec-40af-b8ba-3a049b340f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-0e3c6c3c-0950-4094-8196-6a034812d211,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-83dbc6c6-478f-49ac-b1df-d5e74dabe79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-9a9a5dba-48a9-488b-9700-f95dbfaab607,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-d3c2e0ff-3cbe-4e0f-a259-bcb9c187bad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-24ee8017-e103-4b0f-a704-7bcd79a3e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-ee3ea1f6-1721-4557-aa88-f91c815d03f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190369252-172.17.0.21-1597648018779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-0d5b9e3e-e23a-445c-84ab-da59f237bed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-1c4b250f-ca6a-4ba6-a695-1960055ecc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-d77ae036-f8cc-4edc-a5b6-dd6649bab347,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-34680d95-70fb-4d0a-a35f-7951545181ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-d33ced30-11d7-4de9-8a13-0a0fb3a8fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-3024e43e-12fa-4cfb-b3d3-6e92ca33d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-3edd5e03-3b85-4d27-a025-b33152ac5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-1de8491e-a999-4cb9-af08-fba83b1b175d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190369252-172.17.0.21-1597648018779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-0d5b9e3e-e23a-445c-84ab-da59f237bed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-1c4b250f-ca6a-4ba6-a695-1960055ecc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-d77ae036-f8cc-4edc-a5b6-dd6649bab347,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-34680d95-70fb-4d0a-a35f-7951545181ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-d33ced30-11d7-4de9-8a13-0a0fb3a8fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-3024e43e-12fa-4cfb-b3d3-6e92ca33d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-3edd5e03-3b85-4d27-a025-b33152ac5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-1de8491e-a999-4cb9-af08-fba83b1b175d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 500000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399672693-172.17.0.21-1597648271028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-ad607480-7df6-4c33-a868-19704fcf870a,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2f2f0c4c-edd0-4340-9834-e32b388c8992,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-696577c3-5299-4071-8486-fed40a2c9b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-d1749733-39bb-40fc-9f77-1bde271eea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-38c22cc7-729b-4912-a3a6-e654c6c82473,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-93bcc340-854a-46c0-a7a8-b845e8cf85d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-90da45df-8342-4b9d-ba58-e00ae538f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-560cd409-415a-45b5-b55f-b6569671bd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399672693-172.17.0.21-1597648271028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-ad607480-7df6-4c33-a868-19704fcf870a,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2f2f0c4c-edd0-4340-9834-e32b388c8992,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-696577c3-5299-4071-8486-fed40a2c9b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-d1749733-39bb-40fc-9f77-1bde271eea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-38c22cc7-729b-4912-a3a6-e654c6c82473,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-93bcc340-854a-46c0-a7a8-b845e8cf85d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-90da45df-8342-4b9d-ba58-e00ae538f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-560cd409-415a-45b5-b55f-b6569671bd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5665
