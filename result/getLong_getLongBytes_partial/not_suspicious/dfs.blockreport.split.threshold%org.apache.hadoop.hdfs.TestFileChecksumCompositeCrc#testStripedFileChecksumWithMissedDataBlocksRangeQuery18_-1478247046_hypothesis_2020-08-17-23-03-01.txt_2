reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549325934-172.17.0.11-1597706291076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-8cc03362-9978-42ce-a76a-16e830fda19d,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-2bbf4403-9f8e-4277-b778-7be78a9275e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-a7e232ea-e038-41cd-95ef-742a9be3f222,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-bbd950f3-e2c1-42cb-a815-e3bc3764ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-34911d86-c27f-4006-8ede-7c02b210a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-6ca94159-21f2-4bd9-9b4f-098a40cc7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-3c4b3918-7743-48d4-b9f7-cc9e63612149,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c5721427-e7dd-43d5-b1f6-f66f33eb5e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549325934-172.17.0.11-1597706291076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-8cc03362-9978-42ce-a76a-16e830fda19d,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-2bbf4403-9f8e-4277-b778-7be78a9275e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-a7e232ea-e038-41cd-95ef-742a9be3f222,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-bbd950f3-e2c1-42cb-a815-e3bc3764ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-34911d86-c27f-4006-8ede-7c02b210a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-6ca94159-21f2-4bd9-9b4f-098a40cc7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-3c4b3918-7743-48d4-b9f7-cc9e63612149,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c5721427-e7dd-43d5-b1f6-f66f33eb5e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054148249-172.17.0.11-1597707009741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-11bfe5d2-791c-4453-b0a1-d5b4c7d380e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-360c0aa4-4618-4830-bdd6-f9fd97ea807a,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-a85c4087-226a-45b1-bf69-bd533b3e4df7,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-3965749d-7a48-4bec-b4c7-5a46bc14f777,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-f1d1a8c4-6ec5-4e97-a094-e381983ca12d,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3989b60a-1c27-41c3-a8bb-570666693fed,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d3baa45e-bbb6-46fd-ae32-738012dcb68b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-6901083f-dd62-487f-922f-640ebc47b928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054148249-172.17.0.11-1597707009741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-11bfe5d2-791c-4453-b0a1-d5b4c7d380e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-360c0aa4-4618-4830-bdd6-f9fd97ea807a,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-a85c4087-226a-45b1-bf69-bd533b3e4df7,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-3965749d-7a48-4bec-b4c7-5a46bc14f777,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-f1d1a8c4-6ec5-4e97-a094-e381983ca12d,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3989b60a-1c27-41c3-a8bb-570666693fed,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d3baa45e-bbb6-46fd-ae32-738012dcb68b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-6901083f-dd62-487f-922f-640ebc47b928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471216227-172.17.0.11-1597707499433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-5c63e01a-a35b-4ce2-ad91-08daf166ea62,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-f4764b44-7fd0-471d-a887-17104f44f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-8fcc4982-d90f-4be9-a826-79e6e1e034f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-b140ce55-92c5-44d7-8e52-c4b4d7cd7873,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-e0bcb641-c4cd-4820-95d2-a9d27f6330e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-99bd7b24-ee8b-4eeb-b4b0-42ddcac35f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-e38d1d17-b226-40e4-92da-5c5ec035056f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-10803d91-4ed2-43e6-9a1c-8f140f11b5fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471216227-172.17.0.11-1597707499433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-5c63e01a-a35b-4ce2-ad91-08daf166ea62,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-f4764b44-7fd0-471d-a887-17104f44f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-8fcc4982-d90f-4be9-a826-79e6e1e034f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-b140ce55-92c5-44d7-8e52-c4b4d7cd7873,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-e0bcb641-c4cd-4820-95d2-a9d27f6330e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-99bd7b24-ee8b-4eeb-b4b0-42ddcac35f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-e38d1d17-b226-40e4-92da-5c5ec035056f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-10803d91-4ed2-43e6-9a1c-8f140f11b5fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341314704-172.17.0.11-1597707698206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-9df88ce1-4efd-4948-990b-a84157c41c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-1b31359e-25d0-4549-b4f6-4f6c6697c909,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-f9f5cec4-ce1e-49e3-b998-ce4da67b0f16,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-db90c9ff-a1b1-4d1c-b9b8-3353118d31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-61a9e8ea-0817-4331-8e64-58a26c5d4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-abc9f16b-fe7a-440f-928b-92869d20a0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-3f65eea4-6875-43ff-b118-4f90888cfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-3d13ba3d-f5d0-43c8-a01c-d596a5b6f884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341314704-172.17.0.11-1597707698206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-9df88ce1-4efd-4948-990b-a84157c41c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-1b31359e-25d0-4549-b4f6-4f6c6697c909,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-f9f5cec4-ce1e-49e3-b998-ce4da67b0f16,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-db90c9ff-a1b1-4d1c-b9b8-3353118d31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-61a9e8ea-0817-4331-8e64-58a26c5d4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-abc9f16b-fe7a-440f-928b-92869d20a0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-3f65eea4-6875-43ff-b118-4f90888cfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-3d13ba3d-f5d0-43c8-a01c-d596a5b6f884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720056362-172.17.0.11-1597708116752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-6bacdc06-0321-4033-bf9d-be4d3e63a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-68ad9db8-1179-4ace-b8cb-2ce27918e932,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-dddc78ce-9a8d-4585-9a3b-2aa8d0d3b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-11ce7b67-7a59-4240-927c-9629c7ddc548,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-0e4b4da6-3605-4f28-87b7-ca4783652619,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-19aef609-a409-48b1-87e0-cbaaf74bf615,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-f48077bf-a637-4a3b-bbda-72aeb77d4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-c1b5a451-8a4c-42bc-9265-95f891a0820d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720056362-172.17.0.11-1597708116752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-6bacdc06-0321-4033-bf9d-be4d3e63a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-68ad9db8-1179-4ace-b8cb-2ce27918e932,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-dddc78ce-9a8d-4585-9a3b-2aa8d0d3b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-11ce7b67-7a59-4240-927c-9629c7ddc548,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-0e4b4da6-3605-4f28-87b7-ca4783652619,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-19aef609-a409-48b1-87e0-cbaaf74bf615,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-f48077bf-a637-4a3b-bbda-72aeb77d4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-c1b5a451-8a4c-42bc-9265-95f891a0820d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108998649-172.17.0.11-1597708294425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-c8c1cbd9-ac2f-4063-a8b5-79f83dbd7941,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d312fdca-1112-4643-b6b9-6272efdc3ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-4fb341e9-8f5d-4d30-9bcd-fca9aaab9651,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-1428b1eb-571d-4286-8f01-97905a1eebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-bb268bae-f273-4445-ae2e-c7e3e380c068,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-139316e1-48b6-423f-8354-e068173a18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e930a41d-d2fc-49ef-ab54-199a0d35aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-fd220690-28bd-4323-bfd1-5f9774de9454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108998649-172.17.0.11-1597708294425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-c8c1cbd9-ac2f-4063-a8b5-79f83dbd7941,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d312fdca-1112-4643-b6b9-6272efdc3ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-4fb341e9-8f5d-4d30-9bcd-fca9aaab9651,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-1428b1eb-571d-4286-8f01-97905a1eebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-bb268bae-f273-4445-ae2e-c7e3e380c068,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-139316e1-48b6-423f-8354-e068173a18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e930a41d-d2fc-49ef-ab54-199a0d35aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-fd220690-28bd-4323-bfd1-5f9774de9454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050518727-172.17.0.11-1597708370050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-9ffce284-24af-4144-841b-376aa5b00539,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-7fbf75c6-6678-4623-9eb5-a91dc7706aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-83fe4146-3a09-4cac-9d46-6585fc26ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-5270e9ed-f1dd-4505-b3b0-f1133ff0d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-29595ff7-4011-437c-8f36-1efd18811119,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-2ea79428-cba4-46f2-8dfc-4bb5936214fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-d404f150-ce30-44b1-840c-057144827121,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-76884305-4fac-4d19-8552-84c7baaecede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050518727-172.17.0.11-1597708370050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-9ffce284-24af-4144-841b-376aa5b00539,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-7fbf75c6-6678-4623-9eb5-a91dc7706aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-83fe4146-3a09-4cac-9d46-6585fc26ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-5270e9ed-f1dd-4505-b3b0-f1133ff0d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-29595ff7-4011-437c-8f36-1efd18811119,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-2ea79428-cba4-46f2-8dfc-4bb5936214fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-d404f150-ce30-44b1-840c-057144827121,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-76884305-4fac-4d19-8552-84c7baaecede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422018453-172.17.0.11-1597708484988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-b8d1ff33-16ea-460b-a4f7-efd63361d141,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-f5ae4b92-934d-4e92-8288-aa948745a195,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-118df64a-7df1-4aae-8b96-58924005708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-e2e4ee24-890a-49af-911a-2a6d47fff0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-f253ae9f-e445-4233-b790-87709e904c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-0b51fb26-df6e-4f5f-b5b3-ebbf304406fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-18455397-c9f6-4a28-b96c-5e598dfe288f,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-42015ead-94b7-475e-8972-6a21f4ca1882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422018453-172.17.0.11-1597708484988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-b8d1ff33-16ea-460b-a4f7-efd63361d141,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-f5ae4b92-934d-4e92-8288-aa948745a195,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-118df64a-7df1-4aae-8b96-58924005708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-e2e4ee24-890a-49af-911a-2a6d47fff0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-f253ae9f-e445-4233-b790-87709e904c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-0b51fb26-df6e-4f5f-b5b3-ebbf304406fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-18455397-c9f6-4a28-b96c-5e598dfe288f,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-42015ead-94b7-475e-8972-6a21f4ca1882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639694943-172.17.0.11-1597709299249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-3bc84bc4-e0ad-4afe-a196-3e69b00b8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-1d9ce10c-c645-4aec-9b58-1282598a377c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-8cbf4c8c-253e-407c-b7ee-6ba05209c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-d1d9b289-18c5-41ad-9e02-7707e14652aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-6fff9a40-f41b-452e-b2c2-ffb6f145be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-1cdc5308-d0cf-457e-9aa9-48087f456ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e33154ca-8269-4834-9d2c-115eda5e403e,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-b84a1243-0d33-490f-85ca-dcf0ffd95be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639694943-172.17.0.11-1597709299249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-3bc84bc4-e0ad-4afe-a196-3e69b00b8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-1d9ce10c-c645-4aec-9b58-1282598a377c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-8cbf4c8c-253e-407c-b7ee-6ba05209c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-d1d9b289-18c5-41ad-9e02-7707e14652aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-6fff9a40-f41b-452e-b2c2-ffb6f145be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-1cdc5308-d0cf-457e-9aa9-48087f456ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e33154ca-8269-4834-9d2c-115eda5e403e,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-b84a1243-0d33-490f-85ca-dcf0ffd95be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514726615-172.17.0.11-1597709448451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-f9c77ab2-7f64-447a-8c06-65355782a067,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-be120246-481a-4af7-a501-32112b6db0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-3b878138-152d-4179-a17f-8f4c042c7258,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-340fbffe-7c49-4ce0-af87-1341034907dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-32a72d29-3acf-4fa8-9704-b8ac6f95f402,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-bc030d1b-89a4-4d26-9d1e-e5653c8b0fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4aa807b7-fadb-427a-a423-fc93b284d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-77af85f6-499f-4751-a134-21dbda92340e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514726615-172.17.0.11-1597709448451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-f9c77ab2-7f64-447a-8c06-65355782a067,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-be120246-481a-4af7-a501-32112b6db0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-3b878138-152d-4179-a17f-8f4c042c7258,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-340fbffe-7c49-4ce0-af87-1341034907dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-32a72d29-3acf-4fa8-9704-b8ac6f95f402,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-bc030d1b-89a4-4d26-9d1e-e5653c8b0fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4aa807b7-fadb-427a-a423-fc93b284d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-77af85f6-499f-4751-a134-21dbda92340e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934046739-172.17.0.11-1597709923389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-28c158d8-ad2a-46b3-8218-d7a3f4a995a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-82653275-b829-41e1-aeac-3d75f9239527,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-161fe8e6-14ac-48e1-b1a4-48e5046501ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-be513a57-22ce-4e2c-afe2-5d9bad1e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-b7d66d2a-4c08-425d-b3cc-3179e7b54eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-17a7e164-a1f7-4294-99b9-e210832c2942,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-60892167-93c7-491b-82de-a6fddc4343d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e486a10c-8093-4d05-a144-0be2a74be229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934046739-172.17.0.11-1597709923389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-28c158d8-ad2a-46b3-8218-d7a3f4a995a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-82653275-b829-41e1-aeac-3d75f9239527,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-161fe8e6-14ac-48e1-b1a4-48e5046501ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-be513a57-22ce-4e2c-afe2-5d9bad1e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-b7d66d2a-4c08-425d-b3cc-3179e7b54eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-17a7e164-a1f7-4294-99b9-e210832c2942,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-60892167-93c7-491b-82de-a6fddc4343d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e486a10c-8093-4d05-a144-0be2a74be229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770267646-172.17.0.11-1597710425494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-239c4e4f-7471-48af-89c0-23102daf4330,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-539c9797-8d23-4c42-baa9-69bf76a41e62,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-69dc3e32-850e-492c-bbac-48cccb1fc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-880660b0-68ce-462b-82ae-67f5934360c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-71797b16-14b7-4b37-b0df-1aff79bb7651,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-59ea1ffc-a38f-475f-9f9d-9b3ace4c7836,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-69e0b80d-d806-4b8b-afe7-fdc645935857,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-0bf075ac-23df-42aa-bbc3-0aecd7942578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770267646-172.17.0.11-1597710425494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-239c4e4f-7471-48af-89c0-23102daf4330,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-539c9797-8d23-4c42-baa9-69bf76a41e62,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-69dc3e32-850e-492c-bbac-48cccb1fc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-880660b0-68ce-462b-82ae-67f5934360c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-71797b16-14b7-4b37-b0df-1aff79bb7651,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-59ea1ffc-a38f-475f-9f9d-9b3ace4c7836,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-69e0b80d-d806-4b8b-afe7-fdc645935857,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-0bf075ac-23df-42aa-bbc3-0aecd7942578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747305534-172.17.0.11-1597710458299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-31395b00-733d-45e6-bb30-177de89cc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e39eb9fb-fd06-4be4-baf7-93d5280cc733,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-fc8715a9-88f0-465e-bbf6-358be29c9962,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-21beb501-abeb-4bc6-8a23-43569fd1afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-f5dd2dbd-d0eb-4c18-a913-0d326fb61990,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-f16633f9-895e-42d4-8780-9311e8127c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-d21de232-3d59-4d16-9d1f-de36c1385261,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c465bca0-88a0-4d10-bd44-61df70e7063d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747305534-172.17.0.11-1597710458299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-31395b00-733d-45e6-bb30-177de89cc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e39eb9fb-fd06-4be4-baf7-93d5280cc733,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-fc8715a9-88f0-465e-bbf6-358be29c9962,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-21beb501-abeb-4bc6-8a23-43569fd1afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-f5dd2dbd-d0eb-4c18-a913-0d326fb61990,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-f16633f9-895e-42d4-8780-9311e8127c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-d21de232-3d59-4d16-9d1f-de36c1385261,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c465bca0-88a0-4d10-bd44-61df70e7063d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344510932-172.17.0.11-1597710842232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-be8f3d7b-e7f9-44ee-bdbe-c58d4f077582,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-4058234c-8308-42ba-bab5-99d95568446f,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-0cc274a0-5070-4aa2-aeaa-fcd4da64ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-4fb5cb69-02ec-47a5-8b40-77f863b9daff,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-27cfc41c-0152-43cb-9056-d1285354d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-02fa4ab5-c94f-4b1a-a5ba-c374def2f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-8edba312-536f-429e-9857-7608b87e8e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-bc8998cd-3ad5-4ded-8362-a870d34fc808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344510932-172.17.0.11-1597710842232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-be8f3d7b-e7f9-44ee-bdbe-c58d4f077582,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-4058234c-8308-42ba-bab5-99d95568446f,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-0cc274a0-5070-4aa2-aeaa-fcd4da64ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-4fb5cb69-02ec-47a5-8b40-77f863b9daff,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-27cfc41c-0152-43cb-9056-d1285354d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-02fa4ab5-c94f-4b1a-a5ba-c374def2f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-8edba312-536f-429e-9857-7608b87e8e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-bc8998cd-3ad5-4ded-8362-a870d34fc808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679385625-172.17.0.11-1597710954315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-753ded53-3f3d-4e84-b9dd-e5c580f32f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-7bf19e37-fec0-4d4f-aa70-8c7c7d1b6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-ea6dbbf6-1732-4f2a-9128-4f05ef529e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-4e3263cb-b04a-44be-9834-d433eb4314d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-0e7868e3-8bf5-4e95-9560-d24d9cc5ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-0c77abb6-a5e6-462c-a905-d3a9c0a8d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-f6844c47-c4f3-45a3-9363-9804cc9c9885,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-61c3ffb3-2532-4402-8971-3caed97dc96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679385625-172.17.0.11-1597710954315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-753ded53-3f3d-4e84-b9dd-e5c580f32f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-7bf19e37-fec0-4d4f-aa70-8c7c7d1b6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-ea6dbbf6-1732-4f2a-9128-4f05ef529e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-4e3263cb-b04a-44be-9834-d433eb4314d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-0e7868e3-8bf5-4e95-9560-d24d9cc5ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-0c77abb6-a5e6-462c-a905-d3a9c0a8d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-f6844c47-c4f3-45a3-9363-9804cc9c9885,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-61c3ffb3-2532-4402-8971-3caed97dc96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5621
