reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055846375-172.17.0.15-1597588336874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-d47a70ca-e089-4ff2-8468-807e50b01190,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-604f4984-81f9-41a3-b48d-9a14cf9e3d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-5414f8c5-5909-48b4-acbc-abbe6d343f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-fc656a2b-9380-4fc4-bfcd-2276585560ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-eef4d91d-a57b-4a65-805b-e6824aea083d,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-f5862cf4-6660-4349-9ea0-53648ec80a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-313396ff-a7c2-4c4d-93fd-56d5ae656a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-88807fc6-b40f-492f-bd57-771533b4375f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055846375-172.17.0.15-1597588336874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-d47a70ca-e089-4ff2-8468-807e50b01190,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-604f4984-81f9-41a3-b48d-9a14cf9e3d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-5414f8c5-5909-48b4-acbc-abbe6d343f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-fc656a2b-9380-4fc4-bfcd-2276585560ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-eef4d91d-a57b-4a65-805b-e6824aea083d,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-f5862cf4-6660-4349-9ea0-53648ec80a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-313396ff-a7c2-4c4d-93fd-56d5ae656a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-88807fc6-b40f-492f-bd57-771533b4375f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764269361-172.17.0.15-1597588654594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41249,DS-ae70c431-4fbb-4d0b-b5c0-1ee8b5ecda11,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-44c62b93-8035-49b7-ae3c-984b904a20af,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-95a1c9e9-3535-44eb-af5f-ec536fb6e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-14f070c0-e0c0-4a80-ba15-326fe0308f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-24dc92de-90e4-44d3-a620-4f1bea8b7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-4dc87f97-7b36-49df-886e-3a9a6363b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-a6ea6812-f7e4-4aad-94f7-2526a2eb4cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-7acfb25d-f0f2-4cff-a5b6-29667ba8a72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764269361-172.17.0.15-1597588654594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41249,DS-ae70c431-4fbb-4d0b-b5c0-1ee8b5ecda11,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-44c62b93-8035-49b7-ae3c-984b904a20af,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-95a1c9e9-3535-44eb-af5f-ec536fb6e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-14f070c0-e0c0-4a80-ba15-326fe0308f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-24dc92de-90e4-44d3-a620-4f1bea8b7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-4dc87f97-7b36-49df-886e-3a9a6363b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-a6ea6812-f7e4-4aad-94f7-2526a2eb4cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-7acfb25d-f0f2-4cff-a5b6-29667ba8a72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36658550-172.17.0.15-1597589798453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-0fd36497-b673-47a6-bb24-b848fa628b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-3fb7f4f8-a111-4151-8a53-80a6e4c53ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-2e143678-e0c0-4218-bff0-c7a80aa12d15,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-2adb0b78-d0d6-4c21-b833-d543a6101706,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-3aa8e902-e59b-42bc-8b24-3f286cf4d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-601b528b-cd84-4ccf-ba18-33e948371930,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-fcbf6244-e80b-4801-aa34-6459bfd55a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-843470d5-17cc-4873-bcce-8f112c59cd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36658550-172.17.0.15-1597589798453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-0fd36497-b673-47a6-bb24-b848fa628b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-3fb7f4f8-a111-4151-8a53-80a6e4c53ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-2e143678-e0c0-4218-bff0-c7a80aa12d15,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-2adb0b78-d0d6-4c21-b833-d543a6101706,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-3aa8e902-e59b-42bc-8b24-3f286cf4d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-601b528b-cd84-4ccf-ba18-33e948371930,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-fcbf6244-e80b-4801-aa34-6459bfd55a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-843470d5-17cc-4873-bcce-8f112c59cd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852475148-172.17.0.15-1597589897410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42328,DS-e61e0be4-bf82-4b76-8c02-85b577392a33,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-c3d03619-9229-4f58-8b0b-1b2872a341fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-64731f3b-982c-4d1f-b94e-b2e7d3b28bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-2e5c8974-4c36-4090-8ae5-00c97bc8f232,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-078acf6e-7499-4236-a277-e1b7a530a4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-a0bd29f0-d45e-447e-8c38-8fce3a8766a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-2cadd8a7-9802-4cf4-b5e4-eaf82cdc8799,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-47dae5a9-ad1a-4edd-bf8f-716fcc245f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852475148-172.17.0.15-1597589897410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42328,DS-e61e0be4-bf82-4b76-8c02-85b577392a33,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-c3d03619-9229-4f58-8b0b-1b2872a341fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-64731f3b-982c-4d1f-b94e-b2e7d3b28bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-2e5c8974-4c36-4090-8ae5-00c97bc8f232,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-078acf6e-7499-4236-a277-e1b7a530a4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-a0bd29f0-d45e-447e-8c38-8fce3a8766a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-2cadd8a7-9802-4cf4-b5e4-eaf82cdc8799,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-47dae5a9-ad1a-4edd-bf8f-716fcc245f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763750548-172.17.0.15-1597591055815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-c58a617f-7045-4e28-8792-42215f2a5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-dd20563f-cd8f-47c0-a8c9-58c972d6f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-6be0cb80-ef3c-490f-9a9a-43c1c6b946dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c1bc0c92-6363-42bc-a117-83d7294f0aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-94a9b1dd-c0e4-4915-bdd0-7a4b5a8b2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-f0c9c258-3801-42ad-ae51-8876b939aaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-62f18d6d-1523-41ca-94d8-589f302ecedf,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-36e7ecec-bfe8-4000-9c09-4800109b4ac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763750548-172.17.0.15-1597591055815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-c58a617f-7045-4e28-8792-42215f2a5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-dd20563f-cd8f-47c0-a8c9-58c972d6f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-6be0cb80-ef3c-490f-9a9a-43c1c6b946dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c1bc0c92-6363-42bc-a117-83d7294f0aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-94a9b1dd-c0e4-4915-bdd0-7a4b5a8b2b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-f0c9c258-3801-42ad-ae51-8876b939aaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-62f18d6d-1523-41ca-94d8-589f302ecedf,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-36e7ecec-bfe8-4000-9c09-4800109b4ac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252690948-172.17.0.15-1597591236167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-0656dd51-45a7-45c3-a2c4-4dc96a3fbaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-4ff83734-8f4c-46c3-a348-3aba70b2ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-6950c7a1-76f8-4523-ab9b-26847e84e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-526ad87e-6f3e-4cce-b28f-a6be0b48972a,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-e5c43f51-60ec-4c65-8b4c-544489ec0c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-3653ea91-9bf3-4fed-b523-d2b85fa3ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-bb029a9b-20a5-41ac-8a86-9b2ee05c93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-57f4ebed-2f8e-4ea1-bdc4-c743e04d944d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252690948-172.17.0.15-1597591236167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-0656dd51-45a7-45c3-a2c4-4dc96a3fbaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-4ff83734-8f4c-46c3-a348-3aba70b2ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-6950c7a1-76f8-4523-ab9b-26847e84e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-526ad87e-6f3e-4cce-b28f-a6be0b48972a,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-e5c43f51-60ec-4c65-8b4c-544489ec0c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-3653ea91-9bf3-4fed-b523-d2b85fa3ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-bb029a9b-20a5-41ac-8a86-9b2ee05c93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-57f4ebed-2f8e-4ea1-bdc4-c743e04d944d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469806862-172.17.0.15-1597591508880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-2dab3144-3428-4857-be05-3839c3e47167,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5fc18d6b-8172-4417-8d72-5a6fb6a4d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-88d327bc-6d21-473e-bdac-5bfbaff32235,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-db488038-62d1-4baf-8acf-12e61a5bf878,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-10715c68-18d5-42fe-a99c-1cdbea87b61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-fa1c8c95-52f4-4660-a429-a3a8b2c10797,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-72b06c1b-a6d8-41ba-820b-58599ac88c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-88e954c8-d11d-4728-8121-11163f7da9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469806862-172.17.0.15-1597591508880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-2dab3144-3428-4857-be05-3839c3e47167,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5fc18d6b-8172-4417-8d72-5a6fb6a4d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-88d327bc-6d21-473e-bdac-5bfbaff32235,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-db488038-62d1-4baf-8acf-12e61a5bf878,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-10715c68-18d5-42fe-a99c-1cdbea87b61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-fa1c8c95-52f4-4660-a429-a3a8b2c10797,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-72b06c1b-a6d8-41ba-820b-58599ac88c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-88e954c8-d11d-4728-8121-11163f7da9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064579205-172.17.0.15-1597591684379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41195,DS-bc34b954-df83-43fb-b6e3-9bc15d7ab419,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-8919479b-de06-4660-aac5-d7feb1ba5734,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f56aeaec-7cca-47f9-8279-7626d297eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-cfeb097a-7458-45d4-b6c4-1874e5e0f865,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-442ca05e-4f22-4179-8101-6f083de08dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-718f5a43-17f6-4be7-9cde-a624f2c22716,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-63979d2c-9285-43a4-91d7-08702a16e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-e6833055-a3e9-453b-8ce2-f842793834ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064579205-172.17.0.15-1597591684379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41195,DS-bc34b954-df83-43fb-b6e3-9bc15d7ab419,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-8919479b-de06-4660-aac5-d7feb1ba5734,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f56aeaec-7cca-47f9-8279-7626d297eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-cfeb097a-7458-45d4-b6c4-1874e5e0f865,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-442ca05e-4f22-4179-8101-6f083de08dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-718f5a43-17f6-4be7-9cde-a624f2c22716,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-63979d2c-9285-43a4-91d7-08702a16e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-e6833055-a3e9-453b-8ce2-f842793834ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825620393-172.17.0.15-1597591843679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-57884793-bf81-454e-9cfb-46711561c311,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-4346bfd2-354c-4673-9e1f-733d1b480bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-7a00a80f-1250-4da1-9209-6d87856a251e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-da3a9633-f003-4713-af82-0ff14b8a6136,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-fd30da8f-2d0c-4a2f-a3cb-d0addbd935d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-e894b5d4-2c1c-4d20-abc4-b2c6d90d5aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-584fb6d4-e28d-4c62-b9c4-7e348a932904,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d154858d-b2aa-4437-98fb-b7aba1f04bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825620393-172.17.0.15-1597591843679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-57884793-bf81-454e-9cfb-46711561c311,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-4346bfd2-354c-4673-9e1f-733d1b480bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-7a00a80f-1250-4da1-9209-6d87856a251e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-da3a9633-f003-4713-af82-0ff14b8a6136,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-fd30da8f-2d0c-4a2f-a3cb-d0addbd935d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-e894b5d4-2c1c-4d20-abc4-b2c6d90d5aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-584fb6d4-e28d-4c62-b9c4-7e348a932904,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d154858d-b2aa-4437-98fb-b7aba1f04bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316193075-172.17.0.15-1597592013250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-2104ab38-b574-452c-9d61-dd6551ded138,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-557f1d55-56f8-4d31-8819-fe3bde78112a,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-90e8abf4-3a05-4c72-9501-00950f568194,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-82aa1d80-50ef-4940-b57b-9f56720f3709,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-953badb1-fdf3-451c-840c-e8de8d77123e,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-9f8d76e5-184a-4407-8da6-c6fc4ba83c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-da8b53bb-6002-4329-9219-d67915712ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-bb7623e6-d85f-467f-8e43-a0e8425a5a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316193075-172.17.0.15-1597592013250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-2104ab38-b574-452c-9d61-dd6551ded138,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-557f1d55-56f8-4d31-8819-fe3bde78112a,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-90e8abf4-3a05-4c72-9501-00950f568194,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-82aa1d80-50ef-4940-b57b-9f56720f3709,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-953badb1-fdf3-451c-840c-e8de8d77123e,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-9f8d76e5-184a-4407-8da6-c6fc4ba83c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-da8b53bb-6002-4329-9219-d67915712ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-bb7623e6-d85f-467f-8e43-a0e8425a5a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072915069-172.17.0.15-1597592064507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44019,DS-3b9475d4-fd6c-4113-a330-8e62860238c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-4468f9cf-038f-4a13-a189-1722f55b9175,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-b724df55-22d5-4914-bd04-e89f697ac71b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f5c7a21d-e59d-416d-947b-9cdafc5e7648,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-5bfbe6f0-f290-41f0-b26e-4f9fecf1807a,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-d1efa937-0e0c-4f2d-9a8b-28033bd30793,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-b3a9f5b0-66f9-4699-884e-994e75608a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-429265be-1a46-477a-8bf8-fa433809b805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072915069-172.17.0.15-1597592064507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44019,DS-3b9475d4-fd6c-4113-a330-8e62860238c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-4468f9cf-038f-4a13-a189-1722f55b9175,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-b724df55-22d5-4914-bd04-e89f697ac71b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f5c7a21d-e59d-416d-947b-9cdafc5e7648,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-5bfbe6f0-f290-41f0-b26e-4f9fecf1807a,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-d1efa937-0e0c-4f2d-9a8b-28033bd30793,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-b3a9f5b0-66f9-4699-884e-994e75608a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-429265be-1a46-477a-8bf8-fa433809b805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614710677-172.17.0.15-1597592190975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43008,DS-1a4b5875-4538-4e90-a61b-a52ae9ea7e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-02fbc46f-6897-488e-99d6-4c7b73257191,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-1325c5e2-140b-4b2b-86ac-b006078dfd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-701f6503-2c6c-4c00-9e8c-f7ca9da7081b,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-1a213f40-d9d8-48ac-9028-09289279145b,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-5957c922-8ee2-4939-9882-da1d78a2a2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-962d3353-a056-48e1-bfc2-15f5cf26a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-fed66a75-99a1-46dc-aea1-468548bee98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614710677-172.17.0.15-1597592190975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43008,DS-1a4b5875-4538-4e90-a61b-a52ae9ea7e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-02fbc46f-6897-488e-99d6-4c7b73257191,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-1325c5e2-140b-4b2b-86ac-b006078dfd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-701f6503-2c6c-4c00-9e8c-f7ca9da7081b,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-1a213f40-d9d8-48ac-9028-09289279145b,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-5957c922-8ee2-4939-9882-da1d78a2a2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-962d3353-a056-48e1-bfc2-15f5cf26a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-fed66a75-99a1-46dc-aea1-468548bee98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789661452-172.17.0.15-1597592600134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-eaf36680-4a38-4c86-a4d5-3b22008f5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-d78d218a-deee-43a4-8449-1453ed37114f,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-0b698726-d3aa-4a63-8359-f43fbbb2692c,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-f5804836-0641-47f1-8d77-41a9f20bab94,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-ce6d2f71-dd16-4164-9061-58baf5c01ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-2364b4f0-4073-46b2-8338-7207d30afa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-6a76af7e-403c-4f1e-b6eb-564a4879257f,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-e64e01e2-d14d-4452-ac59-982445734e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789661452-172.17.0.15-1597592600134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-eaf36680-4a38-4c86-a4d5-3b22008f5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-d78d218a-deee-43a4-8449-1453ed37114f,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-0b698726-d3aa-4a63-8359-f43fbbb2692c,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-f5804836-0641-47f1-8d77-41a9f20bab94,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-ce6d2f71-dd16-4164-9061-58baf5c01ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-2364b4f0-4073-46b2-8338-7207d30afa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-6a76af7e-403c-4f1e-b6eb-564a4879257f,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-e64e01e2-d14d-4452-ac59-982445734e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274429067-172.17.0.15-1597592979734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-ea671169-ffbd-42b1-9053-4c675967c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-97ead42d-a2f6-4a32-8b82-f8f637c899d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-a7206e3f-bef8-461c-9411-961bb8d38d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-7ccbe268-1314-466f-b4a5-e22ae13b421f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ccf8ab4e-5a6f-4d8f-8a5c-cf36f92a03d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-dbd6a00c-dd63-4693-9766-437a53bd6bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-d37e34db-b6f4-4cce-a74d-cb0a6e88a728,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-b6ef8f77-f207-41d4-81a8-97c5cffa31c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274429067-172.17.0.15-1597592979734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-ea671169-ffbd-42b1-9053-4c675967c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-97ead42d-a2f6-4a32-8b82-f8f637c899d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-a7206e3f-bef8-461c-9411-961bb8d38d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-7ccbe268-1314-466f-b4a5-e22ae13b421f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ccf8ab4e-5a6f-4d8f-8a5c-cf36f92a03d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-dbd6a00c-dd63-4693-9766-437a53bd6bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-d37e34db-b6f4-4cce-a74d-cb0a6e88a728,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-b6ef8f77-f207-41d4-81a8-97c5cffa31c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883416946-172.17.0.15-1597593995195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-ff69a856-d315-4342-a0ef-09242fa63fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-3dd4d244-4a92-4bcd-a99e-9d026d4cb334,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-a2dd2669-f9ec-4ab3-b236-b0f0f049b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-3a25998f-fb3c-45e3-a80b-6860b3ed7cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-35338032-3a53-4967-9635-1dbcaf77b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-c978fe15-de39-416d-8abb-5a4c8900de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-fffbca5a-7fd6-48dc-8c8c-58e41dd9b13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-86248304-100a-49f0-a015-b0f7fd4b60b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883416946-172.17.0.15-1597593995195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-ff69a856-d315-4342-a0ef-09242fa63fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-3dd4d244-4a92-4bcd-a99e-9d026d4cb334,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-a2dd2669-f9ec-4ab3-b236-b0f0f049b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-3a25998f-fb3c-45e3-a80b-6860b3ed7cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-35338032-3a53-4967-9635-1dbcaf77b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-c978fe15-de39-416d-8abb-5a4c8900de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-fffbca5a-7fd6-48dc-8c8c-58e41dd9b13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-86248304-100a-49f0-a015-b0f7fd4b60b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117193248-172.17.0.15-1597594183928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-f4a698cd-8080-4565-b498-5418a788bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-d89c9f42-e8c6-4800-8e56-a91d3345ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1aeb3698-7cfd-4c2a-8021-ebc50fb18cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-31ffba6a-5d3c-4c46-b0d9-6c99f90c62ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-cbb2dd0b-65dd-42b6-b098-2f67982672ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-8ae85f40-959c-411e-a82c-761b8ac67b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-d4086b18-81f7-4c95-8e01-d84989342acf,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-8650b270-7186-460a-818d-5b6c02c0a15d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117193248-172.17.0.15-1597594183928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-f4a698cd-8080-4565-b498-5418a788bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-d89c9f42-e8c6-4800-8e56-a91d3345ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1aeb3698-7cfd-4c2a-8021-ebc50fb18cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-31ffba6a-5d3c-4c46-b0d9-6c99f90c62ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-cbb2dd0b-65dd-42b6-b098-2f67982672ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-8ae85f40-959c-411e-a82c-761b8ac67b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-d4086b18-81f7-4c95-8e01-d84989342acf,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-8650b270-7186-460a-818d-5b6c02c0a15d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311073335-172.17.0.15-1597594232200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-cdc22bbf-6c23-43cd-966b-85394bc81fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-fea72b61-563a-4883-add0-2a1f9244bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-df80ec98-df9d-44c2-b1f3-6e6904a098b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-151d8fbd-db59-4bd8-9e32-aa89c94adcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-ec04de0c-8e19-4b53-ac18-dd026f0e7798,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-97fc9d31-0609-4ee5-9c1d-4e1218af7623,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-a067d99f-44c8-44b7-9508-97e1dcf090f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-a67e48c1-3925-47bc-8cff-881a86cf58cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311073335-172.17.0.15-1597594232200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-cdc22bbf-6c23-43cd-966b-85394bc81fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-fea72b61-563a-4883-add0-2a1f9244bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-df80ec98-df9d-44c2-b1f3-6e6904a098b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-151d8fbd-db59-4bd8-9e32-aa89c94adcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-ec04de0c-8e19-4b53-ac18-dd026f0e7798,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-97fc9d31-0609-4ee5-9c1d-4e1218af7623,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-a067d99f-44c8-44b7-9508-97e1dcf090f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-a67e48c1-3925-47bc-8cff-881a86cf58cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7005
