reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19836594-172.17.0.17-1597654777398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-410a140d-c225-49b0-8d38-40ec5f3bb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-147237c2-6cbf-4ff3-a706-6403298aa574,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-ba2c3bba-380c-457d-8cd2-3913a56fe6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-c42618f9-3ff4-4c8d-a89d-b5ba11225917,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-e0d20ff1-69d5-4617-abd6-15c24421bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-f59a3167-33a3-4f62-925e-824a06816823,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7345b1a4-c2b3-41f1-8534-29951d2b3588,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-d7b8d500-1eab-4ccd-ab67-858c4688253d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19836594-172.17.0.17-1597654777398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-410a140d-c225-49b0-8d38-40ec5f3bb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-147237c2-6cbf-4ff3-a706-6403298aa574,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-ba2c3bba-380c-457d-8cd2-3913a56fe6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-c42618f9-3ff4-4c8d-a89d-b5ba11225917,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-e0d20ff1-69d5-4617-abd6-15c24421bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-f59a3167-33a3-4f62-925e-824a06816823,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7345b1a4-c2b3-41f1-8534-29951d2b3588,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-d7b8d500-1eab-4ccd-ab67-858c4688253d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047402702-172.17.0.17-1597654896886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-d3cf3c14-a3bf-4938-8ab8-c1894e0a622c,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-1f642ebf-5857-4ebf-b81d-cdd59ae9723a,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-1e1df959-2037-4512-b332-a2734679afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-18e06478-a022-4ae3-b4af-36618accdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-70735056-697d-41b1-b95c-3e6b6491dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-9e69e87b-5446-4ce8-be8b-a5732c6b4023,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-9d1bc989-7f37-4fb0-b276-18c4588236f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-04652d8a-8ef1-42cc-847a-9535a8ebbb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047402702-172.17.0.17-1597654896886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-d3cf3c14-a3bf-4938-8ab8-c1894e0a622c,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-1f642ebf-5857-4ebf-b81d-cdd59ae9723a,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-1e1df959-2037-4512-b332-a2734679afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-18e06478-a022-4ae3-b4af-36618accdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-70735056-697d-41b1-b95c-3e6b6491dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-9e69e87b-5446-4ce8-be8b-a5732c6b4023,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-9d1bc989-7f37-4fb0-b276-18c4588236f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-04652d8a-8ef1-42cc-847a-9535a8ebbb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881140713-172.17.0.17-1597654930202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39691,DS-2c995473-a059-4a24-8643-26a95353248b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-70f4c57f-dfdb-4c66-b89c-72098472d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-4182c8c0-7ce6-4783-abc5-2554d492ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-0e6fde71-215b-4f9d-8a76-acef898ffaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-975439a6-a8fb-4b9f-89af-44cfbfab31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-3c82e122-4dc8-4657-8349-211a5092b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e649d123-7536-4187-a29e-ee23c63b3a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-3c660ee6-2c4d-4727-87ed-5803deb19b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881140713-172.17.0.17-1597654930202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39691,DS-2c995473-a059-4a24-8643-26a95353248b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-70f4c57f-dfdb-4c66-b89c-72098472d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-4182c8c0-7ce6-4783-abc5-2554d492ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-0e6fde71-215b-4f9d-8a76-acef898ffaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-975439a6-a8fb-4b9f-89af-44cfbfab31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-3c82e122-4dc8-4657-8349-211a5092b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e649d123-7536-4187-a29e-ee23c63b3a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-3c660ee6-2c4d-4727-87ed-5803deb19b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723146687-172.17.0.17-1597655688545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-1d387fe9-cbe3-45ea-b2e1-68dec0c331a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-9c76d3b9-a2fb-4248-b581-b5ee898a15fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-f2a36031-f024-49f3-9b37-880f37cee2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-1b709737-1057-4cfb-a6ce-eec4246933f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-b7f34835-7002-4598-a6e8-4a54085f5783,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-157fd77e-6d58-4310-8c79-d0fc9bfdb5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-3af62c88-da83-4e6e-8531-cd6974a40fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-b9fe1c26-52b6-4fb1-9422-9d4b6538b7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723146687-172.17.0.17-1597655688545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-1d387fe9-cbe3-45ea-b2e1-68dec0c331a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-9c76d3b9-a2fb-4248-b581-b5ee898a15fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-f2a36031-f024-49f3-9b37-880f37cee2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-1b709737-1057-4cfb-a6ce-eec4246933f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-b7f34835-7002-4598-a6e8-4a54085f5783,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-157fd77e-6d58-4310-8c79-d0fc9bfdb5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-3af62c88-da83-4e6e-8531-cd6974a40fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-b9fe1c26-52b6-4fb1-9422-9d4b6538b7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930319791-172.17.0.17-1597656027514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-dc333827-ab4a-4ed1-98c1-6e146a6923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-dcff959a-5ee8-4d73-8f9c-915222d49541,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-3ba2f22e-4b92-45cc-a0b2-a6483b1ce832,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-1be6d85a-7552-428e-be27-c0e911eb109a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-d88ed2e9-d50a-4864-930a-40c7d6752bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-afe3addf-bd80-4bdc-9c36-ae59ee6b7d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-86be0a60-8bbb-4b8c-9556-9bd4d0d04a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-9790e500-fb39-41fa-b4f9-5ae1ddcad99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930319791-172.17.0.17-1597656027514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-dc333827-ab4a-4ed1-98c1-6e146a6923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-dcff959a-5ee8-4d73-8f9c-915222d49541,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-3ba2f22e-4b92-45cc-a0b2-a6483b1ce832,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-1be6d85a-7552-428e-be27-c0e911eb109a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-d88ed2e9-d50a-4864-930a-40c7d6752bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-afe3addf-bd80-4bdc-9c36-ae59ee6b7d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-86be0a60-8bbb-4b8c-9556-9bd4d0d04a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-9790e500-fb39-41fa-b4f9-5ae1ddcad99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232810729-172.17.0.17-1597656338310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-3b892621-f6a8-47ba-ad11-5b17c9cf3642,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ec497516-71ed-43fe-9313-ba921d70950e,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-ba1e6473-4919-4947-b2b1-ee3be6c98852,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-005fc0ba-a43c-4f29-9692-07126cad5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-fcd00d34-0e77-421c-8425-09077f5e58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-82ecdf77-59e1-4d85-8b2e-370c72249c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-3728ee80-e27c-473c-8c91-34bbf4b5b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-4f07a5d8-8288-4dab-bcbe-1d0deb309835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232810729-172.17.0.17-1597656338310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-3b892621-f6a8-47ba-ad11-5b17c9cf3642,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ec497516-71ed-43fe-9313-ba921d70950e,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-ba1e6473-4919-4947-b2b1-ee3be6c98852,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-005fc0ba-a43c-4f29-9692-07126cad5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-fcd00d34-0e77-421c-8425-09077f5e58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-82ecdf77-59e1-4d85-8b2e-370c72249c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-3728ee80-e27c-473c-8c91-34bbf4b5b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-4f07a5d8-8288-4dab-bcbe-1d0deb309835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700964047-172.17.0.17-1597657215661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35975,DS-e9b81dc7-2a98-4487-9c89-b361d3bfb836,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-da785020-adf3-487d-898b-fcff76fcff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c56ab687-8e6c-4f95-9696-e8fea6fe2452,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-ed20a35d-7edc-4103-866c-1c698345ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-9b70026a-3012-426d-88b8-b0a04473c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-957f6b65-1479-48a2-ab3d-4b78a374d404,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-d581a444-d6a8-4cee-afbe-b118036f42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-ec85c215-51be-41a1-b30e-9eff047c76dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700964047-172.17.0.17-1597657215661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35975,DS-e9b81dc7-2a98-4487-9c89-b361d3bfb836,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-da785020-adf3-487d-898b-fcff76fcff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c56ab687-8e6c-4f95-9696-e8fea6fe2452,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-ed20a35d-7edc-4103-866c-1c698345ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-9b70026a-3012-426d-88b8-b0a04473c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-957f6b65-1479-48a2-ab3d-4b78a374d404,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-d581a444-d6a8-4cee-afbe-b118036f42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-ec85c215-51be-41a1-b30e-9eff047c76dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119508960-172.17.0.17-1597658339435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-6eb347d9-2722-4f46-978d-6b7ce44d162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-42182e95-66bd-4ac7-81c9-d41817bccbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-13432e3d-a261-44a9-b88f-a5a4222fc09a,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-26f61886-90d4-46ad-b9ad-e5e833b64e54,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-e8e19058-1ed6-4ba9-b6a2-5dffe15a2305,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-7fe0b518-675e-496e-b666-ad03454dbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ff643c5f-71a5-40f3-a0fa-9ef7e3444aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-85e2b243-e21e-4eb7-8ffa-f99be85df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119508960-172.17.0.17-1597658339435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-6eb347d9-2722-4f46-978d-6b7ce44d162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-42182e95-66bd-4ac7-81c9-d41817bccbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-13432e3d-a261-44a9-b88f-a5a4222fc09a,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-26f61886-90d4-46ad-b9ad-e5e833b64e54,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-e8e19058-1ed6-4ba9-b6a2-5dffe15a2305,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-7fe0b518-675e-496e-b666-ad03454dbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ff643c5f-71a5-40f3-a0fa-9ef7e3444aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-85e2b243-e21e-4eb7-8ffa-f99be85df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603209855-172.17.0.17-1597658369019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-b9c62293-51bf-4a40-805a-e2e6e873e94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-6cebeef6-f6b4-4820-a699-0dbb89bb2796,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-22171942-e00b-403f-9f29-14d55897c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-8bec6960-3cbf-4124-b97a-9491a4ad199e,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-9e750cbf-4e63-4fb6-b57d-992b3858d625,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-61f8e5ad-ae29-4be8-af9b-347449e9ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-1af0c3d0-f2c8-48dd-b4dd-9825024be905,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c3e9b61f-7f04-4869-bf6c-fd05dac8e030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603209855-172.17.0.17-1597658369019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-b9c62293-51bf-4a40-805a-e2e6e873e94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-6cebeef6-f6b4-4820-a699-0dbb89bb2796,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-22171942-e00b-403f-9f29-14d55897c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-8bec6960-3cbf-4124-b97a-9491a4ad199e,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-9e750cbf-4e63-4fb6-b57d-992b3858d625,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-61f8e5ad-ae29-4be8-af9b-347449e9ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-1af0c3d0-f2c8-48dd-b4dd-9825024be905,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c3e9b61f-7f04-4869-bf6c-fd05dac8e030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446588051-172.17.0.17-1597658492541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-9436f2f9-28f5-4af3-b00d-bee3a8fd9cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-31041bff-69a3-4eb9-8a2f-06d8e3d178b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-659dc1b0-155b-495d-83de-54aab12e155c,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-48b8218b-4b6c-4427-b226-b564db29a310,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-a4f7e878-9e5b-44fb-9c94-5a054d8b16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-fe7d80a4-98fc-41d6-ad7c-67f056f35952,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-cdbc23dd-f01c-4d71-9bd2-6a8f9033d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-97585a83-9b1c-4455-a0a2-452cfc3bbf0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446588051-172.17.0.17-1597658492541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-9436f2f9-28f5-4af3-b00d-bee3a8fd9cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-31041bff-69a3-4eb9-8a2f-06d8e3d178b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-659dc1b0-155b-495d-83de-54aab12e155c,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-48b8218b-4b6c-4427-b226-b564db29a310,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-a4f7e878-9e5b-44fb-9c94-5a054d8b16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-fe7d80a4-98fc-41d6-ad7c-67f056f35952,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-cdbc23dd-f01c-4d71-9bd2-6a8f9033d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-97585a83-9b1c-4455-a0a2-452cfc3bbf0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101121538-172.17.0.17-1597658525928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-d73adc40-0016-4471-8bf6-a1d03e4f577e,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-0e6752b5-ef3d-4f2f-9a4f-8996d5c7120e,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-6f10ff70-3781-487f-80cb-18fe667f5c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-c1c7802a-e9c8-4929-9ece-e0d974fed05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-b25e3d01-6453-44c9-b0e6-dad02dca5720,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-4ac2c2b0-5cf1-409d-aa55-f4e63f863ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-3bb9a178-c154-408b-9f52-bd0c26bf3067,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c9a32834-77c4-49f7-ae87-3a878db2e303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101121538-172.17.0.17-1597658525928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-d73adc40-0016-4471-8bf6-a1d03e4f577e,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-0e6752b5-ef3d-4f2f-9a4f-8996d5c7120e,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-6f10ff70-3781-487f-80cb-18fe667f5c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-c1c7802a-e9c8-4929-9ece-e0d974fed05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-b25e3d01-6453-44c9-b0e6-dad02dca5720,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-4ac2c2b0-5cf1-409d-aa55-f4e63f863ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-3bb9a178-c154-408b-9f52-bd0c26bf3067,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c9a32834-77c4-49f7-ae87-3a878db2e303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131079855-172.17.0.17-1597659558143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-f5b930db-2e20-4062-b943-21e2facb0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-d03e48b7-4ead-4bd5-a1a9-6e5749b4f77f,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-2bb0c6fa-ac19-4519-ad06-3d1d89670a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-601d1bdb-9069-4464-8576-2dde5586c755,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-bb2b3f69-73c7-4dea-a6e7-34705b2a9c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-61a8ca25-bc17-46e8-8bcc-64771b2e6643,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-6697df3d-05fb-4759-b867-6d1f72a62f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-7840a853-61e3-4f99-88cc-15d24d176981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131079855-172.17.0.17-1597659558143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-f5b930db-2e20-4062-b943-21e2facb0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-d03e48b7-4ead-4bd5-a1a9-6e5749b4f77f,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-2bb0c6fa-ac19-4519-ad06-3d1d89670a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-601d1bdb-9069-4464-8576-2dde5586c755,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-bb2b3f69-73c7-4dea-a6e7-34705b2a9c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-61a8ca25-bc17-46e8-8bcc-64771b2e6643,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-6697df3d-05fb-4759-b867-6d1f72a62f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-7840a853-61e3-4f99-88cc-15d24d176981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814511910-172.17.0.17-1597659671218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-ac88b41c-49aa-440d-8f46-9419b8948dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4be1e3f2-8c5c-4350-9e80-832fe59fad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-d2494420-ccb7-45ac-bc92-ce10c8be8667,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-20c1779f-c573-46c1-9873-d3fc94326beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-7b251d90-4ae1-4cb3-8816-ee2e6071c74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-5c586401-e49a-4fbc-8209-bcca1899eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-25a22296-d030-49d8-a883-2af68f472ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-bd419c5b-b012-4cd3-a7a3-c210cf238799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814511910-172.17.0.17-1597659671218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-ac88b41c-49aa-440d-8f46-9419b8948dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4be1e3f2-8c5c-4350-9e80-832fe59fad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-d2494420-ccb7-45ac-bc92-ce10c8be8667,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-20c1779f-c573-46c1-9873-d3fc94326beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-7b251d90-4ae1-4cb3-8816-ee2e6071c74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-5c586401-e49a-4fbc-8209-bcca1899eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-25a22296-d030-49d8-a883-2af68f472ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-bd419c5b-b012-4cd3-a7a3-c210cf238799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621889372-172.17.0.17-1597659702536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-f87dc45d-3364-4972-9263-4b7178beaaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-b32feb3f-f096-48b8-9868-07eeec7d0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-2fb03ced-a599-4daf-8c59-2577f2609d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-e4fec716-1145-4d97-a38d-8b1cc7f1249d,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-369bcd8a-f4e5-4745-bf21-effead518742,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-387c6390-7460-48df-82ac-efda73fdb971,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-f7a3226b-2ba1-44f5-873a-3b9833a7938c,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-003ce661-21cd-427a-85c2-12cc26d3fa65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621889372-172.17.0.17-1597659702536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-f87dc45d-3364-4972-9263-4b7178beaaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-b32feb3f-f096-48b8-9868-07eeec7d0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-2fb03ced-a599-4daf-8c59-2577f2609d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-e4fec716-1145-4d97-a38d-8b1cc7f1249d,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-369bcd8a-f4e5-4745-bf21-effead518742,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-387c6390-7460-48df-82ac-efda73fdb971,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-f7a3226b-2ba1-44f5-873a-3b9833a7938c,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-003ce661-21cd-427a-85c2-12cc26d3fa65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658877281-172.17.0.17-1597660023826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41405,DS-d829c9f6-29c4-4856-8f2e-5338c48797ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-d3d79ded-26fa-4fdc-bd63-1ed483884522,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e4283da0-e100-4ed6-8124-48502cafd61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-283f7ee0-47f3-45b9-a424-7a173da70dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6b25f1bf-878d-4d96-a318-f3288dfef4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-36733e74-6ab9-49e1-82c8-5181ebd665d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-e4d1633b-8cfd-4e4e-832f-e6ac0c9de247,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-5d56e397-a03a-4193-9bbf-1e3d1a17b0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658877281-172.17.0.17-1597660023826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41405,DS-d829c9f6-29c4-4856-8f2e-5338c48797ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-d3d79ded-26fa-4fdc-bd63-1ed483884522,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e4283da0-e100-4ed6-8124-48502cafd61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-283f7ee0-47f3-45b9-a424-7a173da70dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6b25f1bf-878d-4d96-a318-f3288dfef4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-36733e74-6ab9-49e1-82c8-5181ebd665d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-e4d1633b-8cfd-4e4e-832f-e6ac0c9de247,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-5d56e397-a03a-4193-9bbf-1e3d1a17b0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5750
