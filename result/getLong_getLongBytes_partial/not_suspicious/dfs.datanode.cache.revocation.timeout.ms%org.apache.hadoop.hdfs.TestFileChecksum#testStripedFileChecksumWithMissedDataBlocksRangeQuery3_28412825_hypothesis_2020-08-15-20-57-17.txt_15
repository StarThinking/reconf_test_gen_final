reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692604086-172.17.0.16-1597525312899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-8c4bf46e-62a2-475e-b700-f80e697c1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-9287996a-a652-4d33-8674-96781d237efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-f2827a6a-a5da-445d-bd27-a2c92cb87314,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-9ad6ce14-9b39-4cef-a426-fc39d6b74fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8644d98b-810a-4d43-af71-a89f51070a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-6ec47565-47c1-40c1-82dc-954f0a9ded69,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-cfbd6abb-38e6-4f3a-be6c-63fc97ad4314,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-33005244-bea9-4629-8216-2beb61c24225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692604086-172.17.0.16-1597525312899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-8c4bf46e-62a2-475e-b700-f80e697c1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-9287996a-a652-4d33-8674-96781d237efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-f2827a6a-a5da-445d-bd27-a2c92cb87314,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-9ad6ce14-9b39-4cef-a426-fc39d6b74fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8644d98b-810a-4d43-af71-a89f51070a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-6ec47565-47c1-40c1-82dc-954f0a9ded69,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-cfbd6abb-38e6-4f3a-be6c-63fc97ad4314,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-33005244-bea9-4629-8216-2beb61c24225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878410459-172.17.0.16-1597525973096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-67f06cd8-14d5-461d-a6bc-e1b8ac2b1df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-366db72f-a0ac-43e0-9b7c-d7ed5b7036af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-e3ae996d-9771-4dc7-900e-f32c6a4a8062,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-22a1414a-7bc0-4159-9e8d-91ca1bc230ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1a1b278d-4e02-4162-a663-ddd2b2a816c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-8636b7b6-e8ac-4d26-a789-80d86449e576,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7cb93a46-90c1-4c64-a523-bd512bad005b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-15ced5e5-c983-4823-bd53-d78e64f77f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878410459-172.17.0.16-1597525973096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-67f06cd8-14d5-461d-a6bc-e1b8ac2b1df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-366db72f-a0ac-43e0-9b7c-d7ed5b7036af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-e3ae996d-9771-4dc7-900e-f32c6a4a8062,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-22a1414a-7bc0-4159-9e8d-91ca1bc230ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1a1b278d-4e02-4162-a663-ddd2b2a816c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-8636b7b6-e8ac-4d26-a789-80d86449e576,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7cb93a46-90c1-4c64-a523-bd512bad005b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-15ced5e5-c983-4823-bd53-d78e64f77f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128724027-172.17.0.16-1597526584193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-f5490b32-c069-42a4-b79f-9c4e4bc4e151,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-1ec1280c-275b-4b57-bc7e-79ec95f4b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-20ee28d3-ac8e-4911-98c9-08bef939aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-3bd62ad9-028f-46ef-90c4-268a4ed8ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-273e5096-c46e-4e46-9ecb-081e5a45a103,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-0827549d-3e91-4aef-96be-6cc8d43a0836,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-68a17ad9-6a36-4fdf-99af-dfa42a546a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4fa32d04-e1e3-4f2e-8781-38d6e46bfb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128724027-172.17.0.16-1597526584193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-f5490b32-c069-42a4-b79f-9c4e4bc4e151,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-1ec1280c-275b-4b57-bc7e-79ec95f4b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-20ee28d3-ac8e-4911-98c9-08bef939aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-3bd62ad9-028f-46ef-90c4-268a4ed8ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-273e5096-c46e-4e46-9ecb-081e5a45a103,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-0827549d-3e91-4aef-96be-6cc8d43a0836,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-68a17ad9-6a36-4fdf-99af-dfa42a546a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4fa32d04-e1e3-4f2e-8781-38d6e46bfb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769841627-172.17.0.16-1597526999845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-6fc7c9ca-de02-4afd-83dd-c2cd47881e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-06d699de-7277-4c42-a236-a3bc242f69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-992bf351-294d-4f65-bcd4-ab92a01698e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-a49f1b9c-01d2-4267-924b-c3520d0dc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-ee540b9a-1844-48e9-8891-2258a9b14e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-72c69399-cc4c-4de6-add1-ab88878c33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-c36d94b7-346d-4986-8f27-3998ec27ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-249f70a4-dc84-41d5-8cd6-faaa1e9ffb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769841627-172.17.0.16-1597526999845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-6fc7c9ca-de02-4afd-83dd-c2cd47881e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-06d699de-7277-4c42-a236-a3bc242f69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-992bf351-294d-4f65-bcd4-ab92a01698e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-a49f1b9c-01d2-4267-924b-c3520d0dc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-ee540b9a-1844-48e9-8891-2258a9b14e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-72c69399-cc4c-4de6-add1-ab88878c33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-c36d94b7-346d-4986-8f27-3998ec27ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-249f70a4-dc84-41d5-8cd6-faaa1e9ffb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125349395-172.17.0.16-1597527191476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-81083fe3-6448-4f13-a746-134ebd24ddef,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-980b29ce-c6b5-4945-80ae-e647531cd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-20fdca75-b591-434c-ba57-51cc94f081a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-91aceff2-c1ed-4b0a-98a8-0a7fd6feedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-5d63b7f7-943c-48a0-ad34-fdb6c6ca2598,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-eaffe918-4eae-4080-aa86-5f245363a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-f3f38995-aa96-4608-b7d6-a33deb097ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-562a60af-44b9-4cad-8eab-2b1d54fd699a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125349395-172.17.0.16-1597527191476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-81083fe3-6448-4f13-a746-134ebd24ddef,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-980b29ce-c6b5-4945-80ae-e647531cd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-20fdca75-b591-434c-ba57-51cc94f081a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-91aceff2-c1ed-4b0a-98a8-0a7fd6feedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-5d63b7f7-943c-48a0-ad34-fdb6c6ca2598,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-eaffe918-4eae-4080-aa86-5f245363a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-f3f38995-aa96-4608-b7d6-a33deb097ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-562a60af-44b9-4cad-8eab-2b1d54fd699a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370831397-172.17.0.16-1597527533249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-bc442d5a-1894-439f-be18-850083e19376,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-e20bab4f-cb45-4e3d-aac9-ce829e74833f,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-b4007d53-7fea-4113-831a-1cd33aaf1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-a8ca68c4-b0b8-477a-b2a2-16be27581cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-d63c65fb-b094-4654-a55d-c399d172bdab,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-ae502e51-170a-4cc4-874d-40ef22bdea48,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-f7f6571b-7b5e-4995-adc0-4d32213277f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-f836bbc0-92e5-47ad-88a3-e4dd20d298c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370831397-172.17.0.16-1597527533249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-bc442d5a-1894-439f-be18-850083e19376,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-e20bab4f-cb45-4e3d-aac9-ce829e74833f,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-b4007d53-7fea-4113-831a-1cd33aaf1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-a8ca68c4-b0b8-477a-b2a2-16be27581cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-d63c65fb-b094-4654-a55d-c399d172bdab,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-ae502e51-170a-4cc4-874d-40ef22bdea48,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-f7f6571b-7b5e-4995-adc0-4d32213277f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-f836bbc0-92e5-47ad-88a3-e4dd20d298c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988866853-172.17.0.16-1597527860269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-93bfdaef-e798-4e70-9610-14fab281537f,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-210c6819-0f8a-4e33-9974-8ea4d179c188,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-2da4539d-3043-47e6-ac58-4d270c2c1977,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ede185a8-acd0-4ed5-8b4f-5054a5698031,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-27094b3b-63af-4ebb-b757-82d7bd5fd0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-dc8eeeab-9aa1-49cd-a901-c9aad9644473,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9ee0d47c-b02d-44fc-acca-5225c25c2c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-044787d7-5796-4fdb-ac08-5037436709f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988866853-172.17.0.16-1597527860269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-93bfdaef-e798-4e70-9610-14fab281537f,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-210c6819-0f8a-4e33-9974-8ea4d179c188,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-2da4539d-3043-47e6-ac58-4d270c2c1977,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ede185a8-acd0-4ed5-8b4f-5054a5698031,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-27094b3b-63af-4ebb-b757-82d7bd5fd0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-dc8eeeab-9aa1-49cd-a901-c9aad9644473,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9ee0d47c-b02d-44fc-acca-5225c25c2c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-044787d7-5796-4fdb-ac08-5037436709f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257375395-172.17.0.16-1597528091894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-b0fea69b-4cae-4f82-a8b6-66ea51cbe579,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-8c1697c8-0ba8-48ce-8ceb-095c4d5fbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-76a4b074-4eae-4502-91d4-51d3af3045ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-61014298-d034-490f-8a52-3938ae3d327e,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-16dcca3e-85e3-490d-86f6-10b1f750adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-94e5616a-0aaf-4427-9953-1ef25bb5d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-d940da71-7eb6-476d-a843-e86cd53b0953,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-571f18a2-6bef-4ae9-926d-895ef7f81fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257375395-172.17.0.16-1597528091894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-b0fea69b-4cae-4f82-a8b6-66ea51cbe579,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-8c1697c8-0ba8-48ce-8ceb-095c4d5fbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-76a4b074-4eae-4502-91d4-51d3af3045ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-61014298-d034-490f-8a52-3938ae3d327e,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-16dcca3e-85e3-490d-86f6-10b1f750adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-94e5616a-0aaf-4427-9953-1ef25bb5d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-d940da71-7eb6-476d-a843-e86cd53b0953,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-571f18a2-6bef-4ae9-926d-895ef7f81fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101059314-172.17.0.16-1597528915688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-2409ef60-c7ea-43d8-a1cc-926888f7c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-8ff0b96e-7009-42f2-80fc-43f5639e183e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-9658f630-13c3-4635-8b78-07414106f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-acd41f99-fd77-47da-b20e-bd2b900d84fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-b0b67384-c240-42c5-8df5-8baae0c26179,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b3790047-6255-4d78-a04d-e9753426bd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-92d983f1-43a3-4728-84de-c00377cd8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f664e7a2-6c68-45fe-bd07-b5363a32cfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101059314-172.17.0.16-1597528915688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-2409ef60-c7ea-43d8-a1cc-926888f7c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-8ff0b96e-7009-42f2-80fc-43f5639e183e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-9658f630-13c3-4635-8b78-07414106f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-acd41f99-fd77-47da-b20e-bd2b900d84fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-b0b67384-c240-42c5-8df5-8baae0c26179,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b3790047-6255-4d78-a04d-e9753426bd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-92d983f1-43a3-4728-84de-c00377cd8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f664e7a2-6c68-45fe-bd07-b5363a32cfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713899565-172.17.0.16-1597528991494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-ad398a46-9db3-488f-ac2a-0ef7fff74753,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-505f6102-b8f5-468b-8e87-baa312d6bcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-ebff7398-e5f8-486a-834b-8ceb80cbe555,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-d255deec-161e-4265-82d0-f9fd46c59570,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-4e69c1ab-c805-41a7-bd8d-60cf953528ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-2e3b40ac-b20c-483b-99c9-f160a0f81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-837592ca-4eeb-4f55-8891-64b3709d6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-bf706d0a-8e48-45a6-ab3b-98baa1f42a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713899565-172.17.0.16-1597528991494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-ad398a46-9db3-488f-ac2a-0ef7fff74753,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-505f6102-b8f5-468b-8e87-baa312d6bcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-ebff7398-e5f8-486a-834b-8ceb80cbe555,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-d255deec-161e-4265-82d0-f9fd46c59570,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-4e69c1ab-c805-41a7-bd8d-60cf953528ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-2e3b40ac-b20c-483b-99c9-f160a0f81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-837592ca-4eeb-4f55-8891-64b3709d6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-bf706d0a-8e48-45a6-ab3b-98baa1f42a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488139975-172.17.0.16-1597529452535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33464,DS-92a4a169-faaa-400d-a96d-7f69e2a20dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-b191f681-4921-43f8-87db-00c133f9aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-8801e8a3-7760-4784-aa42-758b0185fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-f476e67d-2773-4443-82b1-9e93af05885d,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-bdde5be7-7255-4d70-bae8-1f00a69472f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5f1e9c7b-c3ed-4394-88f0-5174832f0f67,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-1c4bc40c-27d4-4892-8be6-e6edb0a8a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-e8c070e6-ae1f-46ab-be34-8cf73934b997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488139975-172.17.0.16-1597529452535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33464,DS-92a4a169-faaa-400d-a96d-7f69e2a20dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-b191f681-4921-43f8-87db-00c133f9aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-8801e8a3-7760-4784-aa42-758b0185fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-f476e67d-2773-4443-82b1-9e93af05885d,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-bdde5be7-7255-4d70-bae8-1f00a69472f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5f1e9c7b-c3ed-4394-88f0-5174832f0f67,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-1c4bc40c-27d4-4892-8be6-e6edb0a8a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-e8c070e6-ae1f-46ab-be34-8cf73934b997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321866098-172.17.0.16-1597529717522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-6b77a12f-a6d9-45d5-a328-2a1ad38d8a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-1f062dc7-0471-4266-9d8b-d7a94775677e,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-ec55a77b-06c6-451b-a7f1-f232064b583c,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-457d6a82-bf94-41d7-a086-b014739235f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-1ebdc5a7-4560-4730-adc7-fb8cd827ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-cfc27deb-2b3e-44d7-ab6c-b44bcba8013e,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-f1aae0e7-ba33-4f32-806c-4dc2633022c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-020eea20-f49b-4da5-b4ab-e36e16e41b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321866098-172.17.0.16-1597529717522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-6b77a12f-a6d9-45d5-a328-2a1ad38d8a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-1f062dc7-0471-4266-9d8b-d7a94775677e,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-ec55a77b-06c6-451b-a7f1-f232064b583c,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-457d6a82-bf94-41d7-a086-b014739235f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-1ebdc5a7-4560-4730-adc7-fb8cd827ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-cfc27deb-2b3e-44d7-ab6c-b44bcba8013e,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-f1aae0e7-ba33-4f32-806c-4dc2633022c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-020eea20-f49b-4da5-b4ab-e36e16e41b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582897679-172.17.0.16-1597530039903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-5b33659e-1699-45ba-8aa3-890f4e85ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-349516d8-6153-45c8-9168-b34f96f85e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2e990b75-54ef-443e-a9a2-16644d0718fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-53fe1636-8c8b-473f-a19c-aaf466682692,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-feba382b-e75c-4ac7-92f1-1fa70b52685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-9053dd22-abc6-4ae4-91b6-06200e7c71c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-72d3ebb6-536a-4b14-9cd2-e90266531e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-7b6277e5-635e-4e01-af09-c7332bf7c5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582897679-172.17.0.16-1597530039903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-5b33659e-1699-45ba-8aa3-890f4e85ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-349516d8-6153-45c8-9168-b34f96f85e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2e990b75-54ef-443e-a9a2-16644d0718fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-53fe1636-8c8b-473f-a19c-aaf466682692,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-feba382b-e75c-4ac7-92f1-1fa70b52685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-9053dd22-abc6-4ae4-91b6-06200e7c71c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-72d3ebb6-536a-4b14-9cd2-e90266531e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-7b6277e5-635e-4e01-af09-c7332bf7c5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894736754-172.17.0.16-1597530642410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-63130df5-204b-4320-8a54-61c3df5a3280,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b909171d-a12c-4459-886a-fb2acf2342df,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-ab5673cb-a3cf-4936-b0c6-4ba90c7f7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-a603963d-2319-4f24-af4f-57f7ed33cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-fa53c5ef-948b-49c4-9615-03f6f50d51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-24607c35-dec3-4ed9-af65-bd10793cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-eb6d7b2c-f45e-4f60-8cca-bc0c6f77a0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-ab42a282-ae38-41a4-b1d7-d7e24142a64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894736754-172.17.0.16-1597530642410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-63130df5-204b-4320-8a54-61c3df5a3280,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b909171d-a12c-4459-886a-fb2acf2342df,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-ab5673cb-a3cf-4936-b0c6-4ba90c7f7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-a603963d-2319-4f24-af4f-57f7ed33cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-fa53c5ef-948b-49c4-9615-03f6f50d51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-24607c35-dec3-4ed9-af65-bd10793cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-eb6d7b2c-f45e-4f60-8cca-bc0c6f77a0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-ab42a282-ae38-41a4-b1d7-d7e24142a64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5626
