reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170891608-172.17.0.18-1597695786173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-7475510b-5277-44cf-b106-e362e6a2ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-761536cf-b92d-4fda-a8f9-d94640d4a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-cb9be5de-4e1f-4eb5-8499-dadc9debdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-9919f5e1-3a58-42d4-938f-d78322390cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-c4f119fb-a8f5-4372-819a-2a1c3b15a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-b18175f6-4cb5-45b7-a7e7-b4548fb992dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-87d9af70-21d1-41e0-8340-e598aa17030e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-824bae57-fff5-4789-9da7-5a2524bd932b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170891608-172.17.0.18-1597695786173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-7475510b-5277-44cf-b106-e362e6a2ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-761536cf-b92d-4fda-a8f9-d94640d4a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-cb9be5de-4e1f-4eb5-8499-dadc9debdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-9919f5e1-3a58-42d4-938f-d78322390cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-c4f119fb-a8f5-4372-819a-2a1c3b15a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-b18175f6-4cb5-45b7-a7e7-b4548fb992dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-87d9af70-21d1-41e0-8340-e598aa17030e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-824bae57-fff5-4789-9da7-5a2524bd932b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911552974-172.17.0.18-1597695891333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-4f2e6ae2-1c24-4d10-9154-1c2f35f1eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-481d2f45-5438-4b55-8838-11d202f67b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-d7599486-e660-46d0-b124-fc778f8810c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-31f94cad-677d-4afb-bb9a-c84425333a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-7c38d554-4a57-45d0-9c19-eee50c9eaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-b8e825d9-a03e-4a93-af39-2393b8d5762f,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-d1056b7c-b97b-4353-8a2f-4cafa05bc641,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-c5a9947e-a541-4eae-a3cc-172ad8a18d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911552974-172.17.0.18-1597695891333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-4f2e6ae2-1c24-4d10-9154-1c2f35f1eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-481d2f45-5438-4b55-8838-11d202f67b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-d7599486-e660-46d0-b124-fc778f8810c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-31f94cad-677d-4afb-bb9a-c84425333a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-7c38d554-4a57-45d0-9c19-eee50c9eaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-b8e825d9-a03e-4a93-af39-2393b8d5762f,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-d1056b7c-b97b-4353-8a2f-4cafa05bc641,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-c5a9947e-a541-4eae-a3cc-172ad8a18d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274404599-172.17.0.18-1597696382015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-99b554d9-71bf-42e9-bb56-dc931444c875,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-4811cf92-47bb-4cca-b5e8-5d879438bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-5487df3c-cad4-4b46-a4b2-7623751da059,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-2c12272a-f76f-4d13-91c1-7a2323cd8433,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-44724f6e-1fbb-42b7-b587-3bfdf0b37325,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-964c91f7-16bb-4e74-bd39-13f42f89150b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-80221933-62b1-431f-805e-9c92f4ae5462,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-02d3ab8a-c683-4f16-b838-fb08062c5a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274404599-172.17.0.18-1597696382015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-99b554d9-71bf-42e9-bb56-dc931444c875,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-4811cf92-47bb-4cca-b5e8-5d879438bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-5487df3c-cad4-4b46-a4b2-7623751da059,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-2c12272a-f76f-4d13-91c1-7a2323cd8433,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-44724f6e-1fbb-42b7-b587-3bfdf0b37325,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-964c91f7-16bb-4e74-bd39-13f42f89150b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-80221933-62b1-431f-805e-9c92f4ae5462,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-02d3ab8a-c683-4f16-b838-fb08062c5a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028792933-172.17.0.18-1597696492816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-cc15adc7-98f7-44ac-88e5-98238cc4e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-5c76a7a7-d9e2-4512-aac2-96c1721cb792,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-7e5b51ca-cce3-415f-9b17-c19eb06453a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0f5ca83b-796d-4707-a260-c9faf53da8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-2929245a-766c-4681-ab26-9cdacd32231f,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-50282fdc-1d96-499a-a3ef-647538ec69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-cdc26120-1f6c-4ea9-9ac1-75df4fa56ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-cd9bc8e4-b9c8-43b5-a196-956a2f1f5557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028792933-172.17.0.18-1597696492816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-cc15adc7-98f7-44ac-88e5-98238cc4e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-5c76a7a7-d9e2-4512-aac2-96c1721cb792,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-7e5b51ca-cce3-415f-9b17-c19eb06453a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0f5ca83b-796d-4707-a260-c9faf53da8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-2929245a-766c-4681-ab26-9cdacd32231f,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-50282fdc-1d96-499a-a3ef-647538ec69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-cdc26120-1f6c-4ea9-9ac1-75df4fa56ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-cd9bc8e4-b9c8-43b5-a196-956a2f1f5557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625935365-172.17.0.18-1597697761544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-fb215056-24a3-4021-b273-1919693aa80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-3e835fcb-1ff1-448c-abea-3c3bc711c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-93fa106f-431d-4c5c-9a21-6f00f6eaf0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-df8d8957-35bc-4923-b4fd-42922845d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-35e17887-40d0-4e07-a4c6-63c68c17be42,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-41eee4e5-3bda-4e5c-b231-583a72304987,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-1b2a42b9-876e-47ce-94c9-72a6e16498ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-eea3e014-2f89-4aa4-9c03-604062702c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625935365-172.17.0.18-1597697761544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-fb215056-24a3-4021-b273-1919693aa80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-3e835fcb-1ff1-448c-abea-3c3bc711c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-93fa106f-431d-4c5c-9a21-6f00f6eaf0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-df8d8957-35bc-4923-b4fd-42922845d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-35e17887-40d0-4e07-a4c6-63c68c17be42,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-41eee4e5-3bda-4e5c-b231-583a72304987,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-1b2a42b9-876e-47ce-94c9-72a6e16498ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-eea3e014-2f89-4aa4-9c03-604062702c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122068265-172.17.0.18-1597698111108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-e2d21963-6d71-4e9f-9df8-5d5980925d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-d2b3b4a8-ead8-4217-a61a-978f26a6f674,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-7115f9f4-bc45-420c-81c2-2239dcd2a324,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-ac022334-1576-49b4-b2cb-392fdb9c6186,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-000bb328-3930-4665-a093-b662e357596c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5d756595-7df2-442e-a044-489f5a1b36a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-8b9cff1b-4def-4884-a64c-a0fa928cc154,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-8d009261-278a-44b4-8920-da1a28ac85dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122068265-172.17.0.18-1597698111108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-e2d21963-6d71-4e9f-9df8-5d5980925d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-d2b3b4a8-ead8-4217-a61a-978f26a6f674,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-7115f9f4-bc45-420c-81c2-2239dcd2a324,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-ac022334-1576-49b4-b2cb-392fdb9c6186,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-000bb328-3930-4665-a093-b662e357596c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5d756595-7df2-442e-a044-489f5a1b36a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-8b9cff1b-4def-4884-a64c-a0fa928cc154,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-8d009261-278a-44b4-8920-da1a28ac85dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003686416-172.17.0.18-1597698144477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-01b88045-a350-4d93-b446-b7776100f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a4b4ae40-aea6-49c5-8a5d-a4757fd94806,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-5a06b828-028f-482d-a039-c34516bc9038,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-0a6cba29-460c-46ff-ae33-782edd02381b,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-5cf8cd5e-626b-4c31-aeff-e8333c492bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-d0fa057a-b1e2-464c-b0cd-2dac4c983e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-741c9970-12bc-404a-8505-4cfc745def64,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-17a65573-2244-4743-833f-aea1b4727304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003686416-172.17.0.18-1597698144477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-01b88045-a350-4d93-b446-b7776100f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a4b4ae40-aea6-49c5-8a5d-a4757fd94806,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-5a06b828-028f-482d-a039-c34516bc9038,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-0a6cba29-460c-46ff-ae33-782edd02381b,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-5cf8cd5e-626b-4c31-aeff-e8333c492bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-d0fa057a-b1e2-464c-b0cd-2dac4c983e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-741c9970-12bc-404a-8505-4cfc745def64,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-17a65573-2244-4743-833f-aea1b4727304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261356379-172.17.0.18-1597698225381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-31530170-6293-4e19-a068-8332a0744bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7ca2b653-8e71-40fc-a68b-3e42e04314af,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-80b626c3-23f6-4694-b32e-cf58d7443344,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-efac06b0-dc4e-4adb-855c-1dca0d7cb475,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-fce671f2-4064-4fca-832b-5167f1bd61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-47af7304-ce92-405e-b37c-7c9f12d01493,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3cb7abbe-ea2c-4f00-a2e1-d4feb91ab459,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-f03bbeff-489f-4499-b6ce-d8caeed80ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261356379-172.17.0.18-1597698225381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-31530170-6293-4e19-a068-8332a0744bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7ca2b653-8e71-40fc-a68b-3e42e04314af,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-80b626c3-23f6-4694-b32e-cf58d7443344,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-efac06b0-dc4e-4adb-855c-1dca0d7cb475,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-fce671f2-4064-4fca-832b-5167f1bd61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-47af7304-ce92-405e-b37c-7c9f12d01493,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3cb7abbe-ea2c-4f00-a2e1-d4feb91ab459,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-f03bbeff-489f-4499-b6ce-d8caeed80ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643104361-172.17.0.18-1597698331077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0bc69f18-72bc-4478-a634-29af34c7fee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-3075ee54-6d9b-453e-b7e2-806d79aa672d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ff7ecdc8-3405-4244-85ee-c1d67a86ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-aa1c2889-9524-4505-b2f7-e52262b917c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-0d5de60a-7989-4c85-9265-2532706a74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-f6b61624-4755-42a9-83a2-ce3eb740c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-0674e794-e4a7-4f1c-827a-5447cd8b9115,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-85e2b9fe-2e51-404d-8b52-4c33f7c6b96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643104361-172.17.0.18-1597698331077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0bc69f18-72bc-4478-a634-29af34c7fee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-3075ee54-6d9b-453e-b7e2-806d79aa672d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ff7ecdc8-3405-4244-85ee-c1d67a86ca66,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-aa1c2889-9524-4505-b2f7-e52262b917c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-0d5de60a-7989-4c85-9265-2532706a74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-f6b61624-4755-42a9-83a2-ce3eb740c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-0674e794-e4a7-4f1c-827a-5447cd8b9115,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-85e2b9fe-2e51-404d-8b52-4c33f7c6b96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336259776-172.17.0.18-1597698405974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-47a1fc99-6a04-4eef-829e-b500e836ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-eea7f416-7678-4b28-8005-2dbb240f593c,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-219cd096-e3e2-42a0-978a-ca4bb5eedd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2234b7b7-63cc-4a6d-89e5-1c1c0c3bd611,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-7fee137d-1d56-4f72-a5b6-b02680690d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-6c72e4a6-1768-4af9-abc7-7d018fc51dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-3dc0a84f-5492-462e-bb60-0e64588dda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-3fc35b75-7e6a-4de6-9246-c262eb9da3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336259776-172.17.0.18-1597698405974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-47a1fc99-6a04-4eef-829e-b500e836ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-eea7f416-7678-4b28-8005-2dbb240f593c,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-219cd096-e3e2-42a0-978a-ca4bb5eedd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2234b7b7-63cc-4a6d-89e5-1c1c0c3bd611,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-7fee137d-1d56-4f72-a5b6-b02680690d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-6c72e4a6-1768-4af9-abc7-7d018fc51dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-3dc0a84f-5492-462e-bb60-0e64588dda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-3fc35b75-7e6a-4de6-9246-c262eb9da3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054708721-172.17.0.18-1597698437314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-68b2733c-1981-4be0-b96f-573309475a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1d46e6fe-f7a4-471f-8a99-9e2c285ac18b,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-916ac5f7-feaf-406e-a273-3fbebd2f2575,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-bdc246c9-0f93-4b12-86f4-f1b7631e1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-8d4b9a14-6557-4c5d-b8be-a0b3d2c48dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-f60a4e20-012a-4e1b-9a54-71be9e58e069,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-583d9677-db87-4a72-a8b4-283efe87861c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f76fe4ee-2463-40fe-b4e0-8231824ea2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054708721-172.17.0.18-1597698437314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-68b2733c-1981-4be0-b96f-573309475a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1d46e6fe-f7a4-471f-8a99-9e2c285ac18b,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-916ac5f7-feaf-406e-a273-3fbebd2f2575,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-bdc246c9-0f93-4b12-86f4-f1b7631e1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-8d4b9a14-6557-4c5d-b8be-a0b3d2c48dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-f60a4e20-012a-4e1b-9a54-71be9e58e069,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-583d9677-db87-4a72-a8b4-283efe87861c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f76fe4ee-2463-40fe-b4e0-8231824ea2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126909960-172.17.0.18-1597698574932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-6459a664-964b-413a-907e-f8f49953b454,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-a29e4d4d-47d2-4098-9067-3c0a7266ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6e26b58d-97f5-4940-be17-c28d185159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-905571c5-fd84-4cc4-8900-08716d96f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-6a7deb25-d5c3-407e-ba2d-2d807a544892,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-01a0cf2d-11f6-400e-9ad9-731baed79946,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-80bd965f-f6c2-4e8c-ba61-e7eacde3bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-2f8cd820-6222-44db-bef9-759e21ccc801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126909960-172.17.0.18-1597698574932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-6459a664-964b-413a-907e-f8f49953b454,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-a29e4d4d-47d2-4098-9067-3c0a7266ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6e26b58d-97f5-4940-be17-c28d185159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-905571c5-fd84-4cc4-8900-08716d96f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-6a7deb25-d5c3-407e-ba2d-2d807a544892,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-01a0cf2d-11f6-400e-9ad9-731baed79946,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-80bd965f-f6c2-4e8c-ba61-e7eacde3bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-2f8cd820-6222-44db-bef9-759e21ccc801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682980892-172.17.0.18-1597698901439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-c76def26-887e-405f-ab5b-e7d0210bee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-13969166-bfd3-47f3-a850-38cdcee994f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-2e2edbeb-aa95-43ac-8789-6d7d163cff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-56825869-645d-4270-b9bf-fde54678cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1ededab-db31-4da0-a77f-a0e3d3e79d19,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-3229a985-a32d-459c-ba9f-5cf9a8ac3f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-8935cc9c-570e-4fbb-bd29-619438106bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-d423b767-b2a2-4f1f-91ff-b390b5864a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682980892-172.17.0.18-1597698901439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-c76def26-887e-405f-ab5b-e7d0210bee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-13969166-bfd3-47f3-a850-38cdcee994f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-2e2edbeb-aa95-43ac-8789-6d7d163cff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-56825869-645d-4270-b9bf-fde54678cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1ededab-db31-4da0-a77f-a0e3d3e79d19,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-3229a985-a32d-459c-ba9f-5cf9a8ac3f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-8935cc9c-570e-4fbb-bd29-619438106bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-d423b767-b2a2-4f1f-91ff-b390b5864a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715730909-172.17.0.18-1597699052193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-cf715b30-24ee-44dc-9ac4-687e6490c46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-d37b55e5-fd98-4af9-887b-5d8500d3b206,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-f7c61118-b09e-43a9-bc8c-f8e039d1ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-846ccc61-d5da-49ef-ac49-b0d4102ef221,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-05d3907f-d3fd-4714-bdb5-1051f7f08983,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-742adbf9-2986-45bc-aa4e-a7d8f4ac1fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a2b7684a-b4df-4e1a-8f57-4cbe43e18c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-6c07000c-931f-4123-9725-dadead207104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715730909-172.17.0.18-1597699052193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-cf715b30-24ee-44dc-9ac4-687e6490c46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-d37b55e5-fd98-4af9-887b-5d8500d3b206,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-f7c61118-b09e-43a9-bc8c-f8e039d1ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-846ccc61-d5da-49ef-ac49-b0d4102ef221,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-05d3907f-d3fd-4714-bdb5-1051f7f08983,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-742adbf9-2986-45bc-aa4e-a7d8f4ac1fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a2b7684a-b4df-4e1a-8f57-4cbe43e18c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-6c07000c-931f-4123-9725-dadead207104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431831842-172.17.0.18-1597699090103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-cfb21c83-67f1-486c-8107-06ccaf5db104,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-1fbdca74-03d9-499a-b8e1-dd7ded6a35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-f28d0cd3-f145-4690-a504-75c5adeb93e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-a50f0b89-db48-4344-bb47-c7c58eb38471,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-892b30c7-3bdf-47b8-88b7-68eea2ef2239,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-aba41961-7c69-4dee-8db4-791778d9a031,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-450f84c8-4d44-420c-9fcb-8de4ad6a0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-3f0645b2-f860-452f-b20d-e854c30576b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431831842-172.17.0.18-1597699090103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-cfb21c83-67f1-486c-8107-06ccaf5db104,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-1fbdca74-03d9-499a-b8e1-dd7ded6a35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-f28d0cd3-f145-4690-a504-75c5adeb93e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-a50f0b89-db48-4344-bb47-c7c58eb38471,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-892b30c7-3bdf-47b8-88b7-68eea2ef2239,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-aba41961-7c69-4dee-8db4-791778d9a031,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-450f84c8-4d44-420c-9fcb-8de4ad6a0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-3f0645b2-f860-452f-b20d-e854c30576b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37240254-172.17.0.18-1597699733530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-881d08d9-1157-4f27-a2a1-3bb89088158b,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-a113c4c8-fca3-4dce-8297-8283f3e705d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-36679a0b-40d9-4cc7-a860-ce18bdf39902,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-c386025d-62a4-44a9-a8f2-d06d8b9a7412,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fc51dae3-7c3a-4be5-9bad-84b7772ad385,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-56287ecc-a82e-40b4-927e-d9202945918e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-335e7dd7-2bec-4b57-bdd0-58417d3a2606,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b4a59f2e-5276-4bff-bdad-790d6e3067ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37240254-172.17.0.18-1597699733530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-881d08d9-1157-4f27-a2a1-3bb89088158b,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-a113c4c8-fca3-4dce-8297-8283f3e705d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-36679a0b-40d9-4cc7-a860-ce18bdf39902,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-c386025d-62a4-44a9-a8f2-d06d8b9a7412,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fc51dae3-7c3a-4be5-9bad-84b7772ad385,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-56287ecc-a82e-40b4-927e-d9202945918e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-335e7dd7-2bec-4b57-bdd0-58417d3a2606,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b4a59f2e-5276-4bff-bdad-790d6e3067ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223509992-172.17.0.18-1597699873377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-f24d2b11-0155-4f2e-aa33-69bc3d52420f,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-7f91091e-ed05-4266-a14e-7b0b8dbf3909,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-f817cb2a-434c-4fc4-8bd0-e6b3e92e4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-c3539e42-52bb-4a80-a625-fc924afc5447,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-0c772d54-a9fd-4794-8bd8-24ca1604cc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-0b1b4954-6255-407f-af6c-8c4771789755,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-e8fc7a0a-4962-41bd-8be3-827dbcf24f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-728f2974-fb05-4b10-96fc-40194e6da4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223509992-172.17.0.18-1597699873377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-f24d2b11-0155-4f2e-aa33-69bc3d52420f,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-7f91091e-ed05-4266-a14e-7b0b8dbf3909,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-f817cb2a-434c-4fc4-8bd0-e6b3e92e4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-c3539e42-52bb-4a80-a625-fc924afc5447,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-0c772d54-a9fd-4794-8bd8-24ca1604cc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-0b1b4954-6255-407f-af6c-8c4771789755,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-e8fc7a0a-4962-41bd-8be3-827dbcf24f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-728f2974-fb05-4b10-96fc-40194e6da4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466982679-172.17.0.18-1597700213234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-68fc3c47-6fa4-4329-aa51-34c00f9e3a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-e11dc71a-7bee-4f56-962b-a859af7b599a,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-41372058-954d-4762-a9be-4ddb13828dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9c97d08f-14ac-45c8-a43b-e5f171ae7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-636c7fa8-fa71-462f-81d9-521fbd211c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d234dbfd-1918-4be9-a31a-d575157a282b,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-22004406-2c4a-4bc4-a259-08021ba906be,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-0b67f15a-e8be-411f-a0cf-136a5f1b92bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466982679-172.17.0.18-1597700213234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-68fc3c47-6fa4-4329-aa51-34c00f9e3a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-e11dc71a-7bee-4f56-962b-a859af7b599a,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-41372058-954d-4762-a9be-4ddb13828dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9c97d08f-14ac-45c8-a43b-e5f171ae7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-636c7fa8-fa71-462f-81d9-521fbd211c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d234dbfd-1918-4be9-a31a-d575157a282b,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-22004406-2c4a-4bc4-a259-08021ba906be,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-0b67f15a-e8be-411f-a0cf-136a5f1b92bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5437
