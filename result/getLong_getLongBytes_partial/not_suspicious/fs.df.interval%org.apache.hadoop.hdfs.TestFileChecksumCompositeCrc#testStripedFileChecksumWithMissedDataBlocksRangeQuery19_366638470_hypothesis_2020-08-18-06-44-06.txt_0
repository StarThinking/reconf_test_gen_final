reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208256888-172.17.0.8-1597733364343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-a8d8f63b-9aa2-4b33-b236-fbee7a49b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-6df3c0ec-3f02-401d-8425-23be12289edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-fa959ffe-f95e-4869-82bb-30141cc2d08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b93ef9ff-b6dd-463f-85ed-1dc23384de48,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-eccfabb4-b394-4417-8151-520317391753,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-36351021-78de-4f55-8ce8-750940b2f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-dc1c8c17-e78f-49cb-ae62-c7d6f4f99cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-253b2162-815a-4065-af17-45b8d469aee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208256888-172.17.0.8-1597733364343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-a8d8f63b-9aa2-4b33-b236-fbee7a49b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-6df3c0ec-3f02-401d-8425-23be12289edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-fa959ffe-f95e-4869-82bb-30141cc2d08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b93ef9ff-b6dd-463f-85ed-1dc23384de48,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-eccfabb4-b394-4417-8151-520317391753,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-36351021-78de-4f55-8ce8-750940b2f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-dc1c8c17-e78f-49cb-ae62-c7d6f4f99cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-253b2162-815a-4065-af17-45b8d469aee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234743147-172.17.0.8-1597734039282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-469b694e-0e56-41b5-b745-5be5d521212d,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-d2f2e3fb-d10c-419d-982e-689b88b04cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-a12e084f-ebcb-49c1-9590-012413b898a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-88ca752f-fd7e-4205-a376-737fb663d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c894f5f1-0fca-4a19-9e4d-3563227e4320,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-3ef1d8d1-b96f-44ec-bc5f-1cfd792d2953,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b5826e6a-7781-449a-8b6e-2c836af7dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-a1d77ce3-f48c-40b2-a912-30f532069a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234743147-172.17.0.8-1597734039282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-469b694e-0e56-41b5-b745-5be5d521212d,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-d2f2e3fb-d10c-419d-982e-689b88b04cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-a12e084f-ebcb-49c1-9590-012413b898a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-88ca752f-fd7e-4205-a376-737fb663d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c894f5f1-0fca-4a19-9e4d-3563227e4320,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-3ef1d8d1-b96f-44ec-bc5f-1cfd792d2953,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b5826e6a-7781-449a-8b6e-2c836af7dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-a1d77ce3-f48c-40b2-a912-30f532069a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903575316-172.17.0.8-1597734208909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-a5032bd5-f54b-404d-a116-c9d30e3d7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-8dbe05b9-e128-4f22-903e-1a6d8926c100,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-1f1ec8f5-2d28-45cd-88a0-6251c3c261ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d2a5e2c0-f1b2-4a48-b5d5-0f0446994f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-24f3691e-c838-4f5f-a0c4-27b524746bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-77541063-a749-4a5f-ae10-11c1e682a027,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-72620060-5352-4692-b54f-7de137bcd4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-8368b38b-5b5f-4946-a71d-013f82561aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903575316-172.17.0.8-1597734208909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-a5032bd5-f54b-404d-a116-c9d30e3d7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-8dbe05b9-e128-4f22-903e-1a6d8926c100,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-1f1ec8f5-2d28-45cd-88a0-6251c3c261ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d2a5e2c0-f1b2-4a48-b5d5-0f0446994f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-24f3691e-c838-4f5f-a0c4-27b524746bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-77541063-a749-4a5f-ae10-11c1e682a027,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-72620060-5352-4692-b54f-7de137bcd4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-8368b38b-5b5f-4946-a71d-013f82561aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961112168-172.17.0.8-1597735010971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-7e421766-548f-4e41-8ef1-3ac9d6d8f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bdaf9974-c913-4a3b-95ce-142706676ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-b3240b7d-bc06-41c5-9bde-161d43be1051,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-0423bef9-a593-40a1-8ff8-42b5ee290ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-f7e7a383-2d8c-45c7-8883-fd40935cd3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-4328b294-14a2-495e-8775-715ed26658b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-4add4383-2dc0-4fcb-9a4c-666d593e5a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-890e76dc-ef68-46f6-939a-3f250ead3dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961112168-172.17.0.8-1597735010971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-7e421766-548f-4e41-8ef1-3ac9d6d8f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bdaf9974-c913-4a3b-95ce-142706676ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-b3240b7d-bc06-41c5-9bde-161d43be1051,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-0423bef9-a593-40a1-8ff8-42b5ee290ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-f7e7a383-2d8c-45c7-8883-fd40935cd3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-4328b294-14a2-495e-8775-715ed26658b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-4add4383-2dc0-4fcb-9a4c-666d593e5a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-890e76dc-ef68-46f6-939a-3f250ead3dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201084276-172.17.0.8-1597735360405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-de3704d5-3734-4b52-8c96-82e5dfc01f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-cc341c73-3e0d-47ff-b05f-efb31ed40409,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-13130e05-e518-4ca4-895f-ddd46bef3da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-47677569-e5e8-4a80-849a-9e10743c169b,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3542b0c8-4f90-4323-920c-25f046bb94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-9cf0f9b2-e9b0-4caa-88ee-1b99c3e50d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-5eb581fd-ccef-4fc9-8ef7-e9e1691f6549,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-334c1f77-eeb9-4be8-9a97-21c6c7284695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201084276-172.17.0.8-1597735360405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-de3704d5-3734-4b52-8c96-82e5dfc01f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-cc341c73-3e0d-47ff-b05f-efb31ed40409,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-13130e05-e518-4ca4-895f-ddd46bef3da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-47677569-e5e8-4a80-849a-9e10743c169b,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3542b0c8-4f90-4323-920c-25f046bb94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-9cf0f9b2-e9b0-4caa-88ee-1b99c3e50d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-5eb581fd-ccef-4fc9-8ef7-e9e1691f6549,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-334c1f77-eeb9-4be8-9a97-21c6c7284695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538913401-172.17.0.8-1597735473699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-36fa0888-ae3b-4557-b3a1-4c8cb87224b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-cc3a8758-ef6d-44f1-b171-5e000a58f450,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-7390c05e-d0f8-47a9-8762-8eee4b7fa9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-8f0ec89b-dae5-4e2a-b084-7a0b8c0c8317,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-7fdfc233-c34d-48ba-9aa0-c6099d9d4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-636a2414-e9b7-4b49-87d6-e9b35e7e4def,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-21457ea0-9cf1-4521-8cbc-3133a6e980fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-f2d117cc-6c39-479f-82cb-38ed6647736c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538913401-172.17.0.8-1597735473699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-36fa0888-ae3b-4557-b3a1-4c8cb87224b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-cc3a8758-ef6d-44f1-b171-5e000a58f450,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-7390c05e-d0f8-47a9-8762-8eee4b7fa9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-8f0ec89b-dae5-4e2a-b084-7a0b8c0c8317,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-7fdfc233-c34d-48ba-9aa0-c6099d9d4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-636a2414-e9b7-4b49-87d6-e9b35e7e4def,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-21457ea0-9cf1-4521-8cbc-3133a6e980fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-f2d117cc-6c39-479f-82cb-38ed6647736c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846791582-172.17.0.8-1597735514009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42042,DS-7432f43b-8bc4-444a-8aec-24349a6551aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-5847b52e-23fa-449d-8d47-d1955daf1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-ae6b7f31-b101-4928-aff7-775e74b5b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-1a76490d-fe64-40e1-a6ba-8a792884e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-7ddf769b-9a3d-4fc2-960d-019f715dd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d9691a14-8598-4c6c-bd4a-0d60729d56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-58bd646f-5124-48dd-8a3e-cb97c8f5b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ce36ab0d-d08c-4087-8d43-cbe26fd916a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846791582-172.17.0.8-1597735514009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42042,DS-7432f43b-8bc4-444a-8aec-24349a6551aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-5847b52e-23fa-449d-8d47-d1955daf1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-ae6b7f31-b101-4928-aff7-775e74b5b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-1a76490d-fe64-40e1-a6ba-8a792884e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-7ddf769b-9a3d-4fc2-960d-019f715dd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d9691a14-8598-4c6c-bd4a-0d60729d56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-58bd646f-5124-48dd-8a3e-cb97c8f5b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ce36ab0d-d08c-4087-8d43-cbe26fd916a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847164140-172.17.0.8-1597735653974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-7f4d6477-09c1-4979-ba52-874a35d5c849,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-1dbdb154-c162-449a-95fa-4ec0295059c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-766a8828-590c-41d5-8472-ca4a630abb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-90eeba38-c9f8-470d-9bbc-24ff7bca0dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-dd5e8f10-a69b-44f7-96ac-29da1b02856b,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-01356898-6910-4e0c-b75d-d63cc61aeb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fb1f5fe5-f335-4fa2-b490-204c4e068147,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-e44a84df-8808-40f1-a32c-75d84eee181d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847164140-172.17.0.8-1597735653974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-7f4d6477-09c1-4979-ba52-874a35d5c849,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-1dbdb154-c162-449a-95fa-4ec0295059c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-766a8828-590c-41d5-8472-ca4a630abb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-90eeba38-c9f8-470d-9bbc-24ff7bca0dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-dd5e8f10-a69b-44f7-96ac-29da1b02856b,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-01356898-6910-4e0c-b75d-d63cc61aeb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fb1f5fe5-f335-4fa2-b490-204c4e068147,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-e44a84df-8808-40f1-a32c-75d84eee181d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306493780-172.17.0.8-1597735723029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-02ccd82e-5953-4dd7-b60a-1653b8140344,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-884afffc-06f9-4290-b1e7-57a625080a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-5640209e-da13-4690-b05a-2c1c33a24bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-9b6b6239-bdb4-4be6-ab1b-4cb6e51d0113,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-1f64fd9b-3665-4f77-b173-f00dd2b4d563,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-c24a93f5-5d30-4375-83ef-73e7428b8333,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-6437bc0f-6b3f-4392-a51d-6da1f24855d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-aa2cb02b-f712-4bc6-a020-0416132dd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306493780-172.17.0.8-1597735723029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-02ccd82e-5953-4dd7-b60a-1653b8140344,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-884afffc-06f9-4290-b1e7-57a625080a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-5640209e-da13-4690-b05a-2c1c33a24bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-9b6b6239-bdb4-4be6-ab1b-4cb6e51d0113,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-1f64fd9b-3665-4f77-b173-f00dd2b4d563,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-c24a93f5-5d30-4375-83ef-73e7428b8333,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-6437bc0f-6b3f-4392-a51d-6da1f24855d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-aa2cb02b-f712-4bc6-a020-0416132dd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839520005-172.17.0.8-1597735931257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-b7115132-452c-468b-80e3-8f1a36f6561d,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-ad2c0840-614e-4503-bb7e-527f1ec44b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-bb058068-3964-4ea9-901e-14711817c64f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-e675c768-ebcc-4a51-9a4a-7485ce0af00f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-8357d667-6864-41ae-a304-010dff264362,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-b8e253f0-3ad5-4c9d-b3e8-b1e64067c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-90c2debd-6330-446c-a077-c8e7c0be23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-b376ac7c-0ba8-4915-b0f3-6d4a09fb7776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839520005-172.17.0.8-1597735931257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-b7115132-452c-468b-80e3-8f1a36f6561d,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-ad2c0840-614e-4503-bb7e-527f1ec44b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-bb058068-3964-4ea9-901e-14711817c64f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-e675c768-ebcc-4a51-9a4a-7485ce0af00f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-8357d667-6864-41ae-a304-010dff264362,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-b8e253f0-3ad5-4c9d-b3e8-b1e64067c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-90c2debd-6330-446c-a077-c8e7c0be23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-b376ac7c-0ba8-4915-b0f3-6d4a09fb7776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946782308-172.17.0.8-1597736339581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-9117c5aa-37c6-4944-bd22-276f1cb8281f,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-afbd3eda-ded2-4f03-8678-f89766c61e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b92db932-620c-446b-8c92-2cb77a720a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-8d77e793-330f-481a-8118-800879dcaed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1d384fec-efa6-49ec-b3b7-5dc7405f8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-cd449d21-a8a9-4af6-9042-a015bd6f8a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-be2c7d83-a806-4317-b6b0-0f9391955ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-508b7612-aca1-416e-a011-cc0e24518c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946782308-172.17.0.8-1597736339581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-9117c5aa-37c6-4944-bd22-276f1cb8281f,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-afbd3eda-ded2-4f03-8678-f89766c61e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b92db932-620c-446b-8c92-2cb77a720a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-8d77e793-330f-481a-8118-800879dcaed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1d384fec-efa6-49ec-b3b7-5dc7405f8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-cd449d21-a8a9-4af6-9042-a015bd6f8a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-be2c7d83-a806-4317-b6b0-0f9391955ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-508b7612-aca1-416e-a011-cc0e24518c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139801466-172.17.0.8-1597736744323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-b3b8da3f-eecd-4137-baac-19c971182d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-9cc935ed-83af-4df1-810d-00d1772f3a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-90c41243-ac7b-4182-97f2-75607d75811a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-13d8b058-c504-4e79-a806-89ce86e2cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-c4322487-4d28-4add-9d4b-66e56b191172,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-af7002eb-7da3-4014-853a-ed2ec28f5e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-4a5247c7-2026-41b9-86b6-f30f9f3a5b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-7f7bd6be-a228-442d-bbf4-3408406d92ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139801466-172.17.0.8-1597736744323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-b3b8da3f-eecd-4137-baac-19c971182d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-9cc935ed-83af-4df1-810d-00d1772f3a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-90c41243-ac7b-4182-97f2-75607d75811a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-13d8b058-c504-4e79-a806-89ce86e2cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-c4322487-4d28-4add-9d4b-66e56b191172,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-af7002eb-7da3-4014-853a-ed2ec28f5e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-4a5247c7-2026-41b9-86b6-f30f9f3a5b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-7f7bd6be-a228-442d-bbf4-3408406d92ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7107974-172.17.0.8-1597737090954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-b481174c-cc36-472a-8744-1c4ab89d79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-4ae3660e-f7d4-429a-b873-688a3d3ca06d,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-81d1f6f4-3f61-47c0-a540-1f6c81111caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-76cddfdf-3e8f-42c8-8a24-285bf43ba878,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-a4153426-3d75-4f5b-91c3-8f51de227629,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-da2ca263-0332-41ef-9616-bcb29dfedfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a58d95ec-14bf-4258-82b5-a2b7b2bc6a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-960d479e-8d15-4398-ab77-115ebb6a3258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7107974-172.17.0.8-1597737090954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-b481174c-cc36-472a-8744-1c4ab89d79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-4ae3660e-f7d4-429a-b873-688a3d3ca06d,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-81d1f6f4-3f61-47c0-a540-1f6c81111caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-76cddfdf-3e8f-42c8-8a24-285bf43ba878,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-a4153426-3d75-4f5b-91c3-8f51de227629,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-da2ca263-0332-41ef-9616-bcb29dfedfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a58d95ec-14bf-4258-82b5-a2b7b2bc6a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-960d479e-8d15-4398-ab77-115ebb6a3258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451268079-172.17.0.8-1597737154915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-567575c8-5cc5-4486-a05c-c514250a21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-0a16352d-c905-4789-8200-b589afe27496,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-5db9f405-299a-4864-96e4-6f1a96391918,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-77a8e6b2-c8d4-450d-bbda-3f88ec570686,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-3f1b1a90-977a-4865-8be5-165024457348,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-e2fe9212-9b37-46c1-9120-7facd934204c,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae77a0b0-686c-430f-bc79-6fc7f91cd390,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-cbfccb50-470b-4259-a1a8-b9fcae5d376d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451268079-172.17.0.8-1597737154915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-567575c8-5cc5-4486-a05c-c514250a21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-0a16352d-c905-4789-8200-b589afe27496,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-5db9f405-299a-4864-96e4-6f1a96391918,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-77a8e6b2-c8d4-450d-bbda-3f88ec570686,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-3f1b1a90-977a-4865-8be5-165024457348,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-e2fe9212-9b37-46c1-9120-7facd934204c,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae77a0b0-686c-430f-bc79-6fc7f91cd390,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-cbfccb50-470b-4259-a1a8-b9fcae5d376d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664691230-172.17.0.8-1597737345968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-4de56a29-1cfe-4b54-87d1-c19615c0d999,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-d6fab00b-d2df-4fcb-8573-8c2c697ed6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-e2c543c3-f1fe-4395-93d4-160dbcb65da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-bdfb2320-9f4e-4bd1-9a67-b035bd4de53d,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-18b93c34-be71-4f57-bdb9-e5563d8da14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-69d17dcf-6f9d-49df-b170-92ac27685432,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-4c039e84-83f4-45d5-8ccd-6b774c16a108,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-617a1b78-aa8e-4664-b8df-a28a11bbd772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664691230-172.17.0.8-1597737345968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-4de56a29-1cfe-4b54-87d1-c19615c0d999,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-d6fab00b-d2df-4fcb-8573-8c2c697ed6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-e2c543c3-f1fe-4395-93d4-160dbcb65da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-bdfb2320-9f4e-4bd1-9a67-b035bd4de53d,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-18b93c34-be71-4f57-bdb9-e5563d8da14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-69d17dcf-6f9d-49df-b170-92ac27685432,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-4c039e84-83f4-45d5-8ccd-6b774c16a108,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-617a1b78-aa8e-4664-b8df-a28a11bbd772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102823361-172.17.0.8-1597737422404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-f02f0b87-1168-4af5-b805-7c1d7a84fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-0dc21cc2-c9e2-4840-a028-e0255c103e59,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-2e3c7f7b-aa4a-409e-a100-48c79b44d7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-644b4e73-d636-400a-842e-769127e33d38,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-2ec6f4fc-c823-43a3-81e0-67410b78752d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-0b698c8b-a8de-4439-8272-adb9eb3d4cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-b00d7e07-2c81-4108-ac9b-875882c50982,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-232169db-ddcc-4024-b3ab-471f6986b0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102823361-172.17.0.8-1597737422404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-f02f0b87-1168-4af5-b805-7c1d7a84fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-0dc21cc2-c9e2-4840-a028-e0255c103e59,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-2e3c7f7b-aa4a-409e-a100-48c79b44d7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-644b4e73-d636-400a-842e-769127e33d38,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-2ec6f4fc-c823-43a3-81e0-67410b78752d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-0b698c8b-a8de-4439-8272-adb9eb3d4cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-b00d7e07-2c81-4108-ac9b-875882c50982,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-232169db-ddcc-4024-b3ab-471f6986b0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608135229-172.17.0.8-1597737722466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-85ed87f8-7ef6-4c50-ad07-9884dcc42476,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a26b4d38-a979-48e1-aac2-2c3489ea0bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-9f3fcf17-375f-4974-b11e-facaf648fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-29544594-6591-436f-aea4-53ecc587dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-8b401468-9889-4c01-93bf-3b8bc104eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-98c95bcf-d5e8-467c-b370-1f6811e27d74,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-af87e753-55fd-4b1d-a723-30848af157b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-fd6781fe-4a70-429a-989e-6f190d015f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608135229-172.17.0.8-1597737722466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-85ed87f8-7ef6-4c50-ad07-9884dcc42476,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a26b4d38-a979-48e1-aac2-2c3489ea0bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-9f3fcf17-375f-4974-b11e-facaf648fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-29544594-6591-436f-aea4-53ecc587dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-8b401468-9889-4c01-93bf-3b8bc104eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-98c95bcf-d5e8-467c-b370-1f6811e27d74,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-af87e753-55fd-4b1d-a723-30848af157b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-fd6781fe-4a70-429a-989e-6f190d015f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540638404-172.17.0.8-1597737760041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-3eb12619-1dd7-45f8-89e7-5734c8717cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-105720e6-4718-45bd-8108-70027b777e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-193b0ca2-7918-450d-af61-e0353401d148,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-5e0783fb-d695-43d5-86d3-4a25c6dfa3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-aa0393d5-c373-4a14-845d-69a85252b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-7cef1d09-61f2-41aa-97a5-4ae9a9916331,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8e31196c-0032-471a-b445-abc0505389ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-9b9a573e-7a1f-4af8-bcc7-d04a10a3fbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540638404-172.17.0.8-1597737760041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-3eb12619-1dd7-45f8-89e7-5734c8717cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-105720e6-4718-45bd-8108-70027b777e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-193b0ca2-7918-450d-af61-e0353401d148,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-5e0783fb-d695-43d5-86d3-4a25c6dfa3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-aa0393d5-c373-4a14-845d-69a85252b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-7cef1d09-61f2-41aa-97a5-4ae9a9916331,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8e31196c-0032-471a-b445-abc0505389ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-9b9a573e-7a1f-4af8-bcc7-d04a10a3fbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621708012-172.17.0.8-1597738136429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-e9ba3b19-db98-46c2-a796-9c9b0c5aebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-678d32c6-ed91-490f-99f4-501c5f15d655,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-796ab4c1-87a7-499c-9249-2c9e49f57837,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-8db4a89f-69d4-4ae0-a566-b45d2e4c7ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-cf6faf94-6db8-40fe-ab68-ac691b693cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-601fdddf-7a19-4b74-a9e8-50d08b3a7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-1bdbee04-2519-4d16-b5af-94193012d745,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-17f14b9d-6f42-48fb-b24e-2d706a0f7184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621708012-172.17.0.8-1597738136429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-e9ba3b19-db98-46c2-a796-9c9b0c5aebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-678d32c6-ed91-490f-99f4-501c5f15d655,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-796ab4c1-87a7-499c-9249-2c9e49f57837,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-8db4a89f-69d4-4ae0-a566-b45d2e4c7ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-cf6faf94-6db8-40fe-ab68-ac691b693cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-601fdddf-7a19-4b74-a9e8-50d08b3a7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-1bdbee04-2519-4d16-b5af-94193012d745,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-17f14b9d-6f42-48fb-b24e-2d706a0f7184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5443
