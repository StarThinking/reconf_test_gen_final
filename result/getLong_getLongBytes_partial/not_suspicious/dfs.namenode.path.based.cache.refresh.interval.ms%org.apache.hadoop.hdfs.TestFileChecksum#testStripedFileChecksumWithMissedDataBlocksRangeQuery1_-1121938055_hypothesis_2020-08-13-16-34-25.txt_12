reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53444123-172.17.0.11-1597336594269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-fe93da4c-a55a-48cf-99d9-fd88cc42bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-cbe4c32e-18bc-45e8-866b-ad146dcadb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-f92d254f-5412-466f-a46c-fc6d8915ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-cd1605e6-665a-44a8-9585-32f83df7dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-0c9abc3e-9a87-4c2a-ac19-9929652a8ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-097ca23e-7a3e-4768-ab92-e4a01b34347a,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8a878fe3-ce74-4e69-b41e-e054e14b8e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-f88af81c-c604-4ac2-8936-df4b90c8e656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53444123-172.17.0.11-1597336594269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-fe93da4c-a55a-48cf-99d9-fd88cc42bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-cbe4c32e-18bc-45e8-866b-ad146dcadb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-f92d254f-5412-466f-a46c-fc6d8915ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-cd1605e6-665a-44a8-9585-32f83df7dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-0c9abc3e-9a87-4c2a-ac19-9929652a8ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-097ca23e-7a3e-4768-ab92-e4a01b34347a,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8a878fe3-ce74-4e69-b41e-e054e14b8e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-f88af81c-c604-4ac2-8936-df4b90c8e656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072755700-172.17.0.11-1597336672454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-23518146-d126-4ba7-abc9-73a866b15aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-fee0894a-3096-4bb0-bab5-9d4caa158c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-35d7f519-92e0-4201-bc0c-cc7844563b30,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-d79227fd-e0e5-452d-8d56-b3a3d2243fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-2b5e7991-0c7f-4376-87aa-ec659ca49e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c955ecca-7a9f-463e-a303-aae4d343131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-e4ae6c2e-5ab2-4c69-8e34-9bd570b65b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-39bd0290-7352-4fc4-95e6-2a387c41b334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072755700-172.17.0.11-1597336672454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-23518146-d126-4ba7-abc9-73a866b15aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-fee0894a-3096-4bb0-bab5-9d4caa158c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-35d7f519-92e0-4201-bc0c-cc7844563b30,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-d79227fd-e0e5-452d-8d56-b3a3d2243fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-2b5e7991-0c7f-4376-87aa-ec659ca49e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c955ecca-7a9f-463e-a303-aae4d343131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-e4ae6c2e-5ab2-4c69-8e34-9bd570b65b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-39bd0290-7352-4fc4-95e6-2a387c41b334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629266860-172.17.0.11-1597336883523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-ac1bd1fc-b863-4daa-865c-8039aa112654,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-2e0365af-ed3f-4edb-878d-9e489b6d8a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-d396b583-e280-430d-9450-26cebb42167d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-99a72ad9-f956-4c50-95da-dda564aec85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-709b87a6-f237-4ac7-bfbd-7a4eae26998d,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-02044df8-db01-4196-b263-278663af0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-784acbf6-7fc0-44aa-9657-700bd5483a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-783ad28d-5dc0-41a9-ae76-b7a0543c3af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629266860-172.17.0.11-1597336883523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-ac1bd1fc-b863-4daa-865c-8039aa112654,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-2e0365af-ed3f-4edb-878d-9e489b6d8a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-d396b583-e280-430d-9450-26cebb42167d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-99a72ad9-f956-4c50-95da-dda564aec85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-709b87a6-f237-4ac7-bfbd-7a4eae26998d,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-02044df8-db01-4196-b263-278663af0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-784acbf6-7fc0-44aa-9657-700bd5483a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-783ad28d-5dc0-41a9-ae76-b7a0543c3af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532524770-172.17.0.11-1597336920087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-3dd6acd4-5fe5-4995-9f64-ba1d22d0d729,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-9608686d-feec-425d-a82d-94e2ff316290,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-7772b256-09cc-400e-b87e-95cce0b7823d,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-91aa8a30-421e-442d-b023-3ccc7eefce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-c750c224-d4dc-449f-ac70-1ad332f65baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-3418b21a-a7e6-46d9-a8d3-7b593157a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-e1cc5c65-abaf-44be-aeee-f194d276b338,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-e01efe0d-d055-436f-90d0-c264c8f67eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532524770-172.17.0.11-1597336920087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-3dd6acd4-5fe5-4995-9f64-ba1d22d0d729,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-9608686d-feec-425d-a82d-94e2ff316290,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-7772b256-09cc-400e-b87e-95cce0b7823d,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-91aa8a30-421e-442d-b023-3ccc7eefce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-c750c224-d4dc-449f-ac70-1ad332f65baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-3418b21a-a7e6-46d9-a8d3-7b593157a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-e1cc5c65-abaf-44be-aeee-f194d276b338,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-e01efe0d-d055-436f-90d0-c264c8f67eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710342552-172.17.0.11-1597337098416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-4fdb97e8-eaa7-4473-85db-b7c49a178b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-a4a332bb-b844-4411-a949-3fad79cbb759,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-e94b7c1b-432b-4cdf-b0d7-7e044f783d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-de32e763-c279-48e7-b98e-4db732f6f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-92426c18-1a3a-48d3-8b99-a732668ccaed,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-d544bbcf-aa1b-4702-82f7-20d9ddc689ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-01d995c4-8625-4a5b-b1ce-e282d2c20ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-788fe8c5-5f4a-42bc-b028-91cf7aef051b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710342552-172.17.0.11-1597337098416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-4fdb97e8-eaa7-4473-85db-b7c49a178b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-a4a332bb-b844-4411-a949-3fad79cbb759,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-e94b7c1b-432b-4cdf-b0d7-7e044f783d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-de32e763-c279-48e7-b98e-4db732f6f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-92426c18-1a3a-48d3-8b99-a732668ccaed,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-d544bbcf-aa1b-4702-82f7-20d9ddc689ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-01d995c4-8625-4a5b-b1ce-e282d2c20ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-788fe8c5-5f4a-42bc-b028-91cf7aef051b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258662170-172.17.0.11-1597337244567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-24504cf2-64c7-4abd-b542-c297526dce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-3d4ed1a4-8742-42ca-b134-028f8d74d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-523ee8ed-343e-4cf6-b537-d994ea88988a,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-07bfff33-c8a5-4165-8c3d-866529fb86f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-d71162b1-a56d-4b07-a13f-29b30fe00809,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-0b9853cf-8304-4b0e-92b8-f630cb13a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-d52f1aa4-8353-415a-a0e2-89a7bc0960ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-b18f8a81-070e-4ff3-8c7b-c0b23a4a909d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258662170-172.17.0.11-1597337244567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-24504cf2-64c7-4abd-b542-c297526dce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-3d4ed1a4-8742-42ca-b134-028f8d74d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-523ee8ed-343e-4cf6-b537-d994ea88988a,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-07bfff33-c8a5-4165-8c3d-866529fb86f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-d71162b1-a56d-4b07-a13f-29b30fe00809,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-0b9853cf-8304-4b0e-92b8-f630cb13a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-d52f1aa4-8353-415a-a0e2-89a7bc0960ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-b18f8a81-070e-4ff3-8c7b-c0b23a4a909d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293524742-172.17.0.11-1597337361996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-2f10e119-14d9-4adb-b38b-45e760cd62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-ec1891bd-9770-4eb0-a3b8-8a9ece72af12,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2d9ac5b0-c806-467d-8545-2c647b091542,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3aedc14a-f051-41d9-9eba-0782c51840ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-280942b5-eee9-4d29-9dcc-cec18a2b1a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-61beafe1-f18c-4125-bcac-7e2f87a0234e,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-bccab08d-972b-408d-9f72-12ec06beb08d,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-c8a72fd0-f31b-41d6-bf94-73740a84ad2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293524742-172.17.0.11-1597337361996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-2f10e119-14d9-4adb-b38b-45e760cd62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-ec1891bd-9770-4eb0-a3b8-8a9ece72af12,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2d9ac5b0-c806-467d-8545-2c647b091542,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3aedc14a-f051-41d9-9eba-0782c51840ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-280942b5-eee9-4d29-9dcc-cec18a2b1a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-61beafe1-f18c-4125-bcac-7e2f87a0234e,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-bccab08d-972b-408d-9f72-12ec06beb08d,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-c8a72fd0-f31b-41d6-bf94-73740a84ad2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227670672-172.17.0.11-1597338326350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-18db6858-2e53-4b0b-a2f9-39ca791f2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-ad46da51-11dd-4618-8bfa-cc5a2aac19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-bc42c744-359e-4917-9ae0-719eb2ba1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-d96acf46-740f-4ffb-9732-8fcdf18a020c,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-c690200e-a45a-4b58-805c-ae5b71504301,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-535d26c3-c3f3-40db-b47c-fd4e8ba12b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-b6ae2b78-eb8b-4620-8d36-1c67c269ff42,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-dab9eb4b-c005-4f42-9c94-c6f0a98c1180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227670672-172.17.0.11-1597338326350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-18db6858-2e53-4b0b-a2f9-39ca791f2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-ad46da51-11dd-4618-8bfa-cc5a2aac19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-bc42c744-359e-4917-9ae0-719eb2ba1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-d96acf46-740f-4ffb-9732-8fcdf18a020c,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-c690200e-a45a-4b58-805c-ae5b71504301,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-535d26c3-c3f3-40db-b47c-fd4e8ba12b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-b6ae2b78-eb8b-4620-8d36-1c67c269ff42,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-dab9eb4b-c005-4f42-9c94-c6f0a98c1180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37828379-172.17.0.11-1597339258261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-f9b7ac46-8a65-4514-9857-e658cd43047a,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-38eeb9f4-6ce3-4e05-8bbf-be50cb7d8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-cf344a41-5e91-4da4-95ba-fbc46004ca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-30645b8e-6696-4068-95e2-b06a71ca58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-50a28ed8-2f46-44b1-b98e-c3e1fbbf2cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-59e3d9fa-ecb3-4376-9bf9-84a05fb38d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-ddc63380-6439-40cc-8dc1-bc9728364b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-362d5a29-4d89-44a0-ab0e-19e89a641dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37828379-172.17.0.11-1597339258261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-f9b7ac46-8a65-4514-9857-e658cd43047a,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-38eeb9f4-6ce3-4e05-8bbf-be50cb7d8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-cf344a41-5e91-4da4-95ba-fbc46004ca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-30645b8e-6696-4068-95e2-b06a71ca58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-50a28ed8-2f46-44b1-b98e-c3e1fbbf2cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-59e3d9fa-ecb3-4376-9bf9-84a05fb38d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-ddc63380-6439-40cc-8dc1-bc9728364b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-362d5a29-4d89-44a0-ab0e-19e89a641dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132006763-172.17.0.11-1597339472851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38306,DS-a3149198-4e1e-44fa-9e14-a1e586387e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-47f6b779-1021-4884-8a5a-603925cb2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-d0d50423-d285-475f-983f-9d9e6c7ab32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ee5ecadf-6aea-41e7-a718-75d32a6373a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-52d121ba-02e5-4d72-bd53-680deb38e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-de55a441-1cb7-42a8-a321-6713c8c69236,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-0e396be6-f5cf-42cc-bea5-88330a57aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-a8a1dbab-31e5-42b8-bf63-f39c2887caa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132006763-172.17.0.11-1597339472851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38306,DS-a3149198-4e1e-44fa-9e14-a1e586387e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-47f6b779-1021-4884-8a5a-603925cb2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-d0d50423-d285-475f-983f-9d9e6c7ab32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ee5ecadf-6aea-41e7-a718-75d32a6373a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-52d121ba-02e5-4d72-bd53-680deb38e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-de55a441-1cb7-42a8-a321-6713c8c69236,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-0e396be6-f5cf-42cc-bea5-88330a57aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-a8a1dbab-31e5-42b8-bf63-f39c2887caa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571932362-172.17.0.11-1597339595984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-bdc7da2d-de94-4036-ab3c-49f9dc6c7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-6f071eb4-72e3-4d6d-88e6-b5ceb399323d,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1d2229df-231b-4e67-bd7b-d753824f3647,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-d2452eef-e248-4446-b50a-8d4624d5fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-6c8d68c2-89a6-4fc9-a8cb-bf7b7a5eb97d,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-46fb34b2-c826-4a3a-a315-cff01a72b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-bae8749d-228a-4001-87dc-b87ffad58048,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-14c03cb0-e42c-4530-bdd0-42e88a9f8d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571932362-172.17.0.11-1597339595984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-bdc7da2d-de94-4036-ab3c-49f9dc6c7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-6f071eb4-72e3-4d6d-88e6-b5ceb399323d,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1d2229df-231b-4e67-bd7b-d753824f3647,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-d2452eef-e248-4446-b50a-8d4624d5fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-6c8d68c2-89a6-4fc9-a8cb-bf7b7a5eb97d,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-46fb34b2-c826-4a3a-a315-cff01a72b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-bae8749d-228a-4001-87dc-b87ffad58048,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-14c03cb0-e42c-4530-bdd0-42e88a9f8d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106646393-172.17.0.11-1597339639062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-55bec7d7-5991-40ea-9c3e-e5aa2cc5955f,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-349a46c0-be23-4588-8fdb-2a57c4fc5495,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-52947746-56ac-4546-aabc-7b79be817125,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-931c2410-1d90-4741-a7f3-62c779c1249f,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-6383da35-c944-4b41-bbc3-8e2a7a2f9793,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-2d3ac1df-00ee-40e2-bece-a3094581db94,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-4960563a-4b39-4736-b67c-b27256399653,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-ce231fc6-a79b-47ad-a0b7-0337bfd5bfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106646393-172.17.0.11-1597339639062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-55bec7d7-5991-40ea-9c3e-e5aa2cc5955f,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-349a46c0-be23-4588-8fdb-2a57c4fc5495,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-52947746-56ac-4546-aabc-7b79be817125,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-931c2410-1d90-4741-a7f3-62c779c1249f,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-6383da35-c944-4b41-bbc3-8e2a7a2f9793,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-2d3ac1df-00ee-40e2-bece-a3094581db94,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-4960563a-4b39-4736-b67c-b27256399653,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-ce231fc6-a79b-47ad-a0b7-0337bfd5bfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301682021-172.17.0.11-1597340027008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-dbc77ae4-ce34-42d6-8e4b-c5e275ac3769,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-d00c0d81-0641-40e8-b270-4e250ffdfbab,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-2752760e-fc72-4280-a1a7-8a1f178e01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-efef0c87-1722-4ca6-9605-b00905d6028c,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b57ac6d4-f816-48c9-894d-189f986c3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ccbd94d8-7a1d-4391-9e16-28ef8d1575d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-de5780ca-c5e0-4993-b9d7-36a1f92553c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-6fcc6c54-1cc0-4e92-9f74-90c8f3c01929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301682021-172.17.0.11-1597340027008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-dbc77ae4-ce34-42d6-8e4b-c5e275ac3769,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-d00c0d81-0641-40e8-b270-4e250ffdfbab,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-2752760e-fc72-4280-a1a7-8a1f178e01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-efef0c87-1722-4ca6-9605-b00905d6028c,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b57ac6d4-f816-48c9-894d-189f986c3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ccbd94d8-7a1d-4391-9e16-28ef8d1575d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-de5780ca-c5e0-4993-b9d7-36a1f92553c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-6fcc6c54-1cc0-4e92-9f74-90c8f3c01929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629628626-172.17.0.11-1597340319098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-b00d3fce-9732-4872-975b-16ac9152907b,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6b1a633e-e4e3-4d30-ab6b-44d796047230,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-98eb85da-5a2e-43b6-b45f-db8b35ee0f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-19bb32e2-8534-4727-8462-95e48b049379,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-47cb3194-d3c2-4da1-bd1f-ff2c1d4aeade,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-87a91f9a-96bc-44de-a01d-ee6361c0a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-f00f3d01-af15-409e-8ac9-5dbc537984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-17e1dd31-f679-49b1-9226-f40fb2cbc98b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629628626-172.17.0.11-1597340319098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-b00d3fce-9732-4872-975b-16ac9152907b,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6b1a633e-e4e3-4d30-ab6b-44d796047230,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-98eb85da-5a2e-43b6-b45f-db8b35ee0f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-19bb32e2-8534-4727-8462-95e48b049379,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-47cb3194-d3c2-4da1-bd1f-ff2c1d4aeade,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-87a91f9a-96bc-44de-a01d-ee6361c0a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-f00f3d01-af15-409e-8ac9-5dbc537984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-17e1dd31-f679-49b1-9226-f40fb2cbc98b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536044637-172.17.0.11-1597340466610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-1d1a8e1a-a631-4854-a7bc-464fb885e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-4d4a5f64-4676-47dd-930c-5d27a3f120a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-b05411cf-ec55-486e-9bfc-a7d67a9e234e,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-6f2e1ceb-b5aa-40cd-9bdc-30772cab77b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-42016a7c-fba5-4c4d-9792-b3f195a9b48f,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-21d02983-d920-408b-9eb5-881104b6316a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-d9652263-15f5-494a-9898-033505845b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-ca1f4113-2494-4add-99a0-a352ca73fdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536044637-172.17.0.11-1597340466610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-1d1a8e1a-a631-4854-a7bc-464fb885e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-4d4a5f64-4676-47dd-930c-5d27a3f120a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-b05411cf-ec55-486e-9bfc-a7d67a9e234e,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-6f2e1ceb-b5aa-40cd-9bdc-30772cab77b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-42016a7c-fba5-4c4d-9792-b3f195a9b48f,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-21d02983-d920-408b-9eb5-881104b6316a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-d9652263-15f5-494a-9898-033505845b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-ca1f4113-2494-4add-99a0-a352ca73fdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266068260-172.17.0.11-1597340570503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-4a217937-46ce-45a6-a7f4-e68dafa23734,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d6232bbe-4f00-48e9-b8db-f43c75f6c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-25c79a77-02fe-42bf-bc06-b30861cbf2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-d87ad1df-a916-4042-832b-a3b39783724d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f64a71de-5f3a-4fef-8fd1-b66dd3d878bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-4ca47dc6-50b8-4fbf-9721-3f2c53da5d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-0c7705ea-075b-43e5-b88a-cff4d536a425,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-5b87463b-d28e-4034-98ab-1fea8befb5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266068260-172.17.0.11-1597340570503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-4a217937-46ce-45a6-a7f4-e68dafa23734,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d6232bbe-4f00-48e9-b8db-f43c75f6c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-25c79a77-02fe-42bf-bc06-b30861cbf2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-d87ad1df-a916-4042-832b-a3b39783724d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f64a71de-5f3a-4fef-8fd1-b66dd3d878bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-4ca47dc6-50b8-4fbf-9721-3f2c53da5d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-0c7705ea-075b-43e5-b88a-cff4d536a425,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-5b87463b-d28e-4034-98ab-1fea8befb5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553081451-172.17.0.11-1597340604904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-9696832b-cfb8-4794-b443-56bd04f20ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-db4121d0-dd28-44b3-b5f3-77040a749d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-dbe554e1-b85d-42da-a6c7-4cddbefb587c,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-3751bd70-29ac-4b42-9182-446eb9991b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-b09ce961-4e32-46fd-8d02-271ec3d3663f,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-964c1ff3-f6b6-4944-882b-f9ebb8fe6642,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-66c2e625-555c-4243-afcb-c180ebde19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-97136940-264e-4a8a-b4c4-1251da76e1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553081451-172.17.0.11-1597340604904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-9696832b-cfb8-4794-b443-56bd04f20ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-db4121d0-dd28-44b3-b5f3-77040a749d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-dbe554e1-b85d-42da-a6c7-4cddbefb587c,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-3751bd70-29ac-4b42-9182-446eb9991b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-b09ce961-4e32-46fd-8d02-271ec3d3663f,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-964c1ff3-f6b6-4944-882b-f9ebb8fe6642,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-66c2e625-555c-4243-afcb-c180ebde19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-97136940-264e-4a8a-b4c4-1251da76e1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578007433-172.17.0.11-1597341066704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-b9889947-2a2e-4ad8-aff2-969b85a9233f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-dbc86a68-9fcb-4fc0-8768-966b2451c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-5dcc5632-2b85-4ae7-a5c0-8e157edc37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-00218699-8bff-404e-8089-7c505cf0c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-03215c44-02a0-4be6-acde-c4805a266419,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-491bf0a7-7ff4-41d3-8832-b7af2acf67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-be4c62d2-3961-4d03-990b-f3ae751c1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0e43425d-cddc-4dd2-bd1d-0f06408b6f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578007433-172.17.0.11-1597341066704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-b9889947-2a2e-4ad8-aff2-969b85a9233f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-dbc86a68-9fcb-4fc0-8768-966b2451c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-5dcc5632-2b85-4ae7-a5c0-8e157edc37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-00218699-8bff-404e-8089-7c505cf0c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-03215c44-02a0-4be6-acde-c4805a266419,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-491bf0a7-7ff4-41d3-8832-b7af2acf67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-be4c62d2-3961-4d03-990b-f3ae751c1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0e43425d-cddc-4dd2-bd1d-0f06408b6f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950558029-172.17.0.11-1597341837562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39747,DS-acea65b5-bd4c-4e38-b324-21e41cc7a934,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-e39edbb0-5006-41bb-88b6-b191e32150d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-2c30de47-42ed-45b7-9e8a-4c8ca8a35393,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-bee4fcc8-cf5f-4f72-afec-a6f2cff4f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-f70fa27c-bd80-431b-87a9-afa69277693c,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-16312ca7-801d-4d8f-9d1b-82349de60cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b92d2383-74f2-4c6a-9c0d-c4254ae2868d,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-ea9b0f09-6560-4661-8427-22d1faf60f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950558029-172.17.0.11-1597341837562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39747,DS-acea65b5-bd4c-4e38-b324-21e41cc7a934,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-e39edbb0-5006-41bb-88b6-b191e32150d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-2c30de47-42ed-45b7-9e8a-4c8ca8a35393,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-bee4fcc8-cf5f-4f72-afec-a6f2cff4f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-f70fa27c-bd80-431b-87a9-afa69277693c,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-16312ca7-801d-4d8f-9d1b-82349de60cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b92d2383-74f2-4c6a-9c0d-c4254ae2868d,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-ea9b0f09-6560-4661-8427-22d1faf60f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5479
