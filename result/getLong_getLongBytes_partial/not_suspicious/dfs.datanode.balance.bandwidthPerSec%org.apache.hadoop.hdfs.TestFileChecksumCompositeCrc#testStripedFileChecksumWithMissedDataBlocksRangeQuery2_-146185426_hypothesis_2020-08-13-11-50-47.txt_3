reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189367187-172.17.0.10-1597322632000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-9e6ddd57-d5ec-4513-b176-a98515ddc800,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-ab7665d2-ce47-4805-9e60-9d596f20ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-b91962ae-77b7-4148-92f7-8a6db34919ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-9c666c76-5e6d-4832-8a45-2128a3b30660,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-12910378-eccb-495c-b3db-322be97a9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-0c1ae895-750b-40ef-8312-91dcd62067f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-2cad7c15-dc1f-40ff-9705-e658110c729c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-4095d5e1-d7f7-45a7-a730-545b52cb0c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189367187-172.17.0.10-1597322632000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-9e6ddd57-d5ec-4513-b176-a98515ddc800,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-ab7665d2-ce47-4805-9e60-9d596f20ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-b91962ae-77b7-4148-92f7-8a6db34919ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-9c666c76-5e6d-4832-8a45-2128a3b30660,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-12910378-eccb-495c-b3db-322be97a9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-0c1ae895-750b-40ef-8312-91dcd62067f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-2cad7c15-dc1f-40ff-9705-e658110c729c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-4095d5e1-d7f7-45a7-a730-545b52cb0c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619720359-172.17.0.10-1597323286294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-9554a833-17be-4c12-86c1-0d939d423a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-fef239cb-97b0-4319-8bd5-f574dfb0cd02,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-cc71f7a2-2ce5-433b-8424-4610357b70d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-e0683f65-b73b-4a81-893f-5529b2d7f1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-26b2bba0-3b69-4829-974a-49214bfc82b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-e62082b6-13f3-4c4c-a94a-0579559e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-168f73bb-8776-474c-aea7-4ad598a898a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e17c1caf-998f-452f-a887-dc418e10bafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619720359-172.17.0.10-1597323286294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-9554a833-17be-4c12-86c1-0d939d423a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-fef239cb-97b0-4319-8bd5-f574dfb0cd02,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-cc71f7a2-2ce5-433b-8424-4610357b70d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-e0683f65-b73b-4a81-893f-5529b2d7f1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-26b2bba0-3b69-4829-974a-49214bfc82b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-e62082b6-13f3-4c4c-a94a-0579559e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-168f73bb-8776-474c-aea7-4ad598a898a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e17c1caf-998f-452f-a887-dc418e10bafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229990253-172.17.0.10-1597323424718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-a78d7dc5-0bd2-4005-9d08-96517467dc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f6cdde50-ab27-428b-946b-9760bef91b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-ce84758d-83e0-4d53-820a-36dd53f86d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-307903df-d79e-4905-8137-6eabfd8faa22,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-1205b182-0edd-4300-aa1b-f4c0c4779563,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-be883a3a-5666-4046-be81-a7af08e8f849,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-c6181621-3c2f-46f5-a22d-331e5726756d,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-1e77cbfd-677f-43a1-aa9b-6d03e401dd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229990253-172.17.0.10-1597323424718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-a78d7dc5-0bd2-4005-9d08-96517467dc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f6cdde50-ab27-428b-946b-9760bef91b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-ce84758d-83e0-4d53-820a-36dd53f86d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-307903df-d79e-4905-8137-6eabfd8faa22,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-1205b182-0edd-4300-aa1b-f4c0c4779563,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-be883a3a-5666-4046-be81-a7af08e8f849,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-c6181621-3c2f-46f5-a22d-331e5726756d,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-1e77cbfd-677f-43a1-aa9b-6d03e401dd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403100847-172.17.0.10-1597323622844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea0fa7b9-e458-4979-a892-fbc52d9ceb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-f4ecbcf3-b782-4723-bede-8a219c441958,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-f6172d9c-ce98-4a9e-b858-e96712a58169,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-1fb10804-2524-4d8c-8763-7b83f7d1105e,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-8f4f2caa-fb7c-4300-adf5-b3276b6c4059,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-4786e1c7-620e-412f-bdb3-2b43b2bbfae7,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-be602051-cfb6-4723-8447-218a435dbca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-01076a35-2aaa-425a-b84b-94d1e293cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403100847-172.17.0.10-1597323622844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea0fa7b9-e458-4979-a892-fbc52d9ceb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-f4ecbcf3-b782-4723-bede-8a219c441958,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-f6172d9c-ce98-4a9e-b858-e96712a58169,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-1fb10804-2524-4d8c-8763-7b83f7d1105e,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-8f4f2caa-fb7c-4300-adf5-b3276b6c4059,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-4786e1c7-620e-412f-bdb3-2b43b2bbfae7,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-be602051-cfb6-4723-8447-218a435dbca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-01076a35-2aaa-425a-b84b-94d1e293cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488869922-172.17.0.10-1597323672868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34805,DS-507b2a5b-73bf-4d59-8b22-a6d5a2813fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1c0644de-a557-420f-b2de-66126c533204,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-74d0a033-8638-4907-83ca-6edb42ae713a,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-b547f8b0-6e89-4d02-8cc9-0b9632ef9446,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ac4813ab-52d4-4308-8aee-07681f5a4b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-e161534b-6a7a-4085-a657-a3ef9dd2b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-b2f6d912-8ffc-4e86-8f1a-f5c675c48c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-43ca2570-b2c2-4d6e-9bba-22b112cee9ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488869922-172.17.0.10-1597323672868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34805,DS-507b2a5b-73bf-4d59-8b22-a6d5a2813fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1c0644de-a557-420f-b2de-66126c533204,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-74d0a033-8638-4907-83ca-6edb42ae713a,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-b547f8b0-6e89-4d02-8cc9-0b9632ef9446,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ac4813ab-52d4-4308-8aee-07681f5a4b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-e161534b-6a7a-4085-a657-a3ef9dd2b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-b2f6d912-8ffc-4e86-8f1a-f5c675c48c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-43ca2570-b2c2-4d6e-9bba-22b112cee9ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607494854-172.17.0.10-1597324297793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34272,DS-9625fd5b-b2ee-4bf4-8f38-8f542af775d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-3fbccc46-89df-4079-aafe-05dac5da19af,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-1340f2b1-67a0-42d9-afc0-f2f952eb0171,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-71bfea1c-9f41-4551-ae50-738efede7576,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-54135f09-0e63-4e11-9948-db8593e693b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-026862f8-45dc-4d7f-9e42-a1396dc9e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-81149113-2faf-4b01-a5b6-45ac1439b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-447c7db0-8940-4fd7-9f61-ae2226551fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607494854-172.17.0.10-1597324297793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34272,DS-9625fd5b-b2ee-4bf4-8f38-8f542af775d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-3fbccc46-89df-4079-aafe-05dac5da19af,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-1340f2b1-67a0-42d9-afc0-f2f952eb0171,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-71bfea1c-9f41-4551-ae50-738efede7576,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-54135f09-0e63-4e11-9948-db8593e693b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-026862f8-45dc-4d7f-9e42-a1396dc9e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-81149113-2faf-4b01-a5b6-45ac1439b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-447c7db0-8940-4fd7-9f61-ae2226551fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073169508-172.17.0.10-1597324690350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-c4ee4beb-77dd-4551-b584-62b001f7effd,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-268524ae-93a5-48ec-8292-d6900297040a,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-4ae54ecf-b94a-42f1-93e4-2517d14ec665,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-2fdb7feb-bdc7-4705-908a-82b33b459c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-2745f5e4-f20c-458a-8ba5-530f6723e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-dc218a13-5731-4d49-b93c-e9bff57221db,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-2625b0bf-8837-4d05-bb9b-79997e27f6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-1473f0a5-6132-4070-a6f2-02341f6c0cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073169508-172.17.0.10-1597324690350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-c4ee4beb-77dd-4551-b584-62b001f7effd,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-268524ae-93a5-48ec-8292-d6900297040a,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-4ae54ecf-b94a-42f1-93e4-2517d14ec665,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-2fdb7feb-bdc7-4705-908a-82b33b459c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-2745f5e4-f20c-458a-8ba5-530f6723e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-dc218a13-5731-4d49-b93c-e9bff57221db,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-2625b0bf-8837-4d05-bb9b-79997e27f6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-1473f0a5-6132-4070-a6f2-02341f6c0cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325303619-172.17.0.10-1597324921492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-82661395-eec6-4cb4-902c-f0c17fd6c893,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-2addd093-54b1-419e-80cd-0b37086eacde,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3e7a8b41-000e-4aa8-9c8d-f06c6651061b,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-306c911c-c977-4e19-8cd2-2ef4a6dc638f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-4707010e-f0e6-412a-9ea4-225f1adc900d,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-c5409f4a-41c7-4aa2-a8f4-76a88a2da040,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-7f66d01c-6287-41de-a66f-e5c948e505f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-4500def9-eba4-41aa-b3d6-e1b362dcb7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325303619-172.17.0.10-1597324921492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-82661395-eec6-4cb4-902c-f0c17fd6c893,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-2addd093-54b1-419e-80cd-0b37086eacde,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3e7a8b41-000e-4aa8-9c8d-f06c6651061b,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-306c911c-c977-4e19-8cd2-2ef4a6dc638f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-4707010e-f0e6-412a-9ea4-225f1adc900d,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-c5409f4a-41c7-4aa2-a8f4-76a88a2da040,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-7f66d01c-6287-41de-a66f-e5c948e505f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-4500def9-eba4-41aa-b3d6-e1b362dcb7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943414863-172.17.0.10-1597325588464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-023c346d-4ab9-4761-842c-9e3be1dfa542,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-d270d848-306a-4164-b0ef-e12d94034f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-f866d2cd-e1a6-403e-9064-4a2900486988,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-fb7f65ff-2c77-4d7c-a850-047d40b87550,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-fedc8a9d-d961-42ea-9dc8-69ba36df66be,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-6a2898e6-dcc8-45ce-83a9-f1e98415db07,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-0ed2a18a-1b4f-468a-b2c1-cf2f1c51aa83,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-568b801a-5821-4a04-8ed6-e7dd4fd8c443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943414863-172.17.0.10-1597325588464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-023c346d-4ab9-4761-842c-9e3be1dfa542,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-d270d848-306a-4164-b0ef-e12d94034f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-f866d2cd-e1a6-403e-9064-4a2900486988,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-fb7f65ff-2c77-4d7c-a850-047d40b87550,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-fedc8a9d-d961-42ea-9dc8-69ba36df66be,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-6a2898e6-dcc8-45ce-83a9-f1e98415db07,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-0ed2a18a-1b4f-468a-b2c1-cf2f1c51aa83,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-568b801a-5821-4a04-8ed6-e7dd4fd8c443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981479767-172.17.0.10-1597325787242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-8fa5d1d6-3cd9-4f90-8f58-ce75e0b6d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6c35877f-7743-4d1d-aad1-7b87beba2288,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e3a8410d-ee46-4bf4-84d2-0138aa956ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ca946644-5e29-49af-932e-eb00958a1444,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-923ae002-e13f-4b97-8f34-a748106cbf67,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-d12c6efe-bf00-494e-b258-3535a634ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-e22267a0-99ea-4707-b585-29e2b8b51fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1e9fac2d-c7c1-43f7-bea6-7bd070d25884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981479767-172.17.0.10-1597325787242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-8fa5d1d6-3cd9-4f90-8f58-ce75e0b6d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6c35877f-7743-4d1d-aad1-7b87beba2288,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e3a8410d-ee46-4bf4-84d2-0138aa956ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ca946644-5e29-49af-932e-eb00958a1444,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-923ae002-e13f-4b97-8f34-a748106cbf67,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-d12c6efe-bf00-494e-b258-3535a634ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-e22267a0-99ea-4707-b585-29e2b8b51fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1e9fac2d-c7c1-43f7-bea6-7bd070d25884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371538276-172.17.0.10-1597326324436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-8ddb6e3c-7e5b-4714-b5c8-334cff54d28a,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-eee3f41b-9a33-4666-a5cd-6ecb1e313cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-cd149dab-793f-4657-b973-12075d92a092,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fff6b5f7-06ba-4e74-b264-91b3362a1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-96809d68-16ea-44e8-a56a-43921fb190d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-c3f8b251-727c-4890-aeca-b490dbb983a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-30cd4b52-0238-4f56-a791-939f6826edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-f2e3b18c-1317-46e4-aea9-cdcaab8fe9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371538276-172.17.0.10-1597326324436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-8ddb6e3c-7e5b-4714-b5c8-334cff54d28a,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-eee3f41b-9a33-4666-a5cd-6ecb1e313cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-cd149dab-793f-4657-b973-12075d92a092,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fff6b5f7-06ba-4e74-b264-91b3362a1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-96809d68-16ea-44e8-a56a-43921fb190d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-c3f8b251-727c-4890-aeca-b490dbb983a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-30cd4b52-0238-4f56-a791-939f6826edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-f2e3b18c-1317-46e4-aea9-cdcaab8fe9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7242
