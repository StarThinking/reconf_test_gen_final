reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694692212-172.17.0.2-1597463498136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-e5c00ffa-6df7-4db0-a210-ebcf360110ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-4535d7a8-48ae-4b48-8512-4f8f3a451773,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-7eed562e-34fc-4149-96d9-21cd44fc2d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-ce3a3285-9c93-493d-8bbd-11d90cb40f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-6cd112d2-1ddb-49ca-9e86-8ad3373c9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-cc5b7747-084c-429e-889b-786fc56bd3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-a8c6302f-0f83-4328-8dbe-c03f1739a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-49a088ac-8322-449e-a46c-3c00a54e15b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694692212-172.17.0.2-1597463498136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-e5c00ffa-6df7-4db0-a210-ebcf360110ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-4535d7a8-48ae-4b48-8512-4f8f3a451773,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-7eed562e-34fc-4149-96d9-21cd44fc2d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-ce3a3285-9c93-493d-8bbd-11d90cb40f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-6cd112d2-1ddb-49ca-9e86-8ad3373c9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-cc5b7747-084c-429e-889b-786fc56bd3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-a8c6302f-0f83-4328-8dbe-c03f1739a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-49a088ac-8322-449e-a46c-3c00a54e15b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586848161-172.17.0.2-1597463534932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-536e9f7d-9dc6-4ede-957f-e32f4629c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-2f7da77d-8efe-4528-8d00-78ca53a5e821,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-162419a1-6fe7-4e5c-8c53-9165ff4a7512,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-e664e210-ad92-4371-83d3-518c63a57253,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-73ccbbf7-3438-4222-abf1-21633dc469fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7abdabf6-6e51-4b97-b0f0-b4bc5fcb92c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-d9ff7c63-02ea-46e4-ab54-e47e0a55dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-91dbe9b1-ad85-4fa6-a4a6-77f23adb8a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586848161-172.17.0.2-1597463534932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-536e9f7d-9dc6-4ede-957f-e32f4629c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-2f7da77d-8efe-4528-8d00-78ca53a5e821,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-162419a1-6fe7-4e5c-8c53-9165ff4a7512,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-e664e210-ad92-4371-83d3-518c63a57253,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-73ccbbf7-3438-4222-abf1-21633dc469fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7abdabf6-6e51-4b97-b0f0-b4bc5fcb92c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-d9ff7c63-02ea-46e4-ab54-e47e0a55dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-91dbe9b1-ad85-4fa6-a4a6-77f23adb8a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544471046-172.17.0.2-1597463612609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-a14667ea-1823-4318-921d-c32f1ba52866,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-8bb330dd-b95e-4b65-9c71-812cf16a865d,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2427034c-24ab-4c56-81fc-cefb70c0fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b8050612-6d0d-4d0f-a50a-3df8e5984cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-8d2c4caa-6e09-473f-a978-d8c882a3046a,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-aaca28c3-24d6-454f-accc-36208a015643,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-d8191468-1161-4594-a0b2-0b17c998f416,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-aa5af717-2e13-4404-bd58-cefba9f13c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544471046-172.17.0.2-1597463612609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-a14667ea-1823-4318-921d-c32f1ba52866,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-8bb330dd-b95e-4b65-9c71-812cf16a865d,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2427034c-24ab-4c56-81fc-cefb70c0fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b8050612-6d0d-4d0f-a50a-3df8e5984cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-8d2c4caa-6e09-473f-a978-d8c882a3046a,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-aaca28c3-24d6-454f-accc-36208a015643,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-d8191468-1161-4594-a0b2-0b17c998f416,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-aa5af717-2e13-4404-bd58-cefba9f13c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615372696-172.17.0.2-1597463739373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-a6c92d96-f769-4d89-a19c-c56e3ba0c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-3c78925c-2029-4f40-97ea-efcde1de4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-6676f515-8772-449f-a794-8d657c89702b,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-fc5740cb-6d4a-4447-baa4-ea88a3cb6199,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-505e4db9-a059-439f-95e1-65f0162bd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-96fc7af5-2826-4414-971c-a7a75ff9e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3c06fa73-8d1b-48e2-b92c-650f72231da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-fcdb2cef-f60a-48f9-a23f-ffe5c0e73d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615372696-172.17.0.2-1597463739373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-a6c92d96-f769-4d89-a19c-c56e3ba0c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-3c78925c-2029-4f40-97ea-efcde1de4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-6676f515-8772-449f-a794-8d657c89702b,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-fc5740cb-6d4a-4447-baa4-ea88a3cb6199,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-505e4db9-a059-439f-95e1-65f0162bd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-96fc7af5-2826-4414-971c-a7a75ff9e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3c06fa73-8d1b-48e2-b92c-650f72231da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-fcdb2cef-f60a-48f9-a23f-ffe5c0e73d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029433455-172.17.0.2-1597464072955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-ca8a02c6-ec3d-4ef3-b74c-22a02870b175,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b91a82d8-9f00-4942-8ca6-04c23034af51,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-61b01803-c704-47a7-a64c-c16f248897e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-3c2d2c67-0192-4e4e-9fc8-3acbf88555a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-70d4e7d3-27da-4a82-8036-ba9dc8a306f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2bd42ef1-b23f-4849-91be-bb3870e290fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-1ea40703-8642-4e2a-8d43-c5127359c292,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-e48ad46a-554c-4150-a3c8-7910af51f45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029433455-172.17.0.2-1597464072955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-ca8a02c6-ec3d-4ef3-b74c-22a02870b175,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b91a82d8-9f00-4942-8ca6-04c23034af51,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-61b01803-c704-47a7-a64c-c16f248897e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-3c2d2c67-0192-4e4e-9fc8-3acbf88555a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-70d4e7d3-27da-4a82-8036-ba9dc8a306f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2bd42ef1-b23f-4849-91be-bb3870e290fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-1ea40703-8642-4e2a-8d43-c5127359c292,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-e48ad46a-554c-4150-a3c8-7910af51f45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789207180-172.17.0.2-1597464288935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-1fb28138-b84f-4090-b8fb-096c0e81f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-6ebb53ce-5dc5-49c7-ad35-cc4b3174a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-6cbd3ac9-f9c9-4a27-b9f0-b4d9174f74cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-02d68944-3b01-46a0-8ebe-12297c4fe8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-db05ff92-0e75-4ce5-9bf9-91c77adc21a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-cc476624-31bd-472c-a4f3-4d4427bb792d,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-5d1f1e20-f4d2-4d7d-87e5-704c0f591237,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-3e91a3dc-21f3-4a38-ab68-6e021655848e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789207180-172.17.0.2-1597464288935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-1fb28138-b84f-4090-b8fb-096c0e81f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-6ebb53ce-5dc5-49c7-ad35-cc4b3174a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-6cbd3ac9-f9c9-4a27-b9f0-b4d9174f74cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-02d68944-3b01-46a0-8ebe-12297c4fe8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-db05ff92-0e75-4ce5-9bf9-91c77adc21a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-cc476624-31bd-472c-a4f3-4d4427bb792d,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-5d1f1e20-f4d2-4d7d-87e5-704c0f591237,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-3e91a3dc-21f3-4a38-ab68-6e021655848e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705567753-172.17.0.2-1597465317976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-5e82d6ab-9fad-4313-b083-0a1f8d19771b,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-6a9abfc0-4183-46eb-b1a9-08cdba851db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-a928a0e6-74a7-445e-9ecf-905bdc3edac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-19da2acd-d899-4d43-838d-3ceff01878c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-c3cceb22-9a9e-4aa5-ae00-e4102b831b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-33ad8e70-3c3a-4adb-9b24-c0a8df069c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-75a82e65-a882-43e9-b0a6-07ec36e645c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-5491f19e-8cd0-460f-b840-6a7a35149207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705567753-172.17.0.2-1597465317976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-5e82d6ab-9fad-4313-b083-0a1f8d19771b,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-6a9abfc0-4183-46eb-b1a9-08cdba851db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-a928a0e6-74a7-445e-9ecf-905bdc3edac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-19da2acd-d899-4d43-838d-3ceff01878c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-c3cceb22-9a9e-4aa5-ae00-e4102b831b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-33ad8e70-3c3a-4adb-9b24-c0a8df069c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-75a82e65-a882-43e9-b0a6-07ec36e645c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-5491f19e-8cd0-460f-b840-6a7a35149207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768299728-172.17.0.2-1597465867989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-b1e5f58a-a8c2-4d2f-82bb-dbb1493d9295,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-5e4bb741-09e3-4552-afa9-cfc3a87be1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-7a0c6125-6fd7-409f-b4eb-fe77db5ae988,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-fa2c388b-d61e-4e16-8043-dfeb27b8988a,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-2e2d63e2-2ff9-40b2-afbd-07f46a24e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-16b1036b-cb59-4d84-8406-50b3e7529913,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-0f57f530-0819-4914-a66e-45ccd567be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-680c2188-4911-4129-b0bf-a6462f53739f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768299728-172.17.0.2-1597465867989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-b1e5f58a-a8c2-4d2f-82bb-dbb1493d9295,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-5e4bb741-09e3-4552-afa9-cfc3a87be1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-7a0c6125-6fd7-409f-b4eb-fe77db5ae988,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-fa2c388b-d61e-4e16-8043-dfeb27b8988a,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-2e2d63e2-2ff9-40b2-afbd-07f46a24e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-16b1036b-cb59-4d84-8406-50b3e7529913,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-0f57f530-0819-4914-a66e-45ccd567be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-680c2188-4911-4129-b0bf-a6462f53739f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789899931-172.17.0.2-1597465910659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-10036f66-2689-4b5e-ba44-73382bfe384f,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-774ebe4f-9126-4c05-a9b8-35894e5879c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-52a55e15-fcf7-4132-be69-9be67351e140,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2cec55ff-c550-42cf-b35c-a6762407b477,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-cc9a6505-87ff-4dcf-8b90-1aea9a8edf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-cc193879-1fd6-480a-b0e4-3c259f3a3711,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-f9b808b8-0db2-4baf-803c-5728f000c730,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-fb25efc7-24f8-444a-80ad-e916412e9e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789899931-172.17.0.2-1597465910659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-10036f66-2689-4b5e-ba44-73382bfe384f,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-774ebe4f-9126-4c05-a9b8-35894e5879c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-52a55e15-fcf7-4132-be69-9be67351e140,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2cec55ff-c550-42cf-b35c-a6762407b477,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-cc9a6505-87ff-4dcf-8b90-1aea9a8edf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-cc193879-1fd6-480a-b0e4-3c259f3a3711,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-f9b808b8-0db2-4baf-803c-5728f000c730,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-fb25efc7-24f8-444a-80ad-e916412e9e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398880263-172.17.0.2-1597466212462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-5f940e00-2b36-41c0-9191-6066a1f42370,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-1fa8a911-6799-44bb-8e61-b8403114c570,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1e63055f-04f9-4d62-b547-9f719d69f506,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-3a1519fc-371b-45d0-ae96-3bd3202587d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-c5765d82-0040-49fa-9359-dde220b29727,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-3927cd26-a30b-495a-8294-8d109c2639af,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-07e0e515-8c19-4c0c-8daa-c222f128e451,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-4de243c8-5503-45ba-972a-03b1730cfe18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398880263-172.17.0.2-1597466212462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-5f940e00-2b36-41c0-9191-6066a1f42370,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-1fa8a911-6799-44bb-8e61-b8403114c570,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1e63055f-04f9-4d62-b547-9f719d69f506,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-3a1519fc-371b-45d0-ae96-3bd3202587d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-c5765d82-0040-49fa-9359-dde220b29727,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-3927cd26-a30b-495a-8294-8d109c2639af,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-07e0e515-8c19-4c0c-8daa-c222f128e451,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-4de243c8-5503-45ba-972a-03b1730cfe18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515652966-172.17.0.2-1597466589952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-ff6e4f50-02ad-4d0e-ac41-301e7e02eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-ce86e60c-3799-4c4d-8a2a-76860f37a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-2709f315-81f5-4fdf-b2b4-173269ae5468,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-809978e8-ef2a-4208-ac39-c45f0a14494d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-df2367a1-c7b7-4826-a16a-d9dc25f4626f,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-632e447a-b435-4aee-9793-213d130ba527,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-3d8cb3b3-eded-444d-9232-15889d540428,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-eee62e35-df94-49e8-9f39-0a6033b13512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515652966-172.17.0.2-1597466589952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-ff6e4f50-02ad-4d0e-ac41-301e7e02eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-ce86e60c-3799-4c4d-8a2a-76860f37a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-2709f315-81f5-4fdf-b2b4-173269ae5468,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-809978e8-ef2a-4208-ac39-c45f0a14494d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-df2367a1-c7b7-4826-a16a-d9dc25f4626f,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-632e447a-b435-4aee-9793-213d130ba527,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-3d8cb3b3-eded-444d-9232-15889d540428,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-eee62e35-df94-49e8-9f39-0a6033b13512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931064209-172.17.0.2-1597466816518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36605,DS-ec2ab90f-8588-4de1-95ae-6029705aa32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-7725b8bb-4076-49de-8021-0f2a77256c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-a9780526-cacb-46e5-96d5-95cf765da7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-94b3d558-c848-442c-bff2-50c1b6c0b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-c0903272-b7ca-47da-9024-0fdabedc8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-183fcd7e-4cdc-432c-9b6b-565164eaa493,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e919161e-c658-4a7d-ad5a-e3664502f108,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-b49fc712-dd38-49b0-be45-4b83d7b53ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931064209-172.17.0.2-1597466816518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36605,DS-ec2ab90f-8588-4de1-95ae-6029705aa32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-7725b8bb-4076-49de-8021-0f2a77256c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-a9780526-cacb-46e5-96d5-95cf765da7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-94b3d558-c848-442c-bff2-50c1b6c0b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-c0903272-b7ca-47da-9024-0fdabedc8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-183fcd7e-4cdc-432c-9b6b-565164eaa493,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e919161e-c658-4a7d-ad5a-e3664502f108,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-b49fc712-dd38-49b0-be45-4b83d7b53ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760698338-172.17.0.2-1597466979532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-bbdcbaa6-9fb1-403f-98b4-b85fd5afcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-e515de5a-22be-4391-8493-59a646510d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-193948b9-b4b0-48fa-b1a0-e7186696a377,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-ed92e707-1754-4d1f-9550-4e52723ffb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1626b197-d84f-4c4c-8d9e-d4d16ba786b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-8a455982-2f9b-41c7-9992-91134c5d6a65,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0c13d226-5d5e-4bf1-983d-69a1322f865b,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-2d26ceb1-23fe-421d-8079-3560520493fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760698338-172.17.0.2-1597466979532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-bbdcbaa6-9fb1-403f-98b4-b85fd5afcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-e515de5a-22be-4391-8493-59a646510d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-193948b9-b4b0-48fa-b1a0-e7186696a377,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-ed92e707-1754-4d1f-9550-4e52723ffb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1626b197-d84f-4c4c-8d9e-d4d16ba786b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-8a455982-2f9b-41c7-9992-91134c5d6a65,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0c13d226-5d5e-4bf1-983d-69a1322f865b,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-2d26ceb1-23fe-421d-8079-3560520493fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748754120-172.17.0.2-1597467290360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-0f2b9f64-6cbc-4081-aee2-11d681af115d,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-4cf3c39e-6648-4bdd-8cd6-c1464f270b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-1b241ff1-2566-4ea1-8bc0-df2836cd42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-0c155a9e-9957-4ff0-81e6-40c99088c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-d25104ab-180e-43a2-9ce7-80da6bcc3319,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-a78a2515-40bb-49f0-b1c7-c5ac47842168,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-28dc1d5b-7b2e-45f4-9573-7fd3c0ca5094,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-3bf7acb7-cfc7-4253-ad1d-97372015fe61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748754120-172.17.0.2-1597467290360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-0f2b9f64-6cbc-4081-aee2-11d681af115d,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-4cf3c39e-6648-4bdd-8cd6-c1464f270b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-1b241ff1-2566-4ea1-8bc0-df2836cd42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-0c155a9e-9957-4ff0-81e6-40c99088c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-d25104ab-180e-43a2-9ce7-80da6bcc3319,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-a78a2515-40bb-49f0-b1c7-c5ac47842168,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-28dc1d5b-7b2e-45f4-9573-7fd3c0ca5094,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-3bf7acb7-cfc7-4253-ad1d-97372015fe61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198359687-172.17.0.2-1597467794616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46094,DS-49834884-18bd-4f7b-a4ee-3d040ea825e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-ef75ffcb-e22e-4013-9fb9-a98900662657,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-b68fe9b8-da8a-4288-a9c9-d3874f05d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-0f3b78dd-c663-43e4-8764-c1163a2cd78d,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-0a976b56-a639-49f8-bbfb-3831e24a5bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-553dd13a-5b1c-49d2-8620-cea5dd1faa68,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-8a67e087-f4a8-4351-b516-b7015c22fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-349dbdf1-136d-4f0f-b705-97813ca3a95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198359687-172.17.0.2-1597467794616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46094,DS-49834884-18bd-4f7b-a4ee-3d040ea825e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-ef75ffcb-e22e-4013-9fb9-a98900662657,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-b68fe9b8-da8a-4288-a9c9-d3874f05d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-0f3b78dd-c663-43e4-8764-c1163a2cd78d,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-0a976b56-a639-49f8-bbfb-3831e24a5bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-553dd13a-5b1c-49d2-8620-cea5dd1faa68,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-8a67e087-f4a8-4351-b516-b7015c22fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-349dbdf1-136d-4f0f-b705-97813ca3a95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491196279-172.17.0.2-1597467901463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-099e524c-c390-4198-931b-c96f21e96dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-e11b6bbd-7515-4e47-97c8-b36dff033eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-0d4df0cb-2e0f-405f-89ff-b130de4b8b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-90754d55-f728-45af-afe6-5dd89205d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4ded09ba-c2e7-44af-9798-8d696d0f448f,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-78914d3c-aad9-4e92-bf02-ad64933ce863,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-68ec2e89-6ce3-4b37-b3c0-2a6506afc731,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-491af7fd-d2fd-4785-9a98-d0c7f53ad094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491196279-172.17.0.2-1597467901463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-099e524c-c390-4198-931b-c96f21e96dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-e11b6bbd-7515-4e47-97c8-b36dff033eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-0d4df0cb-2e0f-405f-89ff-b130de4b8b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-90754d55-f728-45af-afe6-5dd89205d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4ded09ba-c2e7-44af-9798-8d696d0f448f,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-78914d3c-aad9-4e92-bf02-ad64933ce863,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-68ec2e89-6ce3-4b37-b3c0-2a6506afc731,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-491af7fd-d2fd-4785-9a98-d0c7f53ad094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901698362-172.17.0.2-1597467938605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-5fdc421c-047d-4449-8c18-74c7d84dab9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d0fe912d-08b0-4059-a61b-3b6509fd8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-12249a0d-7b6b-47a6-a4de-2cfe3b57f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-a9e010a2-54be-423c-b0be-a6012b6d156a,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6054bacb-f4f2-411d-b616-5f27711267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-35174028-1941-467e-a1ca-53432d4879df,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-45dc3288-7bc2-4a93-b51d-a96b6a78e820,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-c84e526f-4e2a-4bd2-aa7a-bacb1b0f29b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901698362-172.17.0.2-1597467938605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-5fdc421c-047d-4449-8c18-74c7d84dab9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d0fe912d-08b0-4059-a61b-3b6509fd8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-12249a0d-7b6b-47a6-a4de-2cfe3b57f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-a9e010a2-54be-423c-b0be-a6012b6d156a,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6054bacb-f4f2-411d-b616-5f27711267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-35174028-1941-467e-a1ca-53432d4879df,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-45dc3288-7bc2-4a93-b51d-a96b6a78e820,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-c84e526f-4e2a-4bd2-aa7a-bacb1b0f29b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885961298-172.17.0.2-1597468299828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38309,DS-b102beac-afcb-4180-a802-c071ec2205cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-98b3e910-bf13-4da0-8513-52df8ad49c07,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-280cb7b3-b963-465b-a636-8529bdef1aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-ac0f80bb-d430-414d-8120-7b208af930a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-c5f4e238-3c10-4716-b2be-f263dbe6cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-48e451df-5595-473d-9ef5-ee3f17818450,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-19df07e2-e57b-40fa-b47d-ed96da96e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-37abc07e-02b8-46bb-83ff-f964d02147e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885961298-172.17.0.2-1597468299828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38309,DS-b102beac-afcb-4180-a802-c071ec2205cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-98b3e910-bf13-4da0-8513-52df8ad49c07,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-280cb7b3-b963-465b-a636-8529bdef1aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-ac0f80bb-d430-414d-8120-7b208af930a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-c5f4e238-3c10-4716-b2be-f263dbe6cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-48e451df-5595-473d-9ef5-ee3f17818450,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-19df07e2-e57b-40fa-b47d-ed96da96e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-37abc07e-02b8-46bb-83ff-f964d02147e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680751955-172.17.0.2-1597468341399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-fc671b4e-c91e-40e2-9afc-4e2ddc674830,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-2223327c-aa32-408e-b922-9d5382ceab65,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-23dc4038-51ea-4f8c-9086-394dfde580e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-33d844fa-115e-44c1-8d26-1faf46947564,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-2a0faaff-0764-4b57-81be-7ec4481db432,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-bca1b9f1-3897-4c32-9af3-8cee8de3860d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-486a50e4-31e9-4a6c-85d9-128081fe9a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-68389407-525c-420c-9152-8df761b775d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680751955-172.17.0.2-1597468341399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-fc671b4e-c91e-40e2-9afc-4e2ddc674830,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-2223327c-aa32-408e-b922-9d5382ceab65,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-23dc4038-51ea-4f8c-9086-394dfde580e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-33d844fa-115e-44c1-8d26-1faf46947564,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-2a0faaff-0764-4b57-81be-7ec4481db432,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-bca1b9f1-3897-4c32-9af3-8cee8de3860d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-486a50e4-31e9-4a6c-85d9-128081fe9a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-68389407-525c-420c-9152-8df761b775d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962338808-172.17.0.2-1597469230083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-7021e031-7588-421b-8318-3f17deb99554,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ec32d390-15f0-4f79-a11d-ad47aa92addb,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-f4987386-329a-4a6e-be1e-c4bf0f342fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-dc97bf2f-4552-496e-943c-fa3136fb7248,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-e1ec2dbf-d38b-4680-b491-417229297729,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-82da5371-dec0-48d8-8f96-120e86571610,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-ba43b7d1-ba3f-418c-9258-a20c8a36c0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-1c3a6884-8c63-4bc5-bfb2-b1a1d8660a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962338808-172.17.0.2-1597469230083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-7021e031-7588-421b-8318-3f17deb99554,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ec32d390-15f0-4f79-a11d-ad47aa92addb,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-f4987386-329a-4a6e-be1e-c4bf0f342fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-dc97bf2f-4552-496e-943c-fa3136fb7248,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-e1ec2dbf-d38b-4680-b491-417229297729,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-82da5371-dec0-48d8-8f96-120e86571610,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-ba43b7d1-ba3f-418c-9258-a20c8a36c0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-1c3a6884-8c63-4bc5-bfb2-b1a1d8660a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5850
