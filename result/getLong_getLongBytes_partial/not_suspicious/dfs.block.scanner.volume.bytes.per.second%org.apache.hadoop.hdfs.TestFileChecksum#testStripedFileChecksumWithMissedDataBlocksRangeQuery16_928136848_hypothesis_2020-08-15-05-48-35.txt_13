reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338089233-172.17.0.19-1597470706673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-d2ee7d8a-19f3-4e3c-b2a0-40d32f5fecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-29c1fae9-e806-4591-87da-d1827bd64c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a302f648-6d9d-40a6-8844-28428f77f121,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-976668b7-e17f-4af0-8fc9-61abfadd3408,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-9f0f44fd-e7ee-4a97-9dcf-a11c474a0649,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-420b04c9-fe30-4daa-9532-9193bb73cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-4f0f4da0-8350-4270-9570-a1f3ac256558,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-ea4201a2-6e41-4501-a04a-a048cb131034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338089233-172.17.0.19-1597470706673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-d2ee7d8a-19f3-4e3c-b2a0-40d32f5fecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-29c1fae9-e806-4591-87da-d1827bd64c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a302f648-6d9d-40a6-8844-28428f77f121,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-976668b7-e17f-4af0-8fc9-61abfadd3408,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-9f0f44fd-e7ee-4a97-9dcf-a11c474a0649,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-420b04c9-fe30-4daa-9532-9193bb73cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-4f0f4da0-8350-4270-9570-a1f3ac256558,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-ea4201a2-6e41-4501-a04a-a048cb131034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699935350-172.17.0.19-1597471221339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-02804b69-c5fa-4570-9faa-c28fdf087319,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-ad6e612d-4a82-4755-bda0-80d02ba1b949,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-47c6ab3b-728f-4752-8aa1-d53816d38786,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-0771293a-f4e5-4fee-bad4-50732cdf6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-f3d00d44-2890-44f3-9d57-4251f3aefc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-960f14f7-e2cf-42fd-a365-1c9bc412c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-bd9e90e9-0b5b-41f3-ba1a-b28c53d7fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-1c268152-0f41-4bf4-abb0-68d3481d8706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699935350-172.17.0.19-1597471221339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-02804b69-c5fa-4570-9faa-c28fdf087319,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-ad6e612d-4a82-4755-bda0-80d02ba1b949,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-47c6ab3b-728f-4752-8aa1-d53816d38786,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-0771293a-f4e5-4fee-bad4-50732cdf6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-f3d00d44-2890-44f3-9d57-4251f3aefc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-960f14f7-e2cf-42fd-a365-1c9bc412c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-bd9e90e9-0b5b-41f3-ba1a-b28c53d7fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-1c268152-0f41-4bf4-abb0-68d3481d8706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209842804-172.17.0.19-1597471259207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-0e50d978-ecbf-4f2b-97ea-4f4e891d50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-52de85e5-5e5b-4c66-a89c-cd19fe46f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a6d9fbfc-d208-495f-9363-7542c3ce2923,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a4f46cfc-6d5e-4f5d-855f-9fd19069106e,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-5723f6e3-a36b-43f2-a157-4154b6c2b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b247058f-11bc-4689-a24d-801b00933f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-2114de83-6e82-497d-b29f-f0edd2bbdb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-6391ca92-0f46-4e1b-966e-a3018be6fef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209842804-172.17.0.19-1597471259207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-0e50d978-ecbf-4f2b-97ea-4f4e891d50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-52de85e5-5e5b-4c66-a89c-cd19fe46f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a6d9fbfc-d208-495f-9363-7542c3ce2923,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a4f46cfc-6d5e-4f5d-855f-9fd19069106e,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-5723f6e3-a36b-43f2-a157-4154b6c2b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b247058f-11bc-4689-a24d-801b00933f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-2114de83-6e82-497d-b29f-f0edd2bbdb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-6391ca92-0f46-4e1b-966e-a3018be6fef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010229296-172.17.0.19-1597471322178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-d4831d1e-34ed-49c2-8005-a466fedbdffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-ba792958-2519-4f84-9e2e-86161156f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-80ae99ab-1137-41e1-8e0d-779bc6027009,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-1179493c-e06e-42a1-ae8d-6aaa073439a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-ab42b4d3-d494-4926-8ab2-ec1f3d3dc27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-5ce09ba3-aa0a-4bff-a3a8-752dec9584bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-766bf01b-69d7-40b8-a8b8-dae9202facb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-d0460f76-dd13-489d-a695-f94c45143e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010229296-172.17.0.19-1597471322178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-d4831d1e-34ed-49c2-8005-a466fedbdffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-ba792958-2519-4f84-9e2e-86161156f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-80ae99ab-1137-41e1-8e0d-779bc6027009,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-1179493c-e06e-42a1-ae8d-6aaa073439a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-ab42b4d3-d494-4926-8ab2-ec1f3d3dc27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-5ce09ba3-aa0a-4bff-a3a8-752dec9584bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-766bf01b-69d7-40b8-a8b8-dae9202facb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-d0460f76-dd13-489d-a695-f94c45143e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801714980-172.17.0.19-1597471685876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-67cc6382-3a1e-4e8f-b6d9-8280d4ad99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-1f7dd746-e549-42a8-b183-1f50d7d58535,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-cc8872d9-6282-4ec0-9dd9-50464a853785,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-fdb31c5e-0768-424a-8dc1-3b2789740e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-ac01a826-b842-449e-b4bf-06681cad1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-ba2fc8a5-c7a7-4cea-8368-b15dc7399ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-6a08ba3f-b8b6-4440-8038-01e9cc836c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-de13568f-f2fb-429c-8493-fd8daa48537d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801714980-172.17.0.19-1597471685876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-67cc6382-3a1e-4e8f-b6d9-8280d4ad99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-1f7dd746-e549-42a8-b183-1f50d7d58535,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-cc8872d9-6282-4ec0-9dd9-50464a853785,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-fdb31c5e-0768-424a-8dc1-3b2789740e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-ac01a826-b842-449e-b4bf-06681cad1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-ba2fc8a5-c7a7-4cea-8368-b15dc7399ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-6a08ba3f-b8b6-4440-8038-01e9cc836c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-de13568f-f2fb-429c-8493-fd8daa48537d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467498232-172.17.0.19-1597471755761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-3364e3ed-7d55-4012-8581-3ae7d4410c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-6a89a5af-3e2b-4ef4-a206-6e6df9689daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-8c2e543c-daae-479e-a63a-e49e03e0c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-44b4a50e-ca0c-4fe9-b29c-fa6a8a798667,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-24ee887d-c530-4f89-bd49-d57f3b73c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-fdc4257f-963e-4fca-b48a-b2162c972e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-afbdf32f-f5be-4011-b2e7-8fa0af2fcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-4d9f439d-ebb9-4413-99e4-8a16d01e32c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467498232-172.17.0.19-1597471755761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-3364e3ed-7d55-4012-8581-3ae7d4410c61,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-6a89a5af-3e2b-4ef4-a206-6e6df9689daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-8c2e543c-daae-479e-a63a-e49e03e0c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-44b4a50e-ca0c-4fe9-b29c-fa6a8a798667,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-24ee887d-c530-4f89-bd49-d57f3b73c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-fdc4257f-963e-4fca-b48a-b2162c972e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-afbdf32f-f5be-4011-b2e7-8fa0af2fcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-4d9f439d-ebb9-4413-99e4-8a16d01e32c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239426804-172.17.0.19-1597472450276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-7ba2b91f-cafc-451b-b1c8-ed8a3bd8a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-7efffc27-4f00-4330-88a6-6aaa54271ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2589b73d-3e7f-4407-bec7-f9dd8f4376fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-c4a5b9e1-5cd9-442b-9efb-97c037eebb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f65147d2-e4f7-463e-91f3-9b94477468ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-da39b50c-c075-491d-a921-17506c212191,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-71598b73-be3a-4791-ae45-67b756536259,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-d3a1ec00-c242-4018-9847-8f560adfb1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239426804-172.17.0.19-1597472450276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-7ba2b91f-cafc-451b-b1c8-ed8a3bd8a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-7efffc27-4f00-4330-88a6-6aaa54271ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2589b73d-3e7f-4407-bec7-f9dd8f4376fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-c4a5b9e1-5cd9-442b-9efb-97c037eebb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f65147d2-e4f7-463e-91f3-9b94477468ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-da39b50c-c075-491d-a921-17506c212191,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-71598b73-be3a-4791-ae45-67b756536259,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-d3a1ec00-c242-4018-9847-8f560adfb1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842807010-172.17.0.19-1597472855840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-4c291510-9ecc-4f4a-a869-db0198490fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-dc8f7d1b-a906-45f7-afb0-75fc4c422534,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-d62ae684-59c2-4331-af51-d440e7c2aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-f338b431-2e64-47aa-94a7-e3a48ae507f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-215a70b7-1722-452e-ba77-41ec99cd8763,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-636bcf22-5af0-4aa5-8ec7-078b92089ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-410ee8c2-2441-4fba-9072-4baacad3bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-5f1a748c-63a2-47f5-ad99-23832df6bcbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842807010-172.17.0.19-1597472855840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-4c291510-9ecc-4f4a-a869-db0198490fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-dc8f7d1b-a906-45f7-afb0-75fc4c422534,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-d62ae684-59c2-4331-af51-d440e7c2aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-f338b431-2e64-47aa-94a7-e3a48ae507f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-215a70b7-1722-452e-ba77-41ec99cd8763,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-636bcf22-5af0-4aa5-8ec7-078b92089ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-410ee8c2-2441-4fba-9072-4baacad3bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-5f1a748c-63a2-47f5-ad99-23832df6bcbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264498310-172.17.0.19-1597472967430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-449fe5e7-c466-42cb-982a-a3ac8e8b0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-6a7de136-7c54-4a26-8544-3968b3e5b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-05065a83-1b6d-4d81-9156-691bfbc156bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-b4138857-08ca-4256-a675-f5fc95be2200,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-397aabce-90b5-469c-9814-270d33cd7325,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-0edc579a-00df-4162-b1fe-b85ce5aa268a,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-bca05ab3-0aa4-4527-b75d-397decb0f824,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-e3ebb233-734c-4942-ae7e-72b6f67de042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264498310-172.17.0.19-1597472967430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-449fe5e7-c466-42cb-982a-a3ac8e8b0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-6a7de136-7c54-4a26-8544-3968b3e5b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-05065a83-1b6d-4d81-9156-691bfbc156bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-b4138857-08ca-4256-a675-f5fc95be2200,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-397aabce-90b5-469c-9814-270d33cd7325,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-0edc579a-00df-4162-b1fe-b85ce5aa268a,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-bca05ab3-0aa4-4527-b75d-397decb0f824,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-e3ebb233-734c-4942-ae7e-72b6f67de042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553906753-172.17.0.19-1597473949058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-78c138f7-7f00-4094-91ae-678f0d54e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-80e0685b-1121-4bb3-9e0e-ef8ed97f6016,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-018a1415-9429-4bb5-a457-cd60676a8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-b885f5b1-2cfb-4100-b22e-f9a9b123d9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-06c652d9-814d-4a79-ad6a-bd7dc57ce594,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ec1724f8-c423-4e7c-ab00-2b8f6e9f2d64,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-9ae82874-3b07-4787-9d81-55e3360dcc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-f5b38d87-3383-4abc-a11a-9357cbc802d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553906753-172.17.0.19-1597473949058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-78c138f7-7f00-4094-91ae-678f0d54e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-80e0685b-1121-4bb3-9e0e-ef8ed97f6016,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-018a1415-9429-4bb5-a457-cd60676a8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-b885f5b1-2cfb-4100-b22e-f9a9b123d9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-06c652d9-814d-4a79-ad6a-bd7dc57ce594,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ec1724f8-c423-4e7c-ab00-2b8f6e9f2d64,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-9ae82874-3b07-4787-9d81-55e3360dcc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-f5b38d87-3383-4abc-a11a-9357cbc802d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432561054-172.17.0.19-1597474178327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-3c995b98-860f-4e79-b309-1c82d880b642,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-6604f47e-11c6-4728-a625-d83c1be2baec,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-eb2dd356-4226-462e-aff3-c8e7f0a197eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-51120477-1a40-462f-a3ae-7f89d8b8704f,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-61489b9e-bad0-4548-bd15-615252e53a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-c1fbc6e0-2e7a-47bd-962f-18cdac09a839,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b23d0b4d-2d16-430b-9790-c447fd1c9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-4225e28e-173f-4523-bcd8-5f4bde576e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432561054-172.17.0.19-1597474178327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-3c995b98-860f-4e79-b309-1c82d880b642,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-6604f47e-11c6-4728-a625-d83c1be2baec,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-eb2dd356-4226-462e-aff3-c8e7f0a197eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-51120477-1a40-462f-a3ae-7f89d8b8704f,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-61489b9e-bad0-4548-bd15-615252e53a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-c1fbc6e0-2e7a-47bd-962f-18cdac09a839,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b23d0b4d-2d16-430b-9790-c447fd1c9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-4225e28e-173f-4523-bcd8-5f4bde576e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548864160-172.17.0.19-1597474425894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34790,DS-0d739ab9-a146-4bce-a220-7a510ef13212,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-979985a2-efa4-4188-aaba-30cd13a50ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-1dc962db-b178-4e0e-8f8b-16c7d318dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-444b9ca8-2a43-48fc-acc9-d4d7200e5772,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-fbcb261c-db29-4028-9567-16eb2305e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-464442e4-2710-4370-bc65-c50997079512,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-0fc7b9fe-7968-4549-9bce-eff3b28a7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-f7c24c20-377d-4ad2-b221-21599e71a428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548864160-172.17.0.19-1597474425894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34790,DS-0d739ab9-a146-4bce-a220-7a510ef13212,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-979985a2-efa4-4188-aaba-30cd13a50ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-1dc962db-b178-4e0e-8f8b-16c7d318dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-444b9ca8-2a43-48fc-acc9-d4d7200e5772,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-fbcb261c-db29-4028-9567-16eb2305e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-464442e4-2710-4370-bc65-c50997079512,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-0fc7b9fe-7968-4549-9bce-eff3b28a7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-f7c24c20-377d-4ad2-b221-21599e71a428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946517169-172.17.0.19-1597474728297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-e6514fa9-1a9e-490b-8f1d-c7cccd0f6b60,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-d3accc4f-e93e-441a-ac16-ab8bd8e0cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-d580cf9a-9d4c-46aa-9da1-60ff23ff4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-d6f8f486-7ef6-4f90-9489-de571f3b877c,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-82d284d1-10b8-4b8c-870e-c22938c80ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-4dd6b745-1b7a-4125-99cc-5e6e67b64dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-5ff12bf8-6ed0-465c-995d-5130e4bce217,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-1276301d-7181-43f9-a28e-a162aff6db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946517169-172.17.0.19-1597474728297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-e6514fa9-1a9e-490b-8f1d-c7cccd0f6b60,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-d3accc4f-e93e-441a-ac16-ab8bd8e0cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-d580cf9a-9d4c-46aa-9da1-60ff23ff4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-d6f8f486-7ef6-4f90-9489-de571f3b877c,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-82d284d1-10b8-4b8c-870e-c22938c80ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-4dd6b745-1b7a-4125-99cc-5e6e67b64dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-5ff12bf8-6ed0-465c-995d-5130e4bce217,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-1276301d-7181-43f9-a28e-a162aff6db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693740723-172.17.0.19-1597475143900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39711,DS-990071f1-be31-46b3-b7cf-144535cfd4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-1dfa421c-ecb3-4f68-8e54-4293ea344866,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-695f8a48-b490-4af0-89ee-8acd38bb871d,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-aa1344fd-ce52-4049-91b8-5d0649029371,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-564f2096-7a7c-4e0d-b81c-c27e6d23d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-40ede6cc-d25b-4da2-b190-81f7fa474018,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-2e672454-5341-4c3d-984f-b7090077bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-98a7eb34-f680-4e40-94b8-03629879b2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693740723-172.17.0.19-1597475143900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39711,DS-990071f1-be31-46b3-b7cf-144535cfd4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-1dfa421c-ecb3-4f68-8e54-4293ea344866,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-695f8a48-b490-4af0-89ee-8acd38bb871d,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-aa1344fd-ce52-4049-91b8-5d0649029371,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-564f2096-7a7c-4e0d-b81c-c27e6d23d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-40ede6cc-d25b-4da2-b190-81f7fa474018,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-2e672454-5341-4c3d-984f-b7090077bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-98a7eb34-f680-4e40-94b8-03629879b2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750192734-172.17.0.19-1597475280264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-e0528bd9-d7b8-46c0-bd6a-68b3e65e588e,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-50570517-3056-40a1-8701-af71c074cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-dc54e01f-f982-45f1-92b6-fad8a71a8cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-38f772d2-7733-4601-84e9-fb3ec68fa9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-8cbfcb5d-59cd-4adc-a0b2-27b4eca86b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-c7fb1720-5bbf-41ee-871c-26892db47e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-5013d378-196f-4ba5-baa7-3069df23183d,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-e9b85411-5e81-454f-947e-37c6cac76c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750192734-172.17.0.19-1597475280264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-e0528bd9-d7b8-46c0-bd6a-68b3e65e588e,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-50570517-3056-40a1-8701-af71c074cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-dc54e01f-f982-45f1-92b6-fad8a71a8cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-38f772d2-7733-4601-84e9-fb3ec68fa9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-8cbfcb5d-59cd-4adc-a0b2-27b4eca86b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-c7fb1720-5bbf-41ee-871c-26892db47e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-5013d378-196f-4ba5-baa7-3069df23183d,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-e9b85411-5e81-454f-947e-37c6cac76c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685988276-172.17.0.19-1597475769726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-09abe3e9-9259-4e3a-a979-12797c55698c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-ae49f641-8f8a-489f-bd5d-41b4fa3607b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-55479ee9-e5bb-4699-953b-d44ee8bf6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-743030ca-1d2e-478d-86ab-425cd1d9b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-04a78a35-fbcc-48e9-938e-8134d38a4f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-c3eb4045-b2fa-4844-803a-ee42c1255f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-de51bd27-1a51-4c55-b22b-cb036eaded56,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-2edff057-7e9e-4386-b67c-13df71aced98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685988276-172.17.0.19-1597475769726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-09abe3e9-9259-4e3a-a979-12797c55698c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-ae49f641-8f8a-489f-bd5d-41b4fa3607b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-55479ee9-e5bb-4699-953b-d44ee8bf6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-743030ca-1d2e-478d-86ab-425cd1d9b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-04a78a35-fbcc-48e9-938e-8134d38a4f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-c3eb4045-b2fa-4844-803a-ee42c1255f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-de51bd27-1a51-4c55-b22b-cb036eaded56,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-2edff057-7e9e-4386-b67c-13df71aced98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659982490-172.17.0.19-1597475808457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-374fc0eb-300c-44a1-8145-2dc21ea4c942,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-bb9a2d41-6b48-4487-ba4f-e86619d1bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-117f7e95-1ad9-4c70-a3d7-f13356b4a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-36571510-9161-478c-9e11-689ea1557a81,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-9eeb33b1-d1f7-43fa-8261-a1ce0bf4bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-c2500115-bb45-48e0-8c60-280d6379e08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-0d90a7a6-869f-4536-930d-cdee8984cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-3d619321-6bb6-4a33-9e6b-8eb543b837a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659982490-172.17.0.19-1597475808457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-374fc0eb-300c-44a1-8145-2dc21ea4c942,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-bb9a2d41-6b48-4487-ba4f-e86619d1bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-117f7e95-1ad9-4c70-a3d7-f13356b4a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-36571510-9161-478c-9e11-689ea1557a81,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-9eeb33b1-d1f7-43fa-8261-a1ce0bf4bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-c2500115-bb45-48e0-8c60-280d6379e08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-0d90a7a6-869f-4536-930d-cdee8984cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-3d619321-6bb6-4a33-9e6b-8eb543b837a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5378
