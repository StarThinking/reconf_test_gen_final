reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855061827-172.17.0.13-1597747990131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-6f763fab-dfb4-423c-9261-f62252b2def2,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-9805a291-4d4f-40af-b53d-0b8231a44eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-94ae670f-64a2-4fe5-a483-048eb6209480,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-7236b4fd-1878-449d-9302-37ea452c0157,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-d7ca1c69-52aa-4c3e-b1b8-d8d051405acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-d37599f5-14ed-4187-947c-e87a3489e272,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-e4373910-8900-4a08-8429-6a3c3c031832,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-0398f140-ce46-47e0-8dee-c22f6e740c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855061827-172.17.0.13-1597747990131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-6f763fab-dfb4-423c-9261-f62252b2def2,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-9805a291-4d4f-40af-b53d-0b8231a44eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-94ae670f-64a2-4fe5-a483-048eb6209480,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-7236b4fd-1878-449d-9302-37ea452c0157,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-d7ca1c69-52aa-4c3e-b1b8-d8d051405acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-d37599f5-14ed-4187-947c-e87a3489e272,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-e4373910-8900-4a08-8429-6a3c3c031832,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-0398f140-ce46-47e0-8dee-c22f6e740c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114992548-172.17.0.13-1597748955973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-e0b63c97-b5a1-4e76-92eb-0aee42281b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-730712f2-9a5c-4c9d-a84a-7d578a6a1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-77c20740-bb8c-4bd0-b2b4-d3a089c2da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-4a4d409c-f31b-4bcc-83ab-42b024d63823,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-fc887098-a4b1-40f5-ad0c-ec8fd5b99a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-537659be-a42b-4712-84b4-0e3a281e3f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-c412842e-8017-4ae6-a9c0-5c0b662de471,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-56d167a8-4973-4a63-9919-c011a163013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114992548-172.17.0.13-1597748955973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-e0b63c97-b5a1-4e76-92eb-0aee42281b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-730712f2-9a5c-4c9d-a84a-7d578a6a1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-77c20740-bb8c-4bd0-b2b4-d3a089c2da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-4a4d409c-f31b-4bcc-83ab-42b024d63823,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-fc887098-a4b1-40f5-ad0c-ec8fd5b99a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-537659be-a42b-4712-84b4-0e3a281e3f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-c412842e-8017-4ae6-a9c0-5c0b662de471,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-56d167a8-4973-4a63-9919-c011a163013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154940070-172.17.0.13-1597749216986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-b33eeadf-9e9e-4189-8f92-00249985d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8ae634a9-1182-463e-99ba-07ae6608a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-0ed113c0-2e53-4448-8bf8-a32b83ae9043,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-1704978a-d2bd-4ce7-b5c7-1b240a0481ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-1ba76d76-9a0a-448d-8398-98eb74b8fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-4ec0e992-d738-4a3a-9e4e-05d3a85a9f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-45fa2fd1-1383-40ec-bc6c-ec85e0351301,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-347c7eaa-fc5a-44b7-bf65-da8551108add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154940070-172.17.0.13-1597749216986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-b33eeadf-9e9e-4189-8f92-00249985d81a,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8ae634a9-1182-463e-99ba-07ae6608a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-0ed113c0-2e53-4448-8bf8-a32b83ae9043,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-1704978a-d2bd-4ce7-b5c7-1b240a0481ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-1ba76d76-9a0a-448d-8398-98eb74b8fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-4ec0e992-d738-4a3a-9e4e-05d3a85a9f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-45fa2fd1-1383-40ec-bc6c-ec85e0351301,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-347c7eaa-fc5a-44b7-bf65-da8551108add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133746216-172.17.0.13-1597749929506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45131,DS-358d7d4d-a012-4a2c-ab64-5410fcc15c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1c4bf288-ae12-4def-b81c-6cca530b4985,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d21fa67b-ffd1-44be-a817-9f35fca15a77,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-96558e2d-0326-4455-a740-dad46fe7eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-599282e6-e164-481e-9e91-75c69032a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-c4cead97-99b8-457a-b84a-885b5cbc2b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-2fef6678-62fb-4870-a382-3619468823e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-95a5aebe-bf88-40ec-b69e-98d5cd4de8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133746216-172.17.0.13-1597749929506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45131,DS-358d7d4d-a012-4a2c-ab64-5410fcc15c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1c4bf288-ae12-4def-b81c-6cca530b4985,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d21fa67b-ffd1-44be-a817-9f35fca15a77,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-96558e2d-0326-4455-a740-dad46fe7eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-599282e6-e164-481e-9e91-75c69032a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-c4cead97-99b8-457a-b84a-885b5cbc2b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-2fef6678-62fb-4870-a382-3619468823e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-95a5aebe-bf88-40ec-b69e-98d5cd4de8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873956717-172.17.0.13-1597750156534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-e455d3c1-ab54-4838-b049-0528a0dd335c,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f1690ee6-875c-40eb-9bf3-11e531db30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-4d143711-e9ee-40fc-8a52-a1db242e1659,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-baef1dfd-cfd2-4d15-8a93-833292be41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-4ceef67a-c915-4988-878d-8fa3f5c0df10,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-0440be75-58df-4d54-b6c8-dadd098cb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-b55354d7-6817-4481-8129-6228d5cd0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-0bac4964-5d1d-4a50-8c3b-3dd6b9e38f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873956717-172.17.0.13-1597750156534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-e455d3c1-ab54-4838-b049-0528a0dd335c,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f1690ee6-875c-40eb-9bf3-11e531db30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-4d143711-e9ee-40fc-8a52-a1db242e1659,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-baef1dfd-cfd2-4d15-8a93-833292be41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-4ceef67a-c915-4988-878d-8fa3f5c0df10,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-0440be75-58df-4d54-b6c8-dadd098cb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-b55354d7-6817-4481-8129-6228d5cd0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-0bac4964-5d1d-4a50-8c3b-3dd6b9e38f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437076484-172.17.0.13-1597750308872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-dc165a61-a5d5-442c-8c3d-250db87ebeda,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-2f1c6a4d-cce8-45f7-803c-438ef6ce5c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cda12033-2e1f-4514-9096-43cc30bc12c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-c53ed37a-8f29-46c0-b16e-6bc81d4f8934,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-4ca45df1-de97-48f8-a0c3-ec9665d07719,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-6ab24a68-0b16-4ada-b527-8ef48ea98381,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7d8e43fb-a977-469f-9ad1-fbe1f19dd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-98adce9f-bdce-4753-b960-1bfdd5e5b364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437076484-172.17.0.13-1597750308872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-dc165a61-a5d5-442c-8c3d-250db87ebeda,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-2f1c6a4d-cce8-45f7-803c-438ef6ce5c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cda12033-2e1f-4514-9096-43cc30bc12c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-c53ed37a-8f29-46c0-b16e-6bc81d4f8934,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-4ca45df1-de97-48f8-a0c3-ec9665d07719,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-6ab24a68-0b16-4ada-b527-8ef48ea98381,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7d8e43fb-a977-469f-9ad1-fbe1f19dd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-98adce9f-bdce-4753-b960-1bfdd5e5b364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429455265-172.17.0.13-1597750717700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33588,DS-1ea526ad-17d0-4dbd-97ed-5dcd11c48bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-4d9250d0-5fc6-41b2-8310-a976e622dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-995417e2-3d9e-4e87-9be3-8f11748d9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-751c9892-6da4-4b23-870c-24c25e7d2d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1dff0a9e-3328-4afe-a7be-d74133ca9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-8b407789-90cc-4321-b761-bc4b446bcdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-621d3cf0-af8f-496d-bd09-ac4de917493e,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-6c8c185b-5086-4317-a70e-8415dcc03818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429455265-172.17.0.13-1597750717700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33588,DS-1ea526ad-17d0-4dbd-97ed-5dcd11c48bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-4d9250d0-5fc6-41b2-8310-a976e622dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-995417e2-3d9e-4e87-9be3-8f11748d9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-751c9892-6da4-4b23-870c-24c25e7d2d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1dff0a9e-3328-4afe-a7be-d74133ca9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-8b407789-90cc-4321-b761-bc4b446bcdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-621d3cf0-af8f-496d-bd09-ac4de917493e,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-6c8c185b-5086-4317-a70e-8415dcc03818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976657315-172.17.0.13-1597750793710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-36a14262-6329-4bed-82ac-bec2b4feb353,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-c1a3bc84-40a8-4674-b06e-4be50fdc39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-edf788cf-2dc6-4a8f-9ecd-83b9df4c95cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-acfae4f1-dcd1-4069-be9e-83588ff2bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-d755f2a1-1806-4425-b8f5-25c10be73600,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-e75c9368-14b0-4e7a-8dac-6f789b6d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-df39e1b9-a620-41d9-938d-25cef9f33549,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-fc576836-cda6-4f21-a949-5578ada7ac49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976657315-172.17.0.13-1597750793710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-36a14262-6329-4bed-82ac-bec2b4feb353,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-c1a3bc84-40a8-4674-b06e-4be50fdc39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-edf788cf-2dc6-4a8f-9ecd-83b9df4c95cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-acfae4f1-dcd1-4069-be9e-83588ff2bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-d755f2a1-1806-4425-b8f5-25c10be73600,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-e75c9368-14b0-4e7a-8dac-6f789b6d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-df39e1b9-a620-41d9-938d-25cef9f33549,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-fc576836-cda6-4f21-a949-5578ada7ac49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001324691-172.17.0.13-1597750836263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-af41a787-8fc4-4571-94f2-059cd89a06d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e83756b8-e0e9-4460-86ad-72e0d84bf192,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2b05eea6-f899-4883-98b3-bf7652f134bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-5d9f5880-4ddb-419f-a34d-ae42dde10114,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-069090c2-fb4e-4eb9-9c88-6d91eaffe79e,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-db27d550-8a25-4399-9e42-e78be0fcec63,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ef6f88ef-5b6a-4ae0-b32a-829e09c7f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-3d05a6f5-ad15-4b7c-9c9e-9c14e3597e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001324691-172.17.0.13-1597750836263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-af41a787-8fc4-4571-94f2-059cd89a06d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e83756b8-e0e9-4460-86ad-72e0d84bf192,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2b05eea6-f899-4883-98b3-bf7652f134bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-5d9f5880-4ddb-419f-a34d-ae42dde10114,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-069090c2-fb4e-4eb9-9c88-6d91eaffe79e,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-db27d550-8a25-4399-9e42-e78be0fcec63,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ef6f88ef-5b6a-4ae0-b32a-829e09c7f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-3d05a6f5-ad15-4b7c-9c9e-9c14e3597e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174234018-172.17.0.13-1597751368752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34706,DS-d5ea68c8-778c-4865-9bfe-4dac70c53636,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a4803764-8a6d-49ca-80b7-35faa6876fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-77bf4968-2821-4c21-b0f7-50c4e3892d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-8728f940-0d4b-4db7-b1c7-1df8e5763323,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ff1dc5e9-1068-44a3-8454-ef14aa8ad492,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-e18d1c55-b267-4ad9-9dba-391d63bccccc,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-da626cb3-d594-49ff-afdf-6ec206b2a3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-809126c7-8750-4d58-b199-dac3a5f8ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174234018-172.17.0.13-1597751368752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34706,DS-d5ea68c8-778c-4865-9bfe-4dac70c53636,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a4803764-8a6d-49ca-80b7-35faa6876fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-77bf4968-2821-4c21-b0f7-50c4e3892d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-8728f940-0d4b-4db7-b1c7-1df8e5763323,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ff1dc5e9-1068-44a3-8454-ef14aa8ad492,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-e18d1c55-b267-4ad9-9dba-391d63bccccc,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-da626cb3-d594-49ff-afdf-6ec206b2a3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-809126c7-8750-4d58-b199-dac3a5f8ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199031245-172.17.0.13-1597751604791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-804edf4e-99a8-45e2-b034-b5c357558dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-67e2c09b-3dd1-4fab-ab6c-e195ae5b5516,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-c3125159-7743-44f5-be4f-2dd08a24d150,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-6c2f8e80-1203-4e37-8d59-6a741f7c9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e25bf406-89a5-438f-971c-ebb02a6be9de,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-fa45bb18-bb9b-4982-b969-b0b461e81bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-04f49230-4c73-4b93-acfc-6024bc5b2f47,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-b77ea0f9-267d-42ce-acbf-9c966a418ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199031245-172.17.0.13-1597751604791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-804edf4e-99a8-45e2-b034-b5c357558dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-67e2c09b-3dd1-4fab-ab6c-e195ae5b5516,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-c3125159-7743-44f5-be4f-2dd08a24d150,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-6c2f8e80-1203-4e37-8d59-6a741f7c9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e25bf406-89a5-438f-971c-ebb02a6be9de,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-fa45bb18-bb9b-4982-b969-b0b461e81bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-04f49230-4c73-4b93-acfc-6024bc5b2f47,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-b77ea0f9-267d-42ce-acbf-9c966a418ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026733415-172.17.0.13-1597751837722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37586,DS-3d08c6c9-465c-4315-bf27-1d66fee18996,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e436d060-7198-4e54-9d9b-19be5cbfdfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-860c77d2-4c99-4a3f-95b7-f48b54819032,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-a9683b05-5444-4dd6-8e53-5410ebb07e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a21e4204-2563-4e12-925f-5a25ecbb0f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-467c9a6c-40dd-453a-a544-ee9728826d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-7aa78362-2264-4213-bc55-7288bff51228,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-f2f1233d-d970-4890-9d19-8d7c8074d32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026733415-172.17.0.13-1597751837722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37586,DS-3d08c6c9-465c-4315-bf27-1d66fee18996,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e436d060-7198-4e54-9d9b-19be5cbfdfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-860c77d2-4c99-4a3f-95b7-f48b54819032,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-a9683b05-5444-4dd6-8e53-5410ebb07e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a21e4204-2563-4e12-925f-5a25ecbb0f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-467c9a6c-40dd-453a-a544-ee9728826d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-7aa78362-2264-4213-bc55-7288bff51228,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-f2f1233d-d970-4890-9d19-8d7c8074d32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979413268-172.17.0.13-1597751882466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-f4aead61-ccd6-4311-93ab-4e49af2d2081,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-6e63cccc-7213-4624-9784-59dce5b9e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-907dbaba-6511-4f65-b197-51416b3ca4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-4c1c4807-bded-4e20-9fce-e698be216fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-ba222f9f-7e86-4ff4-9876-bd4883672a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-33b59fc2-c73b-452e-bfa7-8b10c423402b,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-d25f17d2-dad0-4bb5-a630-cdab5053c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-b31bd8eb-56e6-4f8a-9121-e0d19c2660a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979413268-172.17.0.13-1597751882466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-f4aead61-ccd6-4311-93ab-4e49af2d2081,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-6e63cccc-7213-4624-9784-59dce5b9e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-907dbaba-6511-4f65-b197-51416b3ca4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-4c1c4807-bded-4e20-9fce-e698be216fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-ba222f9f-7e86-4ff4-9876-bd4883672a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-33b59fc2-c73b-452e-bfa7-8b10c423402b,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-d25f17d2-dad0-4bb5-a630-cdab5053c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-b31bd8eb-56e6-4f8a-9121-e0d19c2660a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844187298-172.17.0.13-1597752120100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-c1387743-101f-453c-8f48-cdafcb48cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-78ecc1ad-b1b9-4f4b-b6c9-2e711d008a76,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-8f75353f-9426-4b0e-8708-8fd559ba8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-55d6f524-f584-46c6-93c2-3b9274258683,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-ecb6ee35-e78b-4d2e-ab7c-47cc8244f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-bca47daf-22ac-49d2-ab79-51b93a31df88,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-60bf2857-0356-4795-8d07-5639c360f820,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-8b32de20-3c89-4610-9702-d3b3e8708b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844187298-172.17.0.13-1597752120100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-c1387743-101f-453c-8f48-cdafcb48cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-78ecc1ad-b1b9-4f4b-b6c9-2e711d008a76,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-8f75353f-9426-4b0e-8708-8fd559ba8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-55d6f524-f584-46c6-93c2-3b9274258683,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-ecb6ee35-e78b-4d2e-ab7c-47cc8244f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-bca47daf-22ac-49d2-ab79-51b93a31df88,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-60bf2857-0356-4795-8d07-5639c360f820,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-8b32de20-3c89-4610-9702-d3b3e8708b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039905984-172.17.0.13-1597752152974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-f4390bcd-3e91-4637-a232-9247be7d6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-46acde6c-619d-494c-bc0b-3dec250765f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-4b6f8e22-89d8-40cf-acc8-7c05b5e92f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-78eca042-bcf3-4ffb-969b-9f83b5b22b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-81107eaa-b84b-4722-a412-692bff7dcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-498239df-e099-4fb3-ac13-6b0b011313f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-7a782482-af23-4b42-8e4f-274e3750595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d1fcfe05-1586-4c3e-8ad6-35e2940e96b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039905984-172.17.0.13-1597752152974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-f4390bcd-3e91-4637-a232-9247be7d6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-46acde6c-619d-494c-bc0b-3dec250765f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-4b6f8e22-89d8-40cf-acc8-7c05b5e92f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-78eca042-bcf3-4ffb-969b-9f83b5b22b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-81107eaa-b84b-4722-a412-692bff7dcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-498239df-e099-4fb3-ac13-6b0b011313f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-7a782482-af23-4b42-8e4f-274e3750595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d1fcfe05-1586-4c3e-8ad6-35e2940e96b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390580725-172.17.0.13-1597752595604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-32c4c972-4832-4d51-9ff2-8df3e9a238a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-57b034ce-5ba4-4511-b5d5-d484da8143d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-94f4cc10-275d-461f-8f76-4b0d0e6fb1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-ab601bf0-204b-4cb4-8f31-6fa75bbbb909,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-c3d4a8f0-f2cd-4374-aaec-a6e8a5ff6967,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-03142b38-7b32-4885-9c77-8b06829b6741,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-6a8a1344-ede3-4c02-98fb-1cd875d09174,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ac38eef3-1566-4668-984b-dd6fa78f3958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390580725-172.17.0.13-1597752595604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-32c4c972-4832-4d51-9ff2-8df3e9a238a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-57b034ce-5ba4-4511-b5d5-d484da8143d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-94f4cc10-275d-461f-8f76-4b0d0e6fb1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-ab601bf0-204b-4cb4-8f31-6fa75bbbb909,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-c3d4a8f0-f2cd-4374-aaec-a6e8a5ff6967,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-03142b38-7b32-4885-9c77-8b06829b6741,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-6a8a1344-ede3-4c02-98fb-1cd875d09174,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ac38eef3-1566-4668-984b-dd6fa78f3958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500142932-172.17.0.13-1597752636222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-2ee002db-1090-40ef-82e5-507c397d3433,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-de3fc601-171f-4fe2-b2f0-37d46505b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-eb701519-ef74-4f4e-be84-b7c264a6c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-f164f7b1-eb1e-464f-be47-ec186b62b408,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-0e99024b-904c-4dca-ade7-048bb93dae25,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-90ea8259-72b6-4858-8378-d02d86d1b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-cd236c83-337d-460a-8bed-18ec00274d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-44485515-6318-44bd-9d28-096ebb64f682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500142932-172.17.0.13-1597752636222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-2ee002db-1090-40ef-82e5-507c397d3433,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-de3fc601-171f-4fe2-b2f0-37d46505b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-eb701519-ef74-4f4e-be84-b7c264a6c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-f164f7b1-eb1e-464f-be47-ec186b62b408,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-0e99024b-904c-4dca-ade7-048bb93dae25,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-90ea8259-72b6-4858-8378-d02d86d1b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-cd236c83-337d-460a-8bed-18ec00274d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-44485515-6318-44bd-9d28-096ebb64f682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739318662-172.17.0.13-1597752816249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-69008d2d-5818-4ed2-baa6-575de95b29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-dc966bfe-4197-4ddc-a78c-735f1ce8be29,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-23802bea-95ba-4fdc-9435-fc551cbee761,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-4802a2a5-a2de-40a4-a7ca-380ceca1a406,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-d1bc7507-64c3-4f7b-8f2d-02e4bd2901d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-657274e6-9116-4ecb-a456-57f56382a950,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-0e0f2fb8-43cd-4a26-87e7-5917dcf65407,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-8272752e-e547-4015-971a-58e1c49b27b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739318662-172.17.0.13-1597752816249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-69008d2d-5818-4ed2-baa6-575de95b29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-dc966bfe-4197-4ddc-a78c-735f1ce8be29,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-23802bea-95ba-4fdc-9435-fc551cbee761,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-4802a2a5-a2de-40a4-a7ca-380ceca1a406,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-d1bc7507-64c3-4f7b-8f2d-02e4bd2901d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-657274e6-9116-4ecb-a456-57f56382a950,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-0e0f2fb8-43cd-4a26-87e7-5917dcf65407,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-8272752e-e547-4015-971a-58e1c49b27b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758622572-172.17.0.13-1597753048704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-8c47b0f1-d3ca-49e7-8b11-95de13c3943e,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-0aee2d59-a8d3-444a-a184-b7ec4234d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-5856ab06-3594-4964-b1a8-7b2abba647ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-fb7864ca-fae3-4cc1-9241-b4ef96cbd420,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-085496fb-2aa4-4097-acf0-c218d2952acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-ae44a892-2a38-40da-bc61-0edbdc8b4018,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-0625d639-7d7f-4d3f-98bb-25a55a6cd69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a959ef1c-96fd-4a1e-9ddb-b56e9f5f76bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758622572-172.17.0.13-1597753048704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-8c47b0f1-d3ca-49e7-8b11-95de13c3943e,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-0aee2d59-a8d3-444a-a184-b7ec4234d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-5856ab06-3594-4964-b1a8-7b2abba647ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-fb7864ca-fae3-4cc1-9241-b4ef96cbd420,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-085496fb-2aa4-4097-acf0-c218d2952acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-ae44a892-2a38-40da-bc61-0edbdc8b4018,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-0625d639-7d7f-4d3f-98bb-25a55a6cd69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a959ef1c-96fd-4a1e-9ddb-b56e9f5f76bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443271026-172.17.0.13-1597753388523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-15180006-1009-4b08-981d-f4c7ed23dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-0d89d5b5-7a8b-43be-a9c5-e313ba6421ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-d599fb6a-896f-470a-988e-e43c1893c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-c9bdf6f7-7d79-4e7a-a421-179410bb750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-58ec01b8-ed43-4901-afba-1c95bdc50e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-208f9371-3152-4264-91b6-bb8f4342a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-71c2e934-84fd-4708-8ec5-e60008b06165,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-0fc12aca-d4a4-49d3-80d7-40020bd7ca26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443271026-172.17.0.13-1597753388523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-15180006-1009-4b08-981d-f4c7ed23dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-0d89d5b5-7a8b-43be-a9c5-e313ba6421ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-d599fb6a-896f-470a-988e-e43c1893c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-c9bdf6f7-7d79-4e7a-a421-179410bb750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-58ec01b8-ed43-4901-afba-1c95bdc50e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-208f9371-3152-4264-91b6-bb8f4342a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-71c2e934-84fd-4708-8ec5-e60008b06165,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-0fc12aca-d4a4-49d3-80d7-40020bd7ca26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5679
