reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937119892-172.17.0.12-1597670865809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-1709dacf-df0d-49f4-a62a-997340ce79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-51f66559-ed37-4e49-945e-72a948c5dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-f6ad69e2-3d34-4901-afdc-9b8d187bddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-8f2450c9-9686-4985-8fbd-f226b96d6556,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4ac697b7-aaff-4ba6-af77-e3e6ffce7010,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-7facfebf-7720-4aa1-be45-54c25ac3e304,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-41825b58-ff76-4e9c-a325-1c213cf81b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-21f21c43-8b25-4187-a8a3-789db15305c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937119892-172.17.0.12-1597670865809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-1709dacf-df0d-49f4-a62a-997340ce79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-51f66559-ed37-4e49-945e-72a948c5dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-f6ad69e2-3d34-4901-afdc-9b8d187bddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-8f2450c9-9686-4985-8fbd-f226b96d6556,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4ac697b7-aaff-4ba6-af77-e3e6ffce7010,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-7facfebf-7720-4aa1-be45-54c25ac3e304,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-41825b58-ff76-4e9c-a325-1c213cf81b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-21f21c43-8b25-4187-a8a3-789db15305c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247388234-172.17.0.12-1597671367880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-ef8fd571-4ea9-4217-acbb-66e4e0086a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-8cad7e98-a62f-46a1-ba21-882ad3c03cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-40399f51-1d43-4575-b2b7-42a0ffa80564,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-77b2b1cd-6d44-4782-8c2f-03bbc09bdb42,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-fc9f52d6-192f-42af-8293-1adff90cf5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-e5064640-edd3-411d-80c7-84a2b3fd92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9703cb6b-7768-40ed-b49e-fc12a83e7fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-7edc837e-b4e3-41a9-ad9b-b8cd04318fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247388234-172.17.0.12-1597671367880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-ef8fd571-4ea9-4217-acbb-66e4e0086a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-8cad7e98-a62f-46a1-ba21-882ad3c03cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-40399f51-1d43-4575-b2b7-42a0ffa80564,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-77b2b1cd-6d44-4782-8c2f-03bbc09bdb42,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-fc9f52d6-192f-42af-8293-1adff90cf5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-e5064640-edd3-411d-80c7-84a2b3fd92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9703cb6b-7768-40ed-b49e-fc12a83e7fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-7edc837e-b4e3-41a9-ad9b-b8cd04318fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296565080-172.17.0.12-1597671659218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-9276774b-49d3-400a-97c3-f71a668ebc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-c0deafdd-4f9b-4044-8263-cc7134273bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-d2318e5d-34ee-49ef-b79d-6f183670c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-6abae5bb-768f-4d8a-beff-3027d7570767,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-74d0934c-ac0b-4570-9a20-fc0939f40bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-b49bafd2-ab45-4ee8-a39d-e55381729e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-e950a69a-daa6-42b6-a850-5df8761c4a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-7e92f8e4-8095-4f37-bb28-26a31442a70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296565080-172.17.0.12-1597671659218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-9276774b-49d3-400a-97c3-f71a668ebc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-c0deafdd-4f9b-4044-8263-cc7134273bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-d2318e5d-34ee-49ef-b79d-6f183670c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-6abae5bb-768f-4d8a-beff-3027d7570767,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-74d0934c-ac0b-4570-9a20-fc0939f40bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-b49bafd2-ab45-4ee8-a39d-e55381729e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-e950a69a-daa6-42b6-a850-5df8761c4a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-7e92f8e4-8095-4f37-bb28-26a31442a70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472278723-172.17.0.12-1597671837900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-fc2f8637-eaad-48bb-82f3-ddc482db44f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b2b477c3-52a6-4749-ab60-e36ae5b536a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-2fc2622e-0bbc-4d2d-bd4c-ee8b63236981,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-5673b876-796a-47ca-91aa-5b26aea3cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-632362f9-564c-426f-a105-c98f1d7a86ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-78b2b715-d8a1-4b48-b317-8315aac187f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-88fedaf7-fbdf-42ab-8d4e-73d46fbad60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-dd311e47-eadb-4878-af9e-b835a7137cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472278723-172.17.0.12-1597671837900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-fc2f8637-eaad-48bb-82f3-ddc482db44f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b2b477c3-52a6-4749-ab60-e36ae5b536a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-2fc2622e-0bbc-4d2d-bd4c-ee8b63236981,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-5673b876-796a-47ca-91aa-5b26aea3cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-632362f9-564c-426f-a105-c98f1d7a86ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-78b2b715-d8a1-4b48-b317-8315aac187f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-88fedaf7-fbdf-42ab-8d4e-73d46fbad60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-dd311e47-eadb-4878-af9e-b835a7137cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533945707-172.17.0.12-1597672027966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-d67c26a7-0fde-4488-9656-1907fac0db25,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-fa42df28-0e53-4f2d-88ab-e1ee776bab60,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-2c456838-b1d2-4d51-bab3-0174aaa3a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-6a49f0ca-9d34-41f3-9304-aba1efdb837c,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-3cd39d3b-d628-4eb7-811a-0d0029c8796b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-72d0beee-1c2e-4180-a3b9-bbb357ee8088,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-3f36d30c-130f-40bb-8de7-9100d4e02d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-2a56d800-e2a1-4bca-9608-46d66686dd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533945707-172.17.0.12-1597672027966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-d67c26a7-0fde-4488-9656-1907fac0db25,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-fa42df28-0e53-4f2d-88ab-e1ee776bab60,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-2c456838-b1d2-4d51-bab3-0174aaa3a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-6a49f0ca-9d34-41f3-9304-aba1efdb837c,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-3cd39d3b-d628-4eb7-811a-0d0029c8796b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-72d0beee-1c2e-4180-a3b9-bbb357ee8088,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-3f36d30c-130f-40bb-8de7-9100d4e02d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-2a56d800-e2a1-4bca-9608-46d66686dd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992204445-172.17.0.12-1597672063952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-f2c938ac-b256-4dbc-b0e9-5ca3ca798db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-9360d039-3761-45ac-846a-064095ae0763,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-5ed26819-ca74-4158-920c-4d17bc36d877,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-784c40a0-8beb-4749-bd7e-760bfe6fca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-9672c2af-74c5-43dc-9ba6-2cff18cb6905,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-19e641c7-bd76-442e-a45b-7be254fdd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-7e0040b7-70c8-4b8a-9a36-250e010caf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-be56af11-6e99-4bcd-8300-fca8cf888e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992204445-172.17.0.12-1597672063952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-f2c938ac-b256-4dbc-b0e9-5ca3ca798db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-9360d039-3761-45ac-846a-064095ae0763,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-5ed26819-ca74-4158-920c-4d17bc36d877,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-784c40a0-8beb-4749-bd7e-760bfe6fca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-9672c2af-74c5-43dc-9ba6-2cff18cb6905,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-19e641c7-bd76-442e-a45b-7be254fdd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-7e0040b7-70c8-4b8a-9a36-250e010caf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-be56af11-6e99-4bcd-8300-fca8cf888e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760280728-172.17.0.12-1597672211749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-a402944b-3d62-41b5-83c1-67521a34e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-be6dfdf2-829b-4d63-94c9-8d4354ae8574,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ce9b9a93-550d-4eca-a06e-84bc69dc35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-08579210-52ec-4ba9-99ee-cd00f83c2551,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-e1eb742f-ba0c-4166-a955-900b03f572f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-3ee29851-0978-4b97-a1b6-5760c88c5fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-77d3f48e-9338-4b5c-b26c-5791d5ebdef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-e75f4665-ac43-4f66-b6b8-5036d4235624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760280728-172.17.0.12-1597672211749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-a402944b-3d62-41b5-83c1-67521a34e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-be6dfdf2-829b-4d63-94c9-8d4354ae8574,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ce9b9a93-550d-4eca-a06e-84bc69dc35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-08579210-52ec-4ba9-99ee-cd00f83c2551,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-e1eb742f-ba0c-4166-a955-900b03f572f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-3ee29851-0978-4b97-a1b6-5760c88c5fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-77d3f48e-9338-4b5c-b26c-5791d5ebdef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-e75f4665-ac43-4f66-b6b8-5036d4235624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741543082-172.17.0.12-1597672326014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45427,DS-aa2cb649-a49b-4eb5-94d0-97f9bff17ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-9d6e2276-2404-4645-832a-529a19780586,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-b7f0ebfc-e22c-4471-8357-d32ea065b439,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f9304806-dc54-429c-a186-13c8344539ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-2308e089-8d65-4619-99ea-936fc9b2fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e098ee9e-8de0-44db-a529-9088060532ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-791983c2-b26a-431c-92c3-c42721125315,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-784857eb-2d80-4800-b5fd-b487d590602d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741543082-172.17.0.12-1597672326014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45427,DS-aa2cb649-a49b-4eb5-94d0-97f9bff17ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-9d6e2276-2404-4645-832a-529a19780586,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-b7f0ebfc-e22c-4471-8357-d32ea065b439,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f9304806-dc54-429c-a186-13c8344539ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-2308e089-8d65-4619-99ea-936fc9b2fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e098ee9e-8de0-44db-a529-9088060532ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-791983c2-b26a-431c-92c3-c42721125315,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-784857eb-2d80-4800-b5fd-b487d590602d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092117643-172.17.0.12-1597672406644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-10059f33-b8a2-40d3-a8e1-3e10d6912d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-c3bcfa56-68b3-4f0e-bc1a-541b44ea5617,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-760f81a7-ebb1-42a2-93fe-9ebfe71e74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b249dee9-77cf-457b-a4e3-cf85f27278a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-86c11499-2bf0-4613-831c-25a62f183d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-211db92c-d8b2-4d8a-a4ae-c260131000c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-fab8683b-422c-440d-99bf-91696145a444,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-96f3ddf1-1602-41c4-ba4f-9f85e66246d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092117643-172.17.0.12-1597672406644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-10059f33-b8a2-40d3-a8e1-3e10d6912d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-c3bcfa56-68b3-4f0e-bc1a-541b44ea5617,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-760f81a7-ebb1-42a2-93fe-9ebfe71e74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b249dee9-77cf-457b-a4e3-cf85f27278a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-86c11499-2bf0-4613-831c-25a62f183d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-211db92c-d8b2-4d8a-a4ae-c260131000c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-fab8683b-422c-440d-99bf-91696145a444,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-96f3ddf1-1602-41c4-ba4f-9f85e66246d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034019796-172.17.0.12-1597672869740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-4004ad85-53c3-4c90-ab89-54fce26bb69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-21b9b852-a7f3-40e5-b9ac-ebb9bcb44c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8f6df521-f513-42b8-a666-fde8bba98d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-ee364927-9694-48bf-aa37-f019214865a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9352d00c-4b01-441b-8b05-8c22c52ad363,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-41d82877-4fdc-4418-a31a-bd78d6fdf596,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-598f99a2-bd8a-4545-9987-54ef327702d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-966e703e-8d0d-4339-a0e5-fdd0dc50a89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034019796-172.17.0.12-1597672869740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-4004ad85-53c3-4c90-ab89-54fce26bb69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-21b9b852-a7f3-40e5-b9ac-ebb9bcb44c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8f6df521-f513-42b8-a666-fde8bba98d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-ee364927-9694-48bf-aa37-f019214865a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-9352d00c-4b01-441b-8b05-8c22c52ad363,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-41d82877-4fdc-4418-a31a-bd78d6fdf596,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-598f99a2-bd8a-4545-9987-54ef327702d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-966e703e-8d0d-4339-a0e5-fdd0dc50a89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724735869-172.17.0.12-1597672907118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-658f1f96-aa33-4141-b28e-79ad7d1c72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-60d9fa82-4c39-4987-a2d3-dc634379b781,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-778c2540-ac70-4c3c-b0cf-d8fff0ce6692,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-b3326fc2-8592-4c39-9fcf-b6d5130f9027,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-8adcfeb4-785e-49b3-8210-21afdd53b441,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-7c1a385d-f52a-4e98-932d-23bee45fb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e3d401c4-df09-4929-bb9d-9f4b001dd44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-a85eab65-ba91-41b5-a8cf-f6c252195944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724735869-172.17.0.12-1597672907118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-658f1f96-aa33-4141-b28e-79ad7d1c72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-60d9fa82-4c39-4987-a2d3-dc634379b781,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-778c2540-ac70-4c3c-b0cf-d8fff0ce6692,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-b3326fc2-8592-4c39-9fcf-b6d5130f9027,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-8adcfeb4-785e-49b3-8210-21afdd53b441,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-7c1a385d-f52a-4e98-932d-23bee45fb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e3d401c4-df09-4929-bb9d-9f4b001dd44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-a85eab65-ba91-41b5-a8cf-f6c252195944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963067867-172.17.0.12-1597673268206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-df262399-ce0a-4a13-b073-97b19b2bf7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-f2884fb5-80c8-4ce8-a165-1c7181cb7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-33ffd48e-be6d-49de-9f4d-02520f8000b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-b35e36c1-3474-44b7-b4da-195d831cc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-59a70df3-8796-4d1a-979c-8d310a5851b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-f6050e0e-5e2a-4196-b037-dd832a6ab424,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-6037dfc6-cab8-4678-a046-791da2da2504,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9b93d598-f63f-4211-a837-84e7e2c2987d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963067867-172.17.0.12-1597673268206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-df262399-ce0a-4a13-b073-97b19b2bf7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-f2884fb5-80c8-4ce8-a165-1c7181cb7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-33ffd48e-be6d-49de-9f4d-02520f8000b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-b35e36c1-3474-44b7-b4da-195d831cc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-59a70df3-8796-4d1a-979c-8d310a5851b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-f6050e0e-5e2a-4196-b037-dd832a6ab424,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-6037dfc6-cab8-4678-a046-791da2da2504,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9b93d598-f63f-4211-a837-84e7e2c2987d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147987790-172.17.0.12-1597673343495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-f56e8b64-5718-40d3-befa-0443c68837e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-45fd6a83-2d3c-46aa-a2f9-53075128dc25,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-d2d32c46-d1c8-4b48-88bf-4c54fad8d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-8b0691d0-797b-4657-9640-ff4cc16e3252,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-48691e63-a13c-4c29-b351-99b669e30f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-9fd75b8a-36f2-45de-9d0d-d0be93149507,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-1190986b-c076-4c97-8e49-55e158ec397d,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-adcea0ac-9b84-44dd-a779-690194d3ffec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147987790-172.17.0.12-1597673343495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-f56e8b64-5718-40d3-befa-0443c68837e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-45fd6a83-2d3c-46aa-a2f9-53075128dc25,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-d2d32c46-d1c8-4b48-88bf-4c54fad8d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-8b0691d0-797b-4657-9640-ff4cc16e3252,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-48691e63-a13c-4c29-b351-99b669e30f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-9fd75b8a-36f2-45de-9d0d-d0be93149507,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-1190986b-c076-4c97-8e49-55e158ec397d,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-adcea0ac-9b84-44dd-a779-690194d3ffec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600241300-172.17.0.12-1597673513489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-402cdc7a-2d66-455d-b2fc-8ba717e28881,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9f262717-fb4e-422e-90cf-9344445c4fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-c74f77e7-0bad-469f-b2c9-03e81125bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-29fa6e7f-b33f-414a-807a-5821613226d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-c2cfb554-1ed9-43c8-a7da-b1e032ad1679,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-ca823a64-f124-4a8f-b8eb-921ab42087ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-c6666acd-85ce-45b5-b2bc-5f8e003c62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-1ce41e96-fdb3-4cb9-a1c1-eb3aa3a8a715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600241300-172.17.0.12-1597673513489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-402cdc7a-2d66-455d-b2fc-8ba717e28881,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9f262717-fb4e-422e-90cf-9344445c4fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-c74f77e7-0bad-469f-b2c9-03e81125bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-29fa6e7f-b33f-414a-807a-5821613226d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-c2cfb554-1ed9-43c8-a7da-b1e032ad1679,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-ca823a64-f124-4a8f-b8eb-921ab42087ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-c6666acd-85ce-45b5-b2bc-5f8e003c62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-1ce41e96-fdb3-4cb9-a1c1-eb3aa3a8a715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819056930-172.17.0.12-1597673550087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-136e0408-e9b9-4bde-8040-43935eaabd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5d6df630-2c5a-4810-895d-9b6fd49afb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-14299a08-a837-4833-b565-e2735c4cf366,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-7cda1ef9-11c8-4c5d-ac8f-a1b1b95a1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-95d8bee6-58ed-493f-a415-46c1d5200ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-b8b271df-9270-4e25-89b1-cff1ccd05657,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-bd110db6-766d-4db8-9dee-1f5057cd5745,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-2b8a9104-a576-4baf-9e71-2f44c845ad0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819056930-172.17.0.12-1597673550087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-136e0408-e9b9-4bde-8040-43935eaabd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5d6df630-2c5a-4810-895d-9b6fd49afb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-14299a08-a837-4833-b565-e2735c4cf366,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-7cda1ef9-11c8-4c5d-ac8f-a1b1b95a1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-95d8bee6-58ed-493f-a415-46c1d5200ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-b8b271df-9270-4e25-89b1-cff1ccd05657,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-bd110db6-766d-4db8-9dee-1f5057cd5745,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-2b8a9104-a576-4baf-9e71-2f44c845ad0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735831042-172.17.0.12-1597674443705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-57f8a6a7-d34c-4632-ba9f-610946a846dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-016b2f19-91a5-4f84-83c6-694420204886,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-3ad0ac47-2746-4e07-bf49-3645702a6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-97ebc55e-c02e-44a7-8706-801131dcd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-889417a2-6ea0-4516-b9f3-fcc81eab0e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-28582588-5263-4832-82d9-9ec0e5914bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-5583c9df-6538-4691-9a06-7331b46ec5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-118ad642-08c2-4e9b-89fe-43f52c1d2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735831042-172.17.0.12-1597674443705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-57f8a6a7-d34c-4632-ba9f-610946a846dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-016b2f19-91a5-4f84-83c6-694420204886,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-3ad0ac47-2746-4e07-bf49-3645702a6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-97ebc55e-c02e-44a7-8706-801131dcd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-889417a2-6ea0-4516-b9f3-fcc81eab0e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-28582588-5263-4832-82d9-9ec0e5914bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-5583c9df-6538-4691-9a06-7331b46ec5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-118ad642-08c2-4e9b-89fe-43f52c1d2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963872623-172.17.0.12-1597674679019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-d2c64384-bc72-48cc-b40a-f8632110fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6d17379f-6f35-428a-bb9b-7ba28eff74f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a087286-c042-4723-8fcc-d87e6e98b720,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-274591d4-660a-4ce4-a821-7c15d1bc1665,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-2c7e57cc-4848-4424-8d2b-f186e5501b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-09139963-fca4-4116-9115-8a5a56466153,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-9bd89451-afbc-4546-9c46-6e4b477c64dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d5b9fe70-a6b3-4f2a-8843-ec3dd30f028d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963872623-172.17.0.12-1597674679019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-d2c64384-bc72-48cc-b40a-f8632110fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6d17379f-6f35-428a-bb9b-7ba28eff74f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a087286-c042-4723-8fcc-d87e6e98b720,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-274591d4-660a-4ce4-a821-7c15d1bc1665,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-2c7e57cc-4848-4424-8d2b-f186e5501b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-09139963-fca4-4116-9115-8a5a56466153,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-9bd89451-afbc-4546-9c46-6e4b477c64dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d5b9fe70-a6b3-4f2a-8843-ec3dd30f028d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460377509-172.17.0.12-1597674887556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-c2859dc6-5c6c-4495-a40a-5566372b2999,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-add91a61-8ba3-4672-8588-b52f218b1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-3274e5b4-479c-459f-8c14-622a0bee6383,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-044dc0bd-de28-4b68-a602-cae7293d0771,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-debdc49e-058f-4792-bffd-96e75ae22c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-6baf6f68-6686-4b91-b11c-e6ac1efd4131,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-8c0e0c69-6007-48d6-99fc-1f2359ddeb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-11bbc0a3-0e06-45ec-9b46-291ce5af3628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460377509-172.17.0.12-1597674887556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-c2859dc6-5c6c-4495-a40a-5566372b2999,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-add91a61-8ba3-4672-8588-b52f218b1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-3274e5b4-479c-459f-8c14-622a0bee6383,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-044dc0bd-de28-4b68-a602-cae7293d0771,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-debdc49e-058f-4792-bffd-96e75ae22c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-6baf6f68-6686-4b91-b11c-e6ac1efd4131,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-8c0e0c69-6007-48d6-99fc-1f2359ddeb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-11bbc0a3-0e06-45ec-9b46-291ce5af3628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294133263-172.17.0.12-1597674919699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-e11ea630-1ab9-4b0d-bf9b-cddd4eac332e,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-0497eec1-7a7a-449e-9db5-6dfe4c44fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-279d954d-d30a-4f6e-b40b-7e2e02e0286d,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-875dbd40-1bf0-4eec-9bd3-8b63f62c6b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ff61ac78-23f1-47f2-af84-5fe001128be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-9ae765f5-7ccf-4bf5-96e3-d809243d27b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-0d22c660-c6b9-4660-bb5b-a55ba4111853,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-da6d1061-a9ea-44ee-b7b0-92467ec219ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294133263-172.17.0.12-1597674919699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-e11ea630-1ab9-4b0d-bf9b-cddd4eac332e,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-0497eec1-7a7a-449e-9db5-6dfe4c44fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-279d954d-d30a-4f6e-b40b-7e2e02e0286d,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-875dbd40-1bf0-4eec-9bd3-8b63f62c6b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ff61ac78-23f1-47f2-af84-5fe001128be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-9ae765f5-7ccf-4bf5-96e3-d809243d27b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-0d22c660-c6b9-4660-bb5b-a55ba4111853,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-da6d1061-a9ea-44ee-b7b0-92467ec219ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554797196-172.17.0.12-1597675215010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-385b76a5-08f9-4898-b4a1-0f6805e3be55,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-e47ab95e-1460-47ed-aa29-7ac75c12a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-fd317c59-5248-45f0-91df-eedb69d27f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a08926dc-af11-46dd-b334-0d40da3b3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-cf6c79fd-74da-49ae-831c-f7f3e86c5fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-9c709ee2-2ef7-4f67-a67e-6c9bb6030d44,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-bb645949-279e-4ec4-83a9-924bb8e07310,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-0d757b44-8d6c-4877-b781-17a489b7193d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554797196-172.17.0.12-1597675215010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-385b76a5-08f9-4898-b4a1-0f6805e3be55,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-e47ab95e-1460-47ed-aa29-7ac75c12a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-fd317c59-5248-45f0-91df-eedb69d27f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a08926dc-af11-46dd-b334-0d40da3b3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-cf6c79fd-74da-49ae-831c-f7f3e86c5fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-9c709ee2-2ef7-4f67-a67e-6c9bb6030d44,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-bb645949-279e-4ec4-83a9-924bb8e07310,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-0d757b44-8d6c-4877-b781-17a489b7193d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901522540-172.17.0.12-1597675401266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-79349771-eb3b-4fe6-9c9f-82427de48b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-00056c55-c540-408e-bb04-fba1c1c49deb,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-6d714231-f05b-4251-bfd8-540d1d2a8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-4fd8fcbb-02bd-467a-b39e-b312a6a70044,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-36cbeea0-06f1-43a4-8a07-f9da82c69a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-9b56e66e-d4cf-4ec9-a4d7-c84e41237c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-452eb5d6-55c9-4d0d-90d2-19623bea3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-efc30476-69ef-43e1-bf02-621a3dc4413d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901522540-172.17.0.12-1597675401266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-79349771-eb3b-4fe6-9c9f-82427de48b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-00056c55-c540-408e-bb04-fba1c1c49deb,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-6d714231-f05b-4251-bfd8-540d1d2a8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-4fd8fcbb-02bd-467a-b39e-b312a6a70044,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-36cbeea0-06f1-43a4-8a07-f9da82c69a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-9b56e66e-d4cf-4ec9-a4d7-c84e41237c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-452eb5d6-55c9-4d0d-90d2-19623bea3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-efc30476-69ef-43e1-bf02-621a3dc4413d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061296934-172.17.0.12-1597675728491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-9be1f7d7-f6ee-40eb-ac5d-53348ef97a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d39a840e-bbd1-40c6-a88d-e498b87eedc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-05c1709d-8a46-4cc1-b273-d600b82a0b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-f3092e54-e186-4a16-bf9a-0554ed71d408,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-88e3c716-aee3-47d1-8b4d-9487e4af5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-1cd0202c-1507-45e1-a54c-152e2d87bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-c3f6fc5c-922f-4ca6-a10c-0438223a3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e20eb34d-e210-4fa2-8e23-ca76f3955c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061296934-172.17.0.12-1597675728491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-9be1f7d7-f6ee-40eb-ac5d-53348ef97a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d39a840e-bbd1-40c6-a88d-e498b87eedc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-05c1709d-8a46-4cc1-b273-d600b82a0b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-f3092e54-e186-4a16-bf9a-0554ed71d408,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-88e3c716-aee3-47d1-8b4d-9487e4af5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-1cd0202c-1507-45e1-a54c-152e2d87bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-c3f6fc5c-922f-4ca6-a10c-0438223a3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e20eb34d-e210-4fa2-8e23-ca76f3955c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674642064-172.17.0.12-1597675837376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-0fdcb723-4e39-4914-8bea-99b86b4f7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2d4f5d95-ef10-4e88-aa95-cd055a5bdd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-b48aae18-d112-4585-abeb-1b292b1fbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-b07364fe-12d8-43fa-bfc6-f5ae0599298b,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-e1470c47-6d11-487e-a4b3-bee30a0ec172,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-0da9ecc2-c884-4d6d-8647-b6cb2b2140ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-84b1d7d4-da63-4446-a12f-642f38d86105,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-36803d9a-31c9-4ef7-beae-6b89d9a53a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674642064-172.17.0.12-1597675837376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-0fdcb723-4e39-4914-8bea-99b86b4f7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2d4f5d95-ef10-4e88-aa95-cd055a5bdd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-b48aae18-d112-4585-abeb-1b292b1fbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-b07364fe-12d8-43fa-bfc6-f5ae0599298b,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-e1470c47-6d11-487e-a4b3-bee30a0ec172,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-0da9ecc2-c884-4d6d-8647-b6cb2b2140ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-84b1d7d4-da63-4446-a12f-642f38d86105,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-36803d9a-31c9-4ef7-beae-6b89d9a53a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5209
