reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056911498-172.17.0.10-1597534903489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-f3bad7e2-e10e-4605-a4db-0f5c8b75793e,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-c3179b92-875c-402e-8b42-f76a209093a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-58b77e28-ce49-44bc-9d9c-739551807977,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-a692b540-223b-42fe-a303-5c78ff827448,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-12966678-f9c9-4cc8-8580-0b2e9d015152,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-79de91c9-2d55-4ce1-a5fd-df0a67c5012f,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-e09aad9f-061b-4e21-9daa-c266c45011b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-8aeaba20-1bfb-464f-aef5-10cc01a5160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056911498-172.17.0.10-1597534903489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-f3bad7e2-e10e-4605-a4db-0f5c8b75793e,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-c3179b92-875c-402e-8b42-f76a209093a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-58b77e28-ce49-44bc-9d9c-739551807977,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-a692b540-223b-42fe-a303-5c78ff827448,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-12966678-f9c9-4cc8-8580-0b2e9d015152,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-79de91c9-2d55-4ce1-a5fd-df0a67c5012f,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-e09aad9f-061b-4e21-9daa-c266c45011b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-8aeaba20-1bfb-464f-aef5-10cc01a5160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409523940-172.17.0.10-1597534948992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-c10d8e4d-62e1-447f-a4c5-68b52ea2bc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-f4db15e6-0b11-4e9f-b8c2-42fdbbb3d639,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-e24021a9-952d-4106-a4ed-aa971807de42,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-59023324-cfad-494c-acf5-b5a989b16338,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-7e27fe49-5117-4ab8-b429-019396f18a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-3bf8dd38-6338-45c0-8b31-b3819a4bf5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-1b6a7329-437f-4b4f-ba49-b0242c92393c,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-79c35c54-90ec-42e2-ba4c-01cc041b9234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409523940-172.17.0.10-1597534948992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-c10d8e4d-62e1-447f-a4c5-68b52ea2bc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-f4db15e6-0b11-4e9f-b8c2-42fdbbb3d639,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-e24021a9-952d-4106-a4ed-aa971807de42,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-59023324-cfad-494c-acf5-b5a989b16338,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-7e27fe49-5117-4ab8-b429-019396f18a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-3bf8dd38-6338-45c0-8b31-b3819a4bf5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-1b6a7329-437f-4b4f-ba49-b0242c92393c,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-79c35c54-90ec-42e2-ba4c-01cc041b9234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316909396-172.17.0.10-1597535025191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-483047fb-235f-48c2-ad77-cd66ab5c905c,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-b3ab2965-b49c-436a-80dd-f5786b7e0ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-e2bd1a24-9e29-4ad1-9a7e-5db37aeb2312,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-b0332fec-7ce5-4c89-9680-6064b160b051,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-0ce5dc87-94cb-4ac6-9743-9936c6f6bbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-381e5972-01d0-4b0c-9c5b-e660d7a4326c,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-c4a6a271-399c-4b3c-9f6e-26a2a6e760c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-76e2b378-12cb-4ec9-a6f6-ec5f01f59bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316909396-172.17.0.10-1597535025191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-483047fb-235f-48c2-ad77-cd66ab5c905c,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-b3ab2965-b49c-436a-80dd-f5786b7e0ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-e2bd1a24-9e29-4ad1-9a7e-5db37aeb2312,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-b0332fec-7ce5-4c89-9680-6064b160b051,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-0ce5dc87-94cb-4ac6-9743-9936c6f6bbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-381e5972-01d0-4b0c-9c5b-e660d7a4326c,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-c4a6a271-399c-4b3c-9f6e-26a2a6e760c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-76e2b378-12cb-4ec9-a6f6-ec5f01f59bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842241987-172.17.0.10-1597535302559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-c534a693-e025-4917-884e-6286c29d0988,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-f8722b0f-b322-44b4-ba07-a617ab8b6ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-4a20938c-cd61-4fca-bde5-5e7985155fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-39fea146-672c-4ae0-813f-44ed1965fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-99fb467c-5fd8-4da6-b770-cd2384735110,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-22804d16-beae-4f21-805d-9991c4985d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6ab6652e-b8de-4cab-a0d8-5d6b1b5e06dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-dd7622c0-3e8a-4a8c-aaf7-3ca7e94d91f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842241987-172.17.0.10-1597535302559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-c534a693-e025-4917-884e-6286c29d0988,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-f8722b0f-b322-44b4-ba07-a617ab8b6ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-4a20938c-cd61-4fca-bde5-5e7985155fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-39fea146-672c-4ae0-813f-44ed1965fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-99fb467c-5fd8-4da6-b770-cd2384735110,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-22804d16-beae-4f21-805d-9991c4985d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6ab6652e-b8de-4cab-a0d8-5d6b1b5e06dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-dd7622c0-3e8a-4a8c-aaf7-3ca7e94d91f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970289267-172.17.0.10-1597536441074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-c2bfb976-b4c1-47fa-ad15-d9bba1d5e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-67ed798c-2585-4458-b6da-cb4b35c0a286,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-407a6124-57e4-4d8b-9a83-8d72d36199bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-408ad246-a5b8-4d25-90a4-a5c12149c219,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d4d3cc75-0d31-4dcf-9b0d-ab590a931e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-e6491fb8-9ce0-41d3-ae68-608dfe677674,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-f9b516d1-8064-497c-bf79-03822beb349d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-c9ab701a-6984-4b83-96c9-2e1096999c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970289267-172.17.0.10-1597536441074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-c2bfb976-b4c1-47fa-ad15-d9bba1d5e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-67ed798c-2585-4458-b6da-cb4b35c0a286,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-407a6124-57e4-4d8b-9a83-8d72d36199bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-408ad246-a5b8-4d25-90a4-a5c12149c219,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d4d3cc75-0d31-4dcf-9b0d-ab590a931e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-e6491fb8-9ce0-41d3-ae68-608dfe677674,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-f9b516d1-8064-497c-bf79-03822beb349d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-c9ab701a-6984-4b83-96c9-2e1096999c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509838710-172.17.0.10-1597536482346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-6402cb2c-3593-4428-b248-ef9f478e1c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-6304b98c-ae87-4294-ac0e-00533951ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-9d462ac7-682f-431e-a486-03a81c91e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-4a11ebad-7a49-43fb-bb7b-5f33e16b8581,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-5042cd74-a2bc-4e05-8548-4680286003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-72545b72-e09f-4f03-ac3e-96f8606ff521,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-76eeb936-fb8b-4fd2-8f86-7a6a5cc5f519,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-016e15c3-fe22-4744-aad1-239bfde3c176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509838710-172.17.0.10-1597536482346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-6402cb2c-3593-4428-b248-ef9f478e1c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-6304b98c-ae87-4294-ac0e-00533951ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-9d462ac7-682f-431e-a486-03a81c91e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-4a11ebad-7a49-43fb-bb7b-5f33e16b8581,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-5042cd74-a2bc-4e05-8548-4680286003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-72545b72-e09f-4f03-ac3e-96f8606ff521,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-76eeb936-fb8b-4fd2-8f86-7a6a5cc5f519,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-016e15c3-fe22-4744-aad1-239bfde3c176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668328444-172.17.0.10-1597536718159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-96fedc21-d183-44f9-b400-44962d091436,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-c67e6756-706b-479d-b193-480731099a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-8de9b4e5-68c6-441a-9fb4-8d26f885a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-58ecf0a7-5fd0-4c05-ad8c-c846ed103cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-a99c8f98-20a7-4292-8ce4-572e90b22bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-029ad729-d0a4-4893-8e23-a0e439d9f934,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-dd102ee9-39bd-42b2-ad24-b0a5a40b6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-3eb01640-ef08-42da-af88-bcd1d945a857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668328444-172.17.0.10-1597536718159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-96fedc21-d183-44f9-b400-44962d091436,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-c67e6756-706b-479d-b193-480731099a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-8de9b4e5-68c6-441a-9fb4-8d26f885a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-58ecf0a7-5fd0-4c05-ad8c-c846ed103cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-a99c8f98-20a7-4292-8ce4-572e90b22bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-029ad729-d0a4-4893-8e23-a0e439d9f934,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-dd102ee9-39bd-42b2-ad24-b0a5a40b6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-3eb01640-ef08-42da-af88-bcd1d945a857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240345650-172.17.0.10-1597537199270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-e330fd4a-5aa3-445e-b916-f1622e6f6471,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-fd44d0ee-878e-4db9-8c50-9abee4ed8055,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-0f663b92-2e60-44ae-886f-205997879498,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-cc258cad-fdef-459d-9e31-4251c26bb2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-c76fe6c3-73b9-4ba2-b2d5-508d3a06cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-01d06e17-e10a-4c9b-8f7a-37171317c677,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1045981a-7886-4d35-b965-06f51e2b145e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-4d24b271-6c64-4209-a83a-a13a2dbb2701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240345650-172.17.0.10-1597537199270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-e330fd4a-5aa3-445e-b916-f1622e6f6471,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-fd44d0ee-878e-4db9-8c50-9abee4ed8055,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-0f663b92-2e60-44ae-886f-205997879498,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-cc258cad-fdef-459d-9e31-4251c26bb2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-c76fe6c3-73b9-4ba2-b2d5-508d3a06cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-01d06e17-e10a-4c9b-8f7a-37171317c677,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1045981a-7886-4d35-b965-06f51e2b145e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-4d24b271-6c64-4209-a83a-a13a2dbb2701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140790133-172.17.0.10-1597537275887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-cdf65e76-b8d5-4a46-adaf-cce01f25b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-330764f9-9c9e-4293-a0e1-59abc20cc616,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-66f6c13f-4308-4972-8fda-220edd4eba73,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-91f88e3c-d00a-43dd-805f-a2bc090e4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-95247e5c-894f-45b9-9323-ef4e9c3f4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-913e348d-c370-411a-95d7-a076ddb1fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-daea8f95-313e-44c3-9959-8293856d5456,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ac85122a-f4d6-4d50-9fac-9a0074b7b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140790133-172.17.0.10-1597537275887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-cdf65e76-b8d5-4a46-adaf-cce01f25b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-330764f9-9c9e-4293-a0e1-59abc20cc616,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-66f6c13f-4308-4972-8fda-220edd4eba73,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-91f88e3c-d00a-43dd-805f-a2bc090e4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-95247e5c-894f-45b9-9323-ef4e9c3f4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-913e348d-c370-411a-95d7-a076ddb1fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-daea8f95-313e-44c3-9959-8293856d5456,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ac85122a-f4d6-4d50-9fac-9a0074b7b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555295152-172.17.0.10-1597537307668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-96b3d7ec-0d26-4cb9-ac34-d63e53314ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-af01119c-66df-46e3-8576-5a9db6730bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-3269c996-0c47-44c9-b9b6-edd677a4152f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-60978335-7d66-4504-bd1a-3c3dfa4aef05,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-d321077f-67db-4e41-9d75-ef017083ddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-86995bc1-5dc0-4b96-8535-ccaeb31c3c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-e42e0831-ce31-4275-949a-1520c148c9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-3d5f61dc-e2cd-4b15-8754-43b96a52233b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555295152-172.17.0.10-1597537307668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-96b3d7ec-0d26-4cb9-ac34-d63e53314ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-af01119c-66df-46e3-8576-5a9db6730bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-3269c996-0c47-44c9-b9b6-edd677a4152f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-60978335-7d66-4504-bd1a-3c3dfa4aef05,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-d321077f-67db-4e41-9d75-ef017083ddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-86995bc1-5dc0-4b96-8535-ccaeb31c3c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-e42e0831-ce31-4275-949a-1520c148c9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-3d5f61dc-e2cd-4b15-8754-43b96a52233b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092108837-172.17.0.10-1597537721567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-24cf1c3c-7517-4145-bebe-d5af273db8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-6dc7a5fc-56ad-4c05-8189-9b467aad7961,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-a3828feb-5ab5-4e96-b69b-8e1f986cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-417c9b39-0d9b-4df1-9353-b5fd9865b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-b56613b8-46d1-4a66-a770-1f095ea4aae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-fcb2bb64-04c9-4eaf-9f2f-592f9c6828b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-809e9ff1-fcca-4066-a445-5db44e41e998,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-25e30a89-8144-42e8-b617-481326323276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092108837-172.17.0.10-1597537721567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-24cf1c3c-7517-4145-bebe-d5af273db8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-6dc7a5fc-56ad-4c05-8189-9b467aad7961,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-a3828feb-5ab5-4e96-b69b-8e1f986cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-417c9b39-0d9b-4df1-9353-b5fd9865b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-b56613b8-46d1-4a66-a770-1f095ea4aae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-fcb2bb64-04c9-4eaf-9f2f-592f9c6828b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-809e9ff1-fcca-4066-a445-5db44e41e998,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-25e30a89-8144-42e8-b617-481326323276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20297715-172.17.0.10-1597537762043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-11ecc39c-731c-4a6a-bf6a-957310cc5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-740f01c4-6af4-4a2b-b944-c003f5825d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-77fd5392-623c-4b84-93f0-74ee8746057a,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-8edfaf33-a6d9-4462-9284-53922ecb3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-5e5f7557-c453-4df7-9a0d-51ea024d80ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9afdcad4-4445-40cd-90c3-74f4174e7aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-9fa2a603-4fb3-4a30-8155-4059f66e8641,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-52223f76-a5e2-4b95-8969-81e19ec3619d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20297715-172.17.0.10-1597537762043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-11ecc39c-731c-4a6a-bf6a-957310cc5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-740f01c4-6af4-4a2b-b944-c003f5825d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-77fd5392-623c-4b84-93f0-74ee8746057a,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-8edfaf33-a6d9-4462-9284-53922ecb3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-5e5f7557-c453-4df7-9a0d-51ea024d80ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9afdcad4-4445-40cd-90c3-74f4174e7aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-9fa2a603-4fb3-4a30-8155-4059f66e8641,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-52223f76-a5e2-4b95-8969-81e19ec3619d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071160706-172.17.0.10-1597537982656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43008,DS-ec352d37-e798-470e-a7f7-6128d6bca15b,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-8f9057f3-1f61-4d3a-bdfd-9006f99cc8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5153a343-f214-474e-8ecf-371fdb78894d,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-797382df-8998-444e-898e-c0f0527e856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-e1d55572-3e23-43b9-b721-b2959b8b6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-d757d751-91b0-400b-87a1-3094b768678a,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-619dd18e-434b-4aa0-a229-d059b8880783,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2f1cefb4-2571-4f71-b66a-b28eb846ac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071160706-172.17.0.10-1597537982656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43008,DS-ec352d37-e798-470e-a7f7-6128d6bca15b,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-8f9057f3-1f61-4d3a-bdfd-9006f99cc8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5153a343-f214-474e-8ecf-371fdb78894d,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-797382df-8998-444e-898e-c0f0527e856d,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-e1d55572-3e23-43b9-b721-b2959b8b6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-d757d751-91b0-400b-87a1-3094b768678a,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-619dd18e-434b-4aa0-a229-d059b8880783,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2f1cefb4-2571-4f71-b66a-b28eb846ac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143861697-172.17.0.10-1597538059288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42061,DS-45f0f0a0-c060-484a-a0ed-16d8fde936ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-02638f13-57b4-48bc-9e49-2adfe7133e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-70483c7f-f1ce-47bd-b03f-f71e3a5386bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0684f789-8b7f-403e-a5c9-1cbd5593b2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-4c863477-ef3a-4848-8a38-8099440393c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-d568db84-01ca-496d-b1ae-14fd3c75bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-5a7a38b1-0caa-45d3-9b5a-c4560799fb48,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2177a2d0-b480-4282-9e4c-1e6719efbf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143861697-172.17.0.10-1597538059288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42061,DS-45f0f0a0-c060-484a-a0ed-16d8fde936ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-02638f13-57b4-48bc-9e49-2adfe7133e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-70483c7f-f1ce-47bd-b03f-f71e3a5386bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0684f789-8b7f-403e-a5c9-1cbd5593b2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-4c863477-ef3a-4848-8a38-8099440393c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-d568db84-01ca-496d-b1ae-14fd3c75bf85,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-5a7a38b1-0caa-45d3-9b5a-c4560799fb48,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2177a2d0-b480-4282-9e4c-1e6719efbf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620748814-172.17.0.10-1597538523123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-1a4fb596-618b-4fcb-94f3-d9d9d91341fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-8ea4d9ae-da3f-4df7-af53-698e8f80b950,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-8220640b-b881-4489-9e9f-6f401845d111,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-ee076dc5-ec56-4784-b1fc-d472714ea328,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-768c03cd-b3fe-4e5d-b7f4-e88e5c8e9da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f3663500-d6ea-402b-944e-88ebdb854d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-abcc0d48-e7ed-4cf2-bb37-b321c4e9b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-159dd886-5d60-479e-bdfe-da7eae77e467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620748814-172.17.0.10-1597538523123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-1a4fb596-618b-4fcb-94f3-d9d9d91341fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-8ea4d9ae-da3f-4df7-af53-698e8f80b950,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-8220640b-b881-4489-9e9f-6f401845d111,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-ee076dc5-ec56-4784-b1fc-d472714ea328,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-768c03cd-b3fe-4e5d-b7f4-e88e5c8e9da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f3663500-d6ea-402b-944e-88ebdb854d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-abcc0d48-e7ed-4cf2-bb37-b321c4e9b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-159dd886-5d60-479e-bdfe-da7eae77e467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713199550-172.17.0.10-1597539075721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-37714f6b-2c5c-49e2-9e40-e93f6205cb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0f9604b2-a790-434b-928c-324c792c7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-567af382-ded4-4a06-9945-5899e3c39344,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-4cddd750-04bc-4f0c-97ee-375e78e64764,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-eb69011a-5fa7-4eb4-baef-1716ef2e069b,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-84db049d-0851-4354-90cc-93e1ecb20a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-280548b3-f7bc-41ec-bf38-86008fafe44c,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-936e39d7-39a0-446f-8419-360f8f2af04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713199550-172.17.0.10-1597539075721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-37714f6b-2c5c-49e2-9e40-e93f6205cb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0f9604b2-a790-434b-928c-324c792c7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-567af382-ded4-4a06-9945-5899e3c39344,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-4cddd750-04bc-4f0c-97ee-375e78e64764,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-eb69011a-5fa7-4eb4-baef-1716ef2e069b,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-84db049d-0851-4354-90cc-93e1ecb20a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-280548b3-f7bc-41ec-bf38-86008fafe44c,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-936e39d7-39a0-446f-8419-360f8f2af04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282404265-172.17.0.10-1597539262596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40779,DS-a3549041-13d7-44a5-8f19-a10375b82230,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-e708465b-94f4-4da0-888c-f56be6c58721,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-042f9b98-3578-441c-b347-b0bd17a73811,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-6b14b34d-6999-4420-92b5-57e07562e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3a2177e3-3848-4e96-986e-21069badfa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-1a51c6b6-8dab-434e-9f34-20f98e8a263f,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-801a1cff-c187-432a-8c0e-82c58c4aedc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-f61f01fa-6352-439e-8dda-3aaf8d00c6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282404265-172.17.0.10-1597539262596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40779,DS-a3549041-13d7-44a5-8f19-a10375b82230,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-e708465b-94f4-4da0-888c-f56be6c58721,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-042f9b98-3578-441c-b347-b0bd17a73811,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-6b14b34d-6999-4420-92b5-57e07562e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3a2177e3-3848-4e96-986e-21069badfa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-1a51c6b6-8dab-434e-9f34-20f98e8a263f,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-801a1cff-c187-432a-8c0e-82c58c4aedc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-f61f01fa-6352-439e-8dda-3aaf8d00c6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874668904-172.17.0.10-1597539686173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-4d33189e-8373-4780-9de6-c707c48ce6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-780e8301-4ba4-463e-a1cb-2e5fba4dda92,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-da102194-12bc-43cb-b985-4db30355d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-16eeab50-1550-4ffe-a476-5c351a32f891,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-6acea0a0-ae22-489b-bf5d-6642fe58dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-f67ce789-973a-4766-8cbe-6142f86c4786,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6feaaf2a-b3bd-4f5a-a93b-b89d6db6afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-4e7f02fa-30b4-4f83-9ba3-b68661146704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874668904-172.17.0.10-1597539686173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-4d33189e-8373-4780-9de6-c707c48ce6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-780e8301-4ba4-463e-a1cb-2e5fba4dda92,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-da102194-12bc-43cb-b985-4db30355d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-16eeab50-1550-4ffe-a476-5c351a32f891,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-6acea0a0-ae22-489b-bf5d-6642fe58dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-f67ce789-973a-4766-8cbe-6142f86c4786,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6feaaf2a-b3bd-4f5a-a93b-b89d6db6afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-4e7f02fa-30b4-4f83-9ba3-b68661146704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850953798-172.17.0.10-1597540011386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-a9e3ec56-9d29-4e40-b9fe-c49236c30ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-bc699c29-afd7-4d3a-a651-44e8be69c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-86d5df93-c891-4662-8801-628b837fb5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1fa64b33-3c09-418f-9053-24fd57d2583b,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-f3280275-39c8-453b-9e48-c06896519b92,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-23997c28-5725-44c5-a224-b1bf686094e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8a8ccd61-d179-4e5d-86bb-c9aa022fc259,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-1ecb0be3-5a27-4f28-81db-c2f04794c622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850953798-172.17.0.10-1597540011386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-a9e3ec56-9d29-4e40-b9fe-c49236c30ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-bc699c29-afd7-4d3a-a651-44e8be69c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-86d5df93-c891-4662-8801-628b837fb5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1fa64b33-3c09-418f-9053-24fd57d2583b,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-f3280275-39c8-453b-9e48-c06896519b92,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-23997c28-5725-44c5-a224-b1bf686094e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8a8ccd61-d179-4e5d-86bb-c9aa022fc259,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-1ecb0be3-5a27-4f28-81db-c2f04794c622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5824
