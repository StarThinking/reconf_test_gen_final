reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693161094-172.17.0.4-1597364831810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-6053ed1c-c624-459c-bda7-d5d59bce8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-c14a50cf-19a7-48a4-8ead-e19031f9873b,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-34730c3e-a085-42b1-aa22-ab5cea1eb819,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-f571811f-f03f-485d-865d-1a2338befbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-3445773f-b9b3-41d1-b521-46d01e7cc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-5a5bcbb9-9a2d-4968-b475-b1506b08fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-edff35de-5674-4b05-969a-f4cd8453982c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-d3bfddd7-21b2-469b-b052-764acf858a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693161094-172.17.0.4-1597364831810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-6053ed1c-c624-459c-bda7-d5d59bce8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-c14a50cf-19a7-48a4-8ead-e19031f9873b,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-34730c3e-a085-42b1-aa22-ab5cea1eb819,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-f571811f-f03f-485d-865d-1a2338befbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-3445773f-b9b3-41d1-b521-46d01e7cc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-5a5bcbb9-9a2d-4968-b475-b1506b08fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-edff35de-5674-4b05-969a-f4cd8453982c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-d3bfddd7-21b2-469b-b052-764acf858a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887875730-172.17.0.4-1597365137118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-a40d4421-3686-4878-aa6f-de2b3fcebf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-05a8d2c8-9662-4f89-b3e0-77014da87ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-41028e15-3eb1-4675-91a1-bbe3431cb438,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-22ce6c22-a997-4a9c-b545-1a9a92297263,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-30b2f019-059a-4d0c-9f37-577f2ea9588f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-46d47a17-dde5-41fb-bbf9-af44bf220532,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-0c3d027b-d6b9-4cec-a9f2-8b07586e0441,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-5bd0dc36-5fa4-4c5a-a07d-a34e4de33f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887875730-172.17.0.4-1597365137118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-a40d4421-3686-4878-aa6f-de2b3fcebf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-05a8d2c8-9662-4f89-b3e0-77014da87ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-41028e15-3eb1-4675-91a1-bbe3431cb438,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-22ce6c22-a997-4a9c-b545-1a9a92297263,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-30b2f019-059a-4d0c-9f37-577f2ea9588f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-46d47a17-dde5-41fb-bbf9-af44bf220532,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-0c3d027b-d6b9-4cec-a9f2-8b07586e0441,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-5bd0dc36-5fa4-4c5a-a07d-a34e4de33f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372472393-172.17.0.4-1597365331917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-b1d94350-4e59-481e-b436-cb5d62b9baae,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-cb337541-ac20-460b-ab2a-9a46b84d3728,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7f58d67f-6700-412a-a931-af650392cee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-2497d0af-1a68-42c3-85b1-1f7431024afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-0e2d26e9-b707-44b5-bb7a-7313ac64258a,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-54a21be9-0f46-4b44-85a0-79212d83b525,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-91cb770d-5fe0-49ec-afbb-25409d15dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-e4674308-58db-43c7-8036-23eba0bc750d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372472393-172.17.0.4-1597365331917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-b1d94350-4e59-481e-b436-cb5d62b9baae,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-cb337541-ac20-460b-ab2a-9a46b84d3728,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7f58d67f-6700-412a-a931-af650392cee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-2497d0af-1a68-42c3-85b1-1f7431024afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-0e2d26e9-b707-44b5-bb7a-7313ac64258a,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-54a21be9-0f46-4b44-85a0-79212d83b525,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-91cb770d-5fe0-49ec-afbb-25409d15dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-e4674308-58db-43c7-8036-23eba0bc750d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267002205-172.17.0.4-1597366152871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-5ab9fdad-90f9-4415-892a-85b37762bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-7002ae3a-10eb-43c8-965b-8161adb03290,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-b202a981-590a-48e4-904d-c18c8caa46d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-34137898-c1d5-483d-abc8-55663e064549,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-f277652c-96ae-4af6-b919-ba20623bc541,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-481966b8-08f3-4a7d-97f2-53019d6dfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-a5ab94f2-f9f0-4873-9471-8dc72e75ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-f1f12392-0a18-4f3a-802f-4f643eeb9224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267002205-172.17.0.4-1597366152871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-5ab9fdad-90f9-4415-892a-85b37762bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-7002ae3a-10eb-43c8-965b-8161adb03290,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-b202a981-590a-48e4-904d-c18c8caa46d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-34137898-c1d5-483d-abc8-55663e064549,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-f277652c-96ae-4af6-b919-ba20623bc541,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-481966b8-08f3-4a7d-97f2-53019d6dfacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-a5ab94f2-f9f0-4873-9471-8dc72e75ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-f1f12392-0a18-4f3a-802f-4f643eeb9224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505745598-172.17.0.4-1597366295307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-a61a25a4-27d2-4116-b7a0-da9ac40528f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-cd63735f-8683-44d4-8e14-c32670ab8134,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-6ffa4a4e-e649-41f8-975e-586fa67f7cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-48e426cf-ae67-43fb-93da-d509d44bf980,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-e0b4018e-8b3c-4edd-b664-bfa3be27cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-39640d4a-ffbe-4c8a-a054-ccf7c8b245e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-b289f9ae-e446-442d-bd72-8dbfafc3e18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-68cd1b97-99aa-4795-8afc-8010201c44a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505745598-172.17.0.4-1597366295307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-a61a25a4-27d2-4116-b7a0-da9ac40528f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-cd63735f-8683-44d4-8e14-c32670ab8134,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-6ffa4a4e-e649-41f8-975e-586fa67f7cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-48e426cf-ae67-43fb-93da-d509d44bf980,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-e0b4018e-8b3c-4edd-b664-bfa3be27cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-39640d4a-ffbe-4c8a-a054-ccf7c8b245e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-b289f9ae-e446-442d-bd72-8dbfafc3e18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-68cd1b97-99aa-4795-8afc-8010201c44a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089963314-172.17.0.4-1597366408490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33499,DS-42fdcfb8-557f-47f2-b1b6-fde32bad0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-cdbdd451-0a21-475d-9314-283aca59106f,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-db73b096-97f7-49c4-87ab-c72c4a56d666,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-1f0cc00b-5403-4a9e-a707-9d02caf38cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-06016533-2cdf-4421-9f00-909d7e49a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-45e05b08-aa7a-4220-9e43-b70ddb6645fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-e600c4bb-b962-4fa0-b1b9-6f68be4f9562,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-89588e14-f09c-4893-8846-741bc7873f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089963314-172.17.0.4-1597366408490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33499,DS-42fdcfb8-557f-47f2-b1b6-fde32bad0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-cdbdd451-0a21-475d-9314-283aca59106f,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-db73b096-97f7-49c4-87ab-c72c4a56d666,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-1f0cc00b-5403-4a9e-a707-9d02caf38cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-06016533-2cdf-4421-9f00-909d7e49a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-45e05b08-aa7a-4220-9e43-b70ddb6645fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-e600c4bb-b962-4fa0-b1b9-6f68be4f9562,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-89588e14-f09c-4893-8846-741bc7873f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641540759-172.17.0.4-1597366599298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-7332e781-6079-467c-8956-b62e0b366bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-98d32c25-1052-4966-a08f-c9243353ae69,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a149019c-3e9a-4371-8ecb-863de1853af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2c611ff9-a04e-48f8-a4c7-e35d319f6013,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-d561be97-cd98-4fab-af40-f094086306b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3463ba07-b3fe-4839-83f1-5f4e9539b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a8e21572-5f78-4e60-b8ee-58bd0dc452d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-a79fb1fb-dc1b-4277-954a-dabd1ba4181a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641540759-172.17.0.4-1597366599298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-7332e781-6079-467c-8956-b62e0b366bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-98d32c25-1052-4966-a08f-c9243353ae69,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a149019c-3e9a-4371-8ecb-863de1853af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2c611ff9-a04e-48f8-a4c7-e35d319f6013,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-d561be97-cd98-4fab-af40-f094086306b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3463ba07-b3fe-4839-83f1-5f4e9539b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a8e21572-5f78-4e60-b8ee-58bd0dc452d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-a79fb1fb-dc1b-4277-954a-dabd1ba4181a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155833934-172.17.0.4-1597366739614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-fa623094-2b52-41a0-9038-33765afbba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-e007fe49-da18-4eee-8b1f-5b34cbbf2928,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d7fa5042-77e6-4e9e-950c-bd4272a78ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-851db2a3-6932-4150-ab20-3756ce55f499,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-076e6397-0f75-40c8-ac2a-91b5bbc9a10d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-0050fd75-be6e-41b4-8cec-876ba16648c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-85e19046-9dcc-4669-b0f2-c5471239ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-a78be1cd-842c-4c6f-9c27-9f4802a6872e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155833934-172.17.0.4-1597366739614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-fa623094-2b52-41a0-9038-33765afbba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-e007fe49-da18-4eee-8b1f-5b34cbbf2928,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d7fa5042-77e6-4e9e-950c-bd4272a78ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-851db2a3-6932-4150-ab20-3756ce55f499,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-076e6397-0f75-40c8-ac2a-91b5bbc9a10d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-0050fd75-be6e-41b4-8cec-876ba16648c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-85e19046-9dcc-4669-b0f2-c5471239ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-a78be1cd-842c-4c6f-9c27-9f4802a6872e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257810547-172.17.0.4-1597366938179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-1c2095e6-cf4d-4eeb-aa87-564f6c09a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-64ce601b-aca8-4712-b775-07dc057a2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-0d007fd6-1562-467a-af35-f97c4e6cbbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-c584eb96-323f-4738-b891-9cce7a76f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-d4981241-29bc-41bf-88bd-eba64a159d31,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-0a930ab1-f405-4bcb-ad7b-6a95b0f11fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-c88aea57-22ad-48f6-a97f-01372ee6ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-bcfbbc2d-c26f-4807-8e06-81fbb2ada944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257810547-172.17.0.4-1597366938179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-1c2095e6-cf4d-4eeb-aa87-564f6c09a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-64ce601b-aca8-4712-b775-07dc057a2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-0d007fd6-1562-467a-af35-f97c4e6cbbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-c584eb96-323f-4738-b891-9cce7a76f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-d4981241-29bc-41bf-88bd-eba64a159d31,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-0a930ab1-f405-4bcb-ad7b-6a95b0f11fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-c88aea57-22ad-48f6-a97f-01372ee6ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-bcfbbc2d-c26f-4807-8e06-81fbb2ada944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894326719-172.17.0.4-1597368195471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-d2f26807-e9ab-4413-8a70-4187166aa5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-ff3230da-ccfb-40fc-aca9-665358371eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-02808ba0-03a4-4c92-bd62-a344b8839029,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-5f97cc2b-21fe-4d54-ac19-39adf944e79c,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-46d852d0-5596-4dba-be54-5fbe8e5381d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-937788fa-c827-45a2-8ca4-dc4230731280,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-64628336-bd57-47ad-ad3b-9d76dc96c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0e8679dd-a34e-4027-90bb-cfb067e4a65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894326719-172.17.0.4-1597368195471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-d2f26807-e9ab-4413-8a70-4187166aa5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-ff3230da-ccfb-40fc-aca9-665358371eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-02808ba0-03a4-4c92-bd62-a344b8839029,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-5f97cc2b-21fe-4d54-ac19-39adf944e79c,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-46d852d0-5596-4dba-be54-5fbe8e5381d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-937788fa-c827-45a2-8ca4-dc4230731280,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-64628336-bd57-47ad-ad3b-9d76dc96c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0e8679dd-a34e-4027-90bb-cfb067e4a65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63685915-172.17.0.4-1597368337755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43220,DS-d6c319f4-7223-4390-a816-9e06ed5dd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-46fa1927-b142-4a14-895c-4570a5d04a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-e7b39c99-d783-4328-a2d9-a9d0c8d53816,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-5910c59e-151c-4e48-b2e5-cda6ec31d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-3e771ad5-cfde-486d-b32f-55a38912ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-ae9aebfd-4702-4330-982a-729830c7740d,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-7920883e-7747-4c9a-b4bf-2efaa0bac41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-05bc6704-0160-447f-8a63-4e7fea70d9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63685915-172.17.0.4-1597368337755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43220,DS-d6c319f4-7223-4390-a816-9e06ed5dd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-46fa1927-b142-4a14-895c-4570a5d04a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-e7b39c99-d783-4328-a2d9-a9d0c8d53816,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-5910c59e-151c-4e48-b2e5-cda6ec31d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-3e771ad5-cfde-486d-b32f-55a38912ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-ae9aebfd-4702-4330-982a-729830c7740d,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-7920883e-7747-4c9a-b4bf-2efaa0bac41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-05bc6704-0160-447f-8a63-4e7fea70d9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883514452-172.17.0.4-1597369165991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-fe81e3a4-e922-4b26-8ad8-990e20a61db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-6c7361a0-7686-4a88-b715-4762b0c02a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-73b94734-c0e5-4e7b-838a-0fe062ded34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-26a55c33-513c-4120-9976-37e6e3c026b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-74fb4d4d-8131-4c5f-aa1a-0a416e5181c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-806b1c2d-1b2a-4ccc-a852-3695887d2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-a4c3a0c0-7b07-42e7-9a53-0e70d383b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-454f4859-7939-48f5-9898-eea235d2e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883514452-172.17.0.4-1597369165991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-fe81e3a4-e922-4b26-8ad8-990e20a61db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-6c7361a0-7686-4a88-b715-4762b0c02a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-73b94734-c0e5-4e7b-838a-0fe062ded34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-26a55c33-513c-4120-9976-37e6e3c026b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-74fb4d4d-8131-4c5f-aa1a-0a416e5181c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-806b1c2d-1b2a-4ccc-a852-3695887d2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-a4c3a0c0-7b07-42e7-9a53-0e70d383b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-454f4859-7939-48f5-9898-eea235d2e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5429
