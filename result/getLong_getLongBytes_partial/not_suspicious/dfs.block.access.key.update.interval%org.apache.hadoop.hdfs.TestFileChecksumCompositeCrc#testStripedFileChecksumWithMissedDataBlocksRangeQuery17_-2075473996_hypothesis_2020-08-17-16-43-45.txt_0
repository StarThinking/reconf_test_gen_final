reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845512891-172.17.0.11-1597682708231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-f16c330c-5dff-4b7c-b399-0d4a5124ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-a8895602-2971-4dde-99b6-8180d6c6d312,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-3abfab5a-2c48-4ded-a833-78895a5b5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-019dced5-cde6-4ea9-a6b7-eb9174f8c73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c8cebda2-8a44-4cd4-a5fa-37be1e8e3970,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-6b81a9de-fee6-4b8b-b205-81bad9c5e057,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-8e6a0823-e84c-45c4-afd7-91116b6f4c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-67a38220-7bbb-453e-b970-44936c2d4fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845512891-172.17.0.11-1597682708231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-f16c330c-5dff-4b7c-b399-0d4a5124ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-a8895602-2971-4dde-99b6-8180d6c6d312,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-3abfab5a-2c48-4ded-a833-78895a5b5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-019dced5-cde6-4ea9-a6b7-eb9174f8c73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c8cebda2-8a44-4cd4-a5fa-37be1e8e3970,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-6b81a9de-fee6-4b8b-b205-81bad9c5e057,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-8e6a0823-e84c-45c4-afd7-91116b6f4c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-67a38220-7bbb-453e-b970-44936c2d4fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930654762-172.17.0.11-1597683071868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-668eb4c4-a174-4c9c-84d7-65caa866ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-ab1b4413-055a-4eb8-8062-b32db8b57d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-f01dcf07-3503-438e-96c6-e44d35c3667f,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-297cfc85-13d9-42a2-97be-4a5332200e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-6031d605-5765-486b-8437-a28abcbec554,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-f2cf5181-b549-468a-aae5-888e391ee4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-5989dc18-2af8-46df-a8cd-67b224c4e178,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-e01773ed-48b7-42dc-9dee-5368ea84d32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930654762-172.17.0.11-1597683071868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-668eb4c4-a174-4c9c-84d7-65caa866ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-ab1b4413-055a-4eb8-8062-b32db8b57d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-f01dcf07-3503-438e-96c6-e44d35c3667f,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-297cfc85-13d9-42a2-97be-4a5332200e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-6031d605-5765-486b-8437-a28abcbec554,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-f2cf5181-b549-468a-aae5-888e391ee4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-5989dc18-2af8-46df-a8cd-67b224c4e178,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-e01773ed-48b7-42dc-9dee-5368ea84d32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146245217-172.17.0.11-1597683205319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-bc7a3bc1-14b3-4121-976a-7fc8b469f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5fdb8818-9b15-43c5-8732-2ba21575914a,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-00841a62-7a65-409d-88be-3da519037e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-5ee875a1-6e8c-4a29-b480-9fdf0eec0dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-41f45010-ea40-40d6-ac9e-df1b8e03f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-baf82837-974b-4aaf-a43b-b5a53e21df41,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-501dd1fb-de14-423e-8194-cc9b09bc19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-1aa95bf6-dedc-452a-bd3a-81542ab971c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146245217-172.17.0.11-1597683205319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-bc7a3bc1-14b3-4121-976a-7fc8b469f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5fdb8818-9b15-43c5-8732-2ba21575914a,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-00841a62-7a65-409d-88be-3da519037e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-5ee875a1-6e8c-4a29-b480-9fdf0eec0dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-41f45010-ea40-40d6-ac9e-df1b8e03f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-baf82837-974b-4aaf-a43b-b5a53e21df41,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-501dd1fb-de14-423e-8194-cc9b09bc19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-1aa95bf6-dedc-452a-bd3a-81542ab971c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845342312-172.17.0.11-1597683300597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-95b7bbf8-81ad-45b7-8b0c-14dfedd7e468,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-7c785c92-0357-4569-b5b5-eac44adb984d,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-35030933-3c8c-4e69-af9e-17af9c0972ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-505820cf-40cc-4762-b97f-706cd1078f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-5a98dcbe-f386-49cc-be36-a900777cd20f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-450d7276-d0b7-47f5-8d8d-e4736db9c8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-b8eee974-390c-49f0-921f-d41f2dc2e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c07dd268-863b-40c7-9241-b4413465530a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845342312-172.17.0.11-1597683300597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-95b7bbf8-81ad-45b7-8b0c-14dfedd7e468,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-7c785c92-0357-4569-b5b5-eac44adb984d,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-35030933-3c8c-4e69-af9e-17af9c0972ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-505820cf-40cc-4762-b97f-706cd1078f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-5a98dcbe-f386-49cc-be36-a900777cd20f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-450d7276-d0b7-47f5-8d8d-e4736db9c8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-b8eee974-390c-49f0-921f-d41f2dc2e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c07dd268-863b-40c7-9241-b4413465530a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172870846-172.17.0.11-1597683515136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-b9b3c6e5-2ec9-4f8c-a3d5-e4a46c644878,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5152e1fb-af51-43af-ae17-e4e8261865a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-3d076bb9-00c0-429e-ab29-17d7174f4f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-2fccfbce-af79-485d-8e9d-10b7722b3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-d1761ac1-ac1e-4577-ba70-f0c41b096fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-30375fb3-08bc-4388-a04c-94f77b64a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-15dfe70d-5fab-45fc-a0a6-62854d371aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-fba115e8-9d4d-403e-9825-b5e217ae704b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172870846-172.17.0.11-1597683515136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-b9b3c6e5-2ec9-4f8c-a3d5-e4a46c644878,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5152e1fb-af51-43af-ae17-e4e8261865a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-3d076bb9-00c0-429e-ab29-17d7174f4f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-2fccfbce-af79-485d-8e9d-10b7722b3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-d1761ac1-ac1e-4577-ba70-f0c41b096fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-30375fb3-08bc-4388-a04c-94f77b64a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-15dfe70d-5fab-45fc-a0a6-62854d371aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-fba115e8-9d4d-403e-9825-b5e217ae704b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084725230-172.17.0.11-1597683650527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-630bca74-eb34-40d8-b357-b9e4f56fd4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-0b9cf925-1f58-4c83-aaba-04e8a801da2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c7542365-fa3c-4a13-994f-9996c5346ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-830c7334-f776-42ce-b55a-c9b8ccd76043,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-2a280b93-f489-4a93-ad2a-cc070fba1414,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-20eb9149-dda8-42e3-80d4-8826c52427de,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-afbd983f-cd15-43b1-ae0b-37b1265f9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-c40a3c67-cb50-4dda-b642-c452b2ad7d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084725230-172.17.0.11-1597683650527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-630bca74-eb34-40d8-b357-b9e4f56fd4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-0b9cf925-1f58-4c83-aaba-04e8a801da2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c7542365-fa3c-4a13-994f-9996c5346ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-830c7334-f776-42ce-b55a-c9b8ccd76043,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-2a280b93-f489-4a93-ad2a-cc070fba1414,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-20eb9149-dda8-42e3-80d4-8826c52427de,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-afbd983f-cd15-43b1-ae0b-37b1265f9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-c40a3c67-cb50-4dda-b642-c452b2ad7d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119910988-172.17.0.11-1597683713228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-e99d9821-9e91-4644-a9a8-ede604a7f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-dfb6e3d0-68db-414a-942f-bcd1d46967e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-61cd73cd-741c-46d9-9431-76149201444b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-980f26cc-370d-4032-834a-5c889df646c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-7dfe1020-bfd8-4b40-a4db-efac87bf947e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3d0e19be-ede7-4221-85da-843687da4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-443e53f2-32b9-4c0d-8fc1-2218150e5b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7d3d01fd-3a43-40f4-82d9-08eb0a056b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119910988-172.17.0.11-1597683713228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-e99d9821-9e91-4644-a9a8-ede604a7f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-dfb6e3d0-68db-414a-942f-bcd1d46967e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-61cd73cd-741c-46d9-9431-76149201444b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-980f26cc-370d-4032-834a-5c889df646c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-7dfe1020-bfd8-4b40-a4db-efac87bf947e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3d0e19be-ede7-4221-85da-843687da4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-443e53f2-32b9-4c0d-8fc1-2218150e5b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7d3d01fd-3a43-40f4-82d9-08eb0a056b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569792150-172.17.0.11-1597683750148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-91808f52-8233-4c56-baf2-35a912a2348d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-9178adba-3699-4436-be9c-d787bc953076,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-a374f1a5-7f93-435e-9881-6ce968accd66,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e8a8e3bb-f18d-4d56-9fae-cb8e6d9cee18,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ed898199-bce8-4eb2-973d-acbc06d9d465,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3a578dcd-84a9-45e6-b8ab-2e059e30593d,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-88cf4934-74a6-4308-bafc-4d5b844ecb33,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-19cf06a2-3524-4ecf-a09d-ff715d669530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569792150-172.17.0.11-1597683750148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-91808f52-8233-4c56-baf2-35a912a2348d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-9178adba-3699-4436-be9c-d787bc953076,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-a374f1a5-7f93-435e-9881-6ce968accd66,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e8a8e3bb-f18d-4d56-9fae-cb8e6d9cee18,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ed898199-bce8-4eb2-973d-acbc06d9d465,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3a578dcd-84a9-45e6-b8ab-2e059e30593d,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-88cf4934-74a6-4308-bafc-4d5b844ecb33,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-19cf06a2-3524-4ecf-a09d-ff715d669530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954952908-172.17.0.11-1597683855624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34508,DS-2d272a03-e0fe-4ed4-9f9e-aafaaf36402e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-cd4b1a26-aee9-4f3c-871c-bd43785f912a,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-aba52aaf-c40d-47a5-acd7-70e3399d4a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-ebb4a6a0-97d5-4581-8be0-4d7e5d969691,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-482fa3c9-223f-4269-a67c-c9fbb499b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-1d650bc5-3390-4dfd-8f11-6d4456c79620,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-e6868841-d844-4f68-9e6f-1b21280300ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a79d0e0e-3acd-4af3-8b3a-40834d7be02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954952908-172.17.0.11-1597683855624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34508,DS-2d272a03-e0fe-4ed4-9f9e-aafaaf36402e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-cd4b1a26-aee9-4f3c-871c-bd43785f912a,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-aba52aaf-c40d-47a5-acd7-70e3399d4a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-ebb4a6a0-97d5-4581-8be0-4d7e5d969691,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-482fa3c9-223f-4269-a67c-c9fbb499b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-1d650bc5-3390-4dfd-8f11-6d4456c79620,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-e6868841-d844-4f68-9e6f-1b21280300ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a79d0e0e-3acd-4af3-8b3a-40834d7be02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440115920-172.17.0.11-1597683954729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-c478c8e0-8a5d-49ec-92a0-83b3f3be6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-2144faf5-2dbc-4863-bf3d-19a57fccd740,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-409ed1f9-ed3e-4767-bd7a-5a50763960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-cd7ca8d3-4e72-4cf8-931f-7dbedba74f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-6c6cf2dc-05f8-4c92-ad5f-9f4d93109225,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-5f2206f7-ed4d-46d7-8e3d-f24e12aab2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-46dd9096-3734-43b3-ab0b-13ceaac77e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-bd405e42-5cff-44cc-be38-f1893e12d244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440115920-172.17.0.11-1597683954729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-c478c8e0-8a5d-49ec-92a0-83b3f3be6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-2144faf5-2dbc-4863-bf3d-19a57fccd740,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-409ed1f9-ed3e-4767-bd7a-5a50763960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-cd7ca8d3-4e72-4cf8-931f-7dbedba74f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-6c6cf2dc-05f8-4c92-ad5f-9f4d93109225,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-5f2206f7-ed4d-46d7-8e3d-f24e12aab2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-46dd9096-3734-43b3-ab0b-13ceaac77e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-bd405e42-5cff-44cc-be38-f1893e12d244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017586468-172.17.0.11-1597685246277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-f980ebd4-db42-4569-9b92-d77063105b07,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-639cb6a0-934b-4e79-9815-0d00c92160f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-013623cb-c2c8-4654-a46e-36192c6696c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-cd1475d9-d588-4e0d-828e-9ac174872ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-23a53d3d-d50f-4993-af62-f358253459d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-313e2e69-7cbe-46a3-8564-991d81f35739,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-f0d6b518-8029-407a-a9a5-00234d2674a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-f8714ab2-3d1f-4954-b76e-1f2d149d79d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017586468-172.17.0.11-1597685246277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-f980ebd4-db42-4569-9b92-d77063105b07,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-639cb6a0-934b-4e79-9815-0d00c92160f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-013623cb-c2c8-4654-a46e-36192c6696c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-cd1475d9-d588-4e0d-828e-9ac174872ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-23a53d3d-d50f-4993-af62-f358253459d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-313e2e69-7cbe-46a3-8564-991d81f35739,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-f0d6b518-8029-407a-a9a5-00234d2674a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-f8714ab2-3d1f-4954-b76e-1f2d149d79d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197295372-172.17.0.11-1597685814663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-626ab86a-032c-409b-824c-de07ea0d591a,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-c53ba7d5-ad88-4a92-8ada-f97a338fbec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-54ed71ee-55ef-4b4d-be33-8d204f029e81,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-bd02e80b-4c2c-4ccb-90b9-afa85616a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-50be3659-b756-4ba0-ae77-d9c0479c3150,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-1ae0f045-a32b-41f3-b5b5-cc0689486fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-c92baee7-fd89-44d9-ad30-9d1808a13b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-3ab222e7-9792-4b48-87e0-1a14a58307e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197295372-172.17.0.11-1597685814663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-626ab86a-032c-409b-824c-de07ea0d591a,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-c53ba7d5-ad88-4a92-8ada-f97a338fbec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-54ed71ee-55ef-4b4d-be33-8d204f029e81,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-bd02e80b-4c2c-4ccb-90b9-afa85616a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-50be3659-b756-4ba0-ae77-d9c0479c3150,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-1ae0f045-a32b-41f3-b5b5-cc0689486fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-c92baee7-fd89-44d9-ad30-9d1808a13b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-3ab222e7-9792-4b48-87e0-1a14a58307e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902741670-172.17.0.11-1597686281149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-138d3445-e963-4a69-8e1e-f0bd565c945a,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-9edf3992-cd65-409a-bce9-f16e2b24ddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b167a903-de53-4f48-88b4-7625d83a2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-9e758321-932c-4705-ba2f-64d0e1613a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-ff4bb5fc-b93f-40a4-8483-255ca92cca16,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-5e1821b9-e228-41f6-9372-fed5066faa19,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-12ffe9cb-07bf-44a0-8812-5ec64a492dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-cd45513f-fd31-4263-b1fb-c2ea7927b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902741670-172.17.0.11-1597686281149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-138d3445-e963-4a69-8e1e-f0bd565c945a,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-9edf3992-cd65-409a-bce9-f16e2b24ddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b167a903-de53-4f48-88b4-7625d83a2c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-9e758321-932c-4705-ba2f-64d0e1613a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-ff4bb5fc-b93f-40a4-8483-255ca92cca16,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-5e1821b9-e228-41f6-9372-fed5066faa19,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-12ffe9cb-07bf-44a0-8812-5ec64a492dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-cd45513f-fd31-4263-b1fb-c2ea7927b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493115444-172.17.0.11-1597686358321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-97a4ea53-c55d-4fdd-9df3-fa36acf2daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-ef2c339e-c778-4575-932d-fa859d846014,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-4b4b0b3e-b63e-43eb-bc34-8e0c7cf4d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-ae19154a-a468-4a14-a4cb-3e1743ddb4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-80abaeca-2497-418a-97cf-e1bcfed30562,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-860e2311-0d65-40f2-91de-d3cf4fed58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-c8cd2034-cff4-4144-af38-56dea13b73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-26dffbf6-ec86-4c62-a3bd-8de0adf1f668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493115444-172.17.0.11-1597686358321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-97a4ea53-c55d-4fdd-9df3-fa36acf2daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-ef2c339e-c778-4575-932d-fa859d846014,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-4b4b0b3e-b63e-43eb-bc34-8e0c7cf4d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-ae19154a-a468-4a14-a4cb-3e1743ddb4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-80abaeca-2497-418a-97cf-e1bcfed30562,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-860e2311-0d65-40f2-91de-d3cf4fed58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-c8cd2034-cff4-4144-af38-56dea13b73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-26dffbf6-ec86-4c62-a3bd-8de0adf1f668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202822914-172.17.0.11-1597686429086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-af246cd8-4940-427c-968b-fa234c40a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-573a120f-fb0a-4225-96e2-6b4285c6b5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-01371ef9-caf8-4a47-94f8-d7e9d4571470,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b15587e1-2312-4fa1-aea3-7e6aa218f972,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-5cd0c84e-6710-42b9-a3f0-e828237def62,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-56da4066-6b93-4d0d-9f54-318eb3677db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-c0a365e4-2637-4877-b299-2bcd148df7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-818ecab7-9902-4b75-8139-fde629fb236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202822914-172.17.0.11-1597686429086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-af246cd8-4940-427c-968b-fa234c40a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-573a120f-fb0a-4225-96e2-6b4285c6b5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-01371ef9-caf8-4a47-94f8-d7e9d4571470,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b15587e1-2312-4fa1-aea3-7e6aa218f972,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-5cd0c84e-6710-42b9-a3f0-e828237def62,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-56da4066-6b93-4d0d-9f54-318eb3677db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-c0a365e4-2637-4877-b299-2bcd148df7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-818ecab7-9902-4b75-8139-fde629fb236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817992908-172.17.0.11-1597686941972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-e097bdd9-9999-453b-bcd2-53e4b96132b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-cfc65022-0ce9-4f8f-89be-2db211615e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-225339d8-5c48-4d48-b032-167a949c4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-f4589dfc-d1cc-4317-bbd9-ffbcfd755b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-45d6fe3b-cb7b-4be3-8159-376b774a0e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-565d13f7-9d91-4406-a3e6-6f5b10af8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-8fd7d61b-76c1-450c-897d-eedd6b755eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5184b6eb-4258-4c9b-91e4-0d09a824df59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817992908-172.17.0.11-1597686941972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-e097bdd9-9999-453b-bcd2-53e4b96132b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-cfc65022-0ce9-4f8f-89be-2db211615e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-225339d8-5c48-4d48-b032-167a949c4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-f4589dfc-d1cc-4317-bbd9-ffbcfd755b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-45d6fe3b-cb7b-4be3-8159-376b774a0e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-565d13f7-9d91-4406-a3e6-6f5b10af8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-8fd7d61b-76c1-450c-897d-eedd6b755eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5184b6eb-4258-4c9b-91e4-0d09a824df59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871501669-172.17.0.11-1597687425524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-045d3523-33ef-445b-9ae0-d34ae2e45b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-e0ec8ae1-3147-4974-99a9-20c12657f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ad417657-a6a8-4abe-94ca-3e08c979e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-4ec98bed-19f1-4444-87fa-6d2c053ab9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-b4d0b5a6-d28f-4e69-8dc4-3c757e4a6262,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-cabfea86-c204-4f96-b3bc-b56eba94e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-44e04bd3-446a-4e9b-a5b9-39e98aa299ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-d18f89d0-ded7-4154-b618-046afaa271e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871501669-172.17.0.11-1597687425524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-045d3523-33ef-445b-9ae0-d34ae2e45b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-e0ec8ae1-3147-4974-99a9-20c12657f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ad417657-a6a8-4abe-94ca-3e08c979e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-4ec98bed-19f1-4444-87fa-6d2c053ab9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-b4d0b5a6-d28f-4e69-8dc4-3c757e4a6262,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-cabfea86-c204-4f96-b3bc-b56eba94e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-44e04bd3-446a-4e9b-a5b9-39e98aa299ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-d18f89d0-ded7-4154-b618-046afaa271e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5266
