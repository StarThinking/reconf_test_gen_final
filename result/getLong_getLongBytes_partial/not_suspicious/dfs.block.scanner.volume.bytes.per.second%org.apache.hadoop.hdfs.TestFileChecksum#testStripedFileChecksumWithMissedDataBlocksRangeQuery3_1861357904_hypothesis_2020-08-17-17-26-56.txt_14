reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884213526-172.17.0.7-1597685435106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-7084de69-f8b2-4516-a0db-bd397166a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-2315cbea-e323-4083-aea9-8c22ecbae0af,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-9ee94e4e-4019-47eb-b8f4-2249f4a2df57,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-a989d915-3f1f-41a7-95b3-e9787b44797a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-f6c4978e-031b-4b0a-9d5b-2e36dd0f01c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-f38082a3-6d0c-486c-9d47-d4c9a0090760,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-d789a930-c630-4c1a-bb01-e074ed26fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-ff6cfcb1-08b0-43f2-a5cc-8a5899de3ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884213526-172.17.0.7-1597685435106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-7084de69-f8b2-4516-a0db-bd397166a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-2315cbea-e323-4083-aea9-8c22ecbae0af,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-9ee94e4e-4019-47eb-b8f4-2249f4a2df57,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-a989d915-3f1f-41a7-95b3-e9787b44797a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-f6c4978e-031b-4b0a-9d5b-2e36dd0f01c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-f38082a3-6d0c-486c-9d47-d4c9a0090760,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-d789a930-c630-4c1a-bb01-e074ed26fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-ff6cfcb1-08b0-43f2-a5cc-8a5899de3ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542293557-172.17.0.7-1597685548754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-c7bc76e1-269c-4ddf-8002-c76d2e1fb32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-9358a45c-3b6c-4b5b-82f2-4f71b6421a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5a1530a7-7238-4a72-b72b-a2a5944cb111,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-f02496ed-f927-4651-b2d5-6fd1be21f033,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-43de8b62-1c84-4e26-b399-65112e495b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-7d0e5567-f947-484c-afec-7ea7f6c3845b,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-9431980a-bf9c-490a-9d4a-dd882fc37a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-24f0c624-f75a-47ba-b964-7232fa70bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542293557-172.17.0.7-1597685548754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-c7bc76e1-269c-4ddf-8002-c76d2e1fb32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-9358a45c-3b6c-4b5b-82f2-4f71b6421a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5a1530a7-7238-4a72-b72b-a2a5944cb111,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-f02496ed-f927-4651-b2d5-6fd1be21f033,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-43de8b62-1c84-4e26-b399-65112e495b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-7d0e5567-f947-484c-afec-7ea7f6c3845b,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-9431980a-bf9c-490a-9d4a-dd882fc37a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-24f0c624-f75a-47ba-b964-7232fa70bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594114325-172.17.0.7-1597685817610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44582,DS-3fce9a3d-dcfb-401a-a1cf-7d8c2e71b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-9ffc9bec-3779-4a2c-943c-7e5b07699f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-d12c95c5-f3c8-4487-ac5b-11b16025d115,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-41ec988c-48d7-4161-ab98-1d9f03d083ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-d4f28bf5-99f4-4ead-8b65-68a52d765dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-4d338954-4ad1-40c4-b981-6e10acf1cc63,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-6f057c61-5822-4177-b8ee-15d5953fbdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-0f2f6d0b-6c3b-4c77-b22e-fa26ac057719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594114325-172.17.0.7-1597685817610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44582,DS-3fce9a3d-dcfb-401a-a1cf-7d8c2e71b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-9ffc9bec-3779-4a2c-943c-7e5b07699f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-d12c95c5-f3c8-4487-ac5b-11b16025d115,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-41ec988c-48d7-4161-ab98-1d9f03d083ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-d4f28bf5-99f4-4ead-8b65-68a52d765dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-4d338954-4ad1-40c4-b981-6e10acf1cc63,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-6f057c61-5822-4177-b8ee-15d5953fbdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-0f2f6d0b-6c3b-4c77-b22e-fa26ac057719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084998875-172.17.0.7-1597685963184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-8b8b1565-f5d0-4e2c-8904-7c3f29745aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-1bd50e70-aefa-4a38-b88f-a50a565057e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a8717c40-2762-4a27-92a6-e9879f34e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-8268ee6b-bbe2-43a6-b882-cfcf03a2df19,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-7664be76-ddc0-4769-98ff-d24190b52d57,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-b7a44778-0787-4154-a504-4435b29820b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-6c978dfa-5e7c-496b-8a6a-f7fabf3b2f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a95de1fe-aaa8-4dfa-8086-4aa6871e94a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084998875-172.17.0.7-1597685963184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-8b8b1565-f5d0-4e2c-8904-7c3f29745aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-1bd50e70-aefa-4a38-b88f-a50a565057e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a8717c40-2762-4a27-92a6-e9879f34e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-8268ee6b-bbe2-43a6-b882-cfcf03a2df19,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-7664be76-ddc0-4769-98ff-d24190b52d57,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-b7a44778-0787-4154-a504-4435b29820b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-6c978dfa-5e7c-496b-8a6a-f7fabf3b2f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a95de1fe-aaa8-4dfa-8086-4aa6871e94a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708185961-172.17.0.7-1597686121201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-cef9510e-8498-4ada-a2c6-052ebde15385,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-ccac44f1-758d-4f80-b1e1-c13f8a29c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-9fb893f9-2cdb-4f6f-a873-6dfc399dccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-a4605a63-84ca-4e45-af4a-380c48a52393,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-9cc7611f-05b8-4581-be9e-15f556bd09f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-237313c3-6629-401d-a99d-6f6ab47b7b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-0489f436-e8d6-4fdb-ada2-0cc5a02b1d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-6b7ace9b-ae24-423f-956f-f1cf8045b120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708185961-172.17.0.7-1597686121201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-cef9510e-8498-4ada-a2c6-052ebde15385,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-ccac44f1-758d-4f80-b1e1-c13f8a29c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-9fb893f9-2cdb-4f6f-a873-6dfc399dccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-a4605a63-84ca-4e45-af4a-380c48a52393,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-9cc7611f-05b8-4581-be9e-15f556bd09f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-237313c3-6629-401d-a99d-6f6ab47b7b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-0489f436-e8d6-4fdb-ada2-0cc5a02b1d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-6b7ace9b-ae24-423f-956f-f1cf8045b120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855014119-172.17.0.7-1597687145767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-e5a459fc-7c2f-4ec1-829c-e6a2841353ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-4b149cb5-a536-4b4b-a167-eb46ac8e9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2230bb2c-b60f-47d1-b120-5926cf6d8194,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-a276db46-0cab-495f-aba2-a5ccfb2840d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-e4bb3f8c-2efd-45b0-9370-33d2e0500503,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-bc2b88af-ab05-414e-b7df-e0517525847c,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-dd3be523-c92c-4854-8b18-eb53cef866c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-ca4008d1-b730-4eb1-a492-23b9685d1abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855014119-172.17.0.7-1597687145767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-e5a459fc-7c2f-4ec1-829c-e6a2841353ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-4b149cb5-a536-4b4b-a167-eb46ac8e9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2230bb2c-b60f-47d1-b120-5926cf6d8194,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-a276db46-0cab-495f-aba2-a5ccfb2840d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-e4bb3f8c-2efd-45b0-9370-33d2e0500503,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-bc2b88af-ab05-414e-b7df-e0517525847c,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-dd3be523-c92c-4854-8b18-eb53cef866c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-ca4008d1-b730-4eb1-a492-23b9685d1abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102095801-172.17.0.7-1597687314419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-f781b7b3-136a-419b-a196-4bd8d53c8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2459bc5a-73f9-43da-b4b2-afecbb9c411f,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-7cf3fdae-7852-4ff2-b843-4b5d3a767717,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-1c98c38c-aa14-4ed8-a3da-eb852e6b2f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-270c1976-c104-459d-8d2a-a5c94016c064,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-72560717-9552-4e3c-9228-256cd60c8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-8a64f625-c049-4361-94dd-7da100a81966,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-2068fbee-fe6a-42ae-a97e-814706090ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102095801-172.17.0.7-1597687314419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-f781b7b3-136a-419b-a196-4bd8d53c8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2459bc5a-73f9-43da-b4b2-afecbb9c411f,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-7cf3fdae-7852-4ff2-b843-4b5d3a767717,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-1c98c38c-aa14-4ed8-a3da-eb852e6b2f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-270c1976-c104-459d-8d2a-a5c94016c064,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-72560717-9552-4e3c-9228-256cd60c8d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-8a64f625-c049-4361-94dd-7da100a81966,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-2068fbee-fe6a-42ae-a97e-814706090ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578945945-172.17.0.7-1597687549580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-b635e917-59ad-4477-8258-28d0accf1d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-b2542479-6ca0-47c3-8f0e-328e1cb72f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-6726928a-4d08-4208-bca3-06094d524f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a4d82245-60c0-4a51-a522-9b50583fe282,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-896e34f3-0a86-48a1-80a3-8e28f8eef278,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-1eb2bbed-e36c-4b80-a9a5-44633fd33fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-402fbe1a-866e-471e-8747-27d16ae4d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-22ca6461-3595-4ce6-9142-206c11bff101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578945945-172.17.0.7-1597687549580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-b635e917-59ad-4477-8258-28d0accf1d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-b2542479-6ca0-47c3-8f0e-328e1cb72f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-6726928a-4d08-4208-bca3-06094d524f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a4d82245-60c0-4a51-a522-9b50583fe282,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-896e34f3-0a86-48a1-80a3-8e28f8eef278,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-1eb2bbed-e36c-4b80-a9a5-44633fd33fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-402fbe1a-866e-471e-8747-27d16ae4d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-22ca6461-3595-4ce6-9142-206c11bff101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548990718-172.17.0.7-1597687631028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-b48fca05-f068-4359-80fe-47363adc2e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-0c0c8683-87b3-419d-a8d7-ed51e90ce595,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8edcfb16-0639-4fdb-9ee6-68cd7fb70815,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9d9e709e-bdd3-4ae9-9ebd-cd4c8f14809b,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0e01296f-083d-407c-8e39-5e2ed6bc602c,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-56c22b81-4212-4f8b-96a6-315c2b60d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-9bd7d826-8f9e-43b0-94d4-7ab6d4ddb3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-8e25a581-13bb-42fc-8409-cca9f62fc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548990718-172.17.0.7-1597687631028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-b48fca05-f068-4359-80fe-47363adc2e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-0c0c8683-87b3-419d-a8d7-ed51e90ce595,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8edcfb16-0639-4fdb-9ee6-68cd7fb70815,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9d9e709e-bdd3-4ae9-9ebd-cd4c8f14809b,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0e01296f-083d-407c-8e39-5e2ed6bc602c,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-56c22b81-4212-4f8b-96a6-315c2b60d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-9bd7d826-8f9e-43b0-94d4-7ab6d4ddb3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-8e25a581-13bb-42fc-8409-cca9f62fc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640122074-172.17.0.7-1597687962604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-99caa2a6-bfd0-494d-a119-684410291942,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-6628fb2e-fcb9-4522-afa6-fa666f203889,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-1e424a9f-0d7e-40b1-8b8a-068c2369e701,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-f5b5073a-b20f-451c-915f-911f0e59fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-84c6563d-fe61-464c-a90f-11507253f26f,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-491fc5f2-fd6a-401c-85cc-71643399eada,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-ebbd88a4-9855-47e8-a9b8-a815ae25e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-85b92dd4-f052-4781-9912-1fc2e73549b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640122074-172.17.0.7-1597687962604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-99caa2a6-bfd0-494d-a119-684410291942,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-6628fb2e-fcb9-4522-afa6-fa666f203889,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-1e424a9f-0d7e-40b1-8b8a-068c2369e701,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-f5b5073a-b20f-451c-915f-911f0e59fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-84c6563d-fe61-464c-a90f-11507253f26f,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-491fc5f2-fd6a-401c-85cc-71643399eada,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-ebbd88a4-9855-47e8-a9b8-a815ae25e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-85b92dd4-f052-4781-9912-1fc2e73549b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852494254-172.17.0.7-1597688589131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-72259fa6-16d6-4ae9-a8d9-4072c83e2ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-40b0b1e6-5e5d-4eeb-8bfe-9e55f66095e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-310db260-bc30-4daf-8fcf-0e028f5004fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-2fb8a25e-10da-4e30-a8ce-87456c607908,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-b8466c78-1493-4011-bc63-6cc79a5e9b18,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-8f876e54-aba7-4b75-bac7-cb922ed91ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-16e01344-e714-4ffb-87ab-eb8e7296faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-fdc9dfa3-1fc9-4bcc-9f22-d864c5f04500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852494254-172.17.0.7-1597688589131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-72259fa6-16d6-4ae9-a8d9-4072c83e2ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-40b0b1e6-5e5d-4eeb-8bfe-9e55f66095e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-310db260-bc30-4daf-8fcf-0e028f5004fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-2fb8a25e-10da-4e30-a8ce-87456c607908,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-b8466c78-1493-4011-bc63-6cc79a5e9b18,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-8f876e54-aba7-4b75-bac7-cb922ed91ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-16e01344-e714-4ffb-87ab-eb8e7296faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-fdc9dfa3-1fc9-4bcc-9f22-d864c5f04500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366777008-172.17.0.7-1597688631037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-6b1d3f0e-751b-4732-b0b1-c609a2b817a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-3ea2cd61-5c7a-45cf-873e-0b70dff179a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d8247b7b-89b5-48a2-b933-081bfdf46556,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ea3a304b-a5f6-40c3-8943-0db731c0d58d,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-36f796c2-5765-4a50-968d-b62633606516,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-bce43096-6dd3-49f1-9a02-f6335c09369a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-3a350a91-befe-41b7-9d80-38ccc5df1037,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-b9eebfa9-7146-4766-955b-087056190a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366777008-172.17.0.7-1597688631037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-6b1d3f0e-751b-4732-b0b1-c609a2b817a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-3ea2cd61-5c7a-45cf-873e-0b70dff179a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d8247b7b-89b5-48a2-b933-081bfdf46556,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ea3a304b-a5f6-40c3-8943-0db731c0d58d,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-36f796c2-5765-4a50-968d-b62633606516,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-bce43096-6dd3-49f1-9a02-f6335c09369a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-3a350a91-befe-41b7-9d80-38ccc5df1037,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-b9eebfa9-7146-4766-955b-087056190a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528637280-172.17.0.7-1597688787488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-c1e239b5-50ba-471f-abf2-dc03d3d6aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-79670050-ae14-4dc7-a37e-fee2ef9b894b,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7a0eded0-7234-4c29-899b-cddfd7f4b232,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-869b292c-6846-4447-a253-d277234add91,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-bbaffc9b-d05f-4f56-85ec-5ae68cdff253,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-091b0895-d5f2-4358-a838-8d52e0c406c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-39e96c36-b67b-47c2-8df9-deb8ff12080d,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-3b265f74-83fa-475e-b921-ac7d0f0f7019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528637280-172.17.0.7-1597688787488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-c1e239b5-50ba-471f-abf2-dc03d3d6aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-79670050-ae14-4dc7-a37e-fee2ef9b894b,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7a0eded0-7234-4c29-899b-cddfd7f4b232,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-869b292c-6846-4447-a253-d277234add91,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-bbaffc9b-d05f-4f56-85ec-5ae68cdff253,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-091b0895-d5f2-4358-a838-8d52e0c406c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-39e96c36-b67b-47c2-8df9-deb8ff12080d,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-3b265f74-83fa-475e-b921-ac7d0f0f7019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183446007-172.17.0.7-1597688823393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-3672b617-d953-442e-afb1-1be057ecb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-a9104155-ea2a-46e7-a0f1-5caa385c4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-935658d5-1807-45e0-90a9-2605e53869ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-694216c4-aa6b-44d3-b9f3-b752cd40738d,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-02755f99-5f0f-463d-bd22-3a4b46677cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6388940d-b8d2-433f-9774-36f23e19324d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-be9a25a9-0ff6-4e34-8f71-2513125cc6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-2918c20f-5e17-4429-aef4-1fa6241f2ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183446007-172.17.0.7-1597688823393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-3672b617-d953-442e-afb1-1be057ecb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-a9104155-ea2a-46e7-a0f1-5caa385c4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-935658d5-1807-45e0-90a9-2605e53869ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-694216c4-aa6b-44d3-b9f3-b752cd40738d,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-02755f99-5f0f-463d-bd22-3a4b46677cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6388940d-b8d2-433f-9774-36f23e19324d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-be9a25a9-0ff6-4e34-8f71-2513125cc6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-2918c20f-5e17-4429-aef4-1fa6241f2ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150006331-172.17.0.7-1597689010013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-accc1cd4-3269-4ae1-a4e7-3eadb2aeac48,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-2dc9b373-62db-4683-b631-618059cebee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-0d2c366c-feeb-4bd4-a38f-ec612be98f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-f2a5cbb7-6ed5-40f8-adeb-5ea76441b7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-5709fab1-faa2-4ab4-b881-c60b7ec9c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-f806f6d3-ac22-4103-97ed-af932462b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-119e9bf9-ef4e-4e65-b133-0752778a9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-1440c8d0-698d-4540-b5a8-97ab8d6f8a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150006331-172.17.0.7-1597689010013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-accc1cd4-3269-4ae1-a4e7-3eadb2aeac48,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-2dc9b373-62db-4683-b631-618059cebee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-0d2c366c-feeb-4bd4-a38f-ec612be98f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-f2a5cbb7-6ed5-40f8-adeb-5ea76441b7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-5709fab1-faa2-4ab4-b881-c60b7ec9c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-f806f6d3-ac22-4103-97ed-af932462b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-119e9bf9-ef4e-4e65-b133-0752778a9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-1440c8d0-698d-4540-b5a8-97ab8d6f8a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778065438-172.17.0.7-1597689209856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38083,DS-aae36da2-30d4-4967-a771-4801759947a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-9db262f4-78ce-49ec-bfd1-d9daf7ee32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-4b2bfc88-86d2-4d12-9d0c-9cfc75de523b,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-6e5b66f6-3439-4632-bba5-3374b46b75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-edd48f86-1b43-4ba6-856f-b1b72f109b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-05af97ff-830b-4479-b219-aad8636da427,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-2bea3795-78d5-49ef-93b4-dfb29a9c4836,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-3d12a995-e91b-43a3-866f-7b7382e4ea99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778065438-172.17.0.7-1597689209856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38083,DS-aae36da2-30d4-4967-a771-4801759947a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-9db262f4-78ce-49ec-bfd1-d9daf7ee32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-4b2bfc88-86d2-4d12-9d0c-9cfc75de523b,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-6e5b66f6-3439-4632-bba5-3374b46b75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-edd48f86-1b43-4ba6-856f-b1b72f109b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-05af97ff-830b-4479-b219-aad8636da427,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-2bea3795-78d5-49ef-93b4-dfb29a9c4836,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-3d12a995-e91b-43a3-866f-7b7382e4ea99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660439396-172.17.0.7-1597689579428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-f13910dd-916d-4b29-b82e-fa70a68bcc64,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-b1dc0f2d-03c5-45c8-b405-0f0663531d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-fd723dc2-64d6-429b-b520-31b1b52da553,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-441d0895-6d3f-4ee2-9b52-902631f4e23a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-70ed648e-d427-4016-be79-2dc77a4a8e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-3897efde-bb57-4a67-99b7-c5f1fbb8cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-38a4a4b9-4873-419a-8f6c-f8f2a02c9932,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-6e43858d-0f2f-48e4-bc9b-f2c4869116df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660439396-172.17.0.7-1597689579428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-f13910dd-916d-4b29-b82e-fa70a68bcc64,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-b1dc0f2d-03c5-45c8-b405-0f0663531d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-fd723dc2-64d6-429b-b520-31b1b52da553,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-441d0895-6d3f-4ee2-9b52-902631f4e23a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-70ed648e-d427-4016-be79-2dc77a4a8e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-3897efde-bb57-4a67-99b7-c5f1fbb8cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-38a4a4b9-4873-419a-8f6c-f8f2a02c9932,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-6e43858d-0f2f-48e4-bc9b-f2c4869116df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544948801-172.17.0.7-1597689660365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-9cf6ec24-1fa3-4de9-9aac-9973ed9252ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d15e9d39-7fd0-4eb2-b4da-fda065ccd36e,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-680d318a-729b-48b4-bce6-bdd4ae3b9153,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f1d72227-a675-467b-aa52-6d6adf0e0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-348d5a45-ed49-4ec4-92bb-6ac78b3f746e,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-7fa53365-b477-4f73-ae4a-872dcefa0f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-b4ac2672-1886-4aab-98d9-2a6f0ac3b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-13c1572f-8de7-4ffb-baa1-ad203f1a9956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544948801-172.17.0.7-1597689660365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-9cf6ec24-1fa3-4de9-9aac-9973ed9252ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d15e9d39-7fd0-4eb2-b4da-fda065ccd36e,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-680d318a-729b-48b4-bce6-bdd4ae3b9153,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f1d72227-a675-467b-aa52-6d6adf0e0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-348d5a45-ed49-4ec4-92bb-6ac78b3f746e,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-7fa53365-b477-4f73-ae4a-872dcefa0f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-b4ac2672-1886-4aab-98d9-2a6f0ac3b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-13c1572f-8de7-4ffb-baa1-ad203f1a9956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310133648-172.17.0.7-1597689803583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34833,DS-7050e818-a9b3-4997-82f8-28e6ea2b1ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-052856f2-ff0b-4d4f-b2c3-f07e91af1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-0b0295c6-0b7c-40bc-8532-755e24d0686f,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-6940e5d7-4125-426d-92d2-14bbb48cbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-b07c425a-66e2-4aa0-b190-9aa9f22ab45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-189360e5-39fa-4e52-b37e-2dc84f45b149,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-8a6eb00e-c7b3-4e1c-9edb-53e125da2227,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-832d21d8-8686-40ef-ae42-68659cbcb0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310133648-172.17.0.7-1597689803583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34833,DS-7050e818-a9b3-4997-82f8-28e6ea2b1ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-052856f2-ff0b-4d4f-b2c3-f07e91af1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-0b0295c6-0b7c-40bc-8532-755e24d0686f,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-6940e5d7-4125-426d-92d2-14bbb48cbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-b07c425a-66e2-4aa0-b190-9aa9f22ab45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-189360e5-39fa-4e52-b37e-2dc84f45b149,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-8a6eb00e-c7b3-4e1c-9edb-53e125da2227,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-832d21d8-8686-40ef-ae42-68659cbcb0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612946493-172.17.0.7-1597689845988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-11ad2f94-4096-4bb0-ab25-59c7590d94da,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5bb973e7-654f-4981-b529-40b6e2283ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-f32f7a74-cf20-44f8-b80e-c3adab4018b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d9fc3fa6-335a-4ff5-99e9-b7b4d34edfec,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-b626c436-4db2-4770-841f-9ccfcc4e619b,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-23f7868c-475e-4487-959c-af4cf0d0f21b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a5e61656-85b5-4627-90b6-71c5521bf188,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-f96210ee-e198-40b4-85bc-ed8ac57055be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612946493-172.17.0.7-1597689845988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-11ad2f94-4096-4bb0-ab25-59c7590d94da,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5bb973e7-654f-4981-b529-40b6e2283ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-f32f7a74-cf20-44f8-b80e-c3adab4018b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d9fc3fa6-335a-4ff5-99e9-b7b4d34edfec,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-b626c436-4db2-4770-841f-9ccfcc4e619b,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-23f7868c-475e-4487-959c-af4cf0d0f21b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a5e61656-85b5-4627-90b6-71c5521bf188,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-f96210ee-e198-40b4-85bc-ed8ac57055be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252044458-172.17.0.7-1597690194720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-e68ba718-4e74-4b54-bf61-fadacbd988bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-304babdc-c87e-498c-8584-fbb67fcb8503,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-048e6048-ca78-4247-90b0-b90582e0138c,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-9f879325-7a38-48a1-8315-01702f297913,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-d5ca5653-dea0-407b-ba46-93f7f51264c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-330b9ab4-6f79-4560-8bf5-5ed967857076,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c8746086-d1a6-4e7f-81ac-701f2ba51dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-1780557a-a6a8-483a-84d3-85efdee20cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252044458-172.17.0.7-1597690194720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-e68ba718-4e74-4b54-bf61-fadacbd988bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-304babdc-c87e-498c-8584-fbb67fcb8503,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-048e6048-ca78-4247-90b0-b90582e0138c,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-9f879325-7a38-48a1-8315-01702f297913,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-d5ca5653-dea0-407b-ba46-93f7f51264c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-330b9ab4-6f79-4560-8bf5-5ed967857076,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c8746086-d1a6-4e7f-81ac-701f2ba51dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-1780557a-a6a8-483a-84d3-85efdee20cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38577002-172.17.0.7-1597690753373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-87bee2ba-ec0c-4c3c-949d-1fb9336529c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-d1f010a1-5c39-4ea3-8962-8d716dee2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c19208d5-5cd7-4188-8a47-ef8de5c7e075,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-5826756a-4483-43c8-9549-90b983d8b151,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-51241703-8f98-44c2-8275-1e3e0590ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-787e957a-c708-4cc8-ad1d-c60ee05576d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-34612874-4c20-4741-bb57-0be268ac2b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-b2ad2e2a-e4b5-41cd-9593-e8b04f035bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38577002-172.17.0.7-1597690753373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-87bee2ba-ec0c-4c3c-949d-1fb9336529c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-d1f010a1-5c39-4ea3-8962-8d716dee2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c19208d5-5cd7-4188-8a47-ef8de5c7e075,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-5826756a-4483-43c8-9549-90b983d8b151,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-51241703-8f98-44c2-8275-1e3e0590ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-787e957a-c708-4cc8-ad1d-c60ee05576d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-34612874-4c20-4741-bb57-0be268ac2b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-b2ad2e2a-e4b5-41cd-9593-e8b04f035bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058641966-172.17.0.7-1597690948436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-d7e3e74d-56e6-4392-b200-9c43eac83cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-129b9754-9588-4453-9bd1-6aa600ac528d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-2feeaf86-c5cc-4c37-8a54-f23cb5c6f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-48223833-bdbf-4364-a404-c668ec6527eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c21c2804-0841-47e9-b81e-1f7d92faa079,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-832d3aa0-6a5c-4c02-ab5a-03450f90bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-d142d59d-ca92-4add-bca0-e63e509db38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-cc977af9-7a61-40cf-8562-b58c3b74b69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058641966-172.17.0.7-1597690948436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-d7e3e74d-56e6-4392-b200-9c43eac83cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-129b9754-9588-4453-9bd1-6aa600ac528d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-2feeaf86-c5cc-4c37-8a54-f23cb5c6f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-48223833-bdbf-4364-a404-c668ec6527eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c21c2804-0841-47e9-b81e-1f7d92faa079,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-832d3aa0-6a5c-4c02-ab5a-03450f90bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-d142d59d-ca92-4add-bca0-e63e509db38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-cc977af9-7a61-40cf-8562-b58c3b74b69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5824
