reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860222578-172.17.0.3-1597459762911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-067a669a-9107-4b1e-9f27-0c37ed691a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-76e9d476-4497-41f8-b1f5-840d463a7d60,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-e4bc94be-0b0a-426d-8913-d502bb7dde80,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-f8a94e6f-38c7-4942-9148-20f9893084b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-30ab314c-0c7a-4951-9c69-815a8a5bd299,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-e5fb2cf8-71b5-49a7-ad39-a9bda950c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-7617e7e3-818e-430c-bc37-7b63aabb5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-42fbaeb5-3de5-4075-9bf6-029e1220387f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860222578-172.17.0.3-1597459762911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-067a669a-9107-4b1e-9f27-0c37ed691a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-76e9d476-4497-41f8-b1f5-840d463a7d60,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-e4bc94be-0b0a-426d-8913-d502bb7dde80,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-f8a94e6f-38c7-4942-9148-20f9893084b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-30ab314c-0c7a-4951-9c69-815a8a5bd299,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-e5fb2cf8-71b5-49a7-ad39-a9bda950c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-7617e7e3-818e-430c-bc37-7b63aabb5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-42fbaeb5-3de5-4075-9bf6-029e1220387f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505666381-172.17.0.3-1597460306739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-e4d040f4-d444-4266-ad7d-34d810c59df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-ea9eea93-9095-4959-a822-368aee05001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-98519488-7cb2-4cca-a16b-10b615a85557,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-fb2ca5ed-19c7-4c28-a601-ef27c74179da,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a1667ae5-0c90-486d-80aa-9a9a6f0b8049,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e6f1c5b0-4cd6-4db8-b28c-ecb985e2dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b66e20e7-82bd-44d5-8bc5-96067e513e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-41ad0197-e5bc-4d60-8e14-aab3dbdcd9e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505666381-172.17.0.3-1597460306739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-e4d040f4-d444-4266-ad7d-34d810c59df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-ea9eea93-9095-4959-a822-368aee05001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-98519488-7cb2-4cca-a16b-10b615a85557,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-fb2ca5ed-19c7-4c28-a601-ef27c74179da,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a1667ae5-0c90-486d-80aa-9a9a6f0b8049,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e6f1c5b0-4cd6-4db8-b28c-ecb985e2dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b66e20e7-82bd-44d5-8bc5-96067e513e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-41ad0197-e5bc-4d60-8e14-aab3dbdcd9e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850832396-172.17.0.3-1597460534186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-2069553a-5a4f-45bb-b395-08585dc595de,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-91a5a0a4-2728-4cc5-9f24-d566b595c014,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e719db24-362a-4fc5-abf9-99e1026de031,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-5f221f70-0a57-4ca6-93b1-bb74fbcd6764,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4e8e4950-417c-4e17-8e62-60b12c85c9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c0493be2-6ad6-4bf4-89c7-1d42f95ec2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-fe3f0b40-5114-43e2-932e-fad766504823,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-1dc40b70-752d-430a-b415-60b30a79c747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850832396-172.17.0.3-1597460534186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-2069553a-5a4f-45bb-b395-08585dc595de,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-91a5a0a4-2728-4cc5-9f24-d566b595c014,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-e719db24-362a-4fc5-abf9-99e1026de031,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-5f221f70-0a57-4ca6-93b1-bb74fbcd6764,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4e8e4950-417c-4e17-8e62-60b12c85c9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c0493be2-6ad6-4bf4-89c7-1d42f95ec2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-fe3f0b40-5114-43e2-932e-fad766504823,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-1dc40b70-752d-430a-b415-60b30a79c747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384071993-172.17.0.3-1597460576667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-5d6cf840-c07f-4a3a-9961-3e6dd3f2702f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f30f4793-f3f2-4f3c-acb6-f521c7dfa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-1983f7c8-0064-4c52-aace-91a04d4d9137,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-09990c76-fe65-4259-a7a3-cf848774dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-392b7ad1-9614-4a75-90ce-78a1f4b43c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-225aeaf1-ce5a-4ea9-923d-ac9e3f963aef,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-69ddc477-7346-4ade-bf87-1fe01e66c9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e3feaf2c-6211-46ea-857d-be3803fe3272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384071993-172.17.0.3-1597460576667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-5d6cf840-c07f-4a3a-9961-3e6dd3f2702f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f30f4793-f3f2-4f3c-acb6-f521c7dfa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-1983f7c8-0064-4c52-aace-91a04d4d9137,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-09990c76-fe65-4259-a7a3-cf848774dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-392b7ad1-9614-4a75-90ce-78a1f4b43c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-225aeaf1-ce5a-4ea9-923d-ac9e3f963aef,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-69ddc477-7346-4ade-bf87-1fe01e66c9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e3feaf2c-6211-46ea-857d-be3803fe3272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854322500-172.17.0.3-1597460698361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-755a3f31-54da-4dc3-a333-71620b7bc716,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b970c5f3-77b3-444f-bf25-9640795fde31,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-63827af6-841e-49e1-9364-05fad3fc16a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-2e94895a-ec39-4782-bc2b-b916d59e9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a3c2e967-b0fd-4579-9cd4-37b4086a7b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-7d82dc2f-103e-432f-adcb-1295105bd5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-bd19de4f-94f1-4f4c-97d4-0a4a9bd6d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-0a1b90c3-36a8-4d4e-93ed-554090c52a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854322500-172.17.0.3-1597460698361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-755a3f31-54da-4dc3-a333-71620b7bc716,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b970c5f3-77b3-444f-bf25-9640795fde31,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-63827af6-841e-49e1-9364-05fad3fc16a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-2e94895a-ec39-4782-bc2b-b916d59e9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a3c2e967-b0fd-4579-9cd4-37b4086a7b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-7d82dc2f-103e-432f-adcb-1295105bd5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-bd19de4f-94f1-4f4c-97d4-0a4a9bd6d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-0a1b90c3-36a8-4d4e-93ed-554090c52a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038821254-172.17.0.3-1597461019149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-20d76f48-61fb-4226-8eae-ce7e702b9578,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-701f2177-255f-469a-9620-0ab1551c37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-56b4c7ae-ccb7-48b5-ae92-8d292e96e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-113a47b6-8567-4edc-8ba5-fb42921601f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-117676b8-9e73-49c5-bcc6-85543eddf942,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-28c33bfa-87a0-4b46-821a-d6339512caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-f47a4b1b-5c39-498e-b86f-4014325e65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-57d38818-5b83-4550-9dc5-be837ce85043,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038821254-172.17.0.3-1597461019149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-20d76f48-61fb-4226-8eae-ce7e702b9578,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-701f2177-255f-469a-9620-0ab1551c37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-56b4c7ae-ccb7-48b5-ae92-8d292e96e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-113a47b6-8567-4edc-8ba5-fb42921601f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-117676b8-9e73-49c5-bcc6-85543eddf942,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-28c33bfa-87a0-4b46-821a-d6339512caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-f47a4b1b-5c39-498e-b86f-4014325e65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-57d38818-5b83-4550-9dc5-be837ce85043,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103204727-172.17.0.3-1597461439830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-bbd07b50-a556-41d3-b065-2fdb90f0a787,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2531e46f-d2ac-4474-aab1-b75fb36de201,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-45882fac-b969-44aa-9b5e-3ba6413e07c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-b980b862-dbdb-427c-b37a-09a4c1e957c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-aed2f5cc-5acf-431e-9bf1-e08a2e80d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-62e4797c-ae26-4bad-ba08-253ef9cc9218,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-de2d849b-fcd3-45ef-b6af-cba24d207034,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-4b877947-d7a9-4c6b-9c63-9dfa413a3944,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103204727-172.17.0.3-1597461439830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-bbd07b50-a556-41d3-b065-2fdb90f0a787,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2531e46f-d2ac-4474-aab1-b75fb36de201,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-45882fac-b969-44aa-9b5e-3ba6413e07c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-b980b862-dbdb-427c-b37a-09a4c1e957c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-aed2f5cc-5acf-431e-9bf1-e08a2e80d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-62e4797c-ae26-4bad-ba08-253ef9cc9218,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-de2d849b-fcd3-45ef-b6af-cba24d207034,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-4b877947-d7a9-4c6b-9c63-9dfa413a3944,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840146541-172.17.0.3-1597461683961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34896,DS-79fe8e72-f10b-49f9-9fb5-537e04d5844e,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-7f522fa8-d037-4073-8a2e-952e6d068a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1e39a197-495a-488a-9165-0bc951f68d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-aa3bac79-2ab2-4e3e-966b-02a19e757cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e0c6bd23-1662-447b-a1db-436e8df0444e,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-61e11d0d-76b0-430a-bdae-2f905afbcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-609262a1-2937-41c8-b17c-d4237231eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-a4b59f4e-b44f-4075-addc-353200df11fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840146541-172.17.0.3-1597461683961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34896,DS-79fe8e72-f10b-49f9-9fb5-537e04d5844e,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-7f522fa8-d037-4073-8a2e-952e6d068a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1e39a197-495a-488a-9165-0bc951f68d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-aa3bac79-2ab2-4e3e-966b-02a19e757cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e0c6bd23-1662-447b-a1db-436e8df0444e,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-61e11d0d-76b0-430a-bdae-2f905afbcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-609262a1-2937-41c8-b17c-d4237231eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-a4b59f4e-b44f-4075-addc-353200df11fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778962291-172.17.0.3-1597461717920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-ac207b3e-17b8-4b74-afc7-cc7946e29579,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-73b5ad6b-4775-4da3-a9e1-c440116806f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-3838121d-f36e-427a-9219-01505e74bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-a5cde3e2-eff2-46ec-a719-4670565781c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-03c73439-c0d5-4d99-91e2-f6fbef44fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-3a338f03-3bd5-45db-965d-b36ecd28febb,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-b3483f32-3383-4ad9-b3e6-9a3d6b4ccfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-1fcedc7a-f2e2-4a41-a742-5cefa27089f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778962291-172.17.0.3-1597461717920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-ac207b3e-17b8-4b74-afc7-cc7946e29579,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-73b5ad6b-4775-4da3-a9e1-c440116806f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-3838121d-f36e-427a-9219-01505e74bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-a5cde3e2-eff2-46ec-a719-4670565781c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-03c73439-c0d5-4d99-91e2-f6fbef44fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-3a338f03-3bd5-45db-965d-b36ecd28febb,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-b3483f32-3383-4ad9-b3e6-9a3d6b4ccfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-1fcedc7a-f2e2-4a41-a742-5cefa27089f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347864720-172.17.0.3-1597461798754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-5746378d-5840-4d00-afbd-4a2d206118a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-59060a8c-3e80-43a9-80b9-a1a685d9cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-75f469e9-477c-4064-a4ef-8c8547b0ba62,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-4a677c46-6c30-4e23-932e-a03fb52dbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-6f66acec-54ee-44b8-ae3e-4bc333be03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-af9f913e-e2d8-49c3-8aa5-e5bfbd3522c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-1600739c-4e57-4701-bc8c-86b60b353287,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-c1d6cdd1-8e31-4823-830d-bb2ea90a217c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347864720-172.17.0.3-1597461798754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-5746378d-5840-4d00-afbd-4a2d206118a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-59060a8c-3e80-43a9-80b9-a1a685d9cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-75f469e9-477c-4064-a4ef-8c8547b0ba62,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-4a677c46-6c30-4e23-932e-a03fb52dbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-6f66acec-54ee-44b8-ae3e-4bc333be03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-af9f913e-e2d8-49c3-8aa5-e5bfbd3522c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-1600739c-4e57-4701-bc8c-86b60b353287,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-c1d6cdd1-8e31-4823-830d-bb2ea90a217c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051917335-172.17.0.3-1597461833361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-da2b46a9-80a9-409d-bc41-7e4783748db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-c0d11b23-70e3-4746-9741-cf6259529a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-935bd984-4d7e-4eee-953b-e4dc408e4fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-c4eb9157-dc97-454f-81cf-63f2d4343cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-e74e25a0-e1be-4dad-a51c-3f369b176817,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-c5d62871-6a91-4190-9d2d-1d8a935f01dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-af41cfe4-6c58-4c42-8885-7b1aac6c0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-06aac689-bc4f-473b-9fa2-7fea9157ac88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051917335-172.17.0.3-1597461833361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-da2b46a9-80a9-409d-bc41-7e4783748db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-c0d11b23-70e3-4746-9741-cf6259529a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-935bd984-4d7e-4eee-953b-e4dc408e4fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-c4eb9157-dc97-454f-81cf-63f2d4343cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-e74e25a0-e1be-4dad-a51c-3f369b176817,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-c5d62871-6a91-4190-9d2d-1d8a935f01dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-af41cfe4-6c58-4c42-8885-7b1aac6c0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-06aac689-bc4f-473b-9fa2-7fea9157ac88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758145174-172.17.0.3-1597461870152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-726f5a81-0e1e-4892-816d-6251190aeebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-311f9cd2-4b2e-4a68-943d-0133a7946f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-540883fe-6879-4bc6-938e-588859d2eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8dfed756-11bb-4578-a4fe-7280bdec7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-314bd1e8-7c49-493e-8f52-8bcfa9408d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d44ca342-a5d0-4090-8bac-9814677528d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-00b18a1f-c322-4a0a-8e5d-ca38f0bc44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ca230c7e-bbd8-4ce5-8572-a93c214de80b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758145174-172.17.0.3-1597461870152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-726f5a81-0e1e-4892-816d-6251190aeebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-311f9cd2-4b2e-4a68-943d-0133a7946f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-540883fe-6879-4bc6-938e-588859d2eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8dfed756-11bb-4578-a4fe-7280bdec7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-314bd1e8-7c49-493e-8f52-8bcfa9408d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d44ca342-a5d0-4090-8bac-9814677528d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-00b18a1f-c322-4a0a-8e5d-ca38f0bc44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ca230c7e-bbd8-4ce5-8572-a93c214de80b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172003750-172.17.0.3-1597462013664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-e7d50e07-fb8f-40fe-8a98-d14c914815d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-606bd12f-0fc5-4aa1-a930-6e33c357d822,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-02995a54-2d57-465d-a6db-38f2f92db273,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-6bbd406d-8ebf-4dcb-8224-0ef26c18c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-f226c1fd-5566-4424-ac1d-b5fd96c2ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-caae5e45-2feb-4016-9922-74eefc455cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-531bb4e7-69fb-41a0-9170-3e3e0a93326b,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-2f8411a8-fdbd-428a-893c-1b21a017bc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172003750-172.17.0.3-1597462013664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-e7d50e07-fb8f-40fe-8a98-d14c914815d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-606bd12f-0fc5-4aa1-a930-6e33c357d822,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-02995a54-2d57-465d-a6db-38f2f92db273,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-6bbd406d-8ebf-4dcb-8224-0ef26c18c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-f226c1fd-5566-4424-ac1d-b5fd96c2ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-caae5e45-2feb-4016-9922-74eefc455cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-531bb4e7-69fb-41a0-9170-3e3e0a93326b,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-2f8411a8-fdbd-428a-893c-1b21a017bc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040921108-172.17.0.3-1597462079428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-3bd6d6fb-295d-446c-94f5-6bea513bc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-ccf9a5c2-d835-4b2a-a4af-a8730342120c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-7436727e-8333-49e7-9557-767a61d5c540,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1b4bbc10-9e6e-43b4-bb24-cad09cda4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-6ecdea1d-1704-4f8d-b061-8393c96e2938,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-fef5de68-8cd7-458c-a126-d0d55ce327f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-53fe00db-5a74-4417-87a5-06a24a1e1937,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-f1619dde-d159-427c-abac-17562600a726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040921108-172.17.0.3-1597462079428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-3bd6d6fb-295d-446c-94f5-6bea513bc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-ccf9a5c2-d835-4b2a-a4af-a8730342120c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-7436727e-8333-49e7-9557-767a61d5c540,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1b4bbc10-9e6e-43b4-bb24-cad09cda4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-6ecdea1d-1704-4f8d-b061-8393c96e2938,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-fef5de68-8cd7-458c-a126-d0d55ce327f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-53fe00db-5a74-4417-87a5-06a24a1e1937,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-f1619dde-d159-427c-abac-17562600a726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354920134-172.17.0.3-1597462224729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-7afd12da-7cb4-4950-853f-439952f785ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-36509e66-998f-4c0b-981d-c3d2c334d911,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-abbbea7b-9eae-4d14-846f-4750ac288156,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-5889c2d4-a44e-4dc2-9dc1-d533854f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b7749587-e4e0-46ec-bee2-51e21c01c743,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-3bc3e4b6-4c46-433b-9cb3-7ea4db8ad35f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-f9bef815-31b4-4fca-9aaa-89bb3790fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-6c0358c1-37ac-4553-a421-b2a242ce4313,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354920134-172.17.0.3-1597462224729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-7afd12da-7cb4-4950-853f-439952f785ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-36509e66-998f-4c0b-981d-c3d2c334d911,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-abbbea7b-9eae-4d14-846f-4750ac288156,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-5889c2d4-a44e-4dc2-9dc1-d533854f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b7749587-e4e0-46ec-bee2-51e21c01c743,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-3bc3e4b6-4c46-433b-9cb3-7ea4db8ad35f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-f9bef815-31b4-4fca-9aaa-89bb3790fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-6c0358c1-37ac-4553-a421-b2a242ce4313,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215323155-172.17.0.3-1597462378683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-0a9b5554-ae33-4046-93e3-1d81971af16d,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-4e3b8a06-5703-43fa-b557-dac7955ccbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-eeea6c54-92e0-404e-af96-fd1200530b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-1e72b8cc-81d6-47ff-9e24-c4143ac090b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-821a240d-5ea7-444d-aec4-bc28ccd38d68,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-4d32857f-f374-4a89-81ea-e6d6a2c0782f,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-c93a13ff-d583-43c3-90c9-5f06ccb66a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-1a0de41a-83e3-47f0-a321-58b8808cee44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215323155-172.17.0.3-1597462378683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-0a9b5554-ae33-4046-93e3-1d81971af16d,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-4e3b8a06-5703-43fa-b557-dac7955ccbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-eeea6c54-92e0-404e-af96-fd1200530b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-1e72b8cc-81d6-47ff-9e24-c4143ac090b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-821a240d-5ea7-444d-aec4-bc28ccd38d68,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-4d32857f-f374-4a89-81ea-e6d6a2c0782f,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-c93a13ff-d583-43c3-90c9-5f06ccb66a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-1a0de41a-83e3-47f0-a321-58b8808cee44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776625966-172.17.0.3-1597462411080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-0b399bb1-dce1-499a-afee-9fa137eb35be,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-751f4483-bfd9-4d3d-a352-17c88941a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8072dcf7-df6a-47c5-8993-968dd5293a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d385ce1e-45bd-4ddf-b2a8-96fe59ae4652,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-d659d01e-07a1-4da7-945d-2e7a6980fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-a4e9f116-38ec-4195-a15c-3aabab9011c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-834b2983-ea91-4fba-9df9-7abd89cc5dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-326c461c-9f96-4c0d-89ce-962d8d569a15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776625966-172.17.0.3-1597462411080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-0b399bb1-dce1-499a-afee-9fa137eb35be,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-751f4483-bfd9-4d3d-a352-17c88941a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8072dcf7-df6a-47c5-8993-968dd5293a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d385ce1e-45bd-4ddf-b2a8-96fe59ae4652,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-d659d01e-07a1-4da7-945d-2e7a6980fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-a4e9f116-38ec-4195-a15c-3aabab9011c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-834b2983-ea91-4fba-9df9-7abd89cc5dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-326c461c-9f96-4c0d-89ce-962d8d569a15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691175193-172.17.0.3-1597462450279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-6fb36cef-d2bf-40e1-957a-4497cd1ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-3b774569-2e38-4b6d-a6bc-cf0f9de2db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-cb2f9e2e-113a-4c1c-a560-7e075c6ffce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-f29987c7-7c47-4aeb-98c2-d757f1ebc35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-e7dd4444-8eb8-46a4-8bcf-e0c91038032d,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-5b4ce8d9-58d2-4e5a-b90b-9cb3b66f1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-1ab1c3e0-a133-4c68-b649-1bfe05568a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-4efa3cfe-bed8-49cb-b002-4ead16b75803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691175193-172.17.0.3-1597462450279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-6fb36cef-d2bf-40e1-957a-4497cd1ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-3b774569-2e38-4b6d-a6bc-cf0f9de2db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-cb2f9e2e-113a-4c1c-a560-7e075c6ffce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-f29987c7-7c47-4aeb-98c2-d757f1ebc35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-e7dd4444-8eb8-46a4-8bcf-e0c91038032d,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-5b4ce8d9-58d2-4e5a-b90b-9cb3b66f1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-1ab1c3e0-a133-4c68-b649-1bfe05568a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-4efa3cfe-bed8-49cb-b002-4ead16b75803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555278449-172.17.0.3-1597462775700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-82e80fe9-39a8-4c9f-976c-fa49cba4cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-428ab3bd-007d-43ff-82a7-19f5eab5607e,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-c3c15fdc-b778-43a4-b2e6-bd2af01f14a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-9292ace5-72e1-4461-b171-0e452b78b6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-4ec7ad14-7f23-4ee5-9bcb-bfcef13ff4df,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b845d9b6-0290-48ca-bf9d-b455f3a0a287,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-beb4d132-eefb-4ac4-9c21-8e17df6e95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-77eefb8d-51a4-44fa-9476-31f28ad56ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555278449-172.17.0.3-1597462775700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-82e80fe9-39a8-4c9f-976c-fa49cba4cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-428ab3bd-007d-43ff-82a7-19f5eab5607e,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-c3c15fdc-b778-43a4-b2e6-bd2af01f14a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-9292ace5-72e1-4461-b171-0e452b78b6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-4ec7ad14-7f23-4ee5-9bcb-bfcef13ff4df,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b845d9b6-0290-48ca-bf9d-b455f3a0a287,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-beb4d132-eefb-4ac4-9c21-8e17df6e95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-77eefb8d-51a4-44fa-9476-31f28ad56ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452655718-172.17.0.3-1597463157471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-5cb2f2b1-f8bd-49da-93b4-e153f1350c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-1ea0de47-af77-4d79-8e34-1ace8c740fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-971404fc-31f9-4646-9a25-af327ed76964,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-6bd6b0c0-d824-4db1-be66-093de71362af,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-f4b3ef7e-7c07-4076-9f56-8e3d39dad171,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-a241ae50-0847-4862-a6a6-7668f92e8fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-3647c54a-a6fc-4d96-a86e-d12d8df8383c,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-5ba7c3c6-648a-4bf3-8c24-4e6fad69975e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452655718-172.17.0.3-1597463157471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-5cb2f2b1-f8bd-49da-93b4-e153f1350c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-1ea0de47-af77-4d79-8e34-1ace8c740fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-971404fc-31f9-4646-9a25-af327ed76964,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-6bd6b0c0-d824-4db1-be66-093de71362af,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-f4b3ef7e-7c07-4076-9f56-8e3d39dad171,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-a241ae50-0847-4862-a6a6-7668f92e8fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-3647c54a-a6fc-4d96-a86e-d12d8df8383c,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-5ba7c3c6-648a-4bf3-8c24-4e6fad69975e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830568170-172.17.0.3-1597463294224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-315c4014-c399-4c67-aff5-99b37cca7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-aae404ac-39c6-40ef-8a90-270e36169b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-becef6c7-c30b-4965-825c-b9f43618369d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-d1f9663c-872d-4cb2-af4e-2c3c6a6e52ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-67a7403c-2f9a-439d-9b0f-c866cbae885a,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-58502041-45e9-4cbd-aa70-ca28dbada19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-0f3c120d-ad4d-468e-aba8-18e214fa06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-fd754f34-170b-4ad3-93ad-ec7f1eb01a04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830568170-172.17.0.3-1597463294224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-315c4014-c399-4c67-aff5-99b37cca7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-aae404ac-39c6-40ef-8a90-270e36169b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-becef6c7-c30b-4965-825c-b9f43618369d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-d1f9663c-872d-4cb2-af4e-2c3c6a6e52ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-67a7403c-2f9a-439d-9b0f-c866cbae885a,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-58502041-45e9-4cbd-aa70-ca28dbada19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-0f3c120d-ad4d-468e-aba8-18e214fa06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-fd754f34-170b-4ad3-93ad-ec7f1eb01a04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002684995-172.17.0.3-1597463743029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-9122f4c2-5b7f-4ae9-85d6-32c87d7c8a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-ee27811d-f93a-4d5b-b77a-c0d4208ae991,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-f947abe5-9326-4a38-84ef-5f71611babf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-88178341-4a91-47fc-97ac-88fb1fe1a422,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-59896b0d-790d-4a85-a4f0-7c6f85045181,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-e2860fb8-f5ee-47a7-b2b3-7d9ab713127e,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6ecf4098-269d-4b6f-8322-c351c2063ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-869cfa17-47f4-4688-9922-532c7aed60c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002684995-172.17.0.3-1597463743029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-9122f4c2-5b7f-4ae9-85d6-32c87d7c8a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-ee27811d-f93a-4d5b-b77a-c0d4208ae991,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-f947abe5-9326-4a38-84ef-5f71611babf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-88178341-4a91-47fc-97ac-88fb1fe1a422,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-59896b0d-790d-4a85-a4f0-7c6f85045181,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-e2860fb8-f5ee-47a7-b2b3-7d9ab713127e,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6ecf4098-269d-4b6f-8322-c351c2063ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-869cfa17-47f4-4688-9922-532c7aed60c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838861034-172.17.0.3-1597463855737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-d179d72b-348e-4f9d-b10d-2c93e54368a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d7f63bf6-f61f-45c6-9ee4-13a18a4d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-6ad5cfcc-0194-4973-87fd-6fb1f4cdbd14,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-773af70e-5ee0-4dd9-82a7-f176b9cfecac,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-42a78f81-a7bd-4fdb-a1b3-4e61ff883c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-1eaa77cf-0507-4771-9be5-dcb0a41b073e,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-16172768-39ee-47d1-9d3d-fa460d8abcab,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-d1b11a80-67d0-440e-b53e-efc80c7a2ab1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838861034-172.17.0.3-1597463855737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-d179d72b-348e-4f9d-b10d-2c93e54368a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d7f63bf6-f61f-45c6-9ee4-13a18a4d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-6ad5cfcc-0194-4973-87fd-6fb1f4cdbd14,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-773af70e-5ee0-4dd9-82a7-f176b9cfecac,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-42a78f81-a7bd-4fdb-a1b3-4e61ff883c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-1eaa77cf-0507-4771-9be5-dcb0a41b073e,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-16172768-39ee-47d1-9d3d-fa460d8abcab,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-d1b11a80-67d0-440e-b53e-efc80c7a2ab1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158756859-172.17.0.3-1597464000942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-757b078f-6325-4928-9faa-c9ee5b387f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-07d5bd18-6318-441c-b839-06e1cbddcc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-4fb5a8a4-febd-4fb0-a4f5-5bd2a6435712,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-a9067d51-6d88-4f1a-9bcb-3d1840862243,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-6c52d21f-3926-4af7-b863-ddefb01bb401,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-e03b3692-9a57-4ba2-8ccf-7d0583319474,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-ef5d3ecb-0efd-42d0-985f-02b0594ebc25,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-0fbb11e2-4a12-4e47-9d67-89304f1ee5dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158756859-172.17.0.3-1597464000942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-757b078f-6325-4928-9faa-c9ee5b387f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-07d5bd18-6318-441c-b839-06e1cbddcc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-4fb5a8a4-febd-4fb0-a4f5-5bd2a6435712,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-a9067d51-6d88-4f1a-9bcb-3d1840862243,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-6c52d21f-3926-4af7-b863-ddefb01bb401,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-e03b3692-9a57-4ba2-8ccf-7d0583319474,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-ef5d3ecb-0efd-42d0-985f-02b0594ebc25,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-0fbb11e2-4a12-4e47-9d67-89304f1ee5dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631979960-172.17.0.3-1597464076847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-32f44899-7541-4eb7-bb89-2e437a4efe50,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-1da34d02-bace-4889-a7e7-706ab607c475,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-391b702f-fa28-49d7-9da2-dcf698028304,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-acc60263-f1f4-4489-9ea2-be69379ca77e,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-f022a919-db48-47c4-a395-6213a31cc634,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-a13a0c84-df4c-4d97-b219-4288ab11cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-1afd8a2d-18ed-4a6d-b853-5b96171123c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-87f28f2a-054c-47ef-9b3c-c841f99eb805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631979960-172.17.0.3-1597464076847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-32f44899-7541-4eb7-bb89-2e437a4efe50,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-1da34d02-bace-4889-a7e7-706ab607c475,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-391b702f-fa28-49d7-9da2-dcf698028304,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-acc60263-f1f4-4489-9ea2-be69379ca77e,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-f022a919-db48-47c4-a395-6213a31cc634,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-a13a0c84-df4c-4d97-b219-4288ab11cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-1afd8a2d-18ed-4a6d-b853-5b96171123c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-87f28f2a-054c-47ef-9b3c-c841f99eb805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215277311-172.17.0.3-1597464415575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-11db074a-7c83-41da-a5cc-ca1823616e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-643c6417-6705-44de-808d-e82e0cc361ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-d284b362-5b9f-47a4-bf3a-c7dac3056ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-2c8806c5-5dfd-4d1e-a6ce-2130e25df273,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-f647ccdd-8578-49e9-a225-1cdbaed8eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-bcfed97b-aa63-48bb-82c8-845e896954b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-7965a74f-ab2e-4618-bcf4-20e069a53040,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-7d9ed926-7204-40c5-b88b-e66ff18f3f97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215277311-172.17.0.3-1597464415575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-11db074a-7c83-41da-a5cc-ca1823616e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-643c6417-6705-44de-808d-e82e0cc361ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-d284b362-5b9f-47a4-bf3a-c7dac3056ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-2c8806c5-5dfd-4d1e-a6ce-2130e25df273,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-f647ccdd-8578-49e9-a225-1cdbaed8eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-bcfed97b-aa63-48bb-82c8-845e896954b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-7965a74f-ab2e-4618-bcf4-20e069a53040,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-7d9ed926-7204-40c5-b88b-e66ff18f3f97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117810420-172.17.0.3-1597464451589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-7cfc4d83-1e30-4bf0-9fe2-e7162c24f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-53b38b37-3542-4dfc-8bf2-77253f8574b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-ccc8c95c-23f4-4288-b3a7-cb822a0b6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-abcd323c-52f5-4c36-bcd3-cae192cfaac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-4d440ff0-46e8-455f-a48a-0cfe9f1b51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-a66586f6-90e8-46e4-a21e-923cbb8fdce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-8306425e-2938-4c7d-abc0-34f06c447c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-038b8d63-8c05-4114-a2c5-4bfc7b0ff62e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117810420-172.17.0.3-1597464451589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-7cfc4d83-1e30-4bf0-9fe2-e7162c24f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-53b38b37-3542-4dfc-8bf2-77253f8574b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-ccc8c95c-23f4-4288-b3a7-cb822a0b6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-abcd323c-52f5-4c36-bcd3-cae192cfaac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-4d440ff0-46e8-455f-a48a-0cfe9f1b51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-a66586f6-90e8-46e4-a21e-923cbb8fdce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-8306425e-2938-4c7d-abc0-34f06c447c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-038b8d63-8c05-4114-a2c5-4bfc7b0ff62e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283358692-172.17.0.3-1597464573162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-3bcfea8a-fe27-4608-a8d3-c4f1a5bfa141,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-7039dd46-79d6-481c-b1bb-669b49dc2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-7b04f635-f192-488a-95f7-c76fdd754f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-b7ef09e7-9ea8-44ff-8001-e1f9744ced1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-11f3124c-544a-4b5b-9e74-12d52ffd7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-83d8c06c-1d73-4e32-9ba8-f8ab6dd11ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-eb485f96-f956-4da7-b435-9eadd0a19bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-aafa232e-4d70-4004-b577-672944ec9a4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283358692-172.17.0.3-1597464573162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-3bcfea8a-fe27-4608-a8d3-c4f1a5bfa141,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-7039dd46-79d6-481c-b1bb-669b49dc2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-7b04f635-f192-488a-95f7-c76fdd754f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-b7ef09e7-9ea8-44ff-8001-e1f9744ced1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-11f3124c-544a-4b5b-9e74-12d52ffd7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-83d8c06c-1d73-4e32-9ba8-f8ab6dd11ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-eb485f96-f956-4da7-b435-9eadd0a19bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-aafa232e-4d70-4004-b577-672944ec9a4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010572107-172.17.0.3-1597464808315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-ba3aba58-acf8-4c46-adba-ad3c43afe4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-8c363880-1601-42b4-9d77-3d6b1cee7170,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-7876c9dc-3cad-48a5-8ade-ec19b53491a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-8c4e48cb-44e8-4252-bac9-3d86c398e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-f51347eb-2be6-4aaf-8480-d9e50049292a,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-7ed8c1c1-13ff-41b4-aeb7-622f680ec95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c07c4ce2-bafb-46b4-b619-54c02936274f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e471008a-424c-46d0-bc05-e6ea9e9888be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010572107-172.17.0.3-1597464808315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-ba3aba58-acf8-4c46-adba-ad3c43afe4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-8c363880-1601-42b4-9d77-3d6b1cee7170,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-7876c9dc-3cad-48a5-8ade-ec19b53491a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-8c4e48cb-44e8-4252-bac9-3d86c398e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-f51347eb-2be6-4aaf-8480-d9e50049292a,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-7ed8c1c1-13ff-41b4-aeb7-622f680ec95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c07c4ce2-bafb-46b4-b619-54c02936274f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e471008a-424c-46d0-bc05-e6ea9e9888be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112942387-172.17.0.3-1597464928806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-454b37a6-41a6-43c4-ab54-5da95ec83234,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f8c9e0a3-c4e3-48c6-809b-dbf1e846670d,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-bff2faeb-4305-4a00-b7e3-dd86bb80a61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7d3311dd-7c6a-4aab-8dc9-186d96a219a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-a0999bb1-a4c4-4639-bf35-6f85f3212fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-0e5f87f3-63b6-438c-a8b7-7296cd3e2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47dacc8e-5a96-4cd9-9b44-afc72b8a95fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-efc93aa2-1a9a-419b-bb0d-2980ae90712c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112942387-172.17.0.3-1597464928806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-454b37a6-41a6-43c4-ab54-5da95ec83234,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f8c9e0a3-c4e3-48c6-809b-dbf1e846670d,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-bff2faeb-4305-4a00-b7e3-dd86bb80a61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7d3311dd-7c6a-4aab-8dc9-186d96a219a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-a0999bb1-a4c4-4639-bf35-6f85f3212fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-0e5f87f3-63b6-438c-a8b7-7296cd3e2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47dacc8e-5a96-4cd9-9b44-afc72b8a95fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-efc93aa2-1a9a-419b-bb0d-2980ae90712c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488618615-172.17.0.3-1597465085110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34013,DS-734fb0cf-36aa-4936-801f-c8fad7ba512c,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-fbe6372b-e1b3-406c-97f3-0a3f6a495ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b164ac89-50bc-4c1e-8a11-6edcfe8dfade,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-154ae6c7-c37f-40c1-9a8b-4ec7e506beda,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-f8b2b38b-149d-4ed6-a497-bb83acb69fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-837efc76-90b7-48ac-915a-418d63d1d085,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-9496a47c-d6c1-4e59-b7c8-9b0fbed90d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-d5d0ee45-a0e1-48a1-beab-f6f52fc51f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488618615-172.17.0.3-1597465085110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34013,DS-734fb0cf-36aa-4936-801f-c8fad7ba512c,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-fbe6372b-e1b3-406c-97f3-0a3f6a495ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b164ac89-50bc-4c1e-8a11-6edcfe8dfade,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-154ae6c7-c37f-40c1-9a8b-4ec7e506beda,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-f8b2b38b-149d-4ed6-a497-bb83acb69fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-837efc76-90b7-48ac-915a-418d63d1d085,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-9496a47c-d6c1-4e59-b7c8-9b0fbed90d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-d5d0ee45-a0e1-48a1-beab-f6f52fc51f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879515297-172.17.0.3-1597465123941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-244126b0-ebc3-4fb6-951b-e44a3abdc1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-17f55339-45f7-4f53-a1ef-61c06e55cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ef17f764-1e99-4265-a65b-493b9a0ee633,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-0aa2db78-56f4-47c8-a87f-5d3addf95b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-01006757-4af8-446e-98eb-f31f12a72d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-6a6a3a06-5d58-425b-aab9-cb44d847d608,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-3f55b1aa-f52d-42a9-964c-2449aae9131e,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-26ad9975-f958-41fe-9b42-382c88f3fe1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879515297-172.17.0.3-1597465123941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-244126b0-ebc3-4fb6-951b-e44a3abdc1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-17f55339-45f7-4f53-a1ef-61c06e55cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ef17f764-1e99-4265-a65b-493b9a0ee633,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-0aa2db78-56f4-47c8-a87f-5d3addf95b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-01006757-4af8-446e-98eb-f31f12a72d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-6a6a3a06-5d58-425b-aab9-cb44d847d608,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-3f55b1aa-f52d-42a9-964c-2449aae9131e,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-26ad9975-f958-41fe-9b42-382c88f3fe1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5599
