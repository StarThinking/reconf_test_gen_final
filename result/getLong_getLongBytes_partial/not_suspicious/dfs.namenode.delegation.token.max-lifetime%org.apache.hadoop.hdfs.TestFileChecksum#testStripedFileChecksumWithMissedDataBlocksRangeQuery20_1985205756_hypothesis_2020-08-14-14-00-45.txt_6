reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023470450-172.17.0.12-1597413657887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-9412f846-0e7d-4671-9714-fb23093d8092,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-12b38461-2931-49ad-8ec7-d13c99e08e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-2d4e2f88-872e-4f7a-9f1c-9dc12ca305fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-aa8958f3-7c49-4832-a466-9a561795aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-28d6a8c1-d84d-4dd9-99c4-4baa448452d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-0460c426-48a5-46df-8910-bf62a1dcfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-66ce68b2-7d5a-4545-a32a-dab62d10eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d422ccc0-7b8c-4844-bb4d-1b8c8f171204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023470450-172.17.0.12-1597413657887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-9412f846-0e7d-4671-9714-fb23093d8092,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-12b38461-2931-49ad-8ec7-d13c99e08e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-2d4e2f88-872e-4f7a-9f1c-9dc12ca305fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-aa8958f3-7c49-4832-a466-9a561795aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-28d6a8c1-d84d-4dd9-99c4-4baa448452d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-0460c426-48a5-46df-8910-bf62a1dcfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-66ce68b2-7d5a-4545-a32a-dab62d10eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d422ccc0-7b8c-4844-bb4d-1b8c8f171204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654771672-172.17.0.12-1597414042904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-67f043d1-6098-47cb-b5b6-92dfda3b9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-80dd2af7-03b0-4ff5-9589-78d7df7618f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-ba0742d5-14b3-4cb3-bdc0-740ce5c80698,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-e21ad3d2-b9a0-40e5-922b-b6f8f97164c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-7c929937-c452-4ffc-9e79-34c227c50843,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-dc1e0c2b-8302-4674-8c32-b1f7c9cafa77,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-254cf2b9-742d-4150-9f94-bb761411d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-d57a62e7-aeeb-4f6f-99c6-373bcc07209f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654771672-172.17.0.12-1597414042904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-67f043d1-6098-47cb-b5b6-92dfda3b9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-80dd2af7-03b0-4ff5-9589-78d7df7618f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-ba0742d5-14b3-4cb3-bdc0-740ce5c80698,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-e21ad3d2-b9a0-40e5-922b-b6f8f97164c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-7c929937-c452-4ffc-9e79-34c227c50843,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-dc1e0c2b-8302-4674-8c32-b1f7c9cafa77,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-254cf2b9-742d-4150-9f94-bb761411d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-d57a62e7-aeeb-4f6f-99c6-373bcc07209f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710332346-172.17.0.12-1597414422440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-fb77fbf9-ca85-46a3-a86a-b4f6ffe12290,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-8384a391-b91f-4555-a1c8-0a10dc24351d,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-83116694-fc78-4e44-b730-d1850d8948eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-9d05c64c-2780-4d65-96c7-2a22f68398ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-68307d5e-e136-40a6-818c-773ab847ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-cca96933-89b1-44ec-8f54-a81ec7502735,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-32a02b67-a818-4c02-ad66-d1f7e85a3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-81ce1e62-3e0c-4dbf-8c0c-20400e49d281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710332346-172.17.0.12-1597414422440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-fb77fbf9-ca85-46a3-a86a-b4f6ffe12290,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-8384a391-b91f-4555-a1c8-0a10dc24351d,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-83116694-fc78-4e44-b730-d1850d8948eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-9d05c64c-2780-4d65-96c7-2a22f68398ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-68307d5e-e136-40a6-818c-773ab847ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-cca96933-89b1-44ec-8f54-a81ec7502735,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-32a02b67-a818-4c02-ad66-d1f7e85a3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-81ce1e62-3e0c-4dbf-8c0c-20400e49d281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20331865-172.17.0.12-1597414568424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-301a2abd-eb44-4609-9efb-3e385ea6f070,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-21579d24-a120-43e4-b647-1934ccb4e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-35103d1f-6d2a-4a21-bd39-e376bdd3c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0db21770-c81e-4d78-9c43-7ab7c39e39a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-21814cee-9c99-489f-87f8-b469360ad302,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-f50cc31d-1ded-4ec4-bb9e-0cae9b05ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-de689a76-4d8b-45a8-b169-ded39c17fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-f72d5699-594d-4d99-937f-80482bd79fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20331865-172.17.0.12-1597414568424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-301a2abd-eb44-4609-9efb-3e385ea6f070,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-21579d24-a120-43e4-b647-1934ccb4e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-35103d1f-6d2a-4a21-bd39-e376bdd3c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0db21770-c81e-4d78-9c43-7ab7c39e39a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-21814cee-9c99-489f-87f8-b469360ad302,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-f50cc31d-1ded-4ec4-bb9e-0cae9b05ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-de689a76-4d8b-45a8-b169-ded39c17fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-f72d5699-594d-4d99-937f-80482bd79fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235375498-172.17.0.12-1597414946831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-0b5fa9d6-4268-4ac5-be28-58d56d1794ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1807fe9d-aead-4e94-8caa-41f5e5247d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-c96d3c02-106f-4ea4-8fcb-38197f219921,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-5313df2e-a92d-4df8-ba7a-2d975eb1c443,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-fab67c17-b9d1-4892-adfe-e06b61cb571b,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-dd91b2f0-f69f-49b3-b2e2-6936d46d5375,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-294299fc-e949-4bc0-bc02-16e1590697c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-d1eec1fd-fc07-420c-87e2-045c006ddc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235375498-172.17.0.12-1597414946831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-0b5fa9d6-4268-4ac5-be28-58d56d1794ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1807fe9d-aead-4e94-8caa-41f5e5247d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-c96d3c02-106f-4ea4-8fcb-38197f219921,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-5313df2e-a92d-4df8-ba7a-2d975eb1c443,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-fab67c17-b9d1-4892-adfe-e06b61cb571b,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-dd91b2f0-f69f-49b3-b2e2-6936d46d5375,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-294299fc-e949-4bc0-bc02-16e1590697c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-d1eec1fd-fc07-420c-87e2-045c006ddc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532066101-172.17.0.12-1597416577214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-ecc763f4-d254-452b-81c2-f24d44ac71af,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-378bdab6-c6cb-467c-8d00-76cd3527bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3e93ec05-925a-441a-9e5a-ad4f9857a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-64970fff-a93a-460f-8be3-3bf0d4037d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-a556393b-0269-4417-87bb-1da2f2c19d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-53e87b33-725f-43b5-9340-10086330df28,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-17bf6be5-2ec2-4174-8529-4ce35b3220e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-84671d1f-a707-4a15-977d-a3db68e53f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532066101-172.17.0.12-1597416577214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-ecc763f4-d254-452b-81c2-f24d44ac71af,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-378bdab6-c6cb-467c-8d00-76cd3527bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3e93ec05-925a-441a-9e5a-ad4f9857a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-64970fff-a93a-460f-8be3-3bf0d4037d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-a556393b-0269-4417-87bb-1da2f2c19d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-53e87b33-725f-43b5-9340-10086330df28,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-17bf6be5-2ec2-4174-8529-4ce35b3220e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-84671d1f-a707-4a15-977d-a3db68e53f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988898082-172.17.0.12-1597416986050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-791733ab-e105-487f-a0ba-2e27e8a32b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-76a8e653-f0de-4588-a01d-ade9561b8d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-03c5f7bb-442d-4012-8850-fcb429c78113,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-b8fa2ea5-68f5-4daa-b011-0c7779d29db9,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-e3fcc926-d686-47ff-b327-a41ea6d9644e,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-6aa3f54f-62a7-4228-bdf8-a099a8da0dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-64773309-c6a9-4cca-ad03-c9b885d8caf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-7f1e8926-6c56-4ee2-8054-1a19e8e5f896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988898082-172.17.0.12-1597416986050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-791733ab-e105-487f-a0ba-2e27e8a32b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-76a8e653-f0de-4588-a01d-ade9561b8d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-03c5f7bb-442d-4012-8850-fcb429c78113,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-b8fa2ea5-68f5-4daa-b011-0c7779d29db9,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-e3fcc926-d686-47ff-b327-a41ea6d9644e,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-6aa3f54f-62a7-4228-bdf8-a099a8da0dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-64773309-c6a9-4cca-ad03-c9b885d8caf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-7f1e8926-6c56-4ee2-8054-1a19e8e5f896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332129354-172.17.0.12-1597417708661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-aa8fb529-fa1a-4092-b4a1-ded2c8f6d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-d9577f2d-8dd5-4a59-b5de-3fa683ad8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-4e9cf75f-25f3-49ff-8d8e-158a588fa5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-706caccd-b202-40ce-a4ce-2e6aaafdb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-2919b177-8f66-4e70-964c-06cada77d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-ab29ec2d-1bdb-4d5f-ad61-40bae7209a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-31ed516f-e3b9-4288-819c-27d72438da37,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-f3dc92d8-8b81-44da-9e6c-8156db4124e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332129354-172.17.0.12-1597417708661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-aa8fb529-fa1a-4092-b4a1-ded2c8f6d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-d9577f2d-8dd5-4a59-b5de-3fa683ad8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-4e9cf75f-25f3-49ff-8d8e-158a588fa5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-706caccd-b202-40ce-a4ce-2e6aaafdb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-2919b177-8f66-4e70-964c-06cada77d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-ab29ec2d-1bdb-4d5f-ad61-40bae7209a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-31ed516f-e3b9-4288-819c-27d72438da37,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-f3dc92d8-8b81-44da-9e6c-8156db4124e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858764840-172.17.0.12-1597417750225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-cc8bcefc-6ed6-4eda-bcef-1b4623e7344d,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-2f1d1e66-ff6d-4837-839e-c67b886b800c,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-736f5141-1003-40e5-b682-14d4f77fba61,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-44be6ddb-d1ac-47d8-9a74-d1019c6a7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-11cab85a-2d0f-486e-83df-6793a312daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-4b61e36d-65ba-4ca9-a4ff-4598c10d2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-fbb358f4-b2d4-47f4-901d-f65486b103bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-e38236af-217c-4913-8cc2-57ebd6156857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858764840-172.17.0.12-1597417750225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-cc8bcefc-6ed6-4eda-bcef-1b4623e7344d,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-2f1d1e66-ff6d-4837-839e-c67b886b800c,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-736f5141-1003-40e5-b682-14d4f77fba61,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-44be6ddb-d1ac-47d8-9a74-d1019c6a7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-11cab85a-2d0f-486e-83df-6793a312daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-4b61e36d-65ba-4ca9-a4ff-4598c10d2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-fbb358f4-b2d4-47f4-901d-f65486b103bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-e38236af-217c-4913-8cc2-57ebd6156857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339410052-172.17.0.12-1597417829951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-6985e3b6-d92c-4c41-8a73-fd87fa1ff4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1c50d426-a10b-43a0-9af8-c46a841c197e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-c954e397-d78b-4bf6-962a-e0c14f18172e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-9ea0f9fa-d998-4836-9dcc-fd8f5cff06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-67be101f-c745-462b-9ab3-e4b9f5b0d392,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a99bcc1b-e34b-44eb-8539-b17eb4364ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-ec445e87-3575-45a4-866a-a90100d9833f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-1ca6d4ba-a067-47cb-9a95-4c29059b1916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339410052-172.17.0.12-1597417829951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-6985e3b6-d92c-4c41-8a73-fd87fa1ff4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1c50d426-a10b-43a0-9af8-c46a841c197e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-c954e397-d78b-4bf6-962a-e0c14f18172e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-9ea0f9fa-d998-4836-9dcc-fd8f5cff06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-67be101f-c745-462b-9ab3-e4b9f5b0d392,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a99bcc1b-e34b-44eb-8539-b17eb4364ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-ec445e87-3575-45a4-866a-a90100d9833f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-1ca6d4ba-a067-47cb-9a95-4c29059b1916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933871186-172.17.0.12-1597418295719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-f3a03417-79ff-4f25-ad31-2eeab09a6405,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-8da5d5ee-a7ca-4371-a875-c4241740f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-bbd6afbe-c5db-47f2-abeb-64bccdbb3463,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-e3ca9f61-ea19-459a-b843-38c426a36369,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-88298972-2c8d-493e-bf2e-415b4c8c34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-8d5901a2-be34-4387-a2e9-2a1570e1695e,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f202ba62-bb68-45be-b2c4-c849b93c2234,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-3928f53b-cd98-420c-ac50-d10bb6fe59cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933871186-172.17.0.12-1597418295719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-f3a03417-79ff-4f25-ad31-2eeab09a6405,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-8da5d5ee-a7ca-4371-a875-c4241740f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-bbd6afbe-c5db-47f2-abeb-64bccdbb3463,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-e3ca9f61-ea19-459a-b843-38c426a36369,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-88298972-2c8d-493e-bf2e-415b4c8c34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-8d5901a2-be34-4387-a2e9-2a1570e1695e,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f202ba62-bb68-45be-b2c4-c849b93c2234,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-3928f53b-cd98-420c-ac50-d10bb6fe59cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034899069-172.17.0.12-1597418913870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-c336a4be-67ab-44bd-91b5-dc1d34f3e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a25cebbe-138a-46db-b9da-602f64ca95af,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-c650ca24-1fef-441a-a052-6095a7607c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-8ee28271-5339-4d28-bcb8-a4c75460b906,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-d383b418-7d83-498e-98d3-18a56da4ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-0eca7b15-ff8b-45f3-bfff-84a52d2cea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3996f8c4-3faf-423b-9a22-d0815b2e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a6366d86-497c-4122-bd27-88e31b72e150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034899069-172.17.0.12-1597418913870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-c336a4be-67ab-44bd-91b5-dc1d34f3e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a25cebbe-138a-46db-b9da-602f64ca95af,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-c650ca24-1fef-441a-a052-6095a7607c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-8ee28271-5339-4d28-bcb8-a4c75460b906,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-d383b418-7d83-498e-98d3-18a56da4ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-0eca7b15-ff8b-45f3-bfff-84a52d2cea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3996f8c4-3faf-423b-9a22-d0815b2e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a6366d86-497c-4122-bd27-88e31b72e150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972621463-172.17.0.12-1597418952458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-5c3c9dcb-c56a-47f3-b2ee-77ff73194d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-164d4c99-171c-4caa-b052-ae717e62b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-931565c0-c5b5-4fb3-9820-b2c3f84c6845,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-620a217f-7814-4d86-8274-02b44a464b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-fcaa4847-2410-4d94-8c29-531d8bf753e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-f2fdcffe-e1e9-45cf-891f-28645cc07fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d61b1704-d064-48fd-98f7-a842b2ae97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-444452ab-5828-48c0-9ed3-b2d3f4604869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972621463-172.17.0.12-1597418952458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-5c3c9dcb-c56a-47f3-b2ee-77ff73194d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-164d4c99-171c-4caa-b052-ae717e62b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-931565c0-c5b5-4fb3-9820-b2c3f84c6845,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-620a217f-7814-4d86-8274-02b44a464b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-fcaa4847-2410-4d94-8c29-531d8bf753e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-f2fdcffe-e1e9-45cf-891f-28645cc07fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d61b1704-d064-48fd-98f7-a842b2ae97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-444452ab-5828-48c0-9ed3-b2d3f4604869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759454768-172.17.0.12-1597419080829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-1abc26e4-3217-4176-8ab2-bf66c6f90ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-dba3a101-739f-44ad-9fca-a856d896f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-f5761414-160c-41f0-a744-4a072847bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-f8bf823a-0005-488d-8c3c-1493a061854a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-5234f736-1e3a-46b5-909f-90fe6b402d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-a4acad09-fa9d-4e96-a241-5777ada8fc24,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-15d8652e-879f-4804-879b-f834adcae370,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-56f5bf75-9cb5-4e85-bcef-7cc411170fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759454768-172.17.0.12-1597419080829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-1abc26e4-3217-4176-8ab2-bf66c6f90ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-dba3a101-739f-44ad-9fca-a856d896f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-f5761414-160c-41f0-a744-4a072847bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-f8bf823a-0005-488d-8c3c-1493a061854a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-5234f736-1e3a-46b5-909f-90fe6b402d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-a4acad09-fa9d-4e96-a241-5777ada8fc24,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-15d8652e-879f-4804-879b-f834adcae370,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-56f5bf75-9cb5-4e85-bcef-7cc411170fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 100
v2: 604800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150160441-172.17.0.12-1597419392484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36471,DS-d3fa2ee2-5fbd-443a-8690-5af7881318d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-9a69a6e6-04b3-4d06-9136-8ec7ec46d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-6a231b54-092e-4d59-805e-0490280d1afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-e3342f62-b2ed-4012-adcf-80da03731096,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-fa7ad9e8-5763-4ae5-b3db-7c24c65a8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-d8aaa3bc-9a27-439f-befd-40be54e80e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-c9c62cce-c6bb-4f9c-ac5d-45211320cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-f54044ce-f32f-4a47-8f35-020bf5d5a196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150160441-172.17.0.12-1597419392484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36471,DS-d3fa2ee2-5fbd-443a-8690-5af7881318d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-9a69a6e6-04b3-4d06-9136-8ec7ec46d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-6a231b54-092e-4d59-805e-0490280d1afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-e3342f62-b2ed-4012-adcf-80da03731096,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-fa7ad9e8-5763-4ae5-b3db-7c24c65a8b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-d8aaa3bc-9a27-439f-befd-40be54e80e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-c9c62cce-c6bb-4f9c-ac5d-45211320cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-f54044ce-f32f-4a47-8f35-020bf5d5a196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5804
