reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123871367-172.17.0.5-1597402779312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43208,DS-d16e5405-716c-410b-b3e1-31e347d06b55,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-9dd62052-54ed-41aa-afdd-4af4c6d0ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-c89395cc-c46d-47e1-8bd7-d3c49595e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-3269df35-dad6-478a-ba27-7aa4c15e6996,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-399e9a8c-d3d9-4800-9bfd-644e635af5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-2cc788e5-e090-490d-ae39-56a278261ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-53720cc0-63eb-44db-9044-e14def8ddb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-94c719e8-bac1-474f-8e41-bb6ebfed9328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123871367-172.17.0.5-1597402779312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43208,DS-d16e5405-716c-410b-b3e1-31e347d06b55,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-9dd62052-54ed-41aa-afdd-4af4c6d0ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-c89395cc-c46d-47e1-8bd7-d3c49595e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-3269df35-dad6-478a-ba27-7aa4c15e6996,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-399e9a8c-d3d9-4800-9bfd-644e635af5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-2cc788e5-e090-490d-ae39-56a278261ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-53720cc0-63eb-44db-9044-e14def8ddb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-94c719e8-bac1-474f-8e41-bb6ebfed9328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061453853-172.17.0.5-1597402935549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-c239d668-64b6-47d1-95b0-a5511448dc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-6fe0938d-7772-46e8-ad71-86ca37cee50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-6e758097-36da-4237-885a-15dc79e50264,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-e69e5b83-704d-42f4-9b1c-48409e30c424,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-172d2ed3-4981-4412-ad12-46e6afe772f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-6c910347-9423-493a-9773-a139cde0b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-d36dc512-7b3e-4383-9052-bfdb6dedefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-90f51ff2-601b-4d94-8833-f96abffaf2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061453853-172.17.0.5-1597402935549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-c239d668-64b6-47d1-95b0-a5511448dc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-6fe0938d-7772-46e8-ad71-86ca37cee50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-6e758097-36da-4237-885a-15dc79e50264,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-e69e5b83-704d-42f4-9b1c-48409e30c424,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-172d2ed3-4981-4412-ad12-46e6afe772f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-6c910347-9423-493a-9773-a139cde0b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-d36dc512-7b3e-4383-9052-bfdb6dedefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-90f51ff2-601b-4d94-8833-f96abffaf2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092580016-172.17.0.5-1597403455513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-2f581a04-f6ee-41bc-927a-807cd9a6ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-071fa2d5-59d4-48ce-a060-2ca0c0d98e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-a655bceb-777c-49f6-803e-7b49e94f679f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-3be2981c-04e6-487c-a2bf-0596971abf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-112b31f8-ba44-4c27-ba0a-2b5c2dfe67e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-fa35f814-bfe8-4165-b5a4-4fcd519a276f,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-30c51e70-f5d0-4307-a7ff-a0ad929da956,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-007fe531-0570-4436-a81e-c72e6794231d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092580016-172.17.0.5-1597403455513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-2f581a04-f6ee-41bc-927a-807cd9a6ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-071fa2d5-59d4-48ce-a060-2ca0c0d98e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-a655bceb-777c-49f6-803e-7b49e94f679f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-3be2981c-04e6-487c-a2bf-0596971abf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-112b31f8-ba44-4c27-ba0a-2b5c2dfe67e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-fa35f814-bfe8-4165-b5a4-4fcd519a276f,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-30c51e70-f5d0-4307-a7ff-a0ad929da956,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-007fe531-0570-4436-a81e-c72e6794231d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933861373-172.17.0.5-1597403579242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36587,DS-f870e740-8b6f-4249-a5c0-8fc2b024d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-c53ef35d-b88c-40f2-ac2d-4571f9086149,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-315c1ff7-abb5-4b7a-8e58-4ec1b703c019,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-21293cda-00a6-4403-90c6-4b490447557c,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d75aec73-54aa-4f1b-a39d-9b4bd42b9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-63262f5d-267a-4a59-a5aa-82ed4bb4e946,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-e8ac4b8c-b5d1-41b9-a3e0-7f80d08cc13f,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b37689c9-5622-4723-9aaa-1e94475d2b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933861373-172.17.0.5-1597403579242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36587,DS-f870e740-8b6f-4249-a5c0-8fc2b024d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-c53ef35d-b88c-40f2-ac2d-4571f9086149,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-315c1ff7-abb5-4b7a-8e58-4ec1b703c019,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-21293cda-00a6-4403-90c6-4b490447557c,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d75aec73-54aa-4f1b-a39d-9b4bd42b9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-63262f5d-267a-4a59-a5aa-82ed4bb4e946,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-e8ac4b8c-b5d1-41b9-a3e0-7f80d08cc13f,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b37689c9-5622-4723-9aaa-1e94475d2b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273691758-172.17.0.5-1597403661185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-ce0ee355-932a-4e8a-a4ec-618b7a81afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-076ceea6-28af-4199-b0e2-aa398791202b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-023f8d36-1923-4940-9a3c-c968a766110e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-392edff0-2986-4128-a7a7-608311f4c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9f67ddb8-b634-4fcd-ac0e-e952d0e18c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-0f694630-5afb-43cf-8a2e-6d53f1548453,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-ae4f91ec-7204-4ea7-b1d7-4aefe7fb4dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-d4f04414-bf41-4de5-92a0-f70717e3b649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273691758-172.17.0.5-1597403661185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-ce0ee355-932a-4e8a-a4ec-618b7a81afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-076ceea6-28af-4199-b0e2-aa398791202b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-023f8d36-1923-4940-9a3c-c968a766110e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-392edff0-2986-4128-a7a7-608311f4c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9f67ddb8-b634-4fcd-ac0e-e952d0e18c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-0f694630-5afb-43cf-8a2e-6d53f1548453,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-ae4f91ec-7204-4ea7-b1d7-4aefe7fb4dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-d4f04414-bf41-4de5-92a0-f70717e3b649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268021814-172.17.0.5-1597403698535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-a10cd40f-0863-464a-a98c-d304d130cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-db1b74f2-1cc7-486a-96b1-45e98727f416,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-9165dd91-3f23-460c-98b6-f83a046b1002,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2a9eb90a-47c1-448d-b605-cf938cc5b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c1297b56-b46e-4298-b3a0-4c707e98006e,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-4acb74b4-aba9-4466-8dff-5eaa7c8c3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-c79eb295-632f-495f-9eb0-4af021582700,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-d6af0bff-8988-4d2c-9228-87411b13ef6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268021814-172.17.0.5-1597403698535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-a10cd40f-0863-464a-a98c-d304d130cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-db1b74f2-1cc7-486a-96b1-45e98727f416,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-9165dd91-3f23-460c-98b6-f83a046b1002,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2a9eb90a-47c1-448d-b605-cf938cc5b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c1297b56-b46e-4298-b3a0-4c707e98006e,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-4acb74b4-aba9-4466-8dff-5eaa7c8c3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-c79eb295-632f-495f-9eb0-4af021582700,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-d6af0bff-8988-4d2c-9228-87411b13ef6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830120051-172.17.0.5-1597404090356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-f48ab662-f787-4b30-96d7-6ed7dc392048,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7925212b-ed53-495d-8ea8-c232ca43526c,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-91eb6d60-55f1-4709-ae0f-e9a6b1eb7940,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-583b339c-0b2d-4419-baa8-5e9d74c6ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-c5c0bec1-9da2-48ec-af8d-7166aa3b9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-2b60b80b-cc85-469a-bcd2-e4c423157f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6565580b-b556-4ff8-990a-665737eb9d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-f07b8b23-5eb7-4c79-bf24-f2a4ee2e15a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830120051-172.17.0.5-1597404090356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-f48ab662-f787-4b30-96d7-6ed7dc392048,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7925212b-ed53-495d-8ea8-c232ca43526c,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-91eb6d60-55f1-4709-ae0f-e9a6b1eb7940,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-583b339c-0b2d-4419-baa8-5e9d74c6ad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-c5c0bec1-9da2-48ec-af8d-7166aa3b9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-2b60b80b-cc85-469a-bcd2-e4c423157f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6565580b-b556-4ff8-990a-665737eb9d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-f07b8b23-5eb7-4c79-bf24-f2a4ee2e15a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953846830-172.17.0.5-1597404893961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46320,DS-596cb085-d59e-487e-9103-f63517234991,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b687d3ee-2ee2-4ccc-b299-d468a73629d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-45e17fd2-c38f-4c61-81bd-1551bc6ae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-4ced0d93-9bde-4b31-b3aa-e6739e5ac153,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e302c56d-dd5b-4a4f-b211-ac9de163ea05,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-45e83f8b-718d-4550-89c3-a9d57accb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-cf03c02b-5678-46f9-be19-0ba155e128db,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-edda35eb-5470-4ee6-9178-77fe9a7b0565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953846830-172.17.0.5-1597404893961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46320,DS-596cb085-d59e-487e-9103-f63517234991,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b687d3ee-2ee2-4ccc-b299-d468a73629d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-45e17fd2-c38f-4c61-81bd-1551bc6ae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-4ced0d93-9bde-4b31-b3aa-e6739e5ac153,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e302c56d-dd5b-4a4f-b211-ac9de163ea05,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-45e83f8b-718d-4550-89c3-a9d57accb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-cf03c02b-5678-46f9-be19-0ba155e128db,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-edda35eb-5470-4ee6-9178-77fe9a7b0565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726074508-172.17.0.5-1597405594402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-cc879f32-fbf7-4eaa-9a98-c505cbbef61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-9949de38-130a-4f3f-b4f3-4fbdfa78e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-2656b2d0-653a-42b3-8328-9b9b9f9eac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-5061453a-a639-4d58-b75a-1115f5fa4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-455e8dc8-0323-4d69-936d-23ec1ec21eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-c13f9561-feb0-47c4-9d9d-d36fd4700e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-b1d47740-3463-4e4c-b281-2b3a740abd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-5639fae4-5718-4d60-b6c5-cfc7389b8424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726074508-172.17.0.5-1597405594402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-cc879f32-fbf7-4eaa-9a98-c505cbbef61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-9949de38-130a-4f3f-b4f3-4fbdfa78e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-2656b2d0-653a-42b3-8328-9b9b9f9eac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-5061453a-a639-4d58-b75a-1115f5fa4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-455e8dc8-0323-4d69-936d-23ec1ec21eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-c13f9561-feb0-47c4-9d9d-d36fd4700e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-b1d47740-3463-4e4c-b281-2b3a740abd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-5639fae4-5718-4d60-b6c5-cfc7389b8424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931938273-172.17.0.5-1597406381370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-15bf4aa0-a585-4839-a544-100181b36fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-c519690d-795c-4b91-8cd1-5f7db3a7a278,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-41100f90-63bb-491a-9066-2bee1583b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-d2368658-0c52-419e-8f5e-aee9c11c7d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-6a263e18-d1e8-4a61-86fa-2bb40dff3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-31e04ec2-693c-4a6f-96cb-e1e462a1a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-b4c6ae8e-e962-48ae-822a-e53fbfa4dafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-2e0b4839-8998-47a9-8134-765186c62477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931938273-172.17.0.5-1597406381370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-15bf4aa0-a585-4839-a544-100181b36fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-c519690d-795c-4b91-8cd1-5f7db3a7a278,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-41100f90-63bb-491a-9066-2bee1583b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-d2368658-0c52-419e-8f5e-aee9c11c7d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-6a263e18-d1e8-4a61-86fa-2bb40dff3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-31e04ec2-693c-4a6f-96cb-e1e462a1a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-b4c6ae8e-e962-48ae-822a-e53fbfa4dafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-2e0b4839-8998-47a9-8134-765186c62477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947816850-172.17.0.5-1597407074627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-b1273230-dfe1-48b7-b0bd-7b2fb130baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-c5a5da67-45bb-4a81-8eb1-ca99711be6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-740497fa-8124-4429-a915-8b71a46add30,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-167e86f8-4c9a-4a54-91c1-c58fa3392d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-a5640843-fed3-494d-a659-d13ee89b6c82,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-914706ab-bfe9-4135-9c3b-568b54648886,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-1eef85e0-571a-4725-a0c7-eb1dda34664e,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-cd68af62-9188-4bf5-a9e4-ff653ca96141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947816850-172.17.0.5-1597407074627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-b1273230-dfe1-48b7-b0bd-7b2fb130baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-c5a5da67-45bb-4a81-8eb1-ca99711be6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-740497fa-8124-4429-a915-8b71a46add30,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-167e86f8-4c9a-4a54-91c1-c58fa3392d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-a5640843-fed3-494d-a659-d13ee89b6c82,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-914706ab-bfe9-4135-9c3b-568b54648886,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-1eef85e0-571a-4725-a0c7-eb1dda34664e,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-cd68af62-9188-4bf5-a9e4-ff653ca96141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313530762-172.17.0.5-1597407181748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-9589fd37-5387-4a27-8442-5f257a0a24d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-a3ba9967-54b4-4600-b541-1f79437d3403,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-61a8cd73-74be-41da-8571-049c56dc67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a6ed9505-20b3-487b-b124-f9b81ff5a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-8e583f86-eece-4a81-b826-c311932ad2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-46064706-0fd0-4ba0-bae5-a317c0fff1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-2cb3a43b-2546-4b12-927b-6cffb0a6481c,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-6b869ceb-356f-4df0-bad4-5aefa4cc63cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313530762-172.17.0.5-1597407181748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-9589fd37-5387-4a27-8442-5f257a0a24d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-a3ba9967-54b4-4600-b541-1f79437d3403,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-61a8cd73-74be-41da-8571-049c56dc67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a6ed9505-20b3-487b-b124-f9b81ff5a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-8e583f86-eece-4a81-b826-c311932ad2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-46064706-0fd0-4ba0-bae5-a317c0fff1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-2cb3a43b-2546-4b12-927b-6cffb0a6481c,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-6b869ceb-356f-4df0-bad4-5aefa4cc63cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327870881-172.17.0.5-1597407453657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-e49b2b3c-d38b-4a5b-9f0c-efaa3a77f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3adcbe55-56a0-4f3f-a526-cf32ff0301c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-d9af19e6-1608-4462-95fb-486ea95220ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-45971559-f798-48da-9b8c-84d098735d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-54132703-7c8f-4e01-b788-704c0f33c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-e7dd085b-2503-48ca-918e-1f981c5d4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-30e79dc1-3cec-406e-b31f-5dd560cbcb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-bc8b4671-284a-4abd-ae12-af76c41df1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327870881-172.17.0.5-1597407453657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-e49b2b3c-d38b-4a5b-9f0c-efaa3a77f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3adcbe55-56a0-4f3f-a526-cf32ff0301c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-d9af19e6-1608-4462-95fb-486ea95220ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-45971559-f798-48da-9b8c-84d098735d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-54132703-7c8f-4e01-b788-704c0f33c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-e7dd085b-2503-48ca-918e-1f981c5d4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-30e79dc1-3cec-406e-b31f-5dd560cbcb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-bc8b4671-284a-4abd-ae12-af76c41df1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706269073-172.17.0.5-1597407852544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-9944a173-89f4-4b19-94ad-7c66fe622388,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-fc3bd677-fd98-46de-a596-6fa9d096eab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-360000ca-9de8-428d-92dc-1134b5a655f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-de3374e7-efac-4bdf-9390-9f500b6672e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-a578ebb3-4335-4072-b66f-528ada2b59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2c180c41-253c-4512-9290-bda0ea41ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-10ba6400-e218-430d-97da-525279914b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2c93481e-6dd1-47ba-985c-24b198a1e523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706269073-172.17.0.5-1597407852544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-9944a173-89f4-4b19-94ad-7c66fe622388,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-fc3bd677-fd98-46de-a596-6fa9d096eab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-360000ca-9de8-428d-92dc-1134b5a655f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-de3374e7-efac-4bdf-9390-9f500b6672e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-a578ebb3-4335-4072-b66f-528ada2b59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2c180c41-253c-4512-9290-bda0ea41ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-10ba6400-e218-430d-97da-525279914b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2c93481e-6dd1-47ba-985c-24b198a1e523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5734
