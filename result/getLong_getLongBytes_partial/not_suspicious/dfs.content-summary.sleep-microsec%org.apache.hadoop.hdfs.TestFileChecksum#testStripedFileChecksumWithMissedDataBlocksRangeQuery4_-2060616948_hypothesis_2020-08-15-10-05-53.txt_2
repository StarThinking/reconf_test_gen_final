reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084353510-172.17.0.21-1597486048472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-5a4d2908-1e46-44ff-911a-02e554a8fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-e2b84e31-216b-4a56-b9c2-fe07e87e65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-516282f8-b9c3-4c91-8b65-99a3855064c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-f995cf97-7e44-46d1-b0f3-5828c96d946d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-dbb0ab09-c685-4ca3-a41d-5afcd9d8510b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-151d280f-bc1b-4347-9ccb-f284ce237067,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-c40b4ac2-59a9-4dd3-ac30-9329599a640d,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-9006456c-4387-4157-84c4-dc05dc8a97f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084353510-172.17.0.21-1597486048472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-5a4d2908-1e46-44ff-911a-02e554a8fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-e2b84e31-216b-4a56-b9c2-fe07e87e65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-516282f8-b9c3-4c91-8b65-99a3855064c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-f995cf97-7e44-46d1-b0f3-5828c96d946d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-dbb0ab09-c685-4ca3-a41d-5afcd9d8510b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-151d280f-bc1b-4347-9ccb-f284ce237067,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-c40b4ac2-59a9-4dd3-ac30-9329599a640d,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-9006456c-4387-4157-84c4-dc05dc8a97f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959622381-172.17.0.21-1597486330591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-89cc455b-a577-4b07-acdb-f9462dad3507,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-0a05f512-4353-4844-9551-17b9402c8423,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-dbd465a7-a367-47d7-8d04-3a2bd03da86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-7ecc85e7-3d8c-4e8c-963d-ca9f99b53220,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-7d11ebd0-236c-427a-9ded-cf679a4f4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0ba346c4-53a7-4cb8-b59d-6d28da669779,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9246b69a-2c91-4af1-8c9f-6648b98a66ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-92ed7645-d9c4-4796-b672-b594654da5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959622381-172.17.0.21-1597486330591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-89cc455b-a577-4b07-acdb-f9462dad3507,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-0a05f512-4353-4844-9551-17b9402c8423,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-dbd465a7-a367-47d7-8d04-3a2bd03da86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-7ecc85e7-3d8c-4e8c-963d-ca9f99b53220,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-7d11ebd0-236c-427a-9ded-cf679a4f4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0ba346c4-53a7-4cb8-b59d-6d28da669779,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9246b69a-2c91-4af1-8c9f-6648b98a66ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-92ed7645-d9c4-4796-b672-b594654da5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359300119-172.17.0.21-1597486483646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-b2ea97f3-c9fb-4d86-a521-358328341119,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-abadc52b-ec9d-466e-9c6d-ba980ec67874,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-e5c55b8f-232f-4209-83c0-ccf5043be4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-1ac239d0-492c-47bb-8323-4c3c8b603b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-54c6e5b3-a581-46f0-b040-d9215632ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-a32f0415-5f67-4c67-a4de-e1b7b714e475,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1db5880e-2db4-4327-ac39-3080bd8dc0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-53728574-9909-4e0b-882c-b74c70c3c32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359300119-172.17.0.21-1597486483646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-b2ea97f3-c9fb-4d86-a521-358328341119,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-abadc52b-ec9d-466e-9c6d-ba980ec67874,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-e5c55b8f-232f-4209-83c0-ccf5043be4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-1ac239d0-492c-47bb-8323-4c3c8b603b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-54c6e5b3-a581-46f0-b040-d9215632ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-a32f0415-5f67-4c67-a4de-e1b7b714e475,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1db5880e-2db4-4327-ac39-3080bd8dc0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-53728574-9909-4e0b-882c-b74c70c3c32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189474971-172.17.0.21-1597486895590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-3404cd72-3084-4b2c-9127-0580bb8ee708,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-a8c85036-ca8a-429c-8d23-7075e41f8732,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-2476aa20-d94b-4d98-bbb4-126ce8361a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-eee055ae-d9d1-45ef-b179-5e2c559af236,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-c3428513-1fdc-4910-bd60-d9a4a2b9b623,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-f88344bb-39ad-41f8-a714-5477f7106b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-aa5a8b47-a381-43bd-8900-f191563ee08a,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-bcaaa2be-d0f8-4cf5-b57a-24ec675f26b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189474971-172.17.0.21-1597486895590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-3404cd72-3084-4b2c-9127-0580bb8ee708,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-a8c85036-ca8a-429c-8d23-7075e41f8732,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-2476aa20-d94b-4d98-bbb4-126ce8361a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-eee055ae-d9d1-45ef-b179-5e2c559af236,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-c3428513-1fdc-4910-bd60-d9a4a2b9b623,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-f88344bb-39ad-41f8-a714-5477f7106b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-aa5a8b47-a381-43bd-8900-f191563ee08a,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-bcaaa2be-d0f8-4cf5-b57a-24ec675f26b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331601598-172.17.0.21-1597486936138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37229,DS-1267df9e-0dad-4f05-86c5-3f7acd9cb966,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-963b62fc-be7d-4d59-a24c-19627477a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-3c16e9ff-58bf-4d7c-97ba-ef8b43369a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-2e6afd11-52a8-4f06-a712-1b567caeabc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-2e7f0bd8-b577-4b4f-a34c-d4255044b233,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-e19a9f9e-01e3-4f0a-9e4b-3e3b83db9ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-2d8d94e4-2b1e-487d-8c1d-cc523737a229,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-bc824dd0-7467-42d9-a3c1-ddfc0628895d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331601598-172.17.0.21-1597486936138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37229,DS-1267df9e-0dad-4f05-86c5-3f7acd9cb966,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-963b62fc-be7d-4d59-a24c-19627477a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-3c16e9ff-58bf-4d7c-97ba-ef8b43369a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-2e6afd11-52a8-4f06-a712-1b567caeabc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-2e7f0bd8-b577-4b4f-a34c-d4255044b233,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-e19a9f9e-01e3-4f0a-9e4b-3e3b83db9ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-2d8d94e4-2b1e-487d-8c1d-cc523737a229,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-bc824dd0-7467-42d9-a3c1-ddfc0628895d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388256982-172.17.0.21-1597487634348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-d5245db7-5c39-4ecf-a359-7c851042a4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-b6aeb512-5c4a-4240-b924-5d519a9e5043,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-84be61d7-3674-4515-966a-ebb1df6c0be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-df7778f2-bfd8-4046-97be-1b7f211f06f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-c35bd8fa-a0cc-41c8-a69d-7a6d8ae571d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-962c7260-2cda-4be7-8892-5fedaf084bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-6de5d354-4872-4b79-b576-a52951e329a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-4e2af27b-1b11-48c5-9ac7-7c7121797b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388256982-172.17.0.21-1597487634348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-d5245db7-5c39-4ecf-a359-7c851042a4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-b6aeb512-5c4a-4240-b924-5d519a9e5043,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-84be61d7-3674-4515-966a-ebb1df6c0be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-df7778f2-bfd8-4046-97be-1b7f211f06f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-c35bd8fa-a0cc-41c8-a69d-7a6d8ae571d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-962c7260-2cda-4be7-8892-5fedaf084bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-6de5d354-4872-4b79-b576-a52951e329a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-4e2af27b-1b11-48c5-9ac7-7c7121797b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418704252-172.17.0.21-1597487929806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-1f2b5161-b02e-47f0-87e5-88cb49cf8673,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-adef8e8a-613b-4ac1-85ce-dda0b9efc94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-730d5d3d-5a36-428c-ab42-3848ea08ec10,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-d17e40de-76b0-4ffa-a281-191d91035ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-4058cb2c-5bac-4310-8e16-97c4f114fb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c8181874-18e0-4a32-b594-638b061891d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-79bfebe0-44b0-48df-9bd2-4b3d7728530b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-8d655952-a5d6-4ae4-b1e3-c2bd6b182204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418704252-172.17.0.21-1597487929806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-1f2b5161-b02e-47f0-87e5-88cb49cf8673,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-adef8e8a-613b-4ac1-85ce-dda0b9efc94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-730d5d3d-5a36-428c-ab42-3848ea08ec10,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-d17e40de-76b0-4ffa-a281-191d91035ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-4058cb2c-5bac-4310-8e16-97c4f114fb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c8181874-18e0-4a32-b594-638b061891d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-79bfebe0-44b0-48df-9bd2-4b3d7728530b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-8d655952-a5d6-4ae4-b1e3-c2bd6b182204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380530508-172.17.0.21-1597488484216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33265,DS-67e8e572-32bf-4903-baf6-9a02d493daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5b4827e2-753b-4103-9000-17188856a770,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-edcf1c22-40cc-4930-8dee-49320858e17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-6dc200ab-545a-47e3-b17a-4c62bf1b13dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-cbb38c5d-554b-4c62-bf22-c948d27975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-8e7b2eca-a6ab-486e-8ff5-9efff76d9553,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-aed20d77-9fc0-4304-8b29-8f717868f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-bdf3539b-84f2-43d1-9816-294c850efea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380530508-172.17.0.21-1597488484216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33265,DS-67e8e572-32bf-4903-baf6-9a02d493daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5b4827e2-753b-4103-9000-17188856a770,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-edcf1c22-40cc-4930-8dee-49320858e17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-6dc200ab-545a-47e3-b17a-4c62bf1b13dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-cbb38c5d-554b-4c62-bf22-c948d27975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-8e7b2eca-a6ab-486e-8ff5-9efff76d9553,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-aed20d77-9fc0-4304-8b29-8f717868f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-bdf3539b-84f2-43d1-9816-294c850efea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346947219-172.17.0.21-1597488783963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-d9494c42-6118-420b-b278-442d0f0d4935,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-ee61f775-a237-491a-b23a-00bacc77f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-6a0feee7-9580-4b8c-9868-d07463933a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-74941171-e27d-4e6a-810e-804921008e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b797c4fa-6ee9-4091-8407-3276e1210a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-2426a9db-7001-4225-98bf-70324872d213,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-eaf80f71-62c6-4030-83b7-dd4a88431164,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-bd002df1-5289-495a-8275-0282bd688157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346947219-172.17.0.21-1597488783963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-d9494c42-6118-420b-b278-442d0f0d4935,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-ee61f775-a237-491a-b23a-00bacc77f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-6a0feee7-9580-4b8c-9868-d07463933a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-74941171-e27d-4e6a-810e-804921008e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b797c4fa-6ee9-4091-8407-3276e1210a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-2426a9db-7001-4225-98bf-70324872d213,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-eaf80f71-62c6-4030-83b7-dd4a88431164,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-bd002df1-5289-495a-8275-0282bd688157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92314674-172.17.0.21-1597489348790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-a8e35613-737d-4d67-b9e3-bbbcd0e7824d,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-3044fca0-5b0f-4816-8673-6d8aafcb2376,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-7f1b8317-5714-47c4-b375-33ebd6819657,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-d6e6cab3-f4a3-419e-b54b-4650964b7481,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-3c5b7b78-9ab0-4a38-bfa2-9bf0af87b39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-61eeba6d-53c3-44d2-9c50-710130d092e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-9b5b1011-656d-4dba-b07b-bb0cd6bfafc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-ce8725ef-63f7-456d-8375-dccc7d4f38e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92314674-172.17.0.21-1597489348790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-a8e35613-737d-4d67-b9e3-bbbcd0e7824d,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-3044fca0-5b0f-4816-8673-6d8aafcb2376,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-7f1b8317-5714-47c4-b375-33ebd6819657,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-d6e6cab3-f4a3-419e-b54b-4650964b7481,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-3c5b7b78-9ab0-4a38-bfa2-9bf0af87b39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-61eeba6d-53c3-44d2-9c50-710130d092e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-9b5b1011-656d-4dba-b07b-bb0cd6bfafc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-ce8725ef-63f7-456d-8375-dccc7d4f38e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077482951-172.17.0.21-1597489894263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-2f5ac808-d39a-46fd-8fdc-3a9fe021c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-275a4742-81a5-406e-8010-f4adedbd3150,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-05268c25-743e-46e3-9f8b-6280623d0ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b2a44d88-5205-41b2-b458-0f792294b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-58d3b6ed-1b65-416b-b57d-696e8298bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-ed050d8d-59db-4458-a945-34341cb8bd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-1947d9d2-9791-4bcb-8437-a0576367fc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-eccafae2-1cc9-4508-a8b5-b4cda93ba209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077482951-172.17.0.21-1597489894263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-2f5ac808-d39a-46fd-8fdc-3a9fe021c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-275a4742-81a5-406e-8010-f4adedbd3150,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-05268c25-743e-46e3-9f8b-6280623d0ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b2a44d88-5205-41b2-b458-0f792294b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-58d3b6ed-1b65-416b-b57d-696e8298bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-ed050d8d-59db-4458-a945-34341cb8bd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-1947d9d2-9791-4bcb-8437-a0576367fc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-eccafae2-1cc9-4508-a8b5-b4cda93ba209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877171586-172.17.0.21-1597490126418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-201b72c3-3c88-4457-a595-d002c4282b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-08049551-5eed-410e-b624-67f786900f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-859a43d0-7b04-4e9c-8eb3-eacc47b978aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-397d6e14-f4cc-4b18-bd25-0c787a0639be,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-a8fd5955-ae5c-45c5-9e9e-9e876a76826e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-5a216547-b201-4ca4-a0f8-a70210730ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-265814d9-923c-4f23-b096-5a5fd3373aea,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2258a8d5-2443-48a7-8f8d-1ae37e987384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877171586-172.17.0.21-1597490126418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-201b72c3-3c88-4457-a595-d002c4282b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-08049551-5eed-410e-b624-67f786900f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-859a43d0-7b04-4e9c-8eb3-eacc47b978aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-397d6e14-f4cc-4b18-bd25-0c787a0639be,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-a8fd5955-ae5c-45c5-9e9e-9e876a76826e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-5a216547-b201-4ca4-a0f8-a70210730ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-265814d9-923c-4f23-b096-5a5fd3373aea,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2258a8d5-2443-48a7-8f8d-1ae37e987384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631081543-172.17.0.21-1597490171833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-35694e52-acc2-4b82-a552-3f85d255724f,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-845e8016-01e5-4163-93b7-03e90549a955,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-5ee0dbb2-ea28-49c3-a1f0-e28723510207,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-61ef5ddc-dac3-4e13-8651-6a3c431b42c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-ba014af4-7335-45e8-a092-e3d7f3757c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-5d324c4f-8e80-4c91-8ab2-9f354b828a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-fd4d2c75-8980-4d28-8bb4-79407d369e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-98e9f8d7-a7fc-4ce7-9e21-26c51cb4300a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631081543-172.17.0.21-1597490171833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-35694e52-acc2-4b82-a552-3f85d255724f,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-845e8016-01e5-4163-93b7-03e90549a955,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-5ee0dbb2-ea28-49c3-a1f0-e28723510207,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-61ef5ddc-dac3-4e13-8651-6a3c431b42c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-ba014af4-7335-45e8-a092-e3d7f3757c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-5d324c4f-8e80-4c91-8ab2-9f354b828a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-fd4d2c75-8980-4d28-8bb4-79407d369e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-98e9f8d7-a7fc-4ce7-9e21-26c51cb4300a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87996440-172.17.0.21-1597490433153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46848,DS-5329ee4f-7ec7-415c-82c5-21dccf519d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-5314a2ff-2d5d-4a43-b58a-010d4e412183,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-fc67f9b7-58e4-4260-875e-3965e860ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-570a16af-8de3-44e1-8061-eacac395c128,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-00c39951-51d3-4602-bc49-bf8adf3fa942,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-47b5a5b5-46c9-4537-b131-8726b76fe3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-b0bd0043-7c62-4761-b69e-59fcc3a4a490,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-b94c1770-16df-4bc4-9756-5f576dda70dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87996440-172.17.0.21-1597490433153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46848,DS-5329ee4f-7ec7-415c-82c5-21dccf519d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-5314a2ff-2d5d-4a43-b58a-010d4e412183,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-fc67f9b7-58e4-4260-875e-3965e860ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-570a16af-8de3-44e1-8061-eacac395c128,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-00c39951-51d3-4602-bc49-bf8adf3fa942,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-47b5a5b5-46c9-4537-b131-8726b76fe3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-b0bd0043-7c62-4761-b69e-59fcc3a4a490,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-b94c1770-16df-4bc4-9756-5f576dda70dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566339702-172.17.0.21-1597491235367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-e90f56d3-fab5-41d4-8adc-b1a600f65f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-116f00f2-c414-41f0-ac83-c8098c007ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-daf35bfc-0fe2-4408-bcc3-fc8f4cd4e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-b854afb5-2c8a-4929-a81c-a35bdb8a1f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-01963e4f-0b38-4332-a71d-d480411a0639,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-81034e7b-0962-46be-86d2-296607bf315a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-08aa6e0c-56bb-4ce2-bc4f-3425bfe40cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-f4196126-f120-46c6-83ba-0c90dac2a33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566339702-172.17.0.21-1597491235367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-e90f56d3-fab5-41d4-8adc-b1a600f65f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-116f00f2-c414-41f0-ac83-c8098c007ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-daf35bfc-0fe2-4408-bcc3-fc8f4cd4e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-b854afb5-2c8a-4929-a81c-a35bdb8a1f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-01963e4f-0b38-4332-a71d-d480411a0639,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-81034e7b-0962-46be-86d2-296607bf315a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-08aa6e0c-56bb-4ce2-bc4f-3425bfe40cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-f4196126-f120-46c6-83ba-0c90dac2a33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320862715-172.17.0.21-1597491473999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41835,DS-9b9cf90a-9ef5-4899-b0c8-f9eaeb7f947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-504c6a45-a776-44b4-91c5-15072426a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-67f65a6a-19f3-4a46-8319-1dae14e1420a,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-72dc878b-1d17-4738-9cd2-184f3ed67b48,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-e3f51014-24f1-401b-bad5-19663433e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-fe4da7be-3556-4075-a076-5c50bad68fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-dd18f048-3161-49b2-9219-f4ad29ab667d,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-9c8b1cfd-ee2c-4123-b3fc-bfc1a53c6127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320862715-172.17.0.21-1597491473999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41835,DS-9b9cf90a-9ef5-4899-b0c8-f9eaeb7f947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-504c6a45-a776-44b4-91c5-15072426a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-67f65a6a-19f3-4a46-8319-1dae14e1420a,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-72dc878b-1d17-4738-9cd2-184f3ed67b48,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-e3f51014-24f1-401b-bad5-19663433e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-fe4da7be-3556-4075-a076-5c50bad68fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-dd18f048-3161-49b2-9219-f4ad29ab667d,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-9c8b1cfd-ee2c-4123-b3fc-bfc1a53c6127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5646
