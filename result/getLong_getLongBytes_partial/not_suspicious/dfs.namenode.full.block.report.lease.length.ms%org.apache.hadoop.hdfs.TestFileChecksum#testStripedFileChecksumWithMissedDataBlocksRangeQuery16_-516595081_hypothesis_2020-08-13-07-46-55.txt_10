reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804583168-172.17.0.5-1597305104196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-411e9786-1634-4e6d-98e4-1ff5214ca688,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-a7985a8d-a35a-40bd-a9e1-e3bb7ca78b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b8e85c55-d485-4688-9e65-4e181462b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b14d6c30-2aee-42ff-a4f9-ce032195284e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-eb1fb171-7706-4f8b-97bf-cb2def6e46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-9da548ca-8284-48fb-a504-b6cd6e0d0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-c5f1ca54-ff86-444d-843c-f069c5d71cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-2062658b-cabb-4a9e-be83-278a98f2c32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804583168-172.17.0.5-1597305104196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-411e9786-1634-4e6d-98e4-1ff5214ca688,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-a7985a8d-a35a-40bd-a9e1-e3bb7ca78b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b8e85c55-d485-4688-9e65-4e181462b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b14d6c30-2aee-42ff-a4f9-ce032195284e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-eb1fb171-7706-4f8b-97bf-cb2def6e46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-9da548ca-8284-48fb-a504-b6cd6e0d0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-c5f1ca54-ff86-444d-843c-f069c5d71cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-2062658b-cabb-4a9e-be83-278a98f2c32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065677533-172.17.0.5-1597305423582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-8234367d-8cac-47f5-a25f-3b54a35ca328,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-76255fe0-05b9-4019-8add-48ecf212ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-ff04bac8-556e-4632-9f24-e0a49f7bd220,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-f58ebe5f-51aa-4b4b-9413-3213f120b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-4ab1a589-09aa-4987-aa47-e892b020364d,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-5fb2243d-eda0-4509-9008-33436772d060,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-7c7ce794-36f7-451d-ad6c-485453d955a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-2b9aed88-d4e6-4137-8f7f-611a9d214b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065677533-172.17.0.5-1597305423582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-8234367d-8cac-47f5-a25f-3b54a35ca328,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-76255fe0-05b9-4019-8add-48ecf212ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-ff04bac8-556e-4632-9f24-e0a49f7bd220,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-f58ebe5f-51aa-4b4b-9413-3213f120b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-4ab1a589-09aa-4987-aa47-e892b020364d,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-5fb2243d-eda0-4509-9008-33436772d060,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-7c7ce794-36f7-451d-ad6c-485453d955a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-2b9aed88-d4e6-4137-8f7f-611a9d214b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453346548-172.17.0.5-1597306068726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42432,DS-e5e39e8c-cf39-4253-b107-e4dd892264c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-ec09d982-3544-4d50-b0fe-68c923fc6654,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-2a5175c3-923b-4a71-9d81-c829fba8f115,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-5a786286-0f8a-4e58-8ee8-5cb8f90eb557,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3df20505-8d92-4a6d-9094-86ee66c80f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-287067db-d4c8-4282-a96a-0575629998d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-346636c4-f4d0-4c17-9e6a-2f3038da05d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a5b4580a-ff55-44c0-adff-fb3e91861c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453346548-172.17.0.5-1597306068726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42432,DS-e5e39e8c-cf39-4253-b107-e4dd892264c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-ec09d982-3544-4d50-b0fe-68c923fc6654,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-2a5175c3-923b-4a71-9d81-c829fba8f115,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-5a786286-0f8a-4e58-8ee8-5cb8f90eb557,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3df20505-8d92-4a6d-9094-86ee66c80f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-287067db-d4c8-4282-a96a-0575629998d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-346636c4-f4d0-4c17-9e6a-2f3038da05d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a5b4580a-ff55-44c0-adff-fb3e91861c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982641464-172.17.0.5-1597306264659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-0bf676b6-713b-4f99-9759-601b63179857,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-dacaf4bf-cbf3-482e-83de-a682a423561c,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-de78e208-4bbc-4600-bba7-1e8694c01185,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-1054bb9a-72cf-4f1a-b4ab-b5eb50c5c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-9beb5f9d-3b10-427b-808f-995d0d664edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-26046f35-c888-41af-bdf4-b1dfeefc4f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-e6448dd2-da39-4cde-b1d5-3cfa1cbab1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-5e05e77e-b194-49fc-b367-1de836b9f886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982641464-172.17.0.5-1597306264659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-0bf676b6-713b-4f99-9759-601b63179857,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-dacaf4bf-cbf3-482e-83de-a682a423561c,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-de78e208-4bbc-4600-bba7-1e8694c01185,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-1054bb9a-72cf-4f1a-b4ab-b5eb50c5c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-9beb5f9d-3b10-427b-808f-995d0d664edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-26046f35-c888-41af-bdf4-b1dfeefc4f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-e6448dd2-da39-4cde-b1d5-3cfa1cbab1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-5e05e77e-b194-49fc-b367-1de836b9f886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625904639-172.17.0.5-1597306374744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-b44feccc-2bdc-4358-b132-9b5264bfe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-96d60580-806b-49be-903a-3a0542aee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e8da5385-bb87-4ffd-b6f9-2a1a991236c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ae8a888c-9eaa-42ed-bd89-78f30850554a,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f2dc2e83-7ac6-4476-a25c-48bed50e0270,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-c49088a9-e5b3-465a-9a25-9a198adcfd29,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-16107e0c-773a-42cf-aba4-654d0c9bb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d2ce94e9-51f3-4133-84a1-960fb2559d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625904639-172.17.0.5-1597306374744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-b44feccc-2bdc-4358-b132-9b5264bfe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-96d60580-806b-49be-903a-3a0542aee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e8da5385-bb87-4ffd-b6f9-2a1a991236c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ae8a888c-9eaa-42ed-bd89-78f30850554a,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f2dc2e83-7ac6-4476-a25c-48bed50e0270,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-c49088a9-e5b3-465a-9a25-9a198adcfd29,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-16107e0c-773a-42cf-aba4-654d0c9bb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d2ce94e9-51f3-4133-84a1-960fb2559d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485818818-172.17.0.5-1597306954557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-46c44724-ece8-4295-b81f-9cef7f794580,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-200dad4f-6da7-4e94-b5c4-d18043ba8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-18e8a790-9b30-487e-aadb-955706d57e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-9de664b4-e0aa-4cea-a25b-46e351857f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-30d30a43-42b6-45de-a2fb-ca97e0f9a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-0ebae4db-da23-41f2-b379-4c94ebd9a066,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a76302aa-4a4e-4297-b26f-eda28b7954fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-45dce610-6fd0-4e95-aed9-7bb6009d494d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485818818-172.17.0.5-1597306954557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-46c44724-ece8-4295-b81f-9cef7f794580,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-200dad4f-6da7-4e94-b5c4-d18043ba8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-18e8a790-9b30-487e-aadb-955706d57e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-9de664b4-e0aa-4cea-a25b-46e351857f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-30d30a43-42b6-45de-a2fb-ca97e0f9a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-0ebae4db-da23-41f2-b379-4c94ebd9a066,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a76302aa-4a4e-4297-b26f-eda28b7954fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-45dce610-6fd0-4e95-aed9-7bb6009d494d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005646294-172.17.0.5-1597307242617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-e3e17103-2e2e-4c70-acd2-e1119184a271,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-073787d2-008d-4371-992d-ea7c012e10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-a4056189-d949-4c77-9ed0-f1af6aac24bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-48bac3f0-642c-424e-8086-e278a4b5213d,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-31c3ae69-92b2-471b-815e-9cb85e2b71a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-dc4efb70-7da5-4f46-a1c3-230085d134a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-5d7dbf5e-cfea-47dd-946e-39e72fb2990d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-6bad60db-4d9b-4fd6-bead-1fcf19fcb102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005646294-172.17.0.5-1597307242617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-e3e17103-2e2e-4c70-acd2-e1119184a271,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-073787d2-008d-4371-992d-ea7c012e10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-a4056189-d949-4c77-9ed0-f1af6aac24bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-48bac3f0-642c-424e-8086-e278a4b5213d,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-31c3ae69-92b2-471b-815e-9cb85e2b71a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-dc4efb70-7da5-4f46-a1c3-230085d134a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-5d7dbf5e-cfea-47dd-946e-39e72fb2990d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-6bad60db-4d9b-4fd6-bead-1fcf19fcb102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483440734-172.17.0.5-1597307457295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42201,DS-d0778c9e-eb1e-414f-8a69-2e33eaaad83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-dab2edf1-c5f9-4daf-8c35-ff64ad78f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8ba72407-ab20-491b-888b-03943e292b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-74504241-9684-4b53-ba8f-af95dda9f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-a9372c91-50e3-4cc8-bbe5-a6dbba86997c,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-b0fc820f-0743-4d5d-8671-412e6f3f0545,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-04293031-0a7d-4a98-bbaa-727d76c232b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-0f4e3d05-95af-4957-b27b-d906a134c707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483440734-172.17.0.5-1597307457295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42201,DS-d0778c9e-eb1e-414f-8a69-2e33eaaad83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-dab2edf1-c5f9-4daf-8c35-ff64ad78f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8ba72407-ab20-491b-888b-03943e292b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-74504241-9684-4b53-ba8f-af95dda9f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-a9372c91-50e3-4cc8-bbe5-a6dbba86997c,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-b0fc820f-0743-4d5d-8671-412e6f3f0545,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-04293031-0a7d-4a98-bbaa-727d76c232b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-0f4e3d05-95af-4957-b27b-d906a134c707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443522253-172.17.0.5-1597308036794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-f4cae8c3-551b-40da-ade6-bc4a2d9b26c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-496b7dd2-8849-4a68-8779-0eead41189dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-87fbfebd-9726-4159-9266-e6d04d630f71,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-171ad3dc-01aa-46aa-9e43-2a3617a443ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-92a2a83b-bf1e-423e-8a65-486dd6443467,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b78b81ff-6822-4633-a77e-b2b82b39c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ef6b1f8c-c014-4ad5-81d2-5589ca00ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5e2639ce-775a-4f81-9cb3-3dd3923af786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443522253-172.17.0.5-1597308036794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-f4cae8c3-551b-40da-ade6-bc4a2d9b26c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-496b7dd2-8849-4a68-8779-0eead41189dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-87fbfebd-9726-4159-9266-e6d04d630f71,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-171ad3dc-01aa-46aa-9e43-2a3617a443ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-92a2a83b-bf1e-423e-8a65-486dd6443467,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b78b81ff-6822-4633-a77e-b2b82b39c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ef6b1f8c-c014-4ad5-81d2-5589ca00ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5e2639ce-775a-4f81-9cb3-3dd3923af786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197740815-172.17.0.5-1597308243452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36919,DS-3463762c-5b35-45f5-9a8a-a57074ff6611,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-8315d95d-8066-4bf1-81d3-7ae05c49cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-342f2add-8a7b-4f0c-9955-04d17e8107a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-49070078-1b3f-4d28-a4c8-734534ee1aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-0d46a7a7-e5e5-4eb1-911f-ef9a3ec1fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-3855e7a8-1c68-44c8-8ffe-c83147cb7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-df909ab4-bf40-4a1c-a0d0-ae96d51ed854,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-801974f8-a62c-40e7-9586-4629c23a2e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197740815-172.17.0.5-1597308243452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36919,DS-3463762c-5b35-45f5-9a8a-a57074ff6611,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-8315d95d-8066-4bf1-81d3-7ae05c49cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-342f2add-8a7b-4f0c-9955-04d17e8107a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-49070078-1b3f-4d28-a4c8-734534ee1aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-0d46a7a7-e5e5-4eb1-911f-ef9a3ec1fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-3855e7a8-1c68-44c8-8ffe-c83147cb7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-df909ab4-bf40-4a1c-a0d0-ae96d51ed854,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-801974f8-a62c-40e7-9586-4629c23a2e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449893544-172.17.0.5-1597308274463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-0627833d-0282-4fb2-a696-aeae54a2b055,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-3443e161-1621-49c6-912d-032bcc0fe60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-6287d3a7-8037-4d8d-b6d0-3d3101d68642,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8b58497c-ee95-43f6-9509-def7f18dd950,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7f927272-064b-417e-ba3f-2d8c752f6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-0bb0c39e-7753-47cc-8908-27924d327990,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-0af05b5b-8d90-4cfc-b8f5-0019ed632451,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-bfd4e2d3-5ecc-4b5e-8b49-32dc694cc36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449893544-172.17.0.5-1597308274463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-0627833d-0282-4fb2-a696-aeae54a2b055,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-3443e161-1621-49c6-912d-032bcc0fe60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-6287d3a7-8037-4d8d-b6d0-3d3101d68642,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8b58497c-ee95-43f6-9509-def7f18dd950,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7f927272-064b-417e-ba3f-2d8c752f6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-0bb0c39e-7753-47cc-8908-27924d327990,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-0af05b5b-8d90-4cfc-b8f5-0019ed632451,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-bfd4e2d3-5ecc-4b5e-8b49-32dc694cc36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096242766-172.17.0.5-1597308456091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34427,DS-703e1cfc-d0d8-4800-b027-a62c1a0a89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-b5130a65-a261-4c77-b18c-bbb30715f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-5a413b9d-62a6-434c-b348-6557590392d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-03f1f648-6d95-4034-b89b-695a79d73f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-733c266c-ac9f-4c59-8a84-dd9f322877b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-00f29a5b-0e82-443b-b097-ec70325280cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-d9e18bac-be88-4210-9785-b3795afb88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-b0c2e68b-97d9-4d80-9958-504f3ceb2477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096242766-172.17.0.5-1597308456091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34427,DS-703e1cfc-d0d8-4800-b027-a62c1a0a89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-b5130a65-a261-4c77-b18c-bbb30715f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-5a413b9d-62a6-434c-b348-6557590392d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-03f1f648-6d95-4034-b89b-695a79d73f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-733c266c-ac9f-4c59-8a84-dd9f322877b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-00f29a5b-0e82-443b-b097-ec70325280cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-d9e18bac-be88-4210-9785-b3795afb88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-b0c2e68b-97d9-4d80-9958-504f3ceb2477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803785558-172.17.0.5-1597309199843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-43a0fae7-1629-4276-95e1-00bcdf71874a,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-1c9b58fb-7940-48e3-9a6e-84f8bde8d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-de01a8b7-5192-4f25-afdf-628387b8532a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-58b3a19e-65b3-4827-b50b-1089ae857af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a92cbb41-71e0-40b0-a483-9ac95d7b3247,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-24067b4f-5c52-46fa-b223-b451bbfedb88,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-d925b27c-389f-45f8-9f14-eae9d8946296,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-718cc2e6-6b78-4b22-b3aa-437e779e49dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803785558-172.17.0.5-1597309199843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-43a0fae7-1629-4276-95e1-00bcdf71874a,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-1c9b58fb-7940-48e3-9a6e-84f8bde8d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-de01a8b7-5192-4f25-afdf-628387b8532a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-58b3a19e-65b3-4827-b50b-1089ae857af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a92cbb41-71e0-40b0-a483-9ac95d7b3247,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-24067b4f-5c52-46fa-b223-b451bbfedb88,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-d925b27c-389f-45f8-9f14-eae9d8946296,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-718cc2e6-6b78-4b22-b3aa-437e779e49dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859082561-172.17.0.5-1597309747360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-49690bd2-dfac-424f-a13d-f227a3579b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-ca75235e-3aa0-4622-99dc-4226253b9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-06aac901-6602-4fe8-bbd5-b74655e5862d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-4066dbdb-8c4d-4b71-bcde-0b8b501949b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-50ddc79f-5043-4fb3-8fc2-0c64d473c994,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-1dd2a825-fcfb-472f-9906-24a1fcfa26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2cf14960-8428-4fab-8d6d-7d573b46570b,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a6dcf93e-c16e-45bc-97fc-27f0a229efc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859082561-172.17.0.5-1597309747360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-49690bd2-dfac-424f-a13d-f227a3579b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-ca75235e-3aa0-4622-99dc-4226253b9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-06aac901-6602-4fe8-bbd5-b74655e5862d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-4066dbdb-8c4d-4b71-bcde-0b8b501949b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-50ddc79f-5043-4fb3-8fc2-0c64d473c994,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-1dd2a825-fcfb-472f-9906-24a1fcfa26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2cf14960-8428-4fab-8d6d-7d573b46570b,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a6dcf93e-c16e-45bc-97fc-27f0a229efc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053695872-172.17.0.5-1597309919791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34883,DS-6a468760-98ea-4e0a-ba05-316d5e8af15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-10e66219-c38f-4ef4-92c3-4e7da5b10cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-6d88a244-f484-47ba-a255-59107ee52c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-b8580bad-1e18-4170-9ad4-599bd002e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-b8d90f43-5f80-461d-9c38-242563405e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-35e6b1f8-980c-4242-8030-262c32b180bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-394ec688-adf7-4711-935b-7a6f490bf69e,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-a03d38c4-1d3d-449e-a137-a0f57a408c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053695872-172.17.0.5-1597309919791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34883,DS-6a468760-98ea-4e0a-ba05-316d5e8af15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-10e66219-c38f-4ef4-92c3-4e7da5b10cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-6d88a244-f484-47ba-a255-59107ee52c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-b8580bad-1e18-4170-9ad4-599bd002e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-b8d90f43-5f80-461d-9c38-242563405e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-35e6b1f8-980c-4242-8030-262c32b180bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-394ec688-adf7-4711-935b-7a6f490bf69e,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-a03d38c4-1d3d-449e-a137-a0f57a408c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5376
