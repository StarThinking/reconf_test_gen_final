reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515823080-172.17.0.15-1597486813388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-71466e21-1f9f-4d1d-89d6-06d6cfa2199c,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-7dff28e4-87d1-4179-beac-b331130ac9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-0bc7238d-7174-4762-8d6c-d037a738c371,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-e1682a6a-654b-454b-9d15-cd58b5390bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4fabefbd-729a-4e4f-9c88-ef44aa73f132,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-6a3cb288-6e19-4fec-b31e-d393469c5465,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a8f9a35b-f762-4de1-93c6-8e82a998a547,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-3311e2a5-9ab1-49fd-bf25-aa46eaa4ad68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515823080-172.17.0.15-1597486813388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-71466e21-1f9f-4d1d-89d6-06d6cfa2199c,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-7dff28e4-87d1-4179-beac-b331130ac9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-0bc7238d-7174-4762-8d6c-d037a738c371,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-e1682a6a-654b-454b-9d15-cd58b5390bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4fabefbd-729a-4e4f-9c88-ef44aa73f132,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-6a3cb288-6e19-4fec-b31e-d393469c5465,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a8f9a35b-f762-4de1-93c6-8e82a998a547,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-3311e2a5-9ab1-49fd-bf25-aa46eaa4ad68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358658649-172.17.0.15-1597487235151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-98697fe7-573e-47a4-90bc-cad6624f2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-ac2fb919-5151-4b98-ab73-664ba61e6261,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c76ec3d7-cfb1-4cd2-a18a-1870c21af5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7667b478-d02b-40c6-bddd-582fc98b7887,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-69aeb92e-12e0-4804-9466-bb981223bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-f575187e-4f57-4248-a59b-5cfff44230c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-0dd93e86-7181-4e9b-94e6-1e8130b6973a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-4e594475-00b9-43d0-a6aa-5ff41cd13f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358658649-172.17.0.15-1597487235151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-98697fe7-573e-47a4-90bc-cad6624f2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-ac2fb919-5151-4b98-ab73-664ba61e6261,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c76ec3d7-cfb1-4cd2-a18a-1870c21af5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7667b478-d02b-40c6-bddd-582fc98b7887,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-69aeb92e-12e0-4804-9466-bb981223bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-f575187e-4f57-4248-a59b-5cfff44230c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-0dd93e86-7181-4e9b-94e6-1e8130b6973a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-4e594475-00b9-43d0-a6aa-5ff41cd13f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154694164-172.17.0.15-1597487339679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36104,DS-876bb81d-6ea8-41ed-b8d8-9599f605570c,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-a1c8d411-3764-4079-927b-54ed5b4c41de,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-9a5d374b-9356-4e32-bc34-42725d93e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-b3d8e449-61c0-4d7c-86f1-a42c72bef93f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-a57b6cb1-af79-44b2-8df3-a5ebbb9b6cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-9eb63a4f-66e1-42e6-93d4-0349e3f0838d,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-a181c3e7-af7f-4ddc-84ff-144a2d428a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-630fc27b-ca08-4089-ac7b-0c65057725e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154694164-172.17.0.15-1597487339679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36104,DS-876bb81d-6ea8-41ed-b8d8-9599f605570c,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-a1c8d411-3764-4079-927b-54ed5b4c41de,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-9a5d374b-9356-4e32-bc34-42725d93e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-b3d8e449-61c0-4d7c-86f1-a42c72bef93f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-a57b6cb1-af79-44b2-8df3-a5ebbb9b6cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-9eb63a4f-66e1-42e6-93d4-0349e3f0838d,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-a181c3e7-af7f-4ddc-84ff-144a2d428a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-630fc27b-ca08-4089-ac7b-0c65057725e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789331069-172.17.0.15-1597487763687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39880,DS-a668a351-6c9b-4085-af11-27d3e23fefa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-d1a7e695-1c88-4330-be65-3de46a301369,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-98bc86cd-6c14-4f5d-ac99-1f59e304d811,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-3e63880b-65cb-4b20-8c69-9a3d660179fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-7e1aa404-2828-42ac-aea6-bab551521f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-eac1b068-b39e-48e3-b667-ebd581fe2001,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-e373c66d-851e-4e2f-978a-8dbfe0de978e,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-92760779-1f5f-4308-b38a-fb1958bf5427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789331069-172.17.0.15-1597487763687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39880,DS-a668a351-6c9b-4085-af11-27d3e23fefa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-d1a7e695-1c88-4330-be65-3de46a301369,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-98bc86cd-6c14-4f5d-ac99-1f59e304d811,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-3e63880b-65cb-4b20-8c69-9a3d660179fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-7e1aa404-2828-42ac-aea6-bab551521f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-eac1b068-b39e-48e3-b667-ebd581fe2001,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-e373c66d-851e-4e2f-978a-8dbfe0de978e,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-92760779-1f5f-4308-b38a-fb1958bf5427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015628736-172.17.0.15-1597488281980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-352b45f1-e82e-43e0-ac40-d7c27aa0d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-ab24694f-671c-44c6-adee-e0768a5bb796,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-ecc258c9-16f0-4da4-8d53-c92b69ae3d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e9c513bb-56e3-4c86-aa08-ec7eed2eb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-3ccc5c64-af1c-47be-bdc8-9cde4c436272,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-0ac58c10-4a53-4d50-bd9e-d84b2cd2acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-857624f2-8c46-461d-926d-bbe64fa29fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f1271ea9-bb4c-4401-8409-62429bf3c646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015628736-172.17.0.15-1597488281980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-352b45f1-e82e-43e0-ac40-d7c27aa0d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-ab24694f-671c-44c6-adee-e0768a5bb796,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-ecc258c9-16f0-4da4-8d53-c92b69ae3d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e9c513bb-56e3-4c86-aa08-ec7eed2eb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-3ccc5c64-af1c-47be-bdc8-9cde4c436272,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-0ac58c10-4a53-4d50-bd9e-d84b2cd2acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-857624f2-8c46-461d-926d-bbe64fa29fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f1271ea9-bb4c-4401-8409-62429bf3c646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381500788-172.17.0.15-1597488395577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-3e0bbdef-21c5-4b1d-8395-54e06c225fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-ed43a8f6-d406-4914-841c-3a4be41be1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c72748c6-3156-4f36-a173-7345e2a82dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-cab83337-f469-4df4-8d98-9e4d425fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-bdf05471-6f29-4421-9215-3be59557996b,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-84e88048-2d4f-42e1-9672-3a4d7cff6283,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3ba8205a-7edc-4384-b130-57b753a9e528,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-c6cbe350-3dbb-42d9-a2f9-25c0ccca021f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381500788-172.17.0.15-1597488395577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-3e0bbdef-21c5-4b1d-8395-54e06c225fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-ed43a8f6-d406-4914-841c-3a4be41be1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c72748c6-3156-4f36-a173-7345e2a82dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-cab83337-f469-4df4-8d98-9e4d425fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-bdf05471-6f29-4421-9215-3be59557996b,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-84e88048-2d4f-42e1-9672-3a4d7cff6283,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3ba8205a-7edc-4384-b130-57b753a9e528,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-c6cbe350-3dbb-42d9-a2f9-25c0ccca021f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239684467-172.17.0.15-1597488989978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-f25f941a-a960-4887-9266-3140a4b073e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-609712cf-bc48-4bee-90ca-aa75b3c22e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-9dcad939-0cb2-4a80-8803-6ca59fe65b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-b285d2da-15e7-4c76-9578-6e58c81818e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-650f962b-5199-4f20-a1f8-cd4d6bfc2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-4f8def17-988a-4625-9e44-b8e8e475043a,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ecfdedd0-8039-4c0c-be68-0c10bb1c9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-5e727598-6254-4fce-9dce-c07deb3a6deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239684467-172.17.0.15-1597488989978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-f25f941a-a960-4887-9266-3140a4b073e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-609712cf-bc48-4bee-90ca-aa75b3c22e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-9dcad939-0cb2-4a80-8803-6ca59fe65b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-b285d2da-15e7-4c76-9578-6e58c81818e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-650f962b-5199-4f20-a1f8-cd4d6bfc2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-4f8def17-988a-4625-9e44-b8e8e475043a,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ecfdedd0-8039-4c0c-be68-0c10bb1c9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-5e727598-6254-4fce-9dce-c07deb3a6deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218575279-172.17.0.15-1597489446753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-42e49e9b-548e-402d-aaf1-4b1311c1dcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-d3ed39fc-c70f-4c1a-9f87-8d10c8ca8253,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-98792835-4fc6-4ee8-9431-215e296b5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-361fe87e-ae51-495d-802b-926bc3a600a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-5fb56fcb-d77e-4d9f-95b4-0d045f5ba053,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-5decce40-ea71-496f-a6b6-639eb3840dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-71df5bf8-6482-4a1d-8ef8-f3776ffe4a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b7407b47-0cb8-4ebe-b826-2474906552ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218575279-172.17.0.15-1597489446753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-42e49e9b-548e-402d-aaf1-4b1311c1dcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-d3ed39fc-c70f-4c1a-9f87-8d10c8ca8253,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-98792835-4fc6-4ee8-9431-215e296b5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-361fe87e-ae51-495d-802b-926bc3a600a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-5fb56fcb-d77e-4d9f-95b4-0d045f5ba053,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-5decce40-ea71-496f-a6b6-639eb3840dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-71df5bf8-6482-4a1d-8ef8-f3776ffe4a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b7407b47-0cb8-4ebe-b826-2474906552ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542815961-172.17.0.15-1597489721607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-0cb6731d-9df8-429d-be90-a4941a24bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-259a7c81-0674-4e8a-a021-7403c2c2c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b019e4e9-5b53-4d56-849a-05646eade30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-98a73d26-a478-4e65-b481-71e04a9b4238,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-9583d929-2cab-4be3-892d-e00c64416cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-d51e481c-9310-4871-acfb-a4dafefe06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-571e0631-f2cc-4dcc-b609-10501e074bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c14fbf0d-b689-40ba-abac-c1eb1a50f089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542815961-172.17.0.15-1597489721607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-0cb6731d-9df8-429d-be90-a4941a24bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-259a7c81-0674-4e8a-a021-7403c2c2c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b019e4e9-5b53-4d56-849a-05646eade30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-98a73d26-a478-4e65-b481-71e04a9b4238,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-9583d929-2cab-4be3-892d-e00c64416cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-d51e481c-9310-4871-acfb-a4dafefe06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-571e0631-f2cc-4dcc-b609-10501e074bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c14fbf0d-b689-40ba-abac-c1eb1a50f089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013709679-172.17.0.15-1597490374811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-42f113ac-7b9a-42c6-baab-f8e13de4ae87,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-8d054568-2d02-4e79-949a-5a210e6661cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-f9fb8c9f-1c0d-4f80-933b-b5795e0a5602,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-3e657b1c-e57a-4b87-af22-f2704c029fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-c3aa71a5-f737-4294-99ca-5dc6816bdc73,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c5ce4a83-6be9-4e5c-aab9-eb4fb1f22f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4bf02ef1-7221-4a40-957d-8e4abe140820,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-d1130a4f-53c3-4937-938f-46330de35190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013709679-172.17.0.15-1597490374811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-42f113ac-7b9a-42c6-baab-f8e13de4ae87,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-8d054568-2d02-4e79-949a-5a210e6661cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-f9fb8c9f-1c0d-4f80-933b-b5795e0a5602,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-3e657b1c-e57a-4b87-af22-f2704c029fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-c3aa71a5-f737-4294-99ca-5dc6816bdc73,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c5ce4a83-6be9-4e5c-aab9-eb4fb1f22f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4bf02ef1-7221-4a40-957d-8e4abe140820,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-d1130a4f-53c3-4937-938f-46330de35190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374827303-172.17.0.15-1597490555115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-9284894a-f8fc-4e43-9173-e33dec70b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-54f12d89-4cc6-4f84-bbe0-970a17461af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-59efc1ee-5bcb-45d8-a2ba-78749b9c0518,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-b8026b2e-8e97-4b6c-918c-35cd74daef48,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-483d37cc-d116-435c-950b-46102c263a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-4c028f5a-a931-4a2b-a456-b25e0ff229fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-e093e387-3a8a-49ba-85d0-c1bc3a353095,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f640f2e9-9dff-425f-9c8d-563520cbfc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374827303-172.17.0.15-1597490555115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-9284894a-f8fc-4e43-9173-e33dec70b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-54f12d89-4cc6-4f84-bbe0-970a17461af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-59efc1ee-5bcb-45d8-a2ba-78749b9c0518,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-b8026b2e-8e97-4b6c-918c-35cd74daef48,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-483d37cc-d116-435c-950b-46102c263a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-4c028f5a-a931-4a2b-a456-b25e0ff229fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-e093e387-3a8a-49ba-85d0-c1bc3a353095,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f640f2e9-9dff-425f-9c8d-563520cbfc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785827806-172.17.0.15-1597490970059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-b8199b31-5660-4aa0-94cc-b8b6b853ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ced8c37a-1979-4f80-a596-642be3783c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-48961784-0157-43c5-9889-45b88b6fb153,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-46846e04-d3b9-499f-8325-269b736c7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-2fc991ad-319b-4ab4-b6bd-8efe424c4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-f3d04000-964b-44f1-bae9-5b9d8b5a2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-84fbd4c6-9a87-45eb-9380-2b1401489566,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-c1887a10-32fb-4fd5-bc5a-10f5d918af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785827806-172.17.0.15-1597490970059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-b8199b31-5660-4aa0-94cc-b8b6b853ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ced8c37a-1979-4f80-a596-642be3783c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-48961784-0157-43c5-9889-45b88b6fb153,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-46846e04-d3b9-499f-8325-269b736c7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-2fc991ad-319b-4ab4-b6bd-8efe424c4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-f3d04000-964b-44f1-bae9-5b9d8b5a2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-84fbd4c6-9a87-45eb-9380-2b1401489566,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-c1887a10-32fb-4fd5-bc5a-10f5d918af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674868519-172.17.0.15-1597491324577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-4ba8d866-f99e-411d-a89d-68101eb196e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-8f7434ba-874e-4f00-b588-8e1bcb7934a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-67f57df7-4157-456b-94b0-f6a48324c983,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-ee9aa442-2da6-4daf-b5c3-a83a7470becd,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-4ebb8087-6f7d-4620-bf6b-9229b769c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-4023cb9a-be5d-44f0-89dc-11dd18ce9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f51cdd7e-84f2-4e12-a70a-d4b8aa9a8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-a402301b-44ec-4b9c-ad28-1e01e35684b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674868519-172.17.0.15-1597491324577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33457,DS-4ba8d866-f99e-411d-a89d-68101eb196e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-8f7434ba-874e-4f00-b588-8e1bcb7934a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-67f57df7-4157-456b-94b0-f6a48324c983,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-ee9aa442-2da6-4daf-b5c3-a83a7470becd,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-4ebb8087-6f7d-4620-bf6b-9229b769c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-4023cb9a-be5d-44f0-89dc-11dd18ce9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f51cdd7e-84f2-4e12-a70a-d4b8aa9a8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-a402301b-44ec-4b9c-ad28-1e01e35684b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545923685-172.17.0.15-1597491442736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-d261f726-4757-4a21-88f2-8d7c5885483e,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-573f6dcb-f206-413f-8d67-f5d6101c80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-f1992692-f923-4ff6-8d7f-30080a290c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-45aeec46-f8d5-430d-9ede-d1fd79141906,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-4cc46bde-6c9a-42d6-ba81-0b6cde911fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-96ef14e4-70dc-47d0-b9f6-160b47155c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-97becaa9-bb82-40b3-a5a8-111bd5138990,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-64257432-01d1-4d54-92a9-e35f78f2995f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545923685-172.17.0.15-1597491442736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-d261f726-4757-4a21-88f2-8d7c5885483e,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-573f6dcb-f206-413f-8d67-f5d6101c80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-f1992692-f923-4ff6-8d7f-30080a290c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-45aeec46-f8d5-430d-9ede-d1fd79141906,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-4cc46bde-6c9a-42d6-ba81-0b6cde911fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-96ef14e4-70dc-47d0-b9f6-160b47155c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-97becaa9-bb82-40b3-a5a8-111bd5138990,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-64257432-01d1-4d54-92a9-e35f78f2995f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376454363-172.17.0.15-1597492171574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-4162c8f0-7b9a-4bff-8c14-f7a0f8f4c393,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-3e24b058-b0d6-4f8e-aa8e-84851e791678,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-522a800e-ff5b-477c-88c9-24228cc9abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-3c62e69b-1353-4f89-8cc5-54ce6ebb42e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-8a79cf9d-1b9d-478d-9da4-8f396b0f2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-5df0435f-1d00-4a0e-ab4d-8bde52e063da,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-524572d3-8632-4ab2-9deb-f652a1b17410,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-b41f1b5a-e941-42bc-b4c7-effc2102949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376454363-172.17.0.15-1597492171574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-4162c8f0-7b9a-4bff-8c14-f7a0f8f4c393,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-3e24b058-b0d6-4f8e-aa8e-84851e791678,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-522a800e-ff5b-477c-88c9-24228cc9abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-3c62e69b-1353-4f89-8cc5-54ce6ebb42e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-8a79cf9d-1b9d-478d-9da4-8f396b0f2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-5df0435f-1d00-4a0e-ab4d-8bde52e063da,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-524572d3-8632-4ab2-9deb-f652a1b17410,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-b41f1b5a-e941-42bc-b4c7-effc2102949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5462
