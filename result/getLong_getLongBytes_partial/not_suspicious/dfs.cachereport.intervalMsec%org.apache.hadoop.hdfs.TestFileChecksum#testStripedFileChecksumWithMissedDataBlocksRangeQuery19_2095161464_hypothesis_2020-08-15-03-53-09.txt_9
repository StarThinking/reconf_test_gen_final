reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083726575-172.17.0.6-1597464582475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-8e4f8f0a-bf9f-42c1-bc75-5f944f22b005,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-18c58de0-289c-4d06-924f-cf7d69bde43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-84986aca-abc3-46ef-b567-7559aec3d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-219c3a23-9972-4f50-a5d3-2b5267309261,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-73102f0a-5dc6-43b2-8f8e-20d3c1a82419,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-95abf6f3-e9f5-489b-96a7-ca300458404f,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-d20c696e-2bd7-43f4-a5e5-d7a37600e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-3060431c-b681-46e6-ab95-957af2865152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083726575-172.17.0.6-1597464582475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-8e4f8f0a-bf9f-42c1-bc75-5f944f22b005,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-18c58de0-289c-4d06-924f-cf7d69bde43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-84986aca-abc3-46ef-b567-7559aec3d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-219c3a23-9972-4f50-a5d3-2b5267309261,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-73102f0a-5dc6-43b2-8f8e-20d3c1a82419,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-95abf6f3-e9f5-489b-96a7-ca300458404f,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-d20c696e-2bd7-43f4-a5e5-d7a37600e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-3060431c-b681-46e6-ab95-957af2865152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505618530-172.17.0.6-1597464711385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43001,DS-61cefbff-7dfc-4e94-a32e-d1fae94e352c,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-dc17d010-e8b7-4ad1-8647-7d8828ec6e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-a7df2d31-843f-4a97-b4f9-39080adfd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-abfba494-4de9-4b7d-b321-8092448e1a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-99330de3-6f01-4dd9-a849-ef01a75a8783,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-84598bc8-a946-4bb9-9c5f-97ba8cb561e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-1c2a4e9f-cbe0-49a6-a3c2-4f73b4c7e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0b6fa8d4-e155-4c9b-945a-e71817fcde36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505618530-172.17.0.6-1597464711385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43001,DS-61cefbff-7dfc-4e94-a32e-d1fae94e352c,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-dc17d010-e8b7-4ad1-8647-7d8828ec6e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-a7df2d31-843f-4a97-b4f9-39080adfd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-abfba494-4de9-4b7d-b321-8092448e1a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-99330de3-6f01-4dd9-a849-ef01a75a8783,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-84598bc8-a946-4bb9-9c5f-97ba8cb561e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-1c2a4e9f-cbe0-49a6-a3c2-4f73b4c7e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0b6fa8d4-e155-4c9b-945a-e71817fcde36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503855655-172.17.0.6-1597464898946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36001,DS-80e825ba-a7af-4a73-8db4-de29f2f6f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-3866538a-4b25-4868-b38e-42d0d3576f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-6f95dd2e-4249-49c6-bbe2-6599559b0df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-176bef3a-b8a2-4232-936c-e199b928ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-1c94774f-175f-4542-8c95-af2075ff6583,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-796dcedf-257d-47e0-ba83-a473ba3632a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-91c90eea-2968-48d4-87ef-a88a1366c404,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-9c1496d2-ea7f-43f3-a952-eb6b2c2a606b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503855655-172.17.0.6-1597464898946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36001,DS-80e825ba-a7af-4a73-8db4-de29f2f6f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-3866538a-4b25-4868-b38e-42d0d3576f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-6f95dd2e-4249-49c6-bbe2-6599559b0df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-176bef3a-b8a2-4232-936c-e199b928ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-1c94774f-175f-4542-8c95-af2075ff6583,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-796dcedf-257d-47e0-ba83-a473ba3632a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-91c90eea-2968-48d4-87ef-a88a1366c404,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-9c1496d2-ea7f-43f3-a952-eb6b2c2a606b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134338550-172.17.0.6-1597465105948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-05f15124-4489-4c8d-b959-0dece25b8ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a7b8c143-2d29-40be-bcc0-da0b2315c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-18b6677b-5b63-4f02-9379-5571a0de09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-d8f1f2f1-3cdb-4ff0-ae6b-398760b68607,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-0466b8ee-511b-40cd-a2c8-72fcf7df544d,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-d49b16c0-aaaa-48df-be25-8cdf0c9f003f,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-fb1c06da-f80f-4028-bce5-f1cf89738b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-322d6471-92b3-4f75-8322-510452c2e05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134338550-172.17.0.6-1597465105948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-05f15124-4489-4c8d-b959-0dece25b8ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a7b8c143-2d29-40be-bcc0-da0b2315c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-18b6677b-5b63-4f02-9379-5571a0de09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-d8f1f2f1-3cdb-4ff0-ae6b-398760b68607,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-0466b8ee-511b-40cd-a2c8-72fcf7df544d,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-d49b16c0-aaaa-48df-be25-8cdf0c9f003f,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-fb1c06da-f80f-4028-bce5-f1cf89738b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-322d6471-92b3-4f75-8322-510452c2e05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752991550-172.17.0.6-1597465309867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35510,DS-746d0d12-53f5-4f2c-9255-45f9c9e0ebf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-e730ae1a-6323-4e9c-ac18-22e97a2a260e,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-3a321bc6-51dc-486c-991e-faf63df257a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-d68801e8-55f2-46c3-9a19-a9b385060641,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-426630cb-fc0e-40f5-a91f-5bb4da603183,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-14b924b1-d601-4cd3-8cf8-4013c1584d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a9e41e3d-5985-4a92-9121-dea1c9d37a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-a265b842-f861-4719-a915-6f5094c0b0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752991550-172.17.0.6-1597465309867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35510,DS-746d0d12-53f5-4f2c-9255-45f9c9e0ebf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-e730ae1a-6323-4e9c-ac18-22e97a2a260e,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-3a321bc6-51dc-486c-991e-faf63df257a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-d68801e8-55f2-46c3-9a19-a9b385060641,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-426630cb-fc0e-40f5-a91f-5bb4da603183,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-14b924b1-d601-4cd3-8cf8-4013c1584d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a9e41e3d-5985-4a92-9121-dea1c9d37a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-a265b842-f861-4719-a915-6f5094c0b0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90184577-172.17.0.6-1597465494673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-107d2186-8c7a-4fde-be84-62e8c0a48b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-65a57cd5-ab66-4ec1-bb7e-082bb0605411,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-b0a4f253-0fc1-4578-ad82-d8e4c3d5b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-77a24ba7-13c5-4793-920b-aabb8d61f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-81d2f25f-75bd-4433-bce2-3374aaa19fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-7b85a38c-0554-405b-ba57-2dcb06dabf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0fc09f38-7cb0-4822-a711-48a5b6455433,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-f2b1fc2c-1e54-4cf5-b51a-4635985f216d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90184577-172.17.0.6-1597465494673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-107d2186-8c7a-4fde-be84-62e8c0a48b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-65a57cd5-ab66-4ec1-bb7e-082bb0605411,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-b0a4f253-0fc1-4578-ad82-d8e4c3d5b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-77a24ba7-13c5-4793-920b-aabb8d61f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-81d2f25f-75bd-4433-bce2-3374aaa19fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-7b85a38c-0554-405b-ba57-2dcb06dabf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0fc09f38-7cb0-4822-a711-48a5b6455433,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-f2b1fc2c-1e54-4cf5-b51a-4635985f216d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589200596-172.17.0.6-1597465778154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-81f68c5b-ca80-4c27-89b5-f927c790fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-f5cdf276-8f6b-4bd0-ac10-cc64a00e6706,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f980ef7c-7a0a-4d02-94bd-00319b810666,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0993f014-8458-4f19-920b-54cee7f3f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-132b7b63-1403-4703-860a-e89ffb0f4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-6713b22e-b24c-4fcd-b9d9-8bd0fa568f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-73aaffb3-bddb-4d5a-9efe-778df4ae8f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-73fe9af1-4c35-4bd9-a60b-76ad752df5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589200596-172.17.0.6-1597465778154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-81f68c5b-ca80-4c27-89b5-f927c790fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-f5cdf276-8f6b-4bd0-ac10-cc64a00e6706,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f980ef7c-7a0a-4d02-94bd-00319b810666,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0993f014-8458-4f19-920b-54cee7f3f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-132b7b63-1403-4703-860a-e89ffb0f4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-6713b22e-b24c-4fcd-b9d9-8bd0fa568f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-73aaffb3-bddb-4d5a-9efe-778df4ae8f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-73fe9af1-4c35-4bd9-a60b-76ad752df5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307445281-172.17.0.6-1597466074341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40363,DS-45f93154-4368-49a0-87a5-3ff2b05688a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-359ae468-edef-4da8-93e1-d63c0b1bc4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-36be6aea-4734-46f0-b495-5814401913f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-63fe6edd-aa0e-4671-be8f-eba124e3e60c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f69c7011-f94f-42e1-8b7e-76e4e12da32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-49846bf2-8cce-45a4-8f4c-82dd15703ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4a258747-a234-4016-920c-f5e30f745e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-c947fafb-01f8-4c47-8959-57ab7c02780a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307445281-172.17.0.6-1597466074341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40363,DS-45f93154-4368-49a0-87a5-3ff2b05688a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-359ae468-edef-4da8-93e1-d63c0b1bc4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-36be6aea-4734-46f0-b495-5814401913f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-63fe6edd-aa0e-4671-be8f-eba124e3e60c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f69c7011-f94f-42e1-8b7e-76e4e12da32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-49846bf2-8cce-45a4-8f4c-82dd15703ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4a258747-a234-4016-920c-f5e30f745e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-c947fafb-01f8-4c47-8959-57ab7c02780a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229755807-172.17.0.6-1597466203596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-ae3f413d-f340-4631-8857-99c97544e653,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-8a98f17c-0359-40d7-9bb6-413c5152e822,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-29b5bdb4-5459-4df4-a77c-f42a9016cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-9619c0e2-43b9-45f2-a410-a460ba3b3113,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-f92700ba-6534-475d-9a04-b3d11bc64f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-29c4c10c-a397-4046-bf4b-cc998fbe3573,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-078c599e-1543-4536-ad27-b0e2b0306a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-adfc4205-52d3-46aa-89be-b8168ab135dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229755807-172.17.0.6-1597466203596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-ae3f413d-f340-4631-8857-99c97544e653,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-8a98f17c-0359-40d7-9bb6-413c5152e822,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-29b5bdb4-5459-4df4-a77c-f42a9016cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-9619c0e2-43b9-45f2-a410-a460ba3b3113,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-f92700ba-6534-475d-9a04-b3d11bc64f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-29c4c10c-a397-4046-bf4b-cc998fbe3573,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-078c599e-1543-4536-ad27-b0e2b0306a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-adfc4205-52d3-46aa-89be-b8168ab135dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944245169-172.17.0.6-1597466955789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-c4c97ea0-9a6a-405a-b0d1-690db690bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c2d70068-93e1-4181-a6f8-b8d15ae3d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-67a09407-2446-4375-924d-17d54b7885e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-fa100662-786d-4315-9e0d-27fbb4845c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-3cdd497a-f5fd-4306-ae07-e59175e4676e,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-531c4eb4-60b5-4601-97e1-43e5c4a01c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-bb52f0ca-5803-4031-8370-d8e5d4bbbc42,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-5d668fc4-05a3-4cbf-9bce-f5584c96938a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944245169-172.17.0.6-1597466955789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-c4c97ea0-9a6a-405a-b0d1-690db690bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c2d70068-93e1-4181-a6f8-b8d15ae3d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-67a09407-2446-4375-924d-17d54b7885e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-fa100662-786d-4315-9e0d-27fbb4845c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-3cdd497a-f5fd-4306-ae07-e59175e4676e,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-531c4eb4-60b5-4601-97e1-43e5c4a01c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-bb52f0ca-5803-4031-8370-d8e5d4bbbc42,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-5d668fc4-05a3-4cbf-9bce-f5584c96938a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51273355-172.17.0.6-1597467341777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45620,DS-8592969b-62c0-415c-87d6-86a0aca55361,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-90af12c0-9600-4c49-bee6-f65379ce9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b2137e54-a7cb-4537-a851-3f6d7492e5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7e997fb9-d289-40ba-af87-ed5fb09f2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-da0a1ada-5eef-434c-bc2d-59966aeed307,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aab19ea3-7038-4fe4-9331-8e954a766fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-73c45efc-4d60-4ff3-bfca-639a03b3ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-ae523259-dec8-4ddf-a1c8-574c006c90a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51273355-172.17.0.6-1597467341777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45620,DS-8592969b-62c0-415c-87d6-86a0aca55361,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-90af12c0-9600-4c49-bee6-f65379ce9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b2137e54-a7cb-4537-a851-3f6d7492e5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7e997fb9-d289-40ba-af87-ed5fb09f2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-da0a1ada-5eef-434c-bc2d-59966aeed307,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aab19ea3-7038-4fe4-9331-8e954a766fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-73c45efc-4d60-4ff3-bfca-639a03b3ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-ae523259-dec8-4ddf-a1c8-574c006c90a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758135525-172.17.0.6-1597467937252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-3004f344-9b2e-4c9f-a4fe-3e1ad2435e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b3c1f5c8-84ea-4366-a381-2751b49e4122,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-a34eecc0-86ba-467c-a3d8-20946011c222,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-75ae24e1-4b4c-42b0-94b1-33e0e5a33e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-1a51a75b-b819-49d1-bb73-3f89c9316452,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-611c286e-aeec-4e2b-85a3-efa822e12167,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-2f2c55b1-39fb-4ba6-818b-8dacd113e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-0268eccc-0820-49ec-a080-06e430739771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758135525-172.17.0.6-1597467937252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-3004f344-9b2e-4c9f-a4fe-3e1ad2435e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b3c1f5c8-84ea-4366-a381-2751b49e4122,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-a34eecc0-86ba-467c-a3d8-20946011c222,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-75ae24e1-4b4c-42b0-94b1-33e0e5a33e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-1a51a75b-b819-49d1-bb73-3f89c9316452,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-611c286e-aeec-4e2b-85a3-efa822e12167,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-2f2c55b1-39fb-4ba6-818b-8dacd113e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-0268eccc-0820-49ec-a080-06e430739771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701792354-172.17.0.6-1597468114915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-1f49098c-0b13-4ec0-b850-8a2383106dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-451d7a78-da88-4ad1-a678-29dfb693286d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-528d0857-2bc7-4f4a-900f-bec2980d0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-e8abcb97-118b-44db-9123-0ad015a3afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9c34ef17-9fe6-42e3-8984-e2b6c1371519,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-a4cd70cb-ed88-42ed-aca3-dc84604aad68,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-6552b940-7480-476c-83ee-88507a8a73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-610bb1f3-2dbd-4bb0-954e-d9d7bf5ff400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701792354-172.17.0.6-1597468114915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-1f49098c-0b13-4ec0-b850-8a2383106dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-451d7a78-da88-4ad1-a678-29dfb693286d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-528d0857-2bc7-4f4a-900f-bec2980d0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-e8abcb97-118b-44db-9123-0ad015a3afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9c34ef17-9fe6-42e3-8984-e2b6c1371519,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-a4cd70cb-ed88-42ed-aca3-dc84604aad68,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-6552b940-7480-476c-83ee-88507a8a73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-610bb1f3-2dbd-4bb0-954e-d9d7bf5ff400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566749860-172.17.0.6-1597468150643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-54539ba8-1e1d-4940-b261-5fab14fc35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-96b13d57-b8b1-45da-9f58-86620310c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-df44e5dd-d48b-4fb7-af29-65d29b8392ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b2665709-8544-4c5f-8293-b80b670c12c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-cf571b5d-41cd-4c13-9fe5-6d438c16cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-2e38389f-191c-4c81-b6de-a23e9a59c8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-abb25f09-fb9b-4e27-a281-8596d7f3bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-ca5eaea4-e45c-4a84-baa2-c1b56b21f736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566749860-172.17.0.6-1597468150643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-54539ba8-1e1d-4940-b261-5fab14fc35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-96b13d57-b8b1-45da-9f58-86620310c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-df44e5dd-d48b-4fb7-af29-65d29b8392ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b2665709-8544-4c5f-8293-b80b670c12c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-cf571b5d-41cd-4c13-9fe5-6d438c16cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-2e38389f-191c-4c81-b6de-a23e9a59c8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-abb25f09-fb9b-4e27-a281-8596d7f3bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-ca5eaea4-e45c-4a84-baa2-c1b56b21f736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806203509-172.17.0.6-1597468298992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-c1a9b4ce-f75f-4923-bfe1-b1c8550731ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-8bd90f86-4176-46bc-b2fa-761489109fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-bf848b76-4d7c-42ca-9c07-5b3888cc7249,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-5d0be48e-05e8-43ad-bb37-4809ed815b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-d3c53576-2a67-44c6-a7b2-e8129523b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-59189874-d8eb-4aaa-b6c8-a61d9087810b,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-bdf1edf3-3ead-4c58-ae8e-d1cc4d0390c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-990dc5b9-b9c7-45bf-b03c-01594044d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806203509-172.17.0.6-1597468298992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-c1a9b4ce-f75f-4923-bfe1-b1c8550731ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-8bd90f86-4176-46bc-b2fa-761489109fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-bf848b76-4d7c-42ca-9c07-5b3888cc7249,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-5d0be48e-05e8-43ad-bb37-4809ed815b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-d3c53576-2a67-44c6-a7b2-e8129523b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-59189874-d8eb-4aaa-b6c8-a61d9087810b,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-bdf1edf3-3ead-4c58-ae8e-d1cc4d0390c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-990dc5b9-b9c7-45bf-b03c-01594044d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5284
