reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515345915-172.17.0.6-1597502468801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-0bb8dd8c-01e6-4738-a4d6-412181f8b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1ed95f2a-7276-49eb-8eb4-8a23b7ca4979,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-c1348bbc-e6d8-48b3-bf87-a91e17123c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-bf16be05-1dbe-4981-b4c0-2334843aa12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-3444125a-bfe4-4534-b61b-3d823caccb51,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a86e5c48-5284-4d14-a4e3-d614e16bb163,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-e807202e-5a51-4a84-957e-2d7c8d361791,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-a987048b-0e54-4ff2-9e67-8aa8197ec645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515345915-172.17.0.6-1597502468801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-0bb8dd8c-01e6-4738-a4d6-412181f8b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1ed95f2a-7276-49eb-8eb4-8a23b7ca4979,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-c1348bbc-e6d8-48b3-bf87-a91e17123c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-bf16be05-1dbe-4981-b4c0-2334843aa12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-3444125a-bfe4-4534-b61b-3d823caccb51,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a86e5c48-5284-4d14-a4e3-d614e16bb163,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-e807202e-5a51-4a84-957e-2d7c8d361791,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-a987048b-0e54-4ff2-9e67-8aa8197ec645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027334158-172.17.0.6-1597502563614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-42046d35-be17-416e-9dad-81e05c316b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-71240ab1-ec44-48dc-ae4b-946daf7e0ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-9f3964f4-fbe3-40f6-b7ff-adb7bbc89513,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a2a684e7-4e42-43a3-8de5-2cc9177137a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3b859e3b-13e5-4925-884e-4caa5f3380a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-8329ee5e-c8e2-4ced-9814-64fabf1c7e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-2aac3385-48bf-4ed3-894e-67978529e278,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-7e4031e5-4e96-4752-b4b2-d57b6a3d61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027334158-172.17.0.6-1597502563614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-42046d35-be17-416e-9dad-81e05c316b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-71240ab1-ec44-48dc-ae4b-946daf7e0ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-9f3964f4-fbe3-40f6-b7ff-adb7bbc89513,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a2a684e7-4e42-43a3-8de5-2cc9177137a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3b859e3b-13e5-4925-884e-4caa5f3380a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-8329ee5e-c8e2-4ced-9814-64fabf1c7e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-2aac3385-48bf-4ed3-894e-67978529e278,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-7e4031e5-4e96-4752-b4b2-d57b6a3d61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547201132-172.17.0.6-1597503066163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37694,DS-9c097253-9162-40a4-accd-76066e2ad8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-a79387d5-6ca0-485c-b6ef-3a5986364684,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-57834bc1-6473-4923-8e33-b90689f13b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8e2713b5-2dce-4440-a99b-9e3ef1e2dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-5d40319a-1e4a-4fe4-9b36-97438a17484d,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-3a603d46-b158-47f6-96be-b20cfed4f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-05e42393-e024-44e7-89c9-655fbccdeda6,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-9460871f-b7bc-4cf4-bf73-6c17a5b53748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547201132-172.17.0.6-1597503066163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37694,DS-9c097253-9162-40a4-accd-76066e2ad8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-a79387d5-6ca0-485c-b6ef-3a5986364684,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-57834bc1-6473-4923-8e33-b90689f13b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8e2713b5-2dce-4440-a99b-9e3ef1e2dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-5d40319a-1e4a-4fe4-9b36-97438a17484d,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-3a603d46-b158-47f6-96be-b20cfed4f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-05e42393-e024-44e7-89c9-655fbccdeda6,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-9460871f-b7bc-4cf4-bf73-6c17a5b53748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400675018-172.17.0.6-1597503614483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-9015c2bb-ef4a-4363-8519-e9336e3a680c,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9b5890c6-4aaf-4f4e-920f-5c8332739a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-b42ae2d1-e549-4a22-ae4b-bb1aed33e720,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-f55ee1c3-2c4a-4725-9d00-be8701d66dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-de4af3c8-8058-4211-a2a5-94b172d47d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-1167f25f-e4f2-446e-bcba-b2814f7d8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-eff9baf0-08af-4bbe-abdd-b11aad6fbb69,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-cbed4619-df86-40bc-ae94-60b92494bc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400675018-172.17.0.6-1597503614483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-9015c2bb-ef4a-4363-8519-e9336e3a680c,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9b5890c6-4aaf-4f4e-920f-5c8332739a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-b42ae2d1-e549-4a22-ae4b-bb1aed33e720,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-f55ee1c3-2c4a-4725-9d00-be8701d66dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-de4af3c8-8058-4211-a2a5-94b172d47d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-1167f25f-e4f2-446e-bcba-b2814f7d8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-eff9baf0-08af-4bbe-abdd-b11aad6fbb69,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-cbed4619-df86-40bc-ae94-60b92494bc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915972757-172.17.0.6-1597504018461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-fd61d0a3-de92-4709-9780-7684caebc952,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-447b5282-a2a9-43b3-b6bb-af467890a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-3ca9864f-9263-4953-aed7-0d9624caef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-dbd3c67a-8343-485e-a3d2-195df65c9634,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-e719854b-22cb-45d0-b09e-8e6964e0a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-374e3f49-564d-4db3-a443-17c0c44e927e,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-f9058014-7b9a-480f-a332-5a992190220a,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9b3f4d19-d4bf-4385-b9c2-f4d35860da66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915972757-172.17.0.6-1597504018461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-fd61d0a3-de92-4709-9780-7684caebc952,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-447b5282-a2a9-43b3-b6bb-af467890a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-3ca9864f-9263-4953-aed7-0d9624caef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-dbd3c67a-8343-485e-a3d2-195df65c9634,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-e719854b-22cb-45d0-b09e-8e6964e0a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-374e3f49-564d-4db3-a443-17c0c44e927e,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-f9058014-7b9a-480f-a332-5a992190220a,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9b3f4d19-d4bf-4385-b9c2-f4d35860da66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141795429-172.17.0.6-1597504289366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-647b3ecd-46c3-4868-ac50-bdcd944b1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-84ffc787-268b-414c-a5e2-c2e7e1676efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-b53aadae-9f6b-489e-9941-1436f01f081a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-e0982072-249a-4478-8b20-588f21f78e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-01ccb710-7f5b-48de-8678-a9782f0d976b,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-a8d7b209-8d15-4afe-a4af-a57ea4bae877,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7394307d-5d8a-47d3-8fb9-fd7fa526e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-194f3214-5d03-443a-80dd-d4893776a45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141795429-172.17.0.6-1597504289366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-647b3ecd-46c3-4868-ac50-bdcd944b1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-84ffc787-268b-414c-a5e2-c2e7e1676efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-b53aadae-9f6b-489e-9941-1436f01f081a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-e0982072-249a-4478-8b20-588f21f78e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-01ccb710-7f5b-48de-8678-a9782f0d976b,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-a8d7b209-8d15-4afe-a4af-a57ea4bae877,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7394307d-5d8a-47d3-8fb9-fd7fa526e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-194f3214-5d03-443a-80dd-d4893776a45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735562560-172.17.0.6-1597504840230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-2ce9b427-5b3e-4bad-bf9d-5776092e219d,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-46e2a222-a328-4f7a-95a2-8fe0b457479c,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-6cbcc0ae-c48e-41a8-8ce0-caea394fbb50,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-dd1486e8-5ddc-405f-ae52-eb6cb8ae385b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-0971a5ec-b428-4c3d-bba2-95bf8a5cacc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-288fab50-0f8c-4b87-9640-830814500728,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-fcbecb89-1887-4c29-8713-b2ca38138981,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-93753d77-ba8d-4a2f-89f5-de034bc781d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735562560-172.17.0.6-1597504840230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-2ce9b427-5b3e-4bad-bf9d-5776092e219d,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-46e2a222-a328-4f7a-95a2-8fe0b457479c,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-6cbcc0ae-c48e-41a8-8ce0-caea394fbb50,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-dd1486e8-5ddc-405f-ae52-eb6cb8ae385b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-0971a5ec-b428-4c3d-bba2-95bf8a5cacc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-288fab50-0f8c-4b87-9640-830814500728,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-fcbecb89-1887-4c29-8713-b2ca38138981,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-93753d77-ba8d-4a2f-89f5-de034bc781d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633522035-172.17.0.6-1597505657928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-d9bc1446-926c-49de-b46f-45cdf894b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-37898d25-fe4c-456b-adc9-b930278e880e,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-e78abf33-9dfd-4252-a95e-0c029c3a60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-2be2b1ef-7dd6-457d-b214-e6b70907da58,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-a4c846f0-93fa-41e0-a4f6-d71846ed6442,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-f53ab67a-a631-43e0-9794-9f9bc5bac864,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-863f3fcc-5e25-43c8-b172-3d9cda4d53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0d967e9c-e724-4990-8219-146ea5eec1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633522035-172.17.0.6-1597505657928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-d9bc1446-926c-49de-b46f-45cdf894b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-37898d25-fe4c-456b-adc9-b930278e880e,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-e78abf33-9dfd-4252-a95e-0c029c3a60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-2be2b1ef-7dd6-457d-b214-e6b70907da58,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-a4c846f0-93fa-41e0-a4f6-d71846ed6442,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-f53ab67a-a631-43e0-9794-9f9bc5bac864,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-863f3fcc-5e25-43c8-b172-3d9cda4d53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0d967e9c-e724-4990-8219-146ea5eec1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935152172-172.17.0.6-1597505709929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-b73b8871-8468-419e-9fdf-4d667173df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-4dc3aa8f-3647-47cd-9318-33ca5572e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-946bc0d7-92e1-4db5-a37c-577cf5f91349,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-893c0790-40ea-4dfe-b0f9-d63a784f9a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-183a284c-d052-4e8c-9b46-a03c43a0e528,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-477b4e1a-3673-4f47-890b-04ca44abdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-dadc443a-d2f8-426a-b4ff-c89ad89911d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-ea7e471f-9602-4f85-817f-9188aac614e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935152172-172.17.0.6-1597505709929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-b73b8871-8468-419e-9fdf-4d667173df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-4dc3aa8f-3647-47cd-9318-33ca5572e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-946bc0d7-92e1-4db5-a37c-577cf5f91349,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-893c0790-40ea-4dfe-b0f9-d63a784f9a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-183a284c-d052-4e8c-9b46-a03c43a0e528,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-477b4e1a-3673-4f47-890b-04ca44abdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-dadc443a-d2f8-426a-b4ff-c89ad89911d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-ea7e471f-9602-4f85-817f-9188aac614e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638624035-172.17.0.6-1597505880136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-ea145f69-0028-4ce5-b957-a701958b6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-88b2f3bf-fbbf-4f9b-81d2-97f96b900175,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-b9795455-b1c7-4a18-84de-52fe5f2670cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-51f3b178-ccab-483b-b989-3021e9a44087,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-6ca5ff8b-6af6-4a36-83a0-c81f2db14bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-db4a23df-7483-4790-aab5-a2d697615a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a5d2fb66-19c3-47d2-9b57-3f4351f1c618,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-d8310906-4481-438e-b2c3-50609bcbd537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638624035-172.17.0.6-1597505880136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-ea145f69-0028-4ce5-b957-a701958b6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-88b2f3bf-fbbf-4f9b-81d2-97f96b900175,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-b9795455-b1c7-4a18-84de-52fe5f2670cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-51f3b178-ccab-483b-b989-3021e9a44087,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-6ca5ff8b-6af6-4a36-83a0-c81f2db14bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-db4a23df-7483-4790-aab5-a2d697615a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a5d2fb66-19c3-47d2-9b57-3f4351f1c618,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-d8310906-4481-438e-b2c3-50609bcbd537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867001668-172.17.0.6-1597506395408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42098,DS-6c10d960-865e-4662-9e03-23260e0fb285,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-68883bc2-e0f6-48e0-a065-4dd8bc27012b,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-535ad93a-e0fd-4471-bef6-a33ddacbe124,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-8cedfc72-c469-45c6-b9d6-de35589a5379,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-cd639208-5848-43b1-8ef9-fa389ef5f593,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-4421bae1-2245-4598-bae7-e74f88363cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2a4887a9-2ebd-48ec-8e70-14705ac815d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-24699482-31f3-462a-9219-b7defbc3be86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867001668-172.17.0.6-1597506395408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42098,DS-6c10d960-865e-4662-9e03-23260e0fb285,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-68883bc2-e0f6-48e0-a065-4dd8bc27012b,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-535ad93a-e0fd-4471-bef6-a33ddacbe124,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-8cedfc72-c469-45c6-b9d6-de35589a5379,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-cd639208-5848-43b1-8ef9-fa389ef5f593,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-4421bae1-2245-4598-bae7-e74f88363cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2a4887a9-2ebd-48ec-8e70-14705ac815d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-24699482-31f3-462a-9219-b7defbc3be86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547996662-172.17.0.6-1597506535925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-8e56c267-6d19-47d7-a3a1-1f11d6476628,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-b01c4c6c-1d59-4184-bd0b-838d6c610c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-c35dc5d8-d526-4e29-8371-81be3111b47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-ba50760e-77a2-47cb-8939-399733a5642b,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-a677a279-105e-4f88-afc3-8fdc9a58e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-f7960ce4-fa66-4201-8dee-121b574b3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5d8af189-c1cc-458e-84d0-d6c763eb9a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-c2a89880-355e-412f-982f-8d6b5be894bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547996662-172.17.0.6-1597506535925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-8e56c267-6d19-47d7-a3a1-1f11d6476628,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-b01c4c6c-1d59-4184-bd0b-838d6c610c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-c35dc5d8-d526-4e29-8371-81be3111b47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-ba50760e-77a2-47cb-8939-399733a5642b,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-a677a279-105e-4f88-afc3-8fdc9a58e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-f7960ce4-fa66-4201-8dee-121b574b3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5d8af189-c1cc-458e-84d0-d6c763eb9a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-c2a89880-355e-412f-982f-8d6b5be894bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497040829-172.17.0.6-1597507236239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-d2b2c9a2-a3a9-43c2-8a89-ae52545c2968,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1ba1241c-a34b-409c-bbea-922a8a0df6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-57ba0997-aa2f-4227-8a86-fbd2a468d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-8f1e87e3-5c12-4b44-ba79-c31eab651662,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-c03eeb9b-f416-42f0-8b8c-9041ea232ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-033b9579-2175-43ca-a180-8be69a94e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a46e9bf9-7d51-4ec5-87c6-62ef47fb595b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-547faa3e-3034-4779-8d43-437140cdff4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497040829-172.17.0.6-1597507236239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46856,DS-d2b2c9a2-a3a9-43c2-8a89-ae52545c2968,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1ba1241c-a34b-409c-bbea-922a8a0df6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-57ba0997-aa2f-4227-8a86-fbd2a468d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-8f1e87e3-5c12-4b44-ba79-c31eab651662,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-c03eeb9b-f416-42f0-8b8c-9041ea232ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-033b9579-2175-43ca-a180-8be69a94e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-a46e9bf9-7d51-4ec5-87c6-62ef47fb595b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-547faa3e-3034-4779-8d43-437140cdff4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48319485-172.17.0.6-1597507773486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39276,DS-756b5038-8ea3-43bd-b748-6cad77b9149a,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2e3450d0-335c-4eee-a852-14baaef56ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-81a4cdb0-fb2f-4ea4-9160-a2ed8f097646,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-39d92b25-494c-4eb5-bc83-c493e0ade3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-fa08bf25-1e0f-4755-8e03-cb006d1fd068,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e7206333-5d32-4cc7-9f6e-c63f19708bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5036cc3e-de9b-44d5-86f5-1356beafa7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-e5cc88e7-6442-4135-8120-e67613a71c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48319485-172.17.0.6-1597507773486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39276,DS-756b5038-8ea3-43bd-b748-6cad77b9149a,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2e3450d0-335c-4eee-a852-14baaef56ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-81a4cdb0-fb2f-4ea4-9160-a2ed8f097646,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-39d92b25-494c-4eb5-bc83-c493e0ade3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-fa08bf25-1e0f-4755-8e03-cb006d1fd068,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e7206333-5d32-4cc7-9f6e-c63f19708bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5036cc3e-de9b-44d5-86f5-1356beafa7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-e5cc88e7-6442-4135-8120-e67613a71c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321327766-172.17.0.6-1597508685967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39410,DS-59b07a68-207b-4e72-936e-f04b38e89641,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-fe2b69e8-1433-4831-9030-b00180786df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e7a0f035-2757-470d-ba13-bf5dad86101b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-5853e1a3-3ed5-48c3-bb70-aa71ec149847,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-d6526762-799e-453e-9e4b-ca55e78f98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-3ce3916b-9aea-4012-b637-dc62f5834068,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-f868c22b-17b3-40d1-83ef-07891c35c566,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-3273d5e4-342d-49f9-b017-5c7f9f779846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321327766-172.17.0.6-1597508685967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39410,DS-59b07a68-207b-4e72-936e-f04b38e89641,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-fe2b69e8-1433-4831-9030-b00180786df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e7a0f035-2757-470d-ba13-bf5dad86101b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-5853e1a3-3ed5-48c3-bb70-aa71ec149847,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-d6526762-799e-453e-9e4b-ca55e78f98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-3ce3916b-9aea-4012-b637-dc62f5834068,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-f868c22b-17b3-40d1-83ef-07891c35c566,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-3273d5e4-342d-49f9-b017-5c7f9f779846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6864
