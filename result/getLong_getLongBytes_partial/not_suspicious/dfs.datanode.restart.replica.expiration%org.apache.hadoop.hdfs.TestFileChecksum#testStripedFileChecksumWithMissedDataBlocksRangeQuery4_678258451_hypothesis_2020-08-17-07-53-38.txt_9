reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463589552-172.17.0.3-1597650908199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-b0372805-3634-4079-beb6-ef8205c509ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-49b7882b-8383-4b77-b721-97d5b0bbf446,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-5d94520c-5e84-4946-a723-42ffba36b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-f8399284-4702-492d-bb8b-fb2dc481f202,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-db48b3e6-bc96-4f88-981a-beaf7c24613d,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-b04f4691-816f-4abc-b2b8-e55c5e29b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-8efdb9da-30f0-428b-a601-c165f2f2d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-cb71adea-7f22-4661-9df5-0f9c02773146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463589552-172.17.0.3-1597650908199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-b0372805-3634-4079-beb6-ef8205c509ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-49b7882b-8383-4b77-b721-97d5b0bbf446,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-5d94520c-5e84-4946-a723-42ffba36b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-f8399284-4702-492d-bb8b-fb2dc481f202,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-db48b3e6-bc96-4f88-981a-beaf7c24613d,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-b04f4691-816f-4abc-b2b8-e55c5e29b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-8efdb9da-30f0-428b-a601-c165f2f2d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-cb71adea-7f22-4661-9df5-0f9c02773146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347864340-172.17.0.3-1597651082151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-eff9a147-3838-4cfb-9d32-d6a44fcc1355,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-f37911f9-7389-4e13-b1b7-410dc48b7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-7b6eb1f6-19a5-4e24-b365-b62713742c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-a24ef23b-5049-48e5-862e-26581cf3789e,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c82683db-53f7-4678-8ede-352f374aa84c,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-767810b4-7d59-485a-a73c-b53a6a222b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-6886afb9-26ff-494e-bab8-59b238eff036,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-d7cdff04-a101-4f89-925b-fbce4ae554bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347864340-172.17.0.3-1597651082151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-eff9a147-3838-4cfb-9d32-d6a44fcc1355,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-f37911f9-7389-4e13-b1b7-410dc48b7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-7b6eb1f6-19a5-4e24-b365-b62713742c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-a24ef23b-5049-48e5-862e-26581cf3789e,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c82683db-53f7-4678-8ede-352f374aa84c,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-767810b4-7d59-485a-a73c-b53a6a222b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-6886afb9-26ff-494e-bab8-59b238eff036,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-d7cdff04-a101-4f89-925b-fbce4ae554bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541961021-172.17.0.3-1597651196219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-9d6a87e5-1f41-4586-84f5-754d99a7d6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-52781317-5fb0-49c8-8462-5ecd7536391f,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-902496a0-1d1f-4604-b665-86919484e9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-f97b8d0e-fe64-4df0-ac98-525a72c1436c,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-6a9f5143-339f-4b50-a784-08e27005778a,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-53d89cc4-87c9-4696-b376-f5d365dcfcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-a27a7b3d-2647-4c57-806f-ec608cf8819c,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-21017dab-e33f-4e33-9239-372ca6a7b7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541961021-172.17.0.3-1597651196219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-9d6a87e5-1f41-4586-84f5-754d99a7d6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-52781317-5fb0-49c8-8462-5ecd7536391f,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-902496a0-1d1f-4604-b665-86919484e9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-f97b8d0e-fe64-4df0-ac98-525a72c1436c,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-6a9f5143-339f-4b50-a784-08e27005778a,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-53d89cc4-87c9-4696-b376-f5d365dcfcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-a27a7b3d-2647-4c57-806f-ec608cf8819c,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-21017dab-e33f-4e33-9239-372ca6a7b7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654404223-172.17.0.3-1597651493874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38346,DS-d92f72cd-e63b-4ec5-9c8f-f1feafd8a1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0ee0598a-d819-482d-bf72-c7ddb610eccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-a3307c00-9816-48dd-bd01-16a571a92426,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-1f617dfb-e4ee-4bf4-aca5-62f8064f3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-22f8005a-fd0b-49f0-9347-1fd4afc42f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-358bdc42-d97b-471a-ae53-93226eb8d357,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-4c8f2c80-f256-4967-b80e-fe0fda1acf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-d1a40681-d7a6-40c6-b38f-bf01af720b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654404223-172.17.0.3-1597651493874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38346,DS-d92f72cd-e63b-4ec5-9c8f-f1feafd8a1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0ee0598a-d819-482d-bf72-c7ddb610eccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-a3307c00-9816-48dd-bd01-16a571a92426,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-1f617dfb-e4ee-4bf4-aca5-62f8064f3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-22f8005a-fd0b-49f0-9347-1fd4afc42f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-358bdc42-d97b-471a-ae53-93226eb8d357,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-4c8f2c80-f256-4967-b80e-fe0fda1acf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-d1a40681-d7a6-40c6-b38f-bf01af720b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366478454-172.17.0.3-1597651526511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35553,DS-bdc4a596-bdd3-4ade-a283-ce36695a866a,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a8301d82-36a0-4f9c-b17c-09d722d5b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-b1efa44e-9162-4db1-bd2e-df8ab0ed34a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-a27cfeef-1af1-4ea7-b463-9347050435f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-0ac8182b-9712-4cc5-942d-0d7e619ed6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-a5232bc6-7bed-4e02-9af4-fa798bb5fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-34b371f6-9d50-4c4d-9549-ca8cb164542c,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-96a78217-b44b-4d45-8d39-e418bbf9c4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366478454-172.17.0.3-1597651526511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35553,DS-bdc4a596-bdd3-4ade-a283-ce36695a866a,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a8301d82-36a0-4f9c-b17c-09d722d5b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-b1efa44e-9162-4db1-bd2e-df8ab0ed34a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-a27cfeef-1af1-4ea7-b463-9347050435f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-0ac8182b-9712-4cc5-942d-0d7e619ed6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-a5232bc6-7bed-4e02-9af4-fa798bb5fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-34b371f6-9d50-4c4d-9549-ca8cb164542c,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-96a78217-b44b-4d45-8d39-e418bbf9c4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318628677-172.17.0.3-1597652061283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-0c4f099f-54e5-4820-95d4-68bdd1a6b702,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-3cd10569-4525-4987-ba72-2781192abef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-096936a8-3a3d-417b-b3be-56659c60cb21,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-6a3146d9-c895-446b-b7e6-c62cae87cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-a1dca562-cb3c-4c01-87cc-8f33027ea6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-6b4bf77b-02c2-490e-88c3-e3bd25bf15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b35a8a83-b87c-4741-a51a-b6766e55a367,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-d0be4df7-b5ef-4954-ad9c-c6757d3893ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318628677-172.17.0.3-1597652061283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-0c4f099f-54e5-4820-95d4-68bdd1a6b702,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-3cd10569-4525-4987-ba72-2781192abef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-096936a8-3a3d-417b-b3be-56659c60cb21,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-6a3146d9-c895-446b-b7e6-c62cae87cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-a1dca562-cb3c-4c01-87cc-8f33027ea6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-6b4bf77b-02c2-490e-88c3-e3bd25bf15d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b35a8a83-b87c-4741-a51a-b6766e55a367,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-d0be4df7-b5ef-4954-ad9c-c6757d3893ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803427077-172.17.0.3-1597652280587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-2abd5ee7-0af8-4997-85a1-bbe8c37b9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d9a66b6f-e44b-425e-abce-342a59c01b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-753a8f29-bfcc-4b30-a391-37422b673109,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d144b6c9-6e7d-4776-868f-93f03615e682,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1024629d-9bef-4dbc-a81e-d2259d935d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-f48c7948-d26e-4920-b346-a442ab5bbebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-de857023-b650-495f-a658-92f935db6ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-8c876efa-754d-4dc5-bf22-d9106c33fe09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803427077-172.17.0.3-1597652280587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-2abd5ee7-0af8-4997-85a1-bbe8c37b9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d9a66b6f-e44b-425e-abce-342a59c01b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-753a8f29-bfcc-4b30-a391-37422b673109,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d144b6c9-6e7d-4776-868f-93f03615e682,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1024629d-9bef-4dbc-a81e-d2259d935d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-f48c7948-d26e-4920-b346-a442ab5bbebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-de857023-b650-495f-a658-92f935db6ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-8c876efa-754d-4dc5-bf22-d9106c33fe09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804679984-172.17.0.3-1597652358710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-90277b06-c294-4569-912f-1d6a740e0243,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-4621a605-973c-4a5b-b371-b8c9430edda8,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-8d31de52-4166-438b-bb16-f5635e4fa3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-3a354af0-a281-47e4-9fdf-fd492eb811b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ddfc0f96-0189-46e3-8b43-016d258f9745,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-0b24b529-4ee7-4a62-90c5-6a361d578616,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-6399722f-a56f-4522-9808-42d0344952e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-d3ff42d8-384a-4df1-80ac-20a47856215c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804679984-172.17.0.3-1597652358710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-90277b06-c294-4569-912f-1d6a740e0243,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-4621a605-973c-4a5b-b371-b8c9430edda8,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-8d31de52-4166-438b-bb16-f5635e4fa3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-3a354af0-a281-47e4-9fdf-fd492eb811b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ddfc0f96-0189-46e3-8b43-016d258f9745,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-0b24b529-4ee7-4a62-90c5-6a361d578616,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-6399722f-a56f-4522-9808-42d0344952e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-d3ff42d8-384a-4df1-80ac-20a47856215c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962181139-172.17.0.3-1597652528276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-9d05d55f-06ac-4d00-824c-ac6ed46ca394,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-b1cceb10-7148-4c47-ac6c-c711e0aeb572,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-9fc48043-cd18-4dce-8177-3af61548b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-996d02f7-8f02-4a81-b9b9-e7605a748d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-d1d7ea13-62d7-4fc2-8650-d00df5d05902,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-24e7d8a6-1641-409b-960e-a3696671fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-006c7fec-dc38-4aa6-9e44-d44a40bf8654,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7e9097b7-55d5-4039-8447-371fe8bcba03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962181139-172.17.0.3-1597652528276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-9d05d55f-06ac-4d00-824c-ac6ed46ca394,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-b1cceb10-7148-4c47-ac6c-c711e0aeb572,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-9fc48043-cd18-4dce-8177-3af61548b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-996d02f7-8f02-4a81-b9b9-e7605a748d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-d1d7ea13-62d7-4fc2-8650-d00df5d05902,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-24e7d8a6-1641-409b-960e-a3696671fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-006c7fec-dc38-4aa6-9e44-d44a40bf8654,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7e9097b7-55d5-4039-8447-371fe8bcba03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323263021-172.17.0.3-1597652797621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42040,DS-09961a85-a956-408f-966d-7e57b8ed1570,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a18051b9-e1d3-478c-8a13-a716d4c1eb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-6112c952-5a67-48ac-96ae-339e450239a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-5ddae0a2-c2eb-4bdf-9a04-5aca61d6b601,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-b54dc9cb-bbfb-4c55-baa9-5c333c597117,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-7e515634-d393-4da5-b562-8b4241493390,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-379a55f8-5011-441d-89a5-6be002321550,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-a521120c-9e1f-497b-86e0-03c75b884fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323263021-172.17.0.3-1597652797621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42040,DS-09961a85-a956-408f-966d-7e57b8ed1570,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a18051b9-e1d3-478c-8a13-a716d4c1eb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-6112c952-5a67-48ac-96ae-339e450239a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-5ddae0a2-c2eb-4bdf-9a04-5aca61d6b601,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-b54dc9cb-bbfb-4c55-baa9-5c333c597117,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-7e515634-d393-4da5-b562-8b4241493390,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-379a55f8-5011-441d-89a5-6be002321550,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-a521120c-9e1f-497b-86e0-03c75b884fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786359688-172.17.0.3-1597653055422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-e4f79188-e850-497c-93e8-29c7ff31a360,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ceb81813-5b27-4dad-b68a-60c396f7d8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-590ae246-cf68-426e-a53e-4a9ae9eb9e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-a56b4341-b29a-4e26-9ba2-0564fd4dab45,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6337a51c-285b-48ec-9472-8980667c8a95,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c9272c63-376e-4bff-b369-c367f70ceb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-f129754d-c8ed-4014-b218-5a5d9a53659e,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-380bef23-ca90-4361-bcf8-dd3416540fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786359688-172.17.0.3-1597653055422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-e4f79188-e850-497c-93e8-29c7ff31a360,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ceb81813-5b27-4dad-b68a-60c396f7d8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-590ae246-cf68-426e-a53e-4a9ae9eb9e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-a56b4341-b29a-4e26-9ba2-0564fd4dab45,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6337a51c-285b-48ec-9472-8980667c8a95,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c9272c63-376e-4bff-b369-c367f70ceb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-f129754d-c8ed-4014-b218-5a5d9a53659e,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-380bef23-ca90-4361-bcf8-dd3416540fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270935541-172.17.0.3-1597653237058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33749,DS-83e2cd6d-6e1e-47ea-8c8c-a791525bf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-1947e80b-893f-43c7-b1ca-0cf8dcb2d2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-ee59222d-c555-431d-b6c8-09c4877b4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-2d0cff8d-cb56-41dc-8436-7ec283c4745b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-6a626343-5727-43e5-94d5-83986821a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4b60ec06-c08b-44b8-927a-e4608a86670e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-67ba85bd-ef0e-4ffa-9c80-4146a7035ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-6e44ffa7-066a-4043-8e43-ea806b5429ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270935541-172.17.0.3-1597653237058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33749,DS-83e2cd6d-6e1e-47ea-8c8c-a791525bf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-1947e80b-893f-43c7-b1ca-0cf8dcb2d2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-ee59222d-c555-431d-b6c8-09c4877b4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-2d0cff8d-cb56-41dc-8436-7ec283c4745b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-6a626343-5727-43e5-94d5-83986821a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-4b60ec06-c08b-44b8-927a-e4608a86670e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-67ba85bd-ef0e-4ffa-9c80-4146a7035ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-6e44ffa7-066a-4043-8e43-ea806b5429ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309110047-172.17.0.3-1597653552860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-fee457ce-1fe6-4cf5-9920-40f8305fe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ffd85fcf-e00e-4777-848a-d1a2e8e33a73,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-20c4bdf9-08c5-4f43-867f-2bde5454d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-c3b4fa43-74ba-4674-8ccf-b5522755f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-99af3839-8fbf-4d7d-a645-980106976772,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-08475e97-4493-4c5d-919d-290838eddf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-217f8e63-c239-4a35-8f34-230ee9d1b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-b48850b4-7f60-42f1-84d8-c17be2578e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309110047-172.17.0.3-1597653552860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-fee457ce-1fe6-4cf5-9920-40f8305fe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ffd85fcf-e00e-4777-848a-d1a2e8e33a73,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-20c4bdf9-08c5-4f43-867f-2bde5454d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-c3b4fa43-74ba-4674-8ccf-b5522755f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-99af3839-8fbf-4d7d-a645-980106976772,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-08475e97-4493-4c5d-919d-290838eddf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-217f8e63-c239-4a35-8f34-230ee9d1b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-b48850b4-7f60-42f1-84d8-c17be2578e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660451714-172.17.0.3-1597653673487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-10230ea2-c3b1-413c-bd4e-02a470d8af71,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-0fc3edd7-4e3e-4dd8-b276-2ad22b4cd5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-43a814e0-2f78-4fd7-b90e-716758a16a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-ba220be9-5620-4dd6-8f69-58b76cdebe71,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-70fb7431-f038-4d66-ab5b-7e0355884780,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f23f741b-7590-44d3-ad1d-cbf24dc6f651,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-f36c771f-05d9-4026-b687-5fc552a7bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-e37ef694-82b1-4c1f-84e4-34a6431af188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660451714-172.17.0.3-1597653673487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-10230ea2-c3b1-413c-bd4e-02a470d8af71,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-0fc3edd7-4e3e-4dd8-b276-2ad22b4cd5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-43a814e0-2f78-4fd7-b90e-716758a16a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-ba220be9-5620-4dd6-8f69-58b76cdebe71,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-70fb7431-f038-4d66-ab5b-7e0355884780,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f23f741b-7590-44d3-ad1d-cbf24dc6f651,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-f36c771f-05d9-4026-b687-5fc552a7bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-e37ef694-82b1-4c1f-84e4-34a6431af188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775607297-172.17.0.3-1597653829904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-2c912f36-d886-426a-bcc9-4d1cd7d4f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-4a23b913-f515-4ce2-ab4c-0feffc9f8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-a06cc0b1-77ff-4aa0-af72-bbbdca17120b,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-1ccb6498-cd60-4267-8337-2751beb3947b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-592485d3-29ba-44c4-b526-8d7c4ff1b338,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-4d971ead-5209-45cc-bc23-3e5cbe6a6f59,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-b9b939d6-a04b-4a45-975d-cdcd65b4d453,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d4d94c03-38ba-4606-b678-b895509ac437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775607297-172.17.0.3-1597653829904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-2c912f36-d886-426a-bcc9-4d1cd7d4f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-4a23b913-f515-4ce2-ab4c-0feffc9f8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-a06cc0b1-77ff-4aa0-af72-bbbdca17120b,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-1ccb6498-cd60-4267-8337-2751beb3947b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-592485d3-29ba-44c4-b526-8d7c4ff1b338,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-4d971ead-5209-45cc-bc23-3e5cbe6a6f59,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-b9b939d6-a04b-4a45-975d-cdcd65b4d453,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d4d94c03-38ba-4606-b678-b895509ac437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631941073-172.17.0.3-1597654536077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-18292ccf-645e-4e4f-a640-3578e9a592e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-1e2806b8-5284-4fcc-8d52-4d0b4e9d5b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-046a71f5-d95b-4dd5-8cb7-67b5655c209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-b9cad16c-c134-4626-8c87-ea36c53a3e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-7b4b820f-bd39-4f24-8016-cd1dd6853056,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3eac1181-41ff-458a-9243-3c4c5727850a,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-75003f71-3bcb-4347-b25c-459e3cec33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-0c7a7cfa-cf1e-41a8-bea0-3819e15a4002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631941073-172.17.0.3-1597654536077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-18292ccf-645e-4e4f-a640-3578e9a592e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-1e2806b8-5284-4fcc-8d52-4d0b4e9d5b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-046a71f5-d95b-4dd5-8cb7-67b5655c209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-b9cad16c-c134-4626-8c87-ea36c53a3e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-7b4b820f-bd39-4f24-8016-cd1dd6853056,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3eac1181-41ff-458a-9243-3c4c5727850a,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-75003f71-3bcb-4347-b25c-459e3cec33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-0c7a7cfa-cf1e-41a8-bea0-3819e15a4002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100808453-172.17.0.3-1597654688312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-6b66a83c-6f99-4d7b-acf1-06439fe42b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e6cd370d-ea2d-4b82-a96d-3c9bf194ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-da6cc55b-06bf-4016-ace9-9066a438d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-166942db-b363-4f76-9245-48ca6f19e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-4d6a349a-21ca-44af-93e1-246e6cdfe238,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-201fc9d7-04e0-4bf9-ab66-22db5cc0ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-86be412e-dcdf-43f6-8fc5-2c8cc4b90444,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-592c0bc0-1d8a-4456-9e15-516608a9f45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100808453-172.17.0.3-1597654688312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-6b66a83c-6f99-4d7b-acf1-06439fe42b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e6cd370d-ea2d-4b82-a96d-3c9bf194ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-da6cc55b-06bf-4016-ace9-9066a438d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-166942db-b363-4f76-9245-48ca6f19e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-4d6a349a-21ca-44af-93e1-246e6cdfe238,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-201fc9d7-04e0-4bf9-ab66-22db5cc0ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-86be412e-dcdf-43f6-8fc5-2c8cc4b90444,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-592c0bc0-1d8a-4456-9e15-516608a9f45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158481077-172.17.0.3-1597655098537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-4d967d21-9437-459c-9dbb-1519c2474a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7b39749f-5c90-499b-9bc9-1c3574632481,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-fb245868-3b8e-4e39-b798-18bf08c8d695,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d00e4b82-413c-41f4-ad89-53e827cff3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-da6cd62d-2abb-4f77-893a-842a188650a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-5584cc14-f1a6-4819-9e22-ba88152afda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-b91a8424-1747-4eed-8b5d-b4c99a9e9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-d30ee897-92f4-4292-8350-a9724b26ae41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158481077-172.17.0.3-1597655098537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-4d967d21-9437-459c-9dbb-1519c2474a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7b39749f-5c90-499b-9bc9-1c3574632481,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-fb245868-3b8e-4e39-b798-18bf08c8d695,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d00e4b82-413c-41f4-ad89-53e827cff3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-da6cd62d-2abb-4f77-893a-842a188650a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-5584cc14-f1a6-4819-9e22-ba88152afda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-b91a8424-1747-4eed-8b5d-b4c99a9e9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-d30ee897-92f4-4292-8350-a9724b26ae41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545351263-172.17.0.3-1597655336048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-66e024ae-7a69-4913-ab2b-20888376f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-61b1ec3d-d2e5-4940-a3df-935171151cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-4b0a0cdb-d5b6-40dd-8fc5-b520db7c8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-3d75ca85-0448-4719-a3e1-a52bf6702b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-eb2c17e6-261f-461b-86c1-72028c79dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-9a7a01e0-1090-4dec-8f2f-a8e57ec3e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-a7c7b73b-a0e3-4efd-b4c7-a38e2aebc86d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-39513107-55ac-41e2-8dee-66210364b8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545351263-172.17.0.3-1597655336048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-66e024ae-7a69-4913-ab2b-20888376f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-61b1ec3d-d2e5-4940-a3df-935171151cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-4b0a0cdb-d5b6-40dd-8fc5-b520db7c8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-3d75ca85-0448-4719-a3e1-a52bf6702b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-eb2c17e6-261f-461b-86c1-72028c79dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-9a7a01e0-1090-4dec-8f2f-a8e57ec3e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-a7c7b73b-a0e3-4efd-b4c7-a38e2aebc86d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-39513107-55ac-41e2-8dee-66210364b8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902466231-172.17.0.3-1597655376335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-f329c3f2-f1fe-4fb6-a6ff-545395b06a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-9a438d61-e3af-404a-a5db-748f996ee4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-6147933f-ddae-4eb4-aa94-1e885d7afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-e490b270-3697-4d97-b1f8-7ebfccc9f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-2f4e9e19-e880-4632-a256-3ec8fd467f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a526440a-f075-47b7-91b0-d3fdd64b15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c6660d36-2712-4e3d-850c-4c068b73d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-9a1986ff-7fc4-4c31-85a2-e5499c0bcafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902466231-172.17.0.3-1597655376335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-f329c3f2-f1fe-4fb6-a6ff-545395b06a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-9a438d61-e3af-404a-a5db-748f996ee4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-6147933f-ddae-4eb4-aa94-1e885d7afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-e490b270-3697-4d97-b1f8-7ebfccc9f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-2f4e9e19-e880-4632-a256-3ec8fd467f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a526440a-f075-47b7-91b0-d3fdd64b15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c6660d36-2712-4e3d-850c-4c068b73d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-9a1986ff-7fc4-4c31-85a2-e5499c0bcafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280021254-172.17.0.3-1597655985013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-10e07329-8140-4668-af9f-0f7d38dd50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-7d911516-f322-4c32-86c3-2174c3d7a4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7705cb0c-dff7-445e-8c6c-69b13d41f2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-09a5755f-16d5-47e0-9d24-4bf0a82c0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-43962375-469e-439b-b975-6113f9e64a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-2f1c2e09-e097-4482-bb03-3936d8cdf545,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-bd713969-9136-4e89-befd-0caf08423d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-1a97fa65-fbf4-4824-8f1d-e1b70c8cc74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280021254-172.17.0.3-1597655985013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-10e07329-8140-4668-af9f-0f7d38dd50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-7d911516-f322-4c32-86c3-2174c3d7a4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7705cb0c-dff7-445e-8c6c-69b13d41f2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-09a5755f-16d5-47e0-9d24-4bf0a82c0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-43962375-469e-439b-b975-6113f9e64a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-2f1c2e09-e097-4482-bb03-3936d8cdf545,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-bd713969-9136-4e89-befd-0caf08423d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-1a97fa65-fbf4-4824-8f1d-e1b70c8cc74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138931394-172.17.0.3-1597656018270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-1e11af98-a1c7-4532-9e2a-80ebedefe985,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-e1575e41-72c5-413d-886b-72d547fc7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-6aab0a2a-8f9c-4b96-8963-ddeefe28b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-272b0a4e-4784-48e0-84b3-8b89d56f1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-25c9df5a-667d-4685-a470-249cc94960e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-d38ea438-ae6c-4ef7-aabd-669d21edfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-f1043650-bb68-4167-bc19-70a55d87918d,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-2c73354f-8c81-4d07-a94e-1171c536bb75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138931394-172.17.0.3-1597656018270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-1e11af98-a1c7-4532-9e2a-80ebedefe985,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-e1575e41-72c5-413d-886b-72d547fc7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-6aab0a2a-8f9c-4b96-8963-ddeefe28b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-272b0a4e-4784-48e0-84b3-8b89d56f1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-25c9df5a-667d-4685-a470-249cc94960e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-d38ea438-ae6c-4ef7-aabd-669d21edfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-f1043650-bb68-4167-bc19-70a55d87918d,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-2c73354f-8c81-4d07-a94e-1171c536bb75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635303462-172.17.0.3-1597656274509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-eadca6e7-1df3-4f55-b24e-0c601fa96ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-e155a8dc-fd04-4aeb-837e-236844c78934,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-94e615b6-ad60-41a5-9fab-c473175fa24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-5f741e82-3e96-401e-a7e4-02fc311f49fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-75fe27e3-8764-4912-a14d-218731c7a431,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-e73c4a4b-9b96-46b1-bd5c-bb9071eda415,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e379f318-a7fd-4d44-a69b-d97826dc2161,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-09f162c7-92b3-41a1-96ac-91f37f417b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635303462-172.17.0.3-1597656274509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-eadca6e7-1df3-4f55-b24e-0c601fa96ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-e155a8dc-fd04-4aeb-837e-236844c78934,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-94e615b6-ad60-41a5-9fab-c473175fa24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-5f741e82-3e96-401e-a7e4-02fc311f49fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-75fe27e3-8764-4912-a14d-218731c7a431,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-e73c4a4b-9b96-46b1-bd5c-bb9071eda415,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e379f318-a7fd-4d44-a69b-d97826dc2161,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-09f162c7-92b3-41a1-96ac-91f37f417b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5621
