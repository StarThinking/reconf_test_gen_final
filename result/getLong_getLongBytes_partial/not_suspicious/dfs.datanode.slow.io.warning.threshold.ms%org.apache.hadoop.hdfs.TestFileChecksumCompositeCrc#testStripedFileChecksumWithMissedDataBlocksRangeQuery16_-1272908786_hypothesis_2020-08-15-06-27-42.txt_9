reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490039303-172.17.0.15-1597472956920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-fdbe4454-bb79-40a9-89d7-f57c371e9b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-c6bd48df-45b9-4ff6-8424-c8392bcee52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-a04ef12c-533c-4edd-b7db-448a8ceb9b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-351bcba3-2228-4774-8638-41e80ea78661,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2505bc00-03c1-47a5-951f-c60a9703af90,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-829a8c61-5497-4034-a618-f4ed3d31f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-4d2272d1-e5ad-4283-b4ce-32bb9ea38b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e38f987e-61d7-423d-8c68-e81ff91353a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490039303-172.17.0.15-1597472956920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-fdbe4454-bb79-40a9-89d7-f57c371e9b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-c6bd48df-45b9-4ff6-8424-c8392bcee52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-a04ef12c-533c-4edd-b7db-448a8ceb9b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-351bcba3-2228-4774-8638-41e80ea78661,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2505bc00-03c1-47a5-951f-c60a9703af90,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-829a8c61-5497-4034-a618-f4ed3d31f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-4d2272d1-e5ad-4283-b4ce-32bb9ea38b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e38f987e-61d7-423d-8c68-e81ff91353a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259410611-172.17.0.15-1597473403208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-ad525725-38d0-4c5a-80b9-89dd86f13bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-47bf6f01-33a7-4b3e-a38e-44e42337c020,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-f99d78ba-82a3-45e8-98bb-915e7526df20,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-53917053-ea16-4822-8c03-e796855b7e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c177e6e0-372f-430a-b633-cb6592d8edee,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-abb946ac-d496-48b7-a31e-f05cacae5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-244c7c3a-77f7-4f4c-a989-e2ac21c00b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-776c95a8-3ea4-452e-968a-cfd1ca6345dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259410611-172.17.0.15-1597473403208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-ad525725-38d0-4c5a-80b9-89dd86f13bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-47bf6f01-33a7-4b3e-a38e-44e42337c020,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-f99d78ba-82a3-45e8-98bb-915e7526df20,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-53917053-ea16-4822-8c03-e796855b7e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c177e6e0-372f-430a-b633-cb6592d8edee,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-abb946ac-d496-48b7-a31e-f05cacae5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-244c7c3a-77f7-4f4c-a989-e2ac21c00b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-776c95a8-3ea4-452e-968a-cfd1ca6345dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490638421-172.17.0.15-1597473514586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-91e9100e-e3b7-4bc9-95a9-e77bb6deb9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f5a19125-d000-42bb-bcd1-9d74bafeaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-03b4313c-4319-4432-9d8c-f11a35365956,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-c69e841f-9709-4272-a5a2-fd8837e81ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-73527c49-893f-464d-9291-49526baf023d,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-aac8c55d-b91e-48e9-9642-7ddacd34633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-22295ea9-24e8-4eec-a145-eda259efde19,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-becba2e1-d931-4d74-ab4d-a4fd6c218a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490638421-172.17.0.15-1597473514586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-91e9100e-e3b7-4bc9-95a9-e77bb6deb9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f5a19125-d000-42bb-bcd1-9d74bafeaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-03b4313c-4319-4432-9d8c-f11a35365956,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-c69e841f-9709-4272-a5a2-fd8837e81ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-73527c49-893f-464d-9291-49526baf023d,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-aac8c55d-b91e-48e9-9642-7ddacd34633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-22295ea9-24e8-4eec-a145-eda259efde19,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-becba2e1-d931-4d74-ab4d-a4fd6c218a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589312525-172.17.0.15-1597473943628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-2f54c9d5-4398-43b7-b8c1-5c09026156e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-5ef69413-bb0b-460c-baae-d5151177e013,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-b379ecce-67c7-4c45-b65a-8e8f837d225e,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ffe3e1bf-f166-4119-8ee8-4eebab5e7f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-73cc842b-be76-40a9-b231-fbb8b0a3efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-6c93e2e8-6a27-4215-81d0-4132ddb11b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-2efc4d17-a2ec-4f95-b7ce-4ec603323f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-158f2d67-2221-4ed4-847b-1bc7f0beae6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589312525-172.17.0.15-1597473943628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-2f54c9d5-4398-43b7-b8c1-5c09026156e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-5ef69413-bb0b-460c-baae-d5151177e013,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-b379ecce-67c7-4c45-b65a-8e8f837d225e,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ffe3e1bf-f166-4119-8ee8-4eebab5e7f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-73cc842b-be76-40a9-b231-fbb8b0a3efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-6c93e2e8-6a27-4215-81d0-4132ddb11b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-2efc4d17-a2ec-4f95-b7ce-4ec603323f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-158f2d67-2221-4ed4-847b-1bc7f0beae6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676577062-172.17.0.15-1597475230788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-4855f849-9e11-4bda-9b64-72d47d14e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-746b0ee9-65d7-4f05-808b-694ebd95580f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c0fc45e-9705-49e2-a8bb-92c45439a3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-1b6204a0-def0-4c93-ae49-c6fd22932e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-38541e87-2eb6-45f5-b321-caafe8f0f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-8fbd6684-cb2d-4608-8ccc-8fe1d7e42e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-81827eb0-a2f1-45ec-9f61-ba31329af776,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1c6fe019-c4f4-4b04-867e-ec899493a8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676577062-172.17.0.15-1597475230788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-4855f849-9e11-4bda-9b64-72d47d14e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-746b0ee9-65d7-4f05-808b-694ebd95580f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c0fc45e-9705-49e2-a8bb-92c45439a3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-1b6204a0-def0-4c93-ae49-c6fd22932e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-38541e87-2eb6-45f5-b321-caafe8f0f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-8fbd6684-cb2d-4608-8ccc-8fe1d7e42e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-81827eb0-a2f1-45ec-9f61-ba31329af776,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1c6fe019-c4f4-4b04-867e-ec899493a8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101238809-172.17.0.15-1597475451579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-b1adffe9-97ae-4c0a-a40b-fa35e84ba4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-246539cd-442c-4367-a0b5-74de38e770c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-ff1ee90d-0d08-4a12-9fc5-717c988d9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-f7696f57-d353-44f8-8ce9-749811588dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-e433d77b-f69d-4db5-af1a-dab709b00764,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0433b8d5-a96c-4e88-8edd-b96cdbae921c,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cf8677f1-c4e8-45a7-91b4-42d089abb799,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5823a16c-7304-4e98-b702-072809a146f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101238809-172.17.0.15-1597475451579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-b1adffe9-97ae-4c0a-a40b-fa35e84ba4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-246539cd-442c-4367-a0b5-74de38e770c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-ff1ee90d-0d08-4a12-9fc5-717c988d9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-f7696f57-d353-44f8-8ce9-749811588dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-e433d77b-f69d-4db5-af1a-dab709b00764,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0433b8d5-a96c-4e88-8edd-b96cdbae921c,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cf8677f1-c4e8-45a7-91b4-42d089abb799,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5823a16c-7304-4e98-b702-072809a146f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7264838-172.17.0.15-1597476732710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-d11451d7-6977-4bbd-a8e6-36355ccba082,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-3f158ba1-9989-493a-9664-d8e2ccd2987b,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-99722d6d-4008-441f-aa19-0e7c383c8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-7c654103-93d0-4470-b812-20d0d021253e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1a770bb5-08cd-4ec8-87df-d2ce3b5b7a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-b43d8a90-9844-413e-ad8b-0994cc4c1892,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-a6120c50-fb39-4b25-b35d-8477ee0050b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-d0dc3067-8551-4971-958c-ad135e1c724c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7264838-172.17.0.15-1597476732710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-d11451d7-6977-4bbd-a8e6-36355ccba082,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-3f158ba1-9989-493a-9664-d8e2ccd2987b,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-99722d6d-4008-441f-aa19-0e7c383c8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-7c654103-93d0-4470-b812-20d0d021253e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1a770bb5-08cd-4ec8-87df-d2ce3b5b7a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-b43d8a90-9844-413e-ad8b-0994cc4c1892,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-a6120c50-fb39-4b25-b35d-8477ee0050b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-d0dc3067-8551-4971-958c-ad135e1c724c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606560350-172.17.0.15-1597476847592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-5104e105-1396-473a-828e-eaf4c08508cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-549f4b3f-b59f-4716-86e6-ca85a8f47502,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-361d282f-2a62-4878-96eb-30d97e9a2634,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f0e3e375-a55c-4fae-8dab-953b8ab697cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-48494b2c-dad7-442e-aee1-a2f055e383ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-19ae62ed-bbaf-47dc-a761-291eb2895242,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-3b85b7a9-5b7f-4523-b7ab-3ad2d38abe56,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-7a547f6c-d459-4ce3-aa87-e7219d1d14ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606560350-172.17.0.15-1597476847592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-5104e105-1396-473a-828e-eaf4c08508cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-549f4b3f-b59f-4716-86e6-ca85a8f47502,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-361d282f-2a62-4878-96eb-30d97e9a2634,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f0e3e375-a55c-4fae-8dab-953b8ab697cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-48494b2c-dad7-442e-aee1-a2f055e383ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-19ae62ed-bbaf-47dc-a761-291eb2895242,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-3b85b7a9-5b7f-4523-b7ab-3ad2d38abe56,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-7a547f6c-d459-4ce3-aa87-e7219d1d14ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200083033-172.17.0.15-1597477124942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-768dec54-b5fe-4fd2-99bb-3dae84519a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-61010c50-7eb6-4a39-9b4c-b821ba94bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-b0a6199b-8a6f-41ea-83e1-688e9b5a5f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-f00d679a-d8da-4d69-b760-09d70e1c4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-776cf7e8-803c-457c-b5df-24cdffd7ff52,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-5937b3c9-f4bc-4c79-ae86-928128a570f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a88b02c5-01e3-40ad-b517-e8888e08a7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-5c47d5b1-96ce-4b08-9f34-afdfd29dd729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200083033-172.17.0.15-1597477124942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-768dec54-b5fe-4fd2-99bb-3dae84519a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-61010c50-7eb6-4a39-9b4c-b821ba94bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-b0a6199b-8a6f-41ea-83e1-688e9b5a5f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-f00d679a-d8da-4d69-b760-09d70e1c4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-776cf7e8-803c-457c-b5df-24cdffd7ff52,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-5937b3c9-f4bc-4c79-ae86-928128a570f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a88b02c5-01e3-40ad-b517-e8888e08a7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-5c47d5b1-96ce-4b08-9f34-afdfd29dd729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658702249-172.17.0.15-1597477411516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-2381ad1f-c214-410a-9029-b749c7deadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-dd90c3ee-23a9-4b74-a8be-cbd60d80703d,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-0ae8be0e-9242-4cae-bc09-778778f5a127,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-72bf2649-a48e-4a67-8882-e23799b32e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-ee2fd55e-d22e-4c19-9c52-288a448e7a55,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-13ab8255-187d-48ed-acb6-dac5b1796dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-44789d47-e420-4423-b856-0f2ea5ec57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f6916685-73a2-465f-b71a-3eba3864b2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658702249-172.17.0.15-1597477411516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-2381ad1f-c214-410a-9029-b749c7deadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-dd90c3ee-23a9-4b74-a8be-cbd60d80703d,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-0ae8be0e-9242-4cae-bc09-778778f5a127,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-72bf2649-a48e-4a67-8882-e23799b32e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-ee2fd55e-d22e-4c19-9c52-288a448e7a55,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-13ab8255-187d-48ed-acb6-dac5b1796dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-44789d47-e420-4423-b856-0f2ea5ec57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f6916685-73a2-465f-b71a-3eba3864b2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104063310-172.17.0.15-1597478302134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36830,DS-cc828b7b-c451-4115-9f39-2367e3c6a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-bc3a94e5-49be-4039-bb32-13abc4730b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-abc4005f-3b0b-4b80-b000-a37de5bce851,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-00f3e10e-e729-4c99-bea5-1f3fb47f3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e2db4604-7008-4d8b-8215-c776302c7720,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-19d1d5e5-7a5e-495b-b12a-6689a2385be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-5f406527-890b-4ac4-9256-b3365e47fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-9b2c42a3-99d3-4a35-8268-8b4220cf2f0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104063310-172.17.0.15-1597478302134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36830,DS-cc828b7b-c451-4115-9f39-2367e3c6a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-bc3a94e5-49be-4039-bb32-13abc4730b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-abc4005f-3b0b-4b80-b000-a37de5bce851,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-00f3e10e-e729-4c99-bea5-1f3fb47f3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e2db4604-7008-4d8b-8215-c776302c7720,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-19d1d5e5-7a5e-495b-b12a-6689a2385be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-5f406527-890b-4ac4-9256-b3365e47fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-9b2c42a3-99d3-4a35-8268-8b4220cf2f0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5467
