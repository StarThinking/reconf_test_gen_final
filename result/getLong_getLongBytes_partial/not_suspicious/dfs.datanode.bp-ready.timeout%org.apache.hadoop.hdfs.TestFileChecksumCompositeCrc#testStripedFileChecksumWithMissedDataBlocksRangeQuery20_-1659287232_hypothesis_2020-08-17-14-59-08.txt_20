reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141235269-172.17.0.15-1597676587162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-1d10f399-2219-4059-80d2-afa35698bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-83d87942-cb0d-42f3-b068-c9d7e8cea15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-279b1923-dd7b-4531-badc-a214cbb85bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-07589800-264e-4db8-8e55-e1f5b4d7ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-ece30c25-ae8f-4399-b39f-d686a50d5fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-cbbe73b9-3b1c-48ae-803e-3cc1b4495193,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-8a859183-72c7-44f3-8c07-51404c027210,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-3d7c769d-7f9c-43a1-8820-c7492179cb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141235269-172.17.0.15-1597676587162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-1d10f399-2219-4059-80d2-afa35698bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-83d87942-cb0d-42f3-b068-c9d7e8cea15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-279b1923-dd7b-4531-badc-a214cbb85bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-07589800-264e-4db8-8e55-e1f5b4d7ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-ece30c25-ae8f-4399-b39f-d686a50d5fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-cbbe73b9-3b1c-48ae-803e-3cc1b4495193,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-8a859183-72c7-44f3-8c07-51404c027210,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-3d7c769d-7f9c-43a1-8820-c7492179cb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330586285-172.17.0.15-1597677601588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-3caa4454-5b3a-4b32-b160-be124ed5ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-c71be9bf-b8c7-4978-a900-961ff5e7a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-dfa54d6a-a6e6-435c-b334-94bc53e8ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-0e00596c-22da-45e4-b1c1-ebb9ab6e558b,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-7a94a787-d043-4858-b97e-b00706cf77e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-fd844abb-b29b-4cc5-8eb5-e23bd08744d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-8fc1f771-6fd0-42dd-94e1-95eca8d78ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-c6d8d73f-fce1-4328-96f5-ad09d95be1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330586285-172.17.0.15-1597677601588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-3caa4454-5b3a-4b32-b160-be124ed5ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-c71be9bf-b8c7-4978-a900-961ff5e7a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-dfa54d6a-a6e6-435c-b334-94bc53e8ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-0e00596c-22da-45e4-b1c1-ebb9ab6e558b,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-7a94a787-d043-4858-b97e-b00706cf77e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-fd844abb-b29b-4cc5-8eb5-e23bd08744d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-8fc1f771-6fd0-42dd-94e1-95eca8d78ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-c6d8d73f-fce1-4328-96f5-ad09d95be1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469084420-172.17.0.15-1597678556492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-2572db1c-4184-4773-b370-bb170c411a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-de3e1a05-f2c6-4869-89f1-5db2e9c87657,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-a754f643-36f6-4606-b76f-2402adf779ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-7911675a-2f5f-4b2e-913d-dd505acdefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-f495d742-6b6d-43e0-a3bf-f55aec21927d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a2e05097-293f-47cc-816e-1305a40b0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-0774664e-1ebf-457b-a97a-fdda73c0c486,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-c1a17088-932e-4741-9682-a6250937ceee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469084420-172.17.0.15-1597678556492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-2572db1c-4184-4773-b370-bb170c411a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-de3e1a05-f2c6-4869-89f1-5db2e9c87657,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-a754f643-36f6-4606-b76f-2402adf779ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-7911675a-2f5f-4b2e-913d-dd505acdefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-f495d742-6b6d-43e0-a3bf-f55aec21927d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a2e05097-293f-47cc-816e-1305a40b0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-0774664e-1ebf-457b-a97a-fdda73c0c486,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-c1a17088-932e-4741-9682-a6250937ceee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951478165-172.17.0.15-1597679078940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-ae269f9d-d555-4784-aea4-86dac2e977fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-f30a17da-46c6-436a-a476-88890578dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-986dc562-8aa9-49d4-b3ae-28c7ee078220,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8fc0b8a5-3b17-402b-bb27-bb6c449ce87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-6fafd0fe-9ee1-4ba6-a4cf-82310c828f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-830d4a79-a2a0-4cd1-9dc3-137e39b25eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-45fde385-577a-4214-addb-feaf95d97fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-9a0cf1fb-ac91-46aa-ab94-ce94cbf0ef55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951478165-172.17.0.15-1597679078940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-ae269f9d-d555-4784-aea4-86dac2e977fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-f30a17da-46c6-436a-a476-88890578dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-986dc562-8aa9-49d4-b3ae-28c7ee078220,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8fc0b8a5-3b17-402b-bb27-bb6c449ce87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-6fafd0fe-9ee1-4ba6-a4cf-82310c828f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-830d4a79-a2a0-4cd1-9dc3-137e39b25eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-45fde385-577a-4214-addb-feaf95d97fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-9a0cf1fb-ac91-46aa-ab94-ce94cbf0ef55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121572846-172.17.0.15-1597679580463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-c872c86d-5d88-4b16-9e9a-0b088d2b7fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-a7e27770-0e57-44ab-b33c-1d19eb75b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-486594f9-bbdf-4a82-b81c-f09a6ec6541e,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-c1932cee-768b-477e-a4be-a2171bc1f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-bcbc6dc6-3eba-4143-a17b-85b94d7eee14,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-022eef61-e848-4873-ac31-6d3b8629927d,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-d7fce44f-bedc-4c29-bfe0-c1271adf4f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-9b3aa837-a2b3-4f30-b92a-81e1cf3177e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121572846-172.17.0.15-1597679580463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-c872c86d-5d88-4b16-9e9a-0b088d2b7fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-a7e27770-0e57-44ab-b33c-1d19eb75b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-486594f9-bbdf-4a82-b81c-f09a6ec6541e,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-c1932cee-768b-477e-a4be-a2171bc1f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-bcbc6dc6-3eba-4143-a17b-85b94d7eee14,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-022eef61-e848-4873-ac31-6d3b8629927d,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-d7fce44f-bedc-4c29-bfe0-c1271adf4f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-9b3aa837-a2b3-4f30-b92a-81e1cf3177e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339179570-172.17.0.15-1597679934550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-1e0785c1-80a9-4e8e-9c71-3f1ccb671b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-e0887890-8d52-4bdf-a5ad-7fabedb66872,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-bd27ad90-8a2b-42e5-98fd-584bb27823e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-a6f5e32f-f17a-4230-a5c4-b2fde3fab72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-36474337-bcf0-4993-ac45-72ab5e8862a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-0c1eef25-bcd5-4020-ad2f-f72afbbe24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-3b5d453d-cd2e-42cf-82cb-146c257e5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-76145f10-0a2a-4a88-aa49-f151c62f1fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339179570-172.17.0.15-1597679934550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-1e0785c1-80a9-4e8e-9c71-3f1ccb671b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-e0887890-8d52-4bdf-a5ad-7fabedb66872,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-bd27ad90-8a2b-42e5-98fd-584bb27823e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-a6f5e32f-f17a-4230-a5c4-b2fde3fab72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-36474337-bcf0-4993-ac45-72ab5e8862a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-0c1eef25-bcd5-4020-ad2f-f72afbbe24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-3b5d453d-cd2e-42cf-82cb-146c257e5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-76145f10-0a2a-4a88-aa49-f151c62f1fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038873692-172.17.0.15-1597680586503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38843,DS-a82caff2-8dc9-4bbe-baf5-325ddbcec570,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-888d1393-bc96-48e8-9bcb-8e42484b0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-86aba5bd-a168-4a09-9eb3-8c7d751df525,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-4fb3af09-f21c-48d6-8738-141a000272d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-5182943a-37de-4030-98eb-19c72ffeddae,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-cc683d4b-54f6-430a-a7d2-b39b17fa4885,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-d91fb6e0-eca4-4985-b3a9-cff98ecf537b,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-4e51aa84-bf6f-4d39-bb78-5c39b4ec6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038873692-172.17.0.15-1597680586503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38843,DS-a82caff2-8dc9-4bbe-baf5-325ddbcec570,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-888d1393-bc96-48e8-9bcb-8e42484b0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-86aba5bd-a168-4a09-9eb3-8c7d751df525,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-4fb3af09-f21c-48d6-8738-141a000272d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-5182943a-37de-4030-98eb-19c72ffeddae,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-cc683d4b-54f6-430a-a7d2-b39b17fa4885,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-d91fb6e0-eca4-4985-b3a9-cff98ecf537b,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-4e51aa84-bf6f-4d39-bb78-5c39b4ec6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440828308-172.17.0.15-1597680853258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-0784ed78-8fdb-4a0f-b263-2f9862ac4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-ba4eefb0-b59a-4a68-a8c3-7873791b84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-19dff332-07b5-449c-9401-da40090848da,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-8906788f-7765-48d4-88d7-8a016eb0d58d,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-68239633-4366-4251-b707-12b17c939430,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-4e4cb7b2-5b86-4fba-9d54-85634740ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-e8fbf677-791e-4ca4-aa2d-7867484ca6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f368358e-37fb-4da6-95f1-009890bddb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440828308-172.17.0.15-1597680853258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-0784ed78-8fdb-4a0f-b263-2f9862ac4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-ba4eefb0-b59a-4a68-a8c3-7873791b84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-19dff332-07b5-449c-9401-da40090848da,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-8906788f-7765-48d4-88d7-8a016eb0d58d,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-68239633-4366-4251-b707-12b17c939430,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-4e4cb7b2-5b86-4fba-9d54-85634740ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-e8fbf677-791e-4ca4-aa2d-7867484ca6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f368358e-37fb-4da6-95f1-009890bddb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002813579-172.17.0.15-1597682161594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-61fdadef-7e40-4c9a-b9b0-618e5f4e7398,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-a223f64a-86bf-4ad9-92a8-3f316f3ac6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-d68ca359-9b4f-4c92-a0df-eb90f51097e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-0ecfd0fa-d644-416a-af52-0156c4dcb572,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-6d468868-fb49-4d23-9385-3a7639acb6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-17dd5cfd-c33e-4a96-b233-793f7d9b481f,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-36bbf55f-532f-4f49-a422-a02f205d0313,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-73314aa5-5841-48d4-8d12-f152196cec92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002813579-172.17.0.15-1597682161594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-61fdadef-7e40-4c9a-b9b0-618e5f4e7398,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-a223f64a-86bf-4ad9-92a8-3f316f3ac6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-d68ca359-9b4f-4c92-a0df-eb90f51097e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-0ecfd0fa-d644-416a-af52-0156c4dcb572,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-6d468868-fb49-4d23-9385-3a7639acb6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-17dd5cfd-c33e-4a96-b233-793f7d9b481f,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-36bbf55f-532f-4f49-a422-a02f205d0313,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-73314aa5-5841-48d4-8d12-f152196cec92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281508461-172.17.0.15-1597682207957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-02eb8e98-8b67-468e-9e2c-644fb4231a11,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-9cd7f562-65c4-4caa-be73-382543e493c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-4c1b1e7c-0ad3-4634-a363-0e3e84acf83b,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-d381b9d3-887c-4020-bb73-415f2d63898e,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-b00a0652-ac22-4857-9939-23bc62c5ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-dd91b981-c725-4539-8f77-5ca2665f0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7857cd8d-118b-4dfe-8559-b0e3543143c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-7af0b5f2-1d3c-4a05-9b0f-c4996328455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281508461-172.17.0.15-1597682207957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-02eb8e98-8b67-468e-9e2c-644fb4231a11,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-9cd7f562-65c4-4caa-be73-382543e493c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-4c1b1e7c-0ad3-4634-a363-0e3e84acf83b,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-d381b9d3-887c-4020-bb73-415f2d63898e,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-b00a0652-ac22-4857-9939-23bc62c5ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-dd91b981-c725-4539-8f77-5ca2665f0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7857cd8d-118b-4dfe-8559-b0e3543143c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-7af0b5f2-1d3c-4a05-9b0f-c4996328455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357959513-172.17.0.15-1597682258353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-54a96041-1de3-46df-bc73-30b0ae1d6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f13937d1-b971-46c3-b788-ec8df8ad3844,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-40d5fb7a-c117-4bd4-8e98-61cc87e507f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-02c64df0-23e1-41cb-87cc-9c3c5d3ef255,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-c7ef2bce-89cc-4b84-8cfa-d37c3a75947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-67750f87-da39-463c-9cf5-095d3d91ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-dcd58f67-42a7-4229-adc4-2d12df4ef54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e266592f-093e-4405-a900-43217c7b8455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357959513-172.17.0.15-1597682258353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-54a96041-1de3-46df-bc73-30b0ae1d6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f13937d1-b971-46c3-b788-ec8df8ad3844,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-40d5fb7a-c117-4bd4-8e98-61cc87e507f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-02c64df0-23e1-41cb-87cc-9c3c5d3ef255,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-c7ef2bce-89cc-4b84-8cfa-d37c3a75947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-67750f87-da39-463c-9cf5-095d3d91ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-dcd58f67-42a7-4229-adc4-2d12df4ef54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e266592f-093e-4405-a900-43217c7b8455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384372347-172.17.0.15-1597682506436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-05c24b3c-8457-40dc-bacf-c731fd548884,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3564c407-e5f4-473e-af3b-ff8a72a7e5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-8737a65a-46bc-4d23-bca2-1a709da9e129,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-3201f2b3-ae63-4256-98af-26393f085c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-d174b4ec-d02e-4a01-9381-c11790748763,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-399073e4-f7b9-4a51-87e1-9bf5069c9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-9531fbd3-62b2-4414-af6d-b574e674371b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-68661fce-d253-4c73-97e4-3c50fa48cd28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384372347-172.17.0.15-1597682506436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-05c24b3c-8457-40dc-bacf-c731fd548884,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3564c407-e5f4-473e-af3b-ff8a72a7e5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-8737a65a-46bc-4d23-bca2-1a709da9e129,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-3201f2b3-ae63-4256-98af-26393f085c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-d174b4ec-d02e-4a01-9381-c11790748763,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-399073e4-f7b9-4a51-87e1-9bf5069c9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-9531fbd3-62b2-4414-af6d-b574e674371b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-68661fce-d253-4c73-97e4-3c50fa48cd28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538343742-172.17.0.15-1597682819953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-07edef36-3362-4ecd-b56b-f2367358bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-c8d72241-1633-4649-9cd5-7a637692ab24,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-320bb4ca-05c1-4b4f-a33f-dd9a0aef9874,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-ab33f435-0dc9-4e9e-8266-681fa6f8fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-63c20e99-9155-464e-a6e6-767b3f5bbb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-131706c8-6cda-444e-960b-b7a21ce6735c,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-3fdc27f8-72a7-48b3-9189-07caf23e8832,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-96d2514f-f883-45c7-b2e6-c3b351824103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538343742-172.17.0.15-1597682819953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-07edef36-3362-4ecd-b56b-f2367358bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-c8d72241-1633-4649-9cd5-7a637692ab24,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-320bb4ca-05c1-4b4f-a33f-dd9a0aef9874,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-ab33f435-0dc9-4e9e-8266-681fa6f8fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-63c20e99-9155-464e-a6e6-767b3f5bbb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-131706c8-6cda-444e-960b-b7a21ce6735c,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-3fdc27f8-72a7-48b3-9189-07caf23e8832,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-96d2514f-f883-45c7-b2e6-c3b351824103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6584
