reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225842198-172.17.0.14-1597420950695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43657,DS-8c6c7c7f-3355-414b-b68c-2e58832b5919,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-4265fc40-027f-4d94-8ef2-2baa880c912e,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-159a8c35-6a85-4da4-9468-085b0a92f442,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-334ed82a-3558-41f1-88f6-8bb5fb2e2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-ce785ad6-8fac-4230-9766-6240370bfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-c2b3501b-f968-4477-b04a-8a28497e9755,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-5661e43e-5be9-41c1-ac82-7e3aad285408,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-571e32a3-fdce-4b71-b599-ccf5f5ebbcd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225842198-172.17.0.14-1597420950695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43657,DS-8c6c7c7f-3355-414b-b68c-2e58832b5919,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-4265fc40-027f-4d94-8ef2-2baa880c912e,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-159a8c35-6a85-4da4-9468-085b0a92f442,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-334ed82a-3558-41f1-88f6-8bb5fb2e2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-ce785ad6-8fac-4230-9766-6240370bfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-c2b3501b-f968-4477-b04a-8a28497e9755,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-5661e43e-5be9-41c1-ac82-7e3aad285408,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-571e32a3-fdce-4b71-b599-ccf5f5ebbcd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822338480-172.17.0.14-1597420989070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-cd87aef7-d346-4cfd-b878-bc96bc8f8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-b841fe6f-3137-4880-b538-1369d64aac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-9033bb2c-0ab6-4942-bced-f37a6af2d971,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-08ccc778-9504-4b20-9ab0-6e931ee0ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-5d746b03-8a06-4f0a-96a0-1cac3aa96f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-7b46d90f-4433-49c5-ab06-9df6260cbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-2b40b058-55a0-4f2f-bc6f-79df0aade78c,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-cda280d5-b25d-49a8-b8bf-7ff1e0680d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822338480-172.17.0.14-1597420989070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-cd87aef7-d346-4cfd-b878-bc96bc8f8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-b841fe6f-3137-4880-b538-1369d64aac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-9033bb2c-0ab6-4942-bced-f37a6af2d971,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-08ccc778-9504-4b20-9ab0-6e931ee0ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-5d746b03-8a06-4f0a-96a0-1cac3aa96f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-7b46d90f-4433-49c5-ab06-9df6260cbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-2b40b058-55a0-4f2f-bc6f-79df0aade78c,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-cda280d5-b25d-49a8-b8bf-7ff1e0680d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470363479-172.17.0.14-1597421025511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-47434d39-1345-44d7-8018-29b7e3afdd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-378a8e93-c944-472d-bc46-619b214e42ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-d9ab9ca0-0dc9-4773-a60a-5152a435f018,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1c70ad01-cf10-4c71-945c-51ee44d289ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-5c16fe70-866b-4e66-8e90-0ff6a79f4984,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-dfbcabc7-136e-4b36-ac5a-b9f4a48a9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-08beff7b-da09-489a-bc5f-1d2c557f5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-af6af840-7f6c-4e1f-903b-df20b0453534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470363479-172.17.0.14-1597421025511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-47434d39-1345-44d7-8018-29b7e3afdd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-378a8e93-c944-472d-bc46-619b214e42ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-d9ab9ca0-0dc9-4773-a60a-5152a435f018,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1c70ad01-cf10-4c71-945c-51ee44d289ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-5c16fe70-866b-4e66-8e90-0ff6a79f4984,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-dfbcabc7-136e-4b36-ac5a-b9f4a48a9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-08beff7b-da09-489a-bc5f-1d2c557f5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-af6af840-7f6c-4e1f-903b-df20b0453534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866812046-172.17.0.14-1597421164529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-b52df5d2-8582-4dc6-b1e4-8267e18c7205,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-bf45b043-7529-4cb6-8534-1e8a5323110e,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-55a60f44-246b-4a96-ac73-ca47efb86677,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c5b14d0e-6884-47f8-9eb4-4fb826b6078a,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-a5a0bccc-d0f8-4191-9e04-dc5a53f9d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-c13ac631-75ec-4948-b968-1eaf05878fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-30d0db28-c073-4914-bb9c-b0c46ab081b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-3eeed787-925a-46eb-b72d-46352bfa43b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866812046-172.17.0.14-1597421164529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-b52df5d2-8582-4dc6-b1e4-8267e18c7205,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-bf45b043-7529-4cb6-8534-1e8a5323110e,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-55a60f44-246b-4a96-ac73-ca47efb86677,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c5b14d0e-6884-47f8-9eb4-4fb826b6078a,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-a5a0bccc-d0f8-4191-9e04-dc5a53f9d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-c13ac631-75ec-4948-b968-1eaf05878fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-30d0db28-c073-4914-bb9c-b0c46ab081b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-3eeed787-925a-46eb-b72d-46352bfa43b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111877675-172.17.0.14-1597421373439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-d5723daf-ff7a-46cf-b9a3-30766ff1406e,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-f073565d-d6a4-4a1c-9fd6-9f860ea5065d,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e488611-7fe1-45a8-bdad-c2fd9a86abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-6e42ee99-43e6-4031-8c39-b7f3f2525f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-ee090b6a-30ae-4410-84d9-a0b06e560176,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-084885bf-cf68-47a1-82c6-4f9d24d89dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-0250542b-3705-4651-8cd8-63b76b7e1f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d7ba3d0f-f3cf-4838-beeb-52640a9092a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111877675-172.17.0.14-1597421373439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-d5723daf-ff7a-46cf-b9a3-30766ff1406e,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-f073565d-d6a4-4a1c-9fd6-9f860ea5065d,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e488611-7fe1-45a8-bdad-c2fd9a86abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-6e42ee99-43e6-4031-8c39-b7f3f2525f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-ee090b6a-30ae-4410-84d9-a0b06e560176,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-084885bf-cf68-47a1-82c6-4f9d24d89dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-0250542b-3705-4651-8cd8-63b76b7e1f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d7ba3d0f-f3cf-4838-beeb-52640a9092a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414901126-172.17.0.14-1597421405523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-10327539-e902-4714-a897-5ee5f4a6b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-23b0fa94-4b85-4d87-bbeb-7867c70799b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-8701c6f4-62c9-4697-9240-6376b2336a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-5e9c3fe1-f473-447d-b195-36b26d5881f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-2707cfb9-7a3b-468a-b07e-ee6b2a957138,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1a04f0d3-f2f1-4abf-8427-94d831e12fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-00d44d39-9e2a-48f6-8532-d7b452d36834,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-465f77bf-c842-4e9e-8338-173822b54b9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414901126-172.17.0.14-1597421405523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-10327539-e902-4714-a897-5ee5f4a6b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-23b0fa94-4b85-4d87-bbeb-7867c70799b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-8701c6f4-62c9-4697-9240-6376b2336a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-5e9c3fe1-f473-447d-b195-36b26d5881f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-2707cfb9-7a3b-468a-b07e-ee6b2a957138,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1a04f0d3-f2f1-4abf-8427-94d831e12fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-00d44d39-9e2a-48f6-8532-d7b452d36834,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-465f77bf-c842-4e9e-8338-173822b54b9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113995736-172.17.0.14-1597421436309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-34f6b6b9-42e3-41f3-96a0-ac9d47a083b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-b6f4b0da-0d23-4681-b23a-9bcb1ca49111,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-0ed04d30-9610-405a-aff4-91d14f715018,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-1316861a-17b2-4b4f-9db4-2a6f50296d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-30dc1127-8976-40d6-99d8-54b29fdde2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-bae1b332-43ef-4b99-8996-b29e1536526d,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-517dadc9-f6cd-483b-9a89-e27ac9472b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-4170b343-00a0-4fff-8fcd-0186419973e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113995736-172.17.0.14-1597421436309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-34f6b6b9-42e3-41f3-96a0-ac9d47a083b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-b6f4b0da-0d23-4681-b23a-9bcb1ca49111,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-0ed04d30-9610-405a-aff4-91d14f715018,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-1316861a-17b2-4b4f-9db4-2a6f50296d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-30dc1127-8976-40d6-99d8-54b29fdde2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-bae1b332-43ef-4b99-8996-b29e1536526d,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-517dadc9-f6cd-483b-9a89-e27ac9472b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-4170b343-00a0-4fff-8fcd-0186419973e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824363727-172.17.0.14-1597422076591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38298,DS-b47c1040-7ff4-4ab7-93e6-2a383e41ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-d4860a88-1860-4861-9fa0-4685eed5998d,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-9d97fcd4-f6d2-4900-91dd-6617db8b6115,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-f675359a-ecf2-4b92-b018-3d7fdae46179,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-ae050311-eaca-4207-a419-20aeed3e1039,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-80584ccb-7d55-4c95-b304-923cc97924aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-cff9f539-a956-4a7a-8788-3e53401e9ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-1a9b6280-e715-4bb9-a4a8-d039e7fd3896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824363727-172.17.0.14-1597422076591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38298,DS-b47c1040-7ff4-4ab7-93e6-2a383e41ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-d4860a88-1860-4861-9fa0-4685eed5998d,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-9d97fcd4-f6d2-4900-91dd-6617db8b6115,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-f675359a-ecf2-4b92-b018-3d7fdae46179,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-ae050311-eaca-4207-a419-20aeed3e1039,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-80584ccb-7d55-4c95-b304-923cc97924aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-cff9f539-a956-4a7a-8788-3e53401e9ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-1a9b6280-e715-4bb9-a4a8-d039e7fd3896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41088291-172.17.0.14-1597422212031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-96619c84-afd9-4d7a-aaa4-af7cbb1ead7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-da4ab525-7c98-4e27-ba36-7e5211ec1d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-9058f303-3952-48ae-ad12-94e176ab9b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-66082bec-9707-459b-b398-4839c77b9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-87c48de6-3c8f-4511-95ef-403fcca6efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-d2507427-4ff2-45e0-9279-c9c8c7f410d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-d21680e7-159c-4fa2-82fd-61479f3afdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1d16ef09-bb7e-497d-950d-24219edd89b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41088291-172.17.0.14-1597422212031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-96619c84-afd9-4d7a-aaa4-af7cbb1ead7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-da4ab525-7c98-4e27-ba36-7e5211ec1d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-9058f303-3952-48ae-ad12-94e176ab9b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-66082bec-9707-459b-b398-4839c77b9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-87c48de6-3c8f-4511-95ef-403fcca6efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-d2507427-4ff2-45e0-9279-c9c8c7f410d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-d21680e7-159c-4fa2-82fd-61479f3afdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1d16ef09-bb7e-497d-950d-24219edd89b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904566716-172.17.0.14-1597422251876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40997,DS-c159de49-634d-40d9-8f0c-e0c45e820e50,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-a50e3454-81f6-4791-a29f-01b5b98be692,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-254410bd-6d30-4d12-a22c-8ba1bd473b56,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-b59f9435-72c7-444d-b66e-c98c412567b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-bf1f3bd2-3a8a-41d4-8b08-50c5ab4eca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-e97c2cf4-c5b5-452d-955d-8b2d48ee489e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-0233be05-eceb-4734-9d33-2ba89f762230,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-c2800907-13d8-45a0-9b24-7474812c8eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904566716-172.17.0.14-1597422251876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40997,DS-c159de49-634d-40d9-8f0c-e0c45e820e50,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-a50e3454-81f6-4791-a29f-01b5b98be692,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-254410bd-6d30-4d12-a22c-8ba1bd473b56,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-b59f9435-72c7-444d-b66e-c98c412567b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-bf1f3bd2-3a8a-41d4-8b08-50c5ab4eca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-e97c2cf4-c5b5-452d-955d-8b2d48ee489e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-0233be05-eceb-4734-9d33-2ba89f762230,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-c2800907-13d8-45a0-9b24-7474812c8eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144518325-172.17.0.14-1597422553638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-097aa3e7-cc03-4dd8-b028-2dc2519667b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-3c26d105-6043-4c48-8140-21ac3ad9fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-9d7ec8c5-06e0-4e6a-8c34-4b6fc32ab197,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-64f83a0c-58dd-4be9-936b-45c23f8decb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7fb2619e-aa2a-4481-9f2a-51bfca472578,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-e7c41e8f-e60a-4582-9f85-d47e55232a17,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7cf7446e-1c8b-4411-9960-9f74eaf1d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-ae6380e3-4d75-4f21-b364-b43a93997763,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144518325-172.17.0.14-1597422553638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-097aa3e7-cc03-4dd8-b028-2dc2519667b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-3c26d105-6043-4c48-8140-21ac3ad9fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-9d7ec8c5-06e0-4e6a-8c34-4b6fc32ab197,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-64f83a0c-58dd-4be9-936b-45c23f8decb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7fb2619e-aa2a-4481-9f2a-51bfca472578,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-e7c41e8f-e60a-4582-9f85-d47e55232a17,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7cf7446e-1c8b-4411-9960-9f74eaf1d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-ae6380e3-4d75-4f21-b364-b43a93997763,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330036314-172.17.0.14-1597422985091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-0370a6d2-253b-4379-a3dd-0a6262780c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-e7c472a0-35bb-46f2-b9b6-6ca0ed942758,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-265241fe-dcb2-482f-817c-edbf376faf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-80f967f5-8d45-4702-bf0e-ff3c7ec15aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-fe078469-51c4-48c2-81c5-8aa7cd14ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f50dfb7e-faaf-4b6d-b4c3-abf14cb00ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-3857f19f-7986-4b91-a18d-e6b788377d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-77b5a77e-ebd9-45bc-a343-9b864e19a912,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330036314-172.17.0.14-1597422985091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-0370a6d2-253b-4379-a3dd-0a6262780c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-e7c472a0-35bb-46f2-b9b6-6ca0ed942758,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-265241fe-dcb2-482f-817c-edbf376faf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-80f967f5-8d45-4702-bf0e-ff3c7ec15aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-fe078469-51c4-48c2-81c5-8aa7cd14ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f50dfb7e-faaf-4b6d-b4c3-abf14cb00ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-3857f19f-7986-4b91-a18d-e6b788377d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-77b5a77e-ebd9-45bc-a343-9b864e19a912,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59244136-172.17.0.14-1597423230875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-a85aaefb-0015-4bdd-ab39-1f6430a03584,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-e7d4e0d2-33fc-4a1c-bc62-0493f5d3d523,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-eab7799d-f989-4908-96a3-6ae42233960f,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-bdb917f8-b0e5-45db-8182-164021dd8836,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1d6342ed-080e-40f0-bf13-a277d9ccd542,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-acb50efc-0519-4340-9b66-8be6bb6cbbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2725b54d-0c51-4311-8d4f-ff368917f250,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-1f1615f5-c857-4f22-9c7a-a535092a2526,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59244136-172.17.0.14-1597423230875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-a85aaefb-0015-4bdd-ab39-1f6430a03584,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-e7d4e0d2-33fc-4a1c-bc62-0493f5d3d523,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-eab7799d-f989-4908-96a3-6ae42233960f,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-bdb917f8-b0e5-45db-8182-164021dd8836,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1d6342ed-080e-40f0-bf13-a277d9ccd542,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-acb50efc-0519-4340-9b66-8be6bb6cbbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2725b54d-0c51-4311-8d4f-ff368917f250,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-1f1615f5-c857-4f22-9c7a-a535092a2526,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362759792-172.17.0.14-1597423270261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36897,DS-f5c5d0ed-da42-4eba-ba2e-0eff5538d267,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-30f67e56-e3d5-4419-af28-b9efa41e4217,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-0fa6af36-1e77-42e7-be41-ae9e100f1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-8bdee868-99cc-426b-9154-44df4ce3ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7f479160-a20c-442b-91f3-5d01be2860e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4212a9c0-2fde-4b79-8db1-bcde56196c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-82b39049-cb1d-495c-a152-2e6618fb1174,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-337d14c7-d31c-48ab-989a-c0d5ac2157ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362759792-172.17.0.14-1597423270261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36897,DS-f5c5d0ed-da42-4eba-ba2e-0eff5538d267,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-30f67e56-e3d5-4419-af28-b9efa41e4217,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-0fa6af36-1e77-42e7-be41-ae9e100f1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-8bdee868-99cc-426b-9154-44df4ce3ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7f479160-a20c-442b-91f3-5d01be2860e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4212a9c0-2fde-4b79-8db1-bcde56196c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-82b39049-cb1d-495c-a152-2e6618fb1174,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-337d14c7-d31c-48ab-989a-c0d5ac2157ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888787911-172.17.0.14-1597423376179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35409,DS-86bf80d1-c910-4916-8824-6658272c17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-96e07ab7-4b21-4c77-9841-5a2da89b1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-cc0d2256-072a-42ba-b661-52707da3bd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-0c351d18-b478-43e7-8573-004545befbac,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-10d86b9e-87c3-4a4b-b171-69767fef948c,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-25d4f983-475f-4184-89f7-1b159f3bb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-52ec719a-46e2-47da-b762-ec9574642a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-a33a11c9-ad54-4556-bace-72c00c080b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888787911-172.17.0.14-1597423376179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35409,DS-86bf80d1-c910-4916-8824-6658272c17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-96e07ab7-4b21-4c77-9841-5a2da89b1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-cc0d2256-072a-42ba-b661-52707da3bd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-0c351d18-b478-43e7-8573-004545befbac,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-10d86b9e-87c3-4a4b-b171-69767fef948c,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-25d4f983-475f-4184-89f7-1b159f3bb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-52ec719a-46e2-47da-b762-ec9574642a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-a33a11c9-ad54-4556-bace-72c00c080b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284468994-172.17.0.14-1597423551684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-cd0d658d-9bc0-40bc-bf56-a059fdd94c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-1922b0a3-0d54-452a-a6a9-ebe798a37fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-6ecae688-4b7e-4f59-8955-078591de0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-994235e1-c745-4ac6-a5f8-17904245d681,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-4d7749e7-9abf-4182-8147-6b40980053d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-3b3b745e-2f6e-41ed-93b5-a197750983bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-a56737b3-66dc-42fb-a0fe-7439c23e33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-a0537c37-ebb2-4e88-97d1-fff2a4972d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284468994-172.17.0.14-1597423551684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-cd0d658d-9bc0-40bc-bf56-a059fdd94c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-1922b0a3-0d54-452a-a6a9-ebe798a37fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-6ecae688-4b7e-4f59-8955-078591de0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-994235e1-c745-4ac6-a5f8-17904245d681,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-4d7749e7-9abf-4182-8147-6b40980053d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-3b3b745e-2f6e-41ed-93b5-a197750983bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-a56737b3-66dc-42fb-a0fe-7439c23e33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-a0537c37-ebb2-4e88-97d1-fff2a4972d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930732967-172.17.0.14-1597423834393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-7cb8b348-0a87-4216-8057-30330a8aeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-ff76e590-7b9d-43db-a9aa-949c32e63546,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-9c0f1eed-2fd7-439f-8ac4-d20118b548d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-067c6d74-b05f-4946-ac6e-93cca46855c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-59d3ab70-8026-4734-82a6-babaa04b50bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-d5337c42-9ee2-437c-83d0-30cba51de703,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-a267eabd-8915-4bce-a79b-7d8d89bdf2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-87ff4344-9681-4d30-b379-0ef3cb9eea0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930732967-172.17.0.14-1597423834393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-7cb8b348-0a87-4216-8057-30330a8aeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-ff76e590-7b9d-43db-a9aa-949c32e63546,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-9c0f1eed-2fd7-439f-8ac4-d20118b548d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-067c6d74-b05f-4946-ac6e-93cca46855c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-59d3ab70-8026-4734-82a6-babaa04b50bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-d5337c42-9ee2-437c-83d0-30cba51de703,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-a267eabd-8915-4bce-a79b-7d8d89bdf2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-87ff4344-9681-4d30-b379-0ef3cb9eea0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844081260-172.17.0.14-1597423867800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-e87118aa-6100-4b50-af64-ea7aecdf81f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-f295b7df-3f69-4d27-91bf-26a922c006f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-c4ff643b-8958-4e38-8963-ee5dcc58a387,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-62d51151-8fd3-4940-9eac-8a2eaae7e033,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-9864c93c-8fd9-42fa-9d03-266ae328220d,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-0a90139e-5d3e-42b3-b0d2-144cb174340b,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-32c550c1-3fc3-494b-bfe4-d7a37616ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-14036f7b-3668-4d22-ba6d-172318e7b4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844081260-172.17.0.14-1597423867800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-e87118aa-6100-4b50-af64-ea7aecdf81f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-f295b7df-3f69-4d27-91bf-26a922c006f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-c4ff643b-8958-4e38-8963-ee5dcc58a387,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-62d51151-8fd3-4940-9eac-8a2eaae7e033,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-9864c93c-8fd9-42fa-9d03-266ae328220d,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-0a90139e-5d3e-42b3-b0d2-144cb174340b,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-32c550c1-3fc3-494b-bfe4-d7a37616ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-14036f7b-3668-4d22-ba6d-172318e7b4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653724997-172.17.0.14-1597424041498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-3958d537-4e7f-4e22-b16e-7641cca63137,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-2e372950-9447-4217-bb49-f21fd44484ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-304a5455-045c-4ae4-8f8f-dfeb810654b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-0a13d5f4-3780-46f7-94d6-e39b4fc16de2,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-794cbb4f-1705-41bf-ba11-9aa90ee0ae64,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-5ab0ca19-d464-4b6e-8c8f-8ccc0dae2560,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-787e1dcc-e4c4-4672-8d2c-e7dc9c11e380,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-cc3333d2-25fa-42df-a8e1-352dcc2815e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653724997-172.17.0.14-1597424041498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-3958d537-4e7f-4e22-b16e-7641cca63137,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-2e372950-9447-4217-bb49-f21fd44484ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-304a5455-045c-4ae4-8f8f-dfeb810654b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-0a13d5f4-3780-46f7-94d6-e39b4fc16de2,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-794cbb4f-1705-41bf-ba11-9aa90ee0ae64,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-5ab0ca19-d464-4b6e-8c8f-8ccc0dae2560,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-787e1dcc-e4c4-4672-8d2c-e7dc9c11e380,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-cc3333d2-25fa-42df-a8e1-352dcc2815e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241574842-172.17.0.14-1597424352276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-761b9ba2-dfc7-41e4-9c59-a4accc023dac,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-c4719304-f80e-4036-85a6-e1533dcd42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-61368bd1-aca7-4164-a39b-62588cc7bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c3a82a3b-c7cb-4d6b-854c-c1d60d59d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-be48eed9-4fd3-46df-baf7-d0c8a8b49acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-703af6c3-b1b7-4d4c-82fe-ad7d2926c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-c00bd55a-f915-4fdd-a334-afc31f6e895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-5a2df048-fc91-447f-ad27-873469134aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241574842-172.17.0.14-1597424352276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-761b9ba2-dfc7-41e4-9c59-a4accc023dac,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-c4719304-f80e-4036-85a6-e1533dcd42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-61368bd1-aca7-4164-a39b-62588cc7bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c3a82a3b-c7cb-4d6b-854c-c1d60d59d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-be48eed9-4fd3-46df-baf7-d0c8a8b49acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-703af6c3-b1b7-4d4c-82fe-ad7d2926c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-c00bd55a-f915-4fdd-a334-afc31f6e895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-5a2df048-fc91-447f-ad27-873469134aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180479718-172.17.0.14-1597424459486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45582,DS-3dc1dc4b-26d2-491f-a0e7-1f8f370b79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-8b82c1f1-9ead-4ff1-95e3-a3390fdc40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-66e6f1de-6593-4684-b9ac-29d055a2348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-9ca54b8e-e6b4-48f9-80c2-5ed5d37eb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-36bdf206-3700-425c-8b23-3839bb9f9075,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-90a14cec-8b24-45ff-90d6-610660314099,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-90176d64-5da4-45ae-b0f9-0d28ac8152e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-1efe9cd4-8258-43ee-9f50-02009b915058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180479718-172.17.0.14-1597424459486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45582,DS-3dc1dc4b-26d2-491f-a0e7-1f8f370b79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-8b82c1f1-9ead-4ff1-95e3-a3390fdc40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-66e6f1de-6593-4684-b9ac-29d055a2348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-9ca54b8e-e6b4-48f9-80c2-5ed5d37eb9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-36bdf206-3700-425c-8b23-3839bb9f9075,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-90a14cec-8b24-45ff-90d6-610660314099,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-90176d64-5da4-45ae-b0f9-0d28ac8152e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-1efe9cd4-8258-43ee-9f50-02009b915058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987276607-172.17.0.14-1597424784626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-12b6dcad-af6c-4b12-901c-834cd4ebd497,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-833b84bd-b0a4-49bd-bdfd-876791a614fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ab93b941-ed9e-45f6-aa3c-0064d6bad4db,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-9f7e6d59-2e12-4736-9170-3b110bc7ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-b929f0fb-943f-4fb8-a0e9-25ab195b35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-ca013e12-0227-4f2e-834b-8026c0347b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-10cf2b8a-ad9d-4aca-a07a-3023d2aa7c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-a5cdb224-19ef-409e-ad06-47336fc83450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987276607-172.17.0.14-1597424784626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-12b6dcad-af6c-4b12-901c-834cd4ebd497,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-833b84bd-b0a4-49bd-bdfd-876791a614fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ab93b941-ed9e-45f6-aa3c-0064d6bad4db,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-9f7e6d59-2e12-4736-9170-3b110bc7ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-b929f0fb-943f-4fb8-a0e9-25ab195b35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-ca013e12-0227-4f2e-834b-8026c0347b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-10cf2b8a-ad9d-4aca-a07a-3023d2aa7c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-a5cdb224-19ef-409e-ad06-47336fc83450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456205534-172.17.0.14-1597424884793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-e35dbe74-ceb9-47af-a9da-7735d10c6f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-fcff05de-8052-41e6-8070-68f9814b4dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-bd488106-bb5b-4bb4-a2f6-5a23d3a4c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-3e305b7e-cb76-44b3-a9bc-3325906c0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-07be0b99-71dc-45e1-8cda-9bf2b25a671b,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-517a6822-3d1a-4420-88f2-04b694d66800,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-7501b394-819d-4147-a35b-d9d90d18f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-82df3926-98a8-4017-8a3c-dcb872ef4b25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456205534-172.17.0.14-1597424884793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-e35dbe74-ceb9-47af-a9da-7735d10c6f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-fcff05de-8052-41e6-8070-68f9814b4dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-bd488106-bb5b-4bb4-a2f6-5a23d3a4c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-3e305b7e-cb76-44b3-a9bc-3325906c0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-07be0b99-71dc-45e1-8cda-9bf2b25a671b,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-517a6822-3d1a-4420-88f2-04b694d66800,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-7501b394-819d-4147-a35b-d9d90d18f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-82df3926-98a8-4017-8a3c-dcb872ef4b25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60701410-172.17.0.14-1597424939197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-398e3549-2e96-4673-8cc8-dfb4e0a93db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-387ecec1-c6a0-4f1d-9126-c32be0442dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d405b308-c990-4a2d-9571-e8c55a3db9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-552f189c-a13d-426d-aac9-7d8ffcba4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-c29e8dfe-64a9-4a86-8781-c119a7092cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-deb10a73-0277-4d23-a1ab-ee735cc3ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7e841c0e-8914-4cd3-8a75-7301fb2f2065,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-2ebbf8f1-7818-408f-b471-af0e2099c2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60701410-172.17.0.14-1597424939197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-398e3549-2e96-4673-8cc8-dfb4e0a93db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-387ecec1-c6a0-4f1d-9126-c32be0442dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d405b308-c990-4a2d-9571-e8c55a3db9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-552f189c-a13d-426d-aac9-7d8ffcba4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-c29e8dfe-64a9-4a86-8781-c119a7092cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-deb10a73-0277-4d23-a1ab-ee735cc3ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7e841c0e-8914-4cd3-8a75-7301fb2f2065,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-2ebbf8f1-7818-408f-b471-af0e2099c2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413467615-172.17.0.14-1597425043370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-92feef7d-343b-4c44-b762-db72aac61f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-e57e8845-cd02-4fe8-b96f-25cb3831580c,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-7cb2a69a-d170-44e7-83b1-500ef1fe8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-068ffa92-130c-4e12-a79d-cd71eb4c08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2d05460b-5b97-4994-bb48-3d3eb68d4136,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-173bd631-8b0a-4bc7-bd8b-9e25c8eb774e,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-5c976d1e-f12e-4c45-bd10-40a5fd4079a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-dbac5077-296d-4656-b9ed-47deeb7af623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413467615-172.17.0.14-1597425043370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-92feef7d-343b-4c44-b762-db72aac61f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-e57e8845-cd02-4fe8-b96f-25cb3831580c,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-7cb2a69a-d170-44e7-83b1-500ef1fe8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-068ffa92-130c-4e12-a79d-cd71eb4c08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2d05460b-5b97-4994-bb48-3d3eb68d4136,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-173bd631-8b0a-4bc7-bd8b-9e25c8eb774e,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-5c976d1e-f12e-4c45-bd10-40a5fd4079a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-dbac5077-296d-4656-b9ed-47deeb7af623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522176918-172.17.0.14-1597425140379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-6268d560-9804-4a40-9d5d-610787197304,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-5fdca4ab-8010-4914-b9fa-5f0426c82522,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-005334e3-925f-4a19-be87-c3bfbf820fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-ee73d4fb-2a23-4efd-becb-27fcd2e7b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-356eadea-5460-496d-9056-15198d98eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-09e58885-8f3c-4d17-8eb3-9d09d46b4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-c91a920b-5332-4f09-bc8a-9811e77df7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f21450d1-c45d-42a9-9075-08e27c068aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522176918-172.17.0.14-1597425140379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-6268d560-9804-4a40-9d5d-610787197304,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-5fdca4ab-8010-4914-b9fa-5f0426c82522,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-005334e3-925f-4a19-be87-c3bfbf820fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-ee73d4fb-2a23-4efd-becb-27fcd2e7b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-356eadea-5460-496d-9056-15198d98eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-09e58885-8f3c-4d17-8eb3-9d09d46b4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-c91a920b-5332-4f09-bc8a-9811e77df7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f21450d1-c45d-42a9-9075-08e27c068aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914707649-172.17.0.14-1597425168770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-fb9a797a-e3ab-4939-8c6f-45ecdda6b888,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-da9a4163-d865-4336-b5a5-e86905d1f464,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-ca186102-c51c-478c-bb33-bdfe07d86d46,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-4362bb16-8a3d-4b52-acdd-fc9065276aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-df3ca73a-fa8b-49ca-81ee-b442a457cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-197394fe-7ac2-4e43-a1a9-8340612c7caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-04bd2bca-fbe7-48db-9cf5-38719e7aa9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-91988478-8d2b-47b0-b065-91a86399f6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914707649-172.17.0.14-1597425168770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-fb9a797a-e3ab-4939-8c6f-45ecdda6b888,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-da9a4163-d865-4336-b5a5-e86905d1f464,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-ca186102-c51c-478c-bb33-bdfe07d86d46,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-4362bb16-8a3d-4b52-acdd-fc9065276aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-df3ca73a-fa8b-49ca-81ee-b442a457cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-197394fe-7ac2-4e43-a1a9-8340612c7caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-04bd2bca-fbe7-48db-9cf5-38719e7aa9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-91988478-8d2b-47b0-b065-91a86399f6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583758163-172.17.0.14-1597425196492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38833,DS-ecefae4c-573c-49e7-b356-da9baf807470,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bc58e96b-29f5-42ba-b52c-1a479dfd9ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-f92f2901-f11e-4d11-b3ee-278921b1e949,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-b1ca684e-1f27-43d8-8265-1a605c753d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9a3acd29-bb53-42a8-b012-1d147b7d4f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-cf61f26d-18fd-42f6-b9b1-063b2ca0665f,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-a6839728-21c0-4b1b-be4d-de8f388e27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-c1094f5e-b88a-4d12-b08b-5dd009cab8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583758163-172.17.0.14-1597425196492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38833,DS-ecefae4c-573c-49e7-b356-da9baf807470,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bc58e96b-29f5-42ba-b52c-1a479dfd9ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-f92f2901-f11e-4d11-b3ee-278921b1e949,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-b1ca684e-1f27-43d8-8265-1a605c753d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9a3acd29-bb53-42a8-b012-1d147b7d4f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-cf61f26d-18fd-42f6-b9b1-063b2ca0665f,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-a6839728-21c0-4b1b-be4d-de8f388e27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-c1094f5e-b88a-4d12-b08b-5dd009cab8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630045051-172.17.0.14-1597425380292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-2b128a8b-220d-4bfd-95dd-fbd0e336a8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-45e99d6f-1c59-44b4-a521-404ebb1c65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-7551f20a-a979-4ee6-95e3-760d126ca58c,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2434ba96-85cc-4b5e-8ede-af4fd29294a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-13511e30-c754-4556-89b9-7a2e42326c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b565b1b5-7501-4621-8c79-eef417acb245,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-190f5380-0243-448c-989f-651161037f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-f5e515e4-4ac3-484a-b35b-9cc48648f7af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630045051-172.17.0.14-1597425380292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-2b128a8b-220d-4bfd-95dd-fbd0e336a8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-45e99d6f-1c59-44b4-a521-404ebb1c65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-7551f20a-a979-4ee6-95e3-760d126ca58c,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2434ba96-85cc-4b5e-8ede-af4fd29294a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-13511e30-c754-4556-89b9-7a2e42326c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b565b1b5-7501-4621-8c79-eef417acb245,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-190f5380-0243-448c-989f-651161037f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-f5e515e4-4ac3-484a-b35b-9cc48648f7af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53005117-172.17.0.14-1597425599359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-c3a3c523-534e-425a-815d-7385077b4e32,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-53a4f30d-9eae-4918-b027-54f0dd9043eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-5db59f8a-34b9-438e-9e09-117df9941e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d18356db-f6d5-4e35-afb7-ab92a77c6130,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e92374d6-c1b7-480d-bf37-d03f3e6e25be,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-4b6223cb-fba4-4e43-97b2-238439eedf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-34729b93-c3ed-4b37-ac34-e08329e07e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-a6b45ff9-d2ca-4a41-a3a4-3058615e2f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53005117-172.17.0.14-1597425599359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-c3a3c523-534e-425a-815d-7385077b4e32,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-53a4f30d-9eae-4918-b027-54f0dd9043eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-5db59f8a-34b9-438e-9e09-117df9941e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d18356db-f6d5-4e35-afb7-ab92a77c6130,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e92374d6-c1b7-480d-bf37-d03f3e6e25be,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-4b6223cb-fba4-4e43-97b2-238439eedf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-34729b93-c3ed-4b37-ac34-e08329e07e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-a6b45ff9-d2ca-4a41-a3a4-3058615e2f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653082768-172.17.0.14-1597425747135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-d71fa2b8-3d01-4e30-8e5b-270504fcb067,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-8573d7e5-93c8-40fa-ae30-98b43ad98961,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-08ccaa9e-7508-4958-9b82-27f804ae367e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-33e5d38b-5a68-43f9-86c8-c4c6b1bbac49,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-10697f0d-af95-442c-b5d6-a18d17ccba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d8c2e6b6-87ee-4285-bba5-466000f16de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1f1c96ec-d52d-414f-a339-2e74834b7ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-b6f5930a-38c4-4555-b3a0-291861f4c67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653082768-172.17.0.14-1597425747135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-d71fa2b8-3d01-4e30-8e5b-270504fcb067,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-8573d7e5-93c8-40fa-ae30-98b43ad98961,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-08ccaa9e-7508-4958-9b82-27f804ae367e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-33e5d38b-5a68-43f9-86c8-c4c6b1bbac49,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-10697f0d-af95-442c-b5d6-a18d17ccba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d8c2e6b6-87ee-4285-bba5-466000f16de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1f1c96ec-d52d-414f-a339-2e74834b7ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-b6f5930a-38c4-4555-b3a0-291861f4c67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916931695-172.17.0.14-1597425947479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-820b50bc-1f21-4676-8ba5-8eed8ad61013,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-7df11547-5bc1-4d7a-918b-8b45a34751ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-3f99fa64-2a67-4fea-8706-c62bb3cbf134,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8b2fab80-e41a-47e2-a7cb-fe1023702c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-d5d2c4cb-5a43-4463-84e9-2231a27a3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-c71dd254-438a-4a03-99bd-03edb7c7e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-fdfdd163-70de-4f13-807c-9f85ed783876,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-54add7c6-b350-49dc-90ce-b2f85d426d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916931695-172.17.0.14-1597425947479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-820b50bc-1f21-4676-8ba5-8eed8ad61013,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-7df11547-5bc1-4d7a-918b-8b45a34751ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-3f99fa64-2a67-4fea-8706-c62bb3cbf134,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8b2fab80-e41a-47e2-a7cb-fe1023702c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-d5d2c4cb-5a43-4463-84e9-2231a27a3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-c71dd254-438a-4a03-99bd-03edb7c7e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-fdfdd163-70de-4f13-807c-9f85ed783876,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-54add7c6-b350-49dc-90ce-b2f85d426d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5029
