reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430802889-172.17.0.17-1597320238004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-57f7a7ed-c18e-4b77-a620-b5b4d77cb388,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-d723b0b4-8457-48ed-87dd-ea982dda7656,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-163c441d-1cea-447e-9cb6-9ffaab837fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-53a53988-00c2-42e8-ae82-1d25d146d3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-fc1599dd-dfa6-49a3-9d15-2ebfb1e26f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d76f6fac-9ccb-4237-8d9d-a495f2527d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-058df45d-58c0-4223-95c0-866492aecdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-0293364a-00ad-4cab-9a0f-4efeeaa45df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430802889-172.17.0.17-1597320238004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-57f7a7ed-c18e-4b77-a620-b5b4d77cb388,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-d723b0b4-8457-48ed-87dd-ea982dda7656,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-163c441d-1cea-447e-9cb6-9ffaab837fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-53a53988-00c2-42e8-ae82-1d25d146d3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-fc1599dd-dfa6-49a3-9d15-2ebfb1e26f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d76f6fac-9ccb-4237-8d9d-a495f2527d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-058df45d-58c0-4223-95c0-866492aecdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-0293364a-00ad-4cab-9a0f-4efeeaa45df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537941114-172.17.0.17-1597320459807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-7bbd7996-faf2-415b-a00c-a69c74ca2282,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-16e40d67-ca6b-4484-a752-29256c78f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-a6b41b78-6e68-4791-9791-908965ca6196,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-8237c927-c404-4572-88a8-59ab638e96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-0151897b-e770-4430-8ffa-6e6a4234b644,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-f3bfdf95-7e32-46f0-8298-df5a619dcc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-afc50d41-417d-4ab0-8089-0c634cb18179,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-7f8abb5f-3871-493c-b106-eb6bcb2919ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537941114-172.17.0.17-1597320459807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-7bbd7996-faf2-415b-a00c-a69c74ca2282,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-16e40d67-ca6b-4484-a752-29256c78f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-a6b41b78-6e68-4791-9791-908965ca6196,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-8237c927-c404-4572-88a8-59ab638e96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-0151897b-e770-4430-8ffa-6e6a4234b644,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-f3bfdf95-7e32-46f0-8298-df5a619dcc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-afc50d41-417d-4ab0-8089-0c634cb18179,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-7f8abb5f-3871-493c-b106-eb6bcb2919ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013024178-172.17.0.17-1597320723458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-7b5bec3e-c62b-4e28-9e32-c1795bcd7256,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-babbd0e3-b7c7-4ea3-a6be-30f0fdb55135,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-32010a53-3060-4412-80f3-b48438cd2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-213103de-42aa-4f57-ac97-4b0d545c1e71,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-eb5c7d1f-c69b-4d7c-a0a5-2f52fdeea5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-41be86e6-ef58-4835-883e-061c9966f508,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-fc4995eb-7dd9-4d67-8f40-dbf02a526ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-8ed6165b-1783-429f-a857-82dd61a8e7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013024178-172.17.0.17-1597320723458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-7b5bec3e-c62b-4e28-9e32-c1795bcd7256,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-babbd0e3-b7c7-4ea3-a6be-30f0fdb55135,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-32010a53-3060-4412-80f3-b48438cd2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-213103de-42aa-4f57-ac97-4b0d545c1e71,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-eb5c7d1f-c69b-4d7c-a0a5-2f52fdeea5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-41be86e6-ef58-4835-883e-061c9966f508,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-fc4995eb-7dd9-4d67-8f40-dbf02a526ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-8ed6165b-1783-429f-a857-82dd61a8e7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071935452-172.17.0.17-1597320991817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-da191b9d-4614-4bd0-b438-f8c88faa35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-22c5c714-bf1b-4d5c-ad9c-38f18f2183bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-20915b06-d79c-46b7-8162-93e3db8c0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-5b96da81-03cc-4b2b-8282-7ef563cf5c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-926eec02-e6f8-4673-aa0e-76598f98fe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-94d5c989-0feb-4674-a7ad-108c128cc279,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-d67a37f3-0197-4add-bfd9-59b32e3d4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-59371088-6fec-4082-8a15-6ce987ce6618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071935452-172.17.0.17-1597320991817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-da191b9d-4614-4bd0-b438-f8c88faa35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-22c5c714-bf1b-4d5c-ad9c-38f18f2183bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-20915b06-d79c-46b7-8162-93e3db8c0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-5b96da81-03cc-4b2b-8282-7ef563cf5c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-926eec02-e6f8-4673-aa0e-76598f98fe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-94d5c989-0feb-4674-a7ad-108c128cc279,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-d67a37f3-0197-4add-bfd9-59b32e3d4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-59371088-6fec-4082-8a15-6ce987ce6618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445229910-172.17.0.17-1597321308428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-e4ccffcf-aa51-4e4a-8f55-e8c4d963ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-1c8597c1-6967-4584-982a-c240fb782575,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b7384a12-2997-440d-8fdb-ad15fdd9013c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-fe58761e-6961-4b7b-82ad-bd99ec7f6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-43029358-1cb8-433d-b0c2-0ca121ab4577,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-9ba1f397-5509-4545-b766-f1d101a63311,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-2e091228-e151-41b2-875a-d043c285674b,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6a3b8a33-b8b8-4d79-9cc5-1c3e00397fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445229910-172.17.0.17-1597321308428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-e4ccffcf-aa51-4e4a-8f55-e8c4d963ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-1c8597c1-6967-4584-982a-c240fb782575,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b7384a12-2997-440d-8fdb-ad15fdd9013c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-fe58761e-6961-4b7b-82ad-bd99ec7f6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-43029358-1cb8-433d-b0c2-0ca121ab4577,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-9ba1f397-5509-4545-b766-f1d101a63311,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-2e091228-e151-41b2-875a-d043c285674b,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6a3b8a33-b8b8-4d79-9cc5-1c3e00397fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318865638-172.17.0.17-1597321824506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-33696374-3821-42a2-bf7a-ab68a66503a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-b4049bfc-67b9-42d1-9099-99252e3b47d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-f0316648-bd7b-4b9f-9d24-13daeebf933e,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-91be716b-229f-4719-9ce4-92f4b561e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d3ee3878-a520-4869-a6c2-85ee9e224ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-2e39fa2b-4e16-47f9-a914-6c5177676d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-3af663c2-b96f-4c8c-a44d-ff9ca73366bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-e82302bb-d4e7-48a1-824b-af145120f6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318865638-172.17.0.17-1597321824506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-33696374-3821-42a2-bf7a-ab68a66503a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-b4049bfc-67b9-42d1-9099-99252e3b47d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-f0316648-bd7b-4b9f-9d24-13daeebf933e,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-91be716b-229f-4719-9ce4-92f4b561e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d3ee3878-a520-4869-a6c2-85ee9e224ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-2e39fa2b-4e16-47f9-a914-6c5177676d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-3af663c2-b96f-4c8c-a44d-ff9ca73366bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-e82302bb-d4e7-48a1-824b-af145120f6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079234281-172.17.0.17-1597322055929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46362,DS-b8263a6f-8d25-4fc4-a65b-a355615dfd01,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-e635efc5-e121-4433-89df-6c6ddaaf5d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-3608e8c6-4e1a-41f1-b617-9937d1a59bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-92d61cb7-35d2-4729-becf-6f551d389ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-1baa67ee-7d7a-4b00-928a-47bc2fdf3111,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-064e5afa-fca1-43fe-ac8c-7b46c63973bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-0f78f016-daa4-4d94-bcd8-9b3e8d87f852,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-298f92d5-8db4-491b-8ab2-b5fca30ff385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079234281-172.17.0.17-1597322055929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46362,DS-b8263a6f-8d25-4fc4-a65b-a355615dfd01,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-e635efc5-e121-4433-89df-6c6ddaaf5d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-3608e8c6-4e1a-41f1-b617-9937d1a59bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-92d61cb7-35d2-4729-becf-6f551d389ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-1baa67ee-7d7a-4b00-928a-47bc2fdf3111,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-064e5afa-fca1-43fe-ac8c-7b46c63973bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-0f78f016-daa4-4d94-bcd8-9b3e8d87f852,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-298f92d5-8db4-491b-8ab2-b5fca30ff385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986866550-172.17.0.17-1597322090076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34275,DS-34a76fc4-3fe2-4bf6-bed9-b4c6966154b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-77a4f7a6-de50-4a97-b44a-459394a69a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e56318bc-14b7-4c3b-8ece-ddac4cfe2230,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-72cdc48b-ca75-4472-889c-e435eedd5b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-95c905c1-4e04-46c0-bb52-2d902da93e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-1ed3965a-0c99-45c5-ad4f-0fdcc58dc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-6297c3a0-efda-4344-b4f1-531d3aa46d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-dd8aa480-3252-4712-a720-fba1487648a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986866550-172.17.0.17-1597322090076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34275,DS-34a76fc4-3fe2-4bf6-bed9-b4c6966154b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-77a4f7a6-de50-4a97-b44a-459394a69a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e56318bc-14b7-4c3b-8ece-ddac4cfe2230,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-72cdc48b-ca75-4472-889c-e435eedd5b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-95c905c1-4e04-46c0-bb52-2d902da93e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-1ed3965a-0c99-45c5-ad4f-0fdcc58dc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-6297c3a0-efda-4344-b4f1-531d3aa46d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-dd8aa480-3252-4712-a720-fba1487648a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897089300-172.17.0.17-1597322256983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45086,DS-635f6d5d-b12c-48df-af24-c0a90fb74052,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-4c36b7a6-9f77-41aa-a037-6deccf758185,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-59bd2f6b-1b7b-483a-8492-140b9969799b,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-028bcc55-2370-4fc8-ab31-bc9f8e54f654,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-9648f86f-a795-4b7c-af6a-485692ad0bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-cefe4de4-a32e-4eaf-91b6-b70560041cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-d81637e1-817c-4a7b-91eb-b0414f30e180,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-632c41ce-d464-4163-a367-502a6d381d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897089300-172.17.0.17-1597322256983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45086,DS-635f6d5d-b12c-48df-af24-c0a90fb74052,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-4c36b7a6-9f77-41aa-a037-6deccf758185,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-59bd2f6b-1b7b-483a-8492-140b9969799b,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-028bcc55-2370-4fc8-ab31-bc9f8e54f654,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-9648f86f-a795-4b7c-af6a-485692ad0bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-cefe4de4-a32e-4eaf-91b6-b70560041cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-d81637e1-817c-4a7b-91eb-b0414f30e180,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-632c41ce-d464-4163-a367-502a6d381d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933370898-172.17.0.17-1597322407734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-13adaeba-f289-4d0d-b5a4-d4a673da193d,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d208aea8-c2b1-4257-a82b-bc957ec0e798,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-18f6c65e-31db-4a7a-908b-a664c775082c,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-da1e402a-f5df-4639-b671-c59383d4aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-f1c281a4-f84c-4912-bea2-17c030303652,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-bdc9be05-bca2-468f-8adf-22c4fdd29f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-3149fb76-e660-49c7-81fd-80521047aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-2ee9de62-a996-4f90-80ee-46a45b372223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933370898-172.17.0.17-1597322407734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-13adaeba-f289-4d0d-b5a4-d4a673da193d,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d208aea8-c2b1-4257-a82b-bc957ec0e798,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-18f6c65e-31db-4a7a-908b-a664c775082c,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-da1e402a-f5df-4639-b671-c59383d4aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-f1c281a4-f84c-4912-bea2-17c030303652,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-bdc9be05-bca2-468f-8adf-22c4fdd29f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-3149fb76-e660-49c7-81fd-80521047aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-2ee9de62-a996-4f90-80ee-46a45b372223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817227885-172.17.0.17-1597322563023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-3a87a1be-a77d-4c55-9f7d-00da4f4a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-3d19a0e1-1020-4c8c-b7ed-2447b5247bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-50cb0427-9d73-467a-97fc-a0677bcb9bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-8b265560-9b26-4f48-b750-04157bdb5628,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e7c95ac6-b39a-46a7-b4e6-958373e0c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-566d6597-563e-4827-a032-1946431834b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-61c68639-784b-47e6-aa3f-a8d7918c56bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-8f632334-1c09-456b-9159-18277a879e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817227885-172.17.0.17-1597322563023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-3a87a1be-a77d-4c55-9f7d-00da4f4a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-3d19a0e1-1020-4c8c-b7ed-2447b5247bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-50cb0427-9d73-467a-97fc-a0677bcb9bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-8b265560-9b26-4f48-b750-04157bdb5628,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e7c95ac6-b39a-46a7-b4e6-958373e0c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-566d6597-563e-4827-a032-1946431834b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-61c68639-784b-47e6-aa3f-a8d7918c56bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-8f632334-1c09-456b-9159-18277a879e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031220015-172.17.0.17-1597322984269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-ef12464c-1b8e-437d-bfe4-c0dd86777812,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-bdc190b8-6e9a-4835-990b-b81deb55dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-75051d60-215a-4f29-9a6f-dee9af8a9329,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-32a60f59-ea00-4f88-92ec-a05cd1af845a,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-c621a716-f768-486f-a42e-bfdad9834e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-ba92327e-0f08-4569-b974-ae6663ed9a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-42c12331-2f01-44db-be41-97ab3a9419f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-26f2e084-ec1a-45b5-b28f-6a9568598993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031220015-172.17.0.17-1597322984269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-ef12464c-1b8e-437d-bfe4-c0dd86777812,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-bdc190b8-6e9a-4835-990b-b81deb55dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-75051d60-215a-4f29-9a6f-dee9af8a9329,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-32a60f59-ea00-4f88-92ec-a05cd1af845a,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-c621a716-f768-486f-a42e-bfdad9834e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-ba92327e-0f08-4569-b974-ae6663ed9a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-42c12331-2f01-44db-be41-97ab3a9419f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-26f2e084-ec1a-45b5-b28f-6a9568598993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814481534-172.17.0.17-1597323211799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-59bff99b-cc80-4d71-b866-4fd1a725b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d6dd7500-01bc-4cb4-b82c-fe79bf4dc541,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-204fddd1-bb33-4eda-be6e-7f6e0e5b3f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-252fb799-900f-47c9-ad4e-e9bd3d71a525,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-d44c4d13-c72b-4a9e-960e-437c575e44a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-d8cbd100-07fa-482e-a729-0d5e0cffa767,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-f2079bac-93e8-4cb6-982b-960724ce626c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-7e6cfcf8-3314-454b-8dcb-602c79282708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814481534-172.17.0.17-1597323211799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-59bff99b-cc80-4d71-b866-4fd1a725b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d6dd7500-01bc-4cb4-b82c-fe79bf4dc541,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-204fddd1-bb33-4eda-be6e-7f6e0e5b3f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-252fb799-900f-47c9-ad4e-e9bd3d71a525,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-d44c4d13-c72b-4a9e-960e-437c575e44a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-d8cbd100-07fa-482e-a729-0d5e0cffa767,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-f2079bac-93e8-4cb6-982b-960724ce626c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-7e6cfcf8-3314-454b-8dcb-602c79282708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889650166-172.17.0.17-1597323256393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-0f48fc21-d63a-4b01-9e06-0359c359f300,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-27f355a6-2417-4228-8584-79dd1ceb5af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-41845ce4-adf3-480f-bce7-12304835d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1728e761-9f7d-444a-b895-0f2e4673f788,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-66d670d1-298e-4804-89b2-d49031830df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c5f5d27e-5910-4d81-a090-57bf52bdf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-16cb67d9-3d0d-4cf2-b932-715372d4151f,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-98140c2b-e2c4-4984-8aa5-f86bf6edef93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889650166-172.17.0.17-1597323256393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-0f48fc21-d63a-4b01-9e06-0359c359f300,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-27f355a6-2417-4228-8584-79dd1ceb5af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-41845ce4-adf3-480f-bce7-12304835d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1728e761-9f7d-444a-b895-0f2e4673f788,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-66d670d1-298e-4804-89b2-d49031830df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c5f5d27e-5910-4d81-a090-57bf52bdf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-16cb67d9-3d0d-4cf2-b932-715372d4151f,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-98140c2b-e2c4-4984-8aa5-f86bf6edef93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115789086-172.17.0.17-1597323297261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-397544a2-f147-4e12-b668-943385d5f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-8deb3f36-2090-4f3c-819d-4d9920a94f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-d4a1081a-8ab6-4042-823e-c23207c5afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-01b097fd-d9dd-4a41-b47e-0917cf7e0f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-71e53fce-2203-4b4a-997d-0c7739ae839e,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-63a2405c-7db4-4f56-87c9-119dda4f57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-ec7481d0-fcf3-4976-b459-7b903b6c92b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-463ccc76-6b9d-486e-86f2-1d65bc278fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115789086-172.17.0.17-1597323297261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-397544a2-f147-4e12-b668-943385d5f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-8deb3f36-2090-4f3c-819d-4d9920a94f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-d4a1081a-8ab6-4042-823e-c23207c5afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-01b097fd-d9dd-4a41-b47e-0917cf7e0f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-71e53fce-2203-4b4a-997d-0c7739ae839e,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-63a2405c-7db4-4f56-87c9-119dda4f57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-ec7481d0-fcf3-4976-b459-7b903b6c92b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-463ccc76-6b9d-486e-86f2-1d65bc278fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483245634-172.17.0.17-1597323443750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-02bfd055-d12e-4542-b722-833990efbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d42a7c97-841e-4713-9124-87744bd7e4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-f3e6feab-0de4-4c9b-af37-850b0530e116,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-c9254e87-0f71-4389-b860-ee78bf05af69,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-6c546d75-4f14-4dd5-b9c5-0fa3d7941bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9d4ebf88-4ffa-4183-a21a-fe3d47964ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-78b2c7b8-041f-42fa-93c3-276ed34a9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-03283e00-f949-49df-bd07-a7fe637aba85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483245634-172.17.0.17-1597323443750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-02bfd055-d12e-4542-b722-833990efbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d42a7c97-841e-4713-9124-87744bd7e4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-f3e6feab-0de4-4c9b-af37-850b0530e116,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-c9254e87-0f71-4389-b860-ee78bf05af69,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-6c546d75-4f14-4dd5-b9c5-0fa3d7941bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9d4ebf88-4ffa-4183-a21a-fe3d47964ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-78b2c7b8-041f-42fa-93c3-276ed34a9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-03283e00-f949-49df-bd07-a7fe637aba85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801402304-172.17.0.17-1597323669547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-0b2daa39-2334-4e13-96ca-b81fb83181ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-492db47e-fba5-4455-b6d7-28407ff32bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-f3b47638-22e6-4058-91dc-847f392665fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5a46d597-1071-4b51-b7ba-f6705effc86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-23dd117e-77ba-499f-a207-d9a3a4e1a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-3472b9c2-c7e4-4edf-acc2-4b8b87b2eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-f7ee81c8-ddc6-48f3-b199-1eb36b386872,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-1fdc81b8-5b89-4378-8d98-8d286f134a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801402304-172.17.0.17-1597323669547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-0b2daa39-2334-4e13-96ca-b81fb83181ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-492db47e-fba5-4455-b6d7-28407ff32bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-f3b47638-22e6-4058-91dc-847f392665fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5a46d597-1071-4b51-b7ba-f6705effc86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-23dd117e-77ba-499f-a207-d9a3a4e1a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-3472b9c2-c7e4-4edf-acc2-4b8b87b2eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-f7ee81c8-ddc6-48f3-b199-1eb36b386872,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-1fdc81b8-5b89-4378-8d98-8d286f134a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205900768-172.17.0.17-1597323862927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36830,DS-8d2ad171-de99-46b0-9f07-5b4618b0dc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a8bf3de2-edc3-4af0-9f16-c61373ecc07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-ec5674dd-e56e-4a2d-89ff-9ad07c34a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a132ed0e-2259-4e3d-9020-8468575183d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-86bbefc5-1b26-40b4-9afd-f001e7764541,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-1a3300e7-bf31-4581-a700-eae911f60646,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2eadafa2-d3ed-47a9-926e-0a4478588c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-67624cfd-72c4-40ad-8722-444aa8504b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205900768-172.17.0.17-1597323862927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36830,DS-8d2ad171-de99-46b0-9f07-5b4618b0dc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a8bf3de2-edc3-4af0-9f16-c61373ecc07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-ec5674dd-e56e-4a2d-89ff-9ad07c34a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a132ed0e-2259-4e3d-9020-8468575183d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-86bbefc5-1b26-40b4-9afd-f001e7764541,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-1a3300e7-bf31-4581-a700-eae911f60646,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2eadafa2-d3ed-47a9-926e-0a4478588c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-67624cfd-72c4-40ad-8722-444aa8504b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733123496-172.17.0.17-1597323944412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-cddc307c-81c3-43aa-874e-c34291d86f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-dd872887-2a3f-4a19-8a67-bf02c7718cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-84f1aa8a-47bc-4608-a245-1730699a7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-ca97079a-1c59-4dc1-811b-66c0372f428b,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-0e2ed6a4-311b-4114-968d-d469231098f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-11c684bd-2e50-48a4-a23b-391a03740d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-245ef18b-3936-4f29-8033-7173774cdcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-034fbbee-fd30-431a-aa03-300118ea034f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733123496-172.17.0.17-1597323944412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-cddc307c-81c3-43aa-874e-c34291d86f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-dd872887-2a3f-4a19-8a67-bf02c7718cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-84f1aa8a-47bc-4608-a245-1730699a7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-ca97079a-1c59-4dc1-811b-66c0372f428b,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-0e2ed6a4-311b-4114-968d-d469231098f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-11c684bd-2e50-48a4-a23b-391a03740d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-245ef18b-3936-4f29-8033-7173774cdcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-034fbbee-fd30-431a-aa03-300118ea034f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383995348-172.17.0.17-1597324426078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-84d740ac-2aa4-455b-9622-21d499f333e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-ac5e030f-6e3d-4d57-be3a-74fc143938b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-5c35995d-d138-44a6-af93-36e05a822161,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-4770326c-7f37-45c8-a5f3-4477f9b230eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-63d15254-59d3-4951-abb5-362a95890474,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-d4bb16b7-3e4b-4bbf-8b2b-8e0986c46e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-8e5f3d21-7e16-41fb-b56f-43def689d56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-2db1de52-2490-4dd2-b101-ca18009c9d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383995348-172.17.0.17-1597324426078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-84d740ac-2aa4-455b-9622-21d499f333e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-ac5e030f-6e3d-4d57-be3a-74fc143938b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-5c35995d-d138-44a6-af93-36e05a822161,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-4770326c-7f37-45c8-a5f3-4477f9b230eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-63d15254-59d3-4951-abb5-362a95890474,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-d4bb16b7-3e4b-4bbf-8b2b-8e0986c46e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-8e5f3d21-7e16-41fb-b56f-43def689d56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-2db1de52-2490-4dd2-b101-ca18009c9d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323785850-172.17.0.17-1597325224590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-9c00fe2f-480d-4740-9700-be17d5b89caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-b59bbdea-a6b0-4a6a-8675-9c8ec78eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-1d933bc5-ea7d-4610-9443-8dcbf4f0cc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-1298374b-c0f6-4785-8c07-cd540e648e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-df7b7f88-3a07-48be-9aea-b6d6819ac76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-70cc61bb-1a9d-4387-87d9-d29316e64706,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-c3b833ca-35c4-4cd7-b809-128fcc7d43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-ab224668-d734-489c-8ac9-44cd22e0d9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323785850-172.17.0.17-1597325224590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-9c00fe2f-480d-4740-9700-be17d5b89caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-b59bbdea-a6b0-4a6a-8675-9c8ec78eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-1d933bc5-ea7d-4610-9443-8dcbf4f0cc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-1298374b-c0f6-4785-8c07-cd540e648e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-df7b7f88-3a07-48be-9aea-b6d6819ac76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-70cc61bb-1a9d-4387-87d9-d29316e64706,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-c3b833ca-35c4-4cd7-b809-128fcc7d43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-ab224668-d734-489c-8ac9-44cd22e0d9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951361620-172.17.0.17-1597325364869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-179cc555-6097-41d4-8d17-f4155385398f,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-f51f637d-c25f-4a3c-ad70-80977e81ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-f22242bf-1e91-4565-bee9-49356e9bd928,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f32fa6ee-cab7-47ec-81ae-f9ac258343d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-a8a4d4a2-025b-4de2-8d85-e715237e3ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-76bedee7-0627-45ce-a073-5adaf7821983,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-e82339ab-bb7d-4965-b26f-b0c65d3454ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-8fb1a6f2-8c2a-4b8e-b9d6-5b3548bfe84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951361620-172.17.0.17-1597325364869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-179cc555-6097-41d4-8d17-f4155385398f,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-f51f637d-c25f-4a3c-ad70-80977e81ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-f22242bf-1e91-4565-bee9-49356e9bd928,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f32fa6ee-cab7-47ec-81ae-f9ac258343d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-a8a4d4a2-025b-4de2-8d85-e715237e3ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-76bedee7-0627-45ce-a073-5adaf7821983,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-e82339ab-bb7d-4965-b26f-b0c65d3454ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-8fb1a6f2-8c2a-4b8e-b9d6-5b3548bfe84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5665
