reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356202365-172.17.0.10-1597425886824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-2f2c3e48-b19d-46b3-9ed4-e5dcec017bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-35620cc9-1357-4c1f-8622-6cd378d0aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-ab7b7e69-2d7b-435d-aa47-bf2f50bf483d,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-624b5d81-20e5-45c0-b805-a8aa195ba1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-caf620a5-f000-4ca8-8f01-f5b28ded541e,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-7b4ed2de-39b1-4513-ad3b-2a9981ccc109,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-b74aecbd-52a3-41b1-aed0-0d7534d1dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-d952ad84-9fe6-45cb-8578-5e535a317fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356202365-172.17.0.10-1597425886824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-2f2c3e48-b19d-46b3-9ed4-e5dcec017bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-35620cc9-1357-4c1f-8622-6cd378d0aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-ab7b7e69-2d7b-435d-aa47-bf2f50bf483d,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-624b5d81-20e5-45c0-b805-a8aa195ba1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-caf620a5-f000-4ca8-8f01-f5b28ded541e,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-7b4ed2de-39b1-4513-ad3b-2a9981ccc109,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-b74aecbd-52a3-41b1-aed0-0d7534d1dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-d952ad84-9fe6-45cb-8578-5e535a317fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102638194-172.17.0.10-1597426088382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-cd2b3701-7104-4c99-a458-19fdf8d73310,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-1699ecec-1ad2-4c90-ab73-70cd81a15fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3a2c4aa5-7f0d-44f0-822b-8419309201f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-9453fc65-00b8-4c77-841c-acb631b1f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d8b22b16-fd35-4c91-8002-c639c43c2564,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c9c22d35-597b-472d-86d2-b4039a3aef49,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-95afe94d-fbf8-424f-b860-72415c5e0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-8acc47e2-fc2f-4b81-8fc0-9c3c940fe003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102638194-172.17.0.10-1597426088382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-cd2b3701-7104-4c99-a458-19fdf8d73310,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-1699ecec-1ad2-4c90-ab73-70cd81a15fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3a2c4aa5-7f0d-44f0-822b-8419309201f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-9453fc65-00b8-4c77-841c-acb631b1f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d8b22b16-fd35-4c91-8002-c639c43c2564,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c9c22d35-597b-472d-86d2-b4039a3aef49,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-95afe94d-fbf8-424f-b860-72415c5e0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-8acc47e2-fc2f-4b81-8fc0-9c3c940fe003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413799692-172.17.0.10-1597426277734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-5d0569de-9a27-4f8f-ab75-01de149f5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-f8fcf572-dd9e-470a-bab5-ecfa15629ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-84aab3b5-6aac-4dc9-be74-94ecf2de791b,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-992488e4-8a59-4054-a8c2-1f9cbd92d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-c74cfc0a-62ed-42a2-a254-f93c9a3fa497,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-cb4f71c8-ba86-432b-8e6e-0709b4c0331c,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-30f331cc-cfe8-4aac-9df2-d0b2b7c7fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-29709075-04c8-4ce0-917b-e4337c67aa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413799692-172.17.0.10-1597426277734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-5d0569de-9a27-4f8f-ab75-01de149f5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-f8fcf572-dd9e-470a-bab5-ecfa15629ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-84aab3b5-6aac-4dc9-be74-94ecf2de791b,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-992488e4-8a59-4054-a8c2-1f9cbd92d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-c74cfc0a-62ed-42a2-a254-f93c9a3fa497,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-cb4f71c8-ba86-432b-8e6e-0709b4c0331c,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-30f331cc-cfe8-4aac-9df2-d0b2b7c7fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-29709075-04c8-4ce0-917b-e4337c67aa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352700434-172.17.0.10-1597426434619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-c4fb085a-30aa-4934-8ea5-e5bbcf4b3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-93c4f95b-f07f-4673-9d84-5840b61fc939,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ff5203bc-d449-42b3-b616-9cc7f46b09cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-1527907c-3fd2-4a54-a398-13b3aa5fc2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b130ee71-919b-433f-8d39-6387708671e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1b20d562-374c-4c7a-ab75-feea8e031a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-dd28193d-f458-47cd-85e7-a578475a9502,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-c68e7cf1-b6e9-4bb1-86d4-7a9514c533da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352700434-172.17.0.10-1597426434619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-c4fb085a-30aa-4934-8ea5-e5bbcf4b3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-93c4f95b-f07f-4673-9d84-5840b61fc939,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ff5203bc-d449-42b3-b616-9cc7f46b09cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-1527907c-3fd2-4a54-a398-13b3aa5fc2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b130ee71-919b-433f-8d39-6387708671e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1b20d562-374c-4c7a-ab75-feea8e031a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-dd28193d-f458-47cd-85e7-a578475a9502,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-c68e7cf1-b6e9-4bb1-86d4-7a9514c533da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586135235-172.17.0.10-1597426466052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-67184b4e-0261-4e57-9055-af09c05349e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-e189dd23-1c03-446e-98de-8c835b6677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-32db1d35-3ebc-49ec-8a0d-f7624299172d,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-346d24f5-9f9a-4896-8577-983e00a6a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-df820761-f28f-49e0-8d53-63d307d2d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f69aec99-4861-4216-b336-ce949d8d05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-e32676bd-01f2-4093-8378-db8ceda20ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-a6554bd4-44ee-4018-828e-3c7d690e2029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586135235-172.17.0.10-1597426466052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-67184b4e-0261-4e57-9055-af09c05349e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-e189dd23-1c03-446e-98de-8c835b6677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-32db1d35-3ebc-49ec-8a0d-f7624299172d,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-346d24f5-9f9a-4896-8577-983e00a6a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-df820761-f28f-49e0-8d53-63d307d2d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f69aec99-4861-4216-b336-ce949d8d05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-e32676bd-01f2-4093-8378-db8ceda20ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-a6554bd4-44ee-4018-828e-3c7d690e2029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317241821-172.17.0.10-1597426576290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39686,DS-b7865936-2e2e-4926-9ada-54b1f0159548,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-4d59ee00-1d6f-4cfa-802f-85f0f1a61c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-ec7b180f-9126-48af-b7c3-73d2717211b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b2f245d1-51bc-4c3c-8ea8-505fe2a8ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-31d7e22a-af5b-49ec-880c-06a1a19f113d,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-75573b3a-9d01-44f6-a7b4-84450e2f9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-9299cd92-dbb4-41ca-8316-49b30073d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-f2de6ec6-c929-46ec-87d6-8ef146219b69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317241821-172.17.0.10-1597426576290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39686,DS-b7865936-2e2e-4926-9ada-54b1f0159548,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-4d59ee00-1d6f-4cfa-802f-85f0f1a61c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-ec7b180f-9126-48af-b7c3-73d2717211b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b2f245d1-51bc-4c3c-8ea8-505fe2a8ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-31d7e22a-af5b-49ec-880c-06a1a19f113d,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-75573b3a-9d01-44f6-a7b4-84450e2f9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-9299cd92-dbb4-41ca-8316-49b30073d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-f2de6ec6-c929-46ec-87d6-8ef146219b69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285242180-172.17.0.10-1597426655321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-ea71b473-10b4-47f8-82d1-47eefb359bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-92ac6039-a924-4bbe-bfb4-43c1c0d514a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-124b962c-e65d-42a1-afb8-4972d3e837e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ee697361-1cc7-4550-91d1-bd71bfa1d029,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-df115330-00bd-4964-b6a9-4d2fe3283726,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-c54b416a-e6e9-4378-981f-818de4cda5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-b79a5a50-b84d-4dcc-9bb5-69edb0cddcef,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-a52a97e4-ef6f-4ad9-b695-8657eb382be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285242180-172.17.0.10-1597426655321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-ea71b473-10b4-47f8-82d1-47eefb359bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-92ac6039-a924-4bbe-bfb4-43c1c0d514a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-124b962c-e65d-42a1-afb8-4972d3e837e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ee697361-1cc7-4550-91d1-bd71bfa1d029,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-df115330-00bd-4964-b6a9-4d2fe3283726,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-c54b416a-e6e9-4378-981f-818de4cda5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-b79a5a50-b84d-4dcc-9bb5-69edb0cddcef,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-a52a97e4-ef6f-4ad9-b695-8657eb382be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445776855-172.17.0.10-1597426772909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-5c918077-a35f-4a57-9351-ac8c71e40fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-14bde3d3-3a58-4a79-bfd0-ffc4efdd42b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-57c24228-ab3c-4a0f-afdb-408d72262b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-1601d670-d023-452b-917d-ebbcb7339372,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1cb9b473-31b2-4584-8ba4-c8bfbfebafbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-9aa04245-0052-44ef-b86d-ff86807a9366,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-72400b28-053d-44fc-8196-1ab16244e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-e36b4ba6-0e9f-4a58-937d-96c03c2bada0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445776855-172.17.0.10-1597426772909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-5c918077-a35f-4a57-9351-ac8c71e40fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-14bde3d3-3a58-4a79-bfd0-ffc4efdd42b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-57c24228-ab3c-4a0f-afdb-408d72262b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-1601d670-d023-452b-917d-ebbcb7339372,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1cb9b473-31b2-4584-8ba4-c8bfbfebafbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-9aa04245-0052-44ef-b86d-ff86807a9366,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-72400b28-053d-44fc-8196-1ab16244e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-e36b4ba6-0e9f-4a58-937d-96c03c2bada0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125212390-172.17.0.10-1597426890368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-ad279687-3da2-4813-8e1f-9e1c730247d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-949eb78e-9e77-4e6d-9544-813272589223,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-f0486fe6-9499-4723-a350-4b048bca7594,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-f9c087bd-2ab2-4f97-91f5-1ec2e8f5924f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-e5c83bd7-8c63-44fc-8496-8ad67c2f6862,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-2ed15615-9146-4593-953a-08f9b4f9a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-6cb2f8eb-2cd2-4636-add0-cc7451ff4365,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-8e321d85-e67f-4cb9-adf1-474a0d5b0365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125212390-172.17.0.10-1597426890368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-ad279687-3da2-4813-8e1f-9e1c730247d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-949eb78e-9e77-4e6d-9544-813272589223,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-f0486fe6-9499-4723-a350-4b048bca7594,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-f9c087bd-2ab2-4f97-91f5-1ec2e8f5924f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-e5c83bd7-8c63-44fc-8496-8ad67c2f6862,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-2ed15615-9146-4593-953a-08f9b4f9a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-6cb2f8eb-2cd2-4636-add0-cc7451ff4365,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-8e321d85-e67f-4cb9-adf1-474a0d5b0365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886634382-172.17.0.10-1597426966620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-b5a72c22-0bbf-404f-b0cd-092b4b5ffd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-97adef7f-09bd-4b4f-ad18-60dd4d501076,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-f9ba878c-bcc7-48ab-a097-b28641642b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-60dbe3f7-b5b0-4bfb-ba66-de673fbb988c,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-0db25a84-7215-4ddb-b7dc-8e6aaacc1091,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-257a40fd-430a-47ab-9f36-eda8a310dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a21d9882-7f19-4a65-9e42-e24586b8f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-841f34a1-e8b4-4d56-9dc9-0489c46c1a35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886634382-172.17.0.10-1597426966620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-b5a72c22-0bbf-404f-b0cd-092b4b5ffd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-97adef7f-09bd-4b4f-ad18-60dd4d501076,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-f9ba878c-bcc7-48ab-a097-b28641642b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-60dbe3f7-b5b0-4bfb-ba66-de673fbb988c,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-0db25a84-7215-4ddb-b7dc-8e6aaacc1091,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-257a40fd-430a-47ab-9f36-eda8a310dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a21d9882-7f19-4a65-9e42-e24586b8f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-841f34a1-e8b4-4d56-9dc9-0489c46c1a35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786490084-172.17.0.10-1597427003263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-dca69b14-5250-4d4f-9751-ac8547121ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-8692302f-9003-4a0b-b4a2-267f031ce873,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-c7dc198d-7bb1-48de-977d-5a6e749c8256,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-2e86ce7b-7ae8-47fe-ab32-ec396d5bed98,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ed27f582-ad57-4207-9823-a3168d330a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-381e77b0-5b0c-4489-8c14-036ff04e67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-b6d29926-e7b7-4304-8235-f17b14c1dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-4294821d-b546-429a-a1d0-f817a1aa840a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786490084-172.17.0.10-1597427003263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-dca69b14-5250-4d4f-9751-ac8547121ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-8692302f-9003-4a0b-b4a2-267f031ce873,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-c7dc198d-7bb1-48de-977d-5a6e749c8256,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-2e86ce7b-7ae8-47fe-ab32-ec396d5bed98,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ed27f582-ad57-4207-9823-a3168d330a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-381e77b0-5b0c-4489-8c14-036ff04e67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-b6d29926-e7b7-4304-8235-f17b14c1dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-4294821d-b546-429a-a1d0-f817a1aa840a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453442371-172.17.0.10-1597427521643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-a5758d4e-9628-4845-9496-356db95a8095,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-1a153e5a-d01d-46d2-aa8e-7c3a1d3c6592,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-3f1f5a93-71e1-4388-8788-c5d3534302ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-bdae2977-cf0f-4632-989c-76406cdbae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-1cca878e-dc04-4dbf-bba0-2a02486ddc32,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-c06cdba4-44da-44a4-9ad3-90b0a822a31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-45e9e2d5-5f5e-4f46-a052-e36901245d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-f0470c4a-6b12-4b6e-b7a0-66c19040c23d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453442371-172.17.0.10-1597427521643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-a5758d4e-9628-4845-9496-356db95a8095,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-1a153e5a-d01d-46d2-aa8e-7c3a1d3c6592,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-3f1f5a93-71e1-4388-8788-c5d3534302ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-bdae2977-cf0f-4632-989c-76406cdbae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-1cca878e-dc04-4dbf-bba0-2a02486ddc32,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-c06cdba4-44da-44a4-9ad3-90b0a822a31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-45e9e2d5-5f5e-4f46-a052-e36901245d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-f0470c4a-6b12-4b6e-b7a0-66c19040c23d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419154294-172.17.0.10-1597427690567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-aa7e4ff0-842c-419e-aaaf-e75af5b037e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-8531f6e3-be6c-4539-98d3-4466b3adf036,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-3edb2fa5-26b9-4ae1-bf99-d6c9f0259638,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-109ff8c0-4da8-443e-830e-b42e919c395c,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-17b8fd66-f675-4f96-8a2a-9d99eff85d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-32dbb0be-2447-43ce-a8a7-9d5b68d492b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-f7023fb0-4d6a-47bc-a822-2dc0f33d0288,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-1d8e27ee-f508-4e27-b411-fb6f0526a347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419154294-172.17.0.10-1597427690567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-aa7e4ff0-842c-419e-aaaf-e75af5b037e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-8531f6e3-be6c-4539-98d3-4466b3adf036,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-3edb2fa5-26b9-4ae1-bf99-d6c9f0259638,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-109ff8c0-4da8-443e-830e-b42e919c395c,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-17b8fd66-f675-4f96-8a2a-9d99eff85d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-32dbb0be-2447-43ce-a8a7-9d5b68d492b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-f7023fb0-4d6a-47bc-a822-2dc0f33d0288,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-1d8e27ee-f508-4e27-b411-fb6f0526a347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979763592-172.17.0.10-1597427767163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-7a22e779-2d30-4b56-bb20-8e931386e144,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-2ceb9c82-29b9-400c-949c-01e0a757191d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-da659a2d-620e-495f-bcd1-91a340151140,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-53f3ad14-5d97-4665-a97c-6ea4f14c99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-6b63ef7a-503e-4900-b319-4e81fc1d3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-c9133290-e5f1-462f-8297-a6cc53ede9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e921e454-8774-4eff-8267-8613ed2a618b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-9fca138a-1917-40a7-a818-f6ada9827ae7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979763592-172.17.0.10-1597427767163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-7a22e779-2d30-4b56-bb20-8e931386e144,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-2ceb9c82-29b9-400c-949c-01e0a757191d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-da659a2d-620e-495f-bcd1-91a340151140,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-53f3ad14-5d97-4665-a97c-6ea4f14c99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-6b63ef7a-503e-4900-b319-4e81fc1d3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-c9133290-e5f1-462f-8297-a6cc53ede9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e921e454-8774-4eff-8267-8613ed2a618b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-9fca138a-1917-40a7-a818-f6ada9827ae7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518898958-172.17.0.10-1597428177649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-73e4f37e-655b-4b63-9778-a3f7452bdb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-d62166cc-7654-436d-bc97-6d3452b9a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-23589e60-075b-491e-83f9-93db56857989,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-286da802-3c83-481c-b7e6-7fc6c24ab0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-00f5451d-f15e-4f04-8f57-b2500490ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-0f72b9a0-efe6-4667-bf00-2d2fa1244516,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-92c7532c-97d7-43c4-867c-47200e90543a,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-d3d4f969-e6bb-4709-af48-5d0028dea039,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518898958-172.17.0.10-1597428177649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-73e4f37e-655b-4b63-9778-a3f7452bdb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-d62166cc-7654-436d-bc97-6d3452b9a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-23589e60-075b-491e-83f9-93db56857989,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-286da802-3c83-481c-b7e6-7fc6c24ab0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-00f5451d-f15e-4f04-8f57-b2500490ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-0f72b9a0-efe6-4667-bf00-2d2fa1244516,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-92c7532c-97d7-43c4-867c-47200e90543a,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-d3d4f969-e6bb-4709-af48-5d0028dea039,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673194375-172.17.0.10-1597428214514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-4c76df33-aeff-4877-a69b-abae955075b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-cc13b06a-4eaf-450a-ba92-a4bd6d4fb88c,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-9012b5ea-88b4-4951-98ba-a4701b0b5e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-4d3639dd-0e2f-4347-ac25-cc0d112ad60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a9954d32-ddbf-42d9-b607-566bc0cf64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-009a2d55-c18e-4ad5-88c8-02e1c1411cba,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-96267dab-4b70-411f-a818-add80165fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-fac476a9-606a-4242-823b-2409555d4f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673194375-172.17.0.10-1597428214514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-4c76df33-aeff-4877-a69b-abae955075b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-cc13b06a-4eaf-450a-ba92-a4bd6d4fb88c,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-9012b5ea-88b4-4951-98ba-a4701b0b5e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-4d3639dd-0e2f-4347-ac25-cc0d112ad60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a9954d32-ddbf-42d9-b607-566bc0cf64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-009a2d55-c18e-4ad5-88c8-02e1c1411cba,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-96267dab-4b70-411f-a818-add80165fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-fac476a9-606a-4242-823b-2409555d4f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545681335-172.17.0.10-1597428407834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-3baf6ca9-fb2e-483c-843d-de7c88843c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-b9e8b2ae-e0de-4952-8cdd-196c75e5bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-bbd204b1-b2aa-4268-b290-6b339e980c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-5009ed19-0b13-4157-a292-a02e220a5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-a398ba54-a651-4af3-a3b0-ef0e0d0e7c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-c639de79-061d-4e3c-b376-60bd91629e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-be372ac1-94c3-4fdb-bbde-b3821e4121fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-27f581d2-ce7a-4f23-837a-917690a24d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545681335-172.17.0.10-1597428407834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-3baf6ca9-fb2e-483c-843d-de7c88843c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-b9e8b2ae-e0de-4952-8cdd-196c75e5bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-bbd204b1-b2aa-4268-b290-6b339e980c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-5009ed19-0b13-4157-a292-a02e220a5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-a398ba54-a651-4af3-a3b0-ef0e0d0e7c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-c639de79-061d-4e3c-b376-60bd91629e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-be372ac1-94c3-4fdb-bbde-b3821e4121fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-27f581d2-ce7a-4f23-837a-917690a24d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017743244-172.17.0.10-1597428492320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-2baa44db-9a7c-41b3-88a9-4be90ddc7351,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-76d9d7ed-374a-44a0-b4bc-d9fc18c091fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a55a1836-4c57-426c-ac1a-8b2562e252b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ac590c8b-89f4-4fb7-a88d-a66334e72960,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-d222ae89-3dad-441f-bc9a-c27ee1b6ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8cb45098-8f83-4a9e-8ed9-1e35ed9dbbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-e1238ced-ee90-499a-b828-d8412449c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-847558d9-b7ab-4074-b84f-c9fb3803d174,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017743244-172.17.0.10-1597428492320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-2baa44db-9a7c-41b3-88a9-4be90ddc7351,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-76d9d7ed-374a-44a0-b4bc-d9fc18c091fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a55a1836-4c57-426c-ac1a-8b2562e252b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ac590c8b-89f4-4fb7-a88d-a66334e72960,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-d222ae89-3dad-441f-bc9a-c27ee1b6ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8cb45098-8f83-4a9e-8ed9-1e35ed9dbbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-e1238ced-ee90-499a-b828-d8412449c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-847558d9-b7ab-4074-b84f-c9fb3803d174,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889066289-172.17.0.10-1597428959666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-beb17fbb-0b5e-4ffe-ade2-c76f259a7ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-75a1d688-cd43-43c8-96b8-dfb71069541a,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-4aa305d8-448d-40e1-a7f2-cf6bbe7917e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-4a0e191d-fb59-4d81-a1a1-7413a2e217cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c41b9ce4-260a-4a17-af54-6305dcf8461b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-2137280d-90fb-4530-94fd-7d38ded2f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-720a5add-5e11-43b9-b0a8-7b303bc639b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-86a5baed-7cf4-4305-baf9-33378e0c1a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889066289-172.17.0.10-1597428959666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-beb17fbb-0b5e-4ffe-ade2-c76f259a7ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-75a1d688-cd43-43c8-96b8-dfb71069541a,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-4aa305d8-448d-40e1-a7f2-cf6bbe7917e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-4a0e191d-fb59-4d81-a1a1-7413a2e217cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c41b9ce4-260a-4a17-af54-6305dcf8461b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-2137280d-90fb-4530-94fd-7d38ded2f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-720a5add-5e11-43b9-b0a8-7b303bc639b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-86a5baed-7cf4-4305-baf9-33378e0c1a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837157329-172.17.0.10-1597429243419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-398ac5f7-9aab-4f4d-a003-a2a358bcf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-b90b206c-9bc6-4385-af7e-185b633c8618,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-19ac5cdf-86b5-4a2a-b730-432f0fae212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2e5e979a-c896-4146-a189-8c9b8b5b9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-9f5b342c-111a-4bc8-b400-bb8c7616849b,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-fd1eef0e-0ba6-4597-9894-f46afe3484e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-872a6737-ede2-4773-932c-758b1d3228ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-24f9ee10-0e73-445f-8bcd-7d7534a124b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837157329-172.17.0.10-1597429243419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-398ac5f7-9aab-4f4d-a003-a2a358bcf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-b90b206c-9bc6-4385-af7e-185b633c8618,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-19ac5cdf-86b5-4a2a-b730-432f0fae212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2e5e979a-c896-4146-a189-8c9b8b5b9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-9f5b342c-111a-4bc8-b400-bb8c7616849b,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-fd1eef0e-0ba6-4597-9894-f46afe3484e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-872a6737-ede2-4773-932c-758b1d3228ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-24f9ee10-0e73-445f-8bcd-7d7534a124b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587503578-172.17.0.10-1597429554044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-745a90c5-97ad-4f11-ba63-2d8b71f7d499,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ab8cc203-19c4-48a0-bb49-646c6ac0b299,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f92b43d8-44f5-466b-9a71-8ec8fc078bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-9dba4d7d-435d-488d-8408-0f4d2d236dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-898f0ec3-52f5-4e52-9456-9814a140e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-a35bc3df-6765-4d93-a932-225e785ad1de,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-70a2295e-859a-418e-9689-a7d3b6b281b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-26f88463-f74f-449c-93dd-5829848dceee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587503578-172.17.0.10-1597429554044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-745a90c5-97ad-4f11-ba63-2d8b71f7d499,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ab8cc203-19c4-48a0-bb49-646c6ac0b299,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f92b43d8-44f5-466b-9a71-8ec8fc078bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-9dba4d7d-435d-488d-8408-0f4d2d236dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-898f0ec3-52f5-4e52-9456-9814a140e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-a35bc3df-6765-4d93-a932-225e785ad1de,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-70a2295e-859a-418e-9689-a7d3b6b281b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-26f88463-f74f-449c-93dd-5829848dceee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276612087-172.17.0.10-1597429658222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-f2601220-c1ce-4973-9e4a-ec3317855087,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-cc1bf62c-65ea-48b8-8abe-caae41948ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-ba4e7bf2-898c-484a-9ca8-c555df72c730,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1ef89bdf-aafa-4565-a1e4-38c64905179f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-cf6c0c25-6576-49f8-b993-b426ba39f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-55a7f425-ba2b-44bf-8a50-f81575571662,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-773abefc-0f14-425e-a536-734877141979,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-0ad0dc8c-5396-43e1-86b4-00ebbce3926b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276612087-172.17.0.10-1597429658222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-f2601220-c1ce-4973-9e4a-ec3317855087,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-cc1bf62c-65ea-48b8-8abe-caae41948ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-ba4e7bf2-898c-484a-9ca8-c555df72c730,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1ef89bdf-aafa-4565-a1e4-38c64905179f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-cf6c0c25-6576-49f8-b993-b426ba39f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-55a7f425-ba2b-44bf-8a50-f81575571662,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-773abefc-0f14-425e-a536-734877141979,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-0ad0dc8c-5396-43e1-86b4-00ebbce3926b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299817588-172.17.0.10-1597429868279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33386,DS-2b90ad38-482c-4a7a-b8c7-ebdd18d7ba49,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-bfd0e61c-b30c-45e6-b21b-67bb4d9bcb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-d59f9a31-247b-4496-a23a-6a08feb4c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-0a025533-d92c-4743-989d-2317851f1152,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-a876e8e1-6feb-48e4-8378-78fd141cda3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-5d7fcdde-319e-4360-bb96-79b916344408,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-1bc08d5f-399c-4a43-9d39-6728f4077bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-625f2b95-d1bb-4550-8c97-abd4859cda50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299817588-172.17.0.10-1597429868279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33386,DS-2b90ad38-482c-4a7a-b8c7-ebdd18d7ba49,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-bfd0e61c-b30c-45e6-b21b-67bb4d9bcb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-d59f9a31-247b-4496-a23a-6a08feb4c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-0a025533-d92c-4743-989d-2317851f1152,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-a876e8e1-6feb-48e4-8378-78fd141cda3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-5d7fcdde-319e-4360-bb96-79b916344408,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-1bc08d5f-399c-4a43-9d39-6728f4077bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-625f2b95-d1bb-4550-8c97-abd4859cda50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708315506-172.17.0.10-1597429920269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36419,DS-983329c7-b2c3-4d91-ba89-c609b7a1cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c3f8e2d6-502a-49e1-ac05-fff67265f075,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-6098c3cf-44c6-43a1-bf3b-d447ba512568,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d4a39da0-6fc1-402e-8816-94baeff442e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-f237667c-7528-4dba-a953-37a693f122fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-d9de9b66-f453-4b79-8381-812eed5fb806,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-05aa7b4c-0413-496b-8c84-e4b102a7786a,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-12199151-2610-4f6a-aaef-34bd1316fc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708315506-172.17.0.10-1597429920269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36419,DS-983329c7-b2c3-4d91-ba89-c609b7a1cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c3f8e2d6-502a-49e1-ac05-fff67265f075,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-6098c3cf-44c6-43a1-bf3b-d447ba512568,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d4a39da0-6fc1-402e-8816-94baeff442e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-f237667c-7528-4dba-a953-37a693f122fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-d9de9b66-f453-4b79-8381-812eed5fb806,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-05aa7b4c-0413-496b-8c84-e4b102a7786a,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-12199151-2610-4f6a-aaef-34bd1316fc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118254219-172.17.0.10-1597430007996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-9db558f2-d5ca-42df-a528-7131ac07061c,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-54718c3d-f8f5-4ad7-ae36-7a2d9c676e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d26b1613-40f8-4f73-868c-8cae4bd7c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-eeb54c2d-c77c-46eb-b2f1-250af56ed82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-71fe475c-3ca3-4ead-8bd1-14fc7022b533,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-961b4093-2545-40c0-8c98-aa91141ac0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-83a0f2fc-25d1-4d4b-b439-c76c79f8e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-9ee680ca-016c-4297-a7fc-61a40c78e835,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118254219-172.17.0.10-1597430007996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-9db558f2-d5ca-42df-a528-7131ac07061c,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-54718c3d-f8f5-4ad7-ae36-7a2d9c676e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d26b1613-40f8-4f73-868c-8cae4bd7c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-eeb54c2d-c77c-46eb-b2f1-250af56ed82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-71fe475c-3ca3-4ead-8bd1-14fc7022b533,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-961b4093-2545-40c0-8c98-aa91141ac0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-83a0f2fc-25d1-4d4b-b439-c76c79f8e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-9ee680ca-016c-4297-a7fc-61a40c78e835,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150137806-172.17.0.10-1597430074451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-06041c0a-82a4-4263-83db-340fae099283,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-343e815e-2eda-4979-b7b9-9afe3b98a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-31eea2f8-bdd9-46c3-a0bb-1aab09ba6640,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-457922fb-9b60-4caa-9e64-fb246ca777e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-7878fe71-bb9c-4150-9635-d3d45dd15a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-b72db3d5-1707-4755-8b16-04cfa0e1ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-b7f894b7-c0fc-4e7a-a85e-2a5de5c9ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-015f49c9-9fb9-4a93-b788-8f9758fcefa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150137806-172.17.0.10-1597430074451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-06041c0a-82a4-4263-83db-340fae099283,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-343e815e-2eda-4979-b7b9-9afe3b98a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-31eea2f8-bdd9-46c3-a0bb-1aab09ba6640,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-457922fb-9b60-4caa-9e64-fb246ca777e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-7878fe71-bb9c-4150-9635-d3d45dd15a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-b72db3d5-1707-4755-8b16-04cfa0e1ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-b7f894b7-c0fc-4e7a-a85e-2a5de5c9ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-015f49c9-9fb9-4a93-b788-8f9758fcefa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249121165-172.17.0.10-1597430158430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-f03bf1db-178e-4d99-b5ae-4a96d8b5c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-b4364b62-0df5-4b80-a8a0-98ce640ec367,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-b0c65ab7-2aea-4a6c-b6fe-fde160abfda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-21249dca-17e1-4ace-9283-dd7271e57d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-8ea1a111-5b84-47be-b3bd-d914902ff84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-10aea23c-19f5-4df0-8b52-3fb5fa65a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-f904b99f-05bb-4806-8730-954ad892483e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-2926f386-c4f7-42f2-b237-b35efd98072f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249121165-172.17.0.10-1597430158430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-f03bf1db-178e-4d99-b5ae-4a96d8b5c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-b4364b62-0df5-4b80-a8a0-98ce640ec367,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-b0c65ab7-2aea-4a6c-b6fe-fde160abfda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-21249dca-17e1-4ace-9283-dd7271e57d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-8ea1a111-5b84-47be-b3bd-d914902ff84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-10aea23c-19f5-4df0-8b52-3fb5fa65a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-f904b99f-05bb-4806-8730-954ad892483e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-2926f386-c4f7-42f2-b237-b35efd98072f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242620213-172.17.0.10-1597430192572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-923aada9-8e44-4c36-b56f-51b0f6e8a294,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-247115d5-0eba-4a2d-a320-31e1c94585e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-c802ade4-7a77-4421-b2ac-e52e97d06566,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-61555ddb-f70a-4b57-b5c4-68e08c73cded,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-17c9fb26-d9b5-43ed-a1a8-8149b983ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-265b2906-8f22-4764-b76d-00575766cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-46036b56-e354-4aec-8edc-50aafe5d384f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-17f9b1a0-7991-4051-a54b-849e917f88ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242620213-172.17.0.10-1597430192572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-923aada9-8e44-4c36-b56f-51b0f6e8a294,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-247115d5-0eba-4a2d-a320-31e1c94585e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-c802ade4-7a77-4421-b2ac-e52e97d06566,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-61555ddb-f70a-4b57-b5c4-68e08c73cded,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-17c9fb26-d9b5-43ed-a1a8-8149b983ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-265b2906-8f22-4764-b76d-00575766cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-46036b56-e354-4aec-8edc-50aafe5d384f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-17f9b1a0-7991-4051-a54b-849e917f88ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517425632-172.17.0.10-1597430324823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-7de10daa-d5a2-479c-ae4a-78e92291919b,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-4000d196-fddc-4cde-bc66-5c9aaf65c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3ca1a099-85fb-466d-9e1a-de4c129cdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-47359772-72e7-4144-ba75-db4628a5aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-a94acd0a-f715-45ce-9dc9-01844107e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-ef15af0b-246f-4e28-bc78-315ac4b401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-006c6dee-5724-4fcf-8582-38d931d3f189,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b994b515-401e-47a7-8a01-57f83213048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517425632-172.17.0.10-1597430324823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-7de10daa-d5a2-479c-ae4a-78e92291919b,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-4000d196-fddc-4cde-bc66-5c9aaf65c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3ca1a099-85fb-466d-9e1a-de4c129cdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-47359772-72e7-4144-ba75-db4628a5aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-a94acd0a-f715-45ce-9dc9-01844107e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-ef15af0b-246f-4e28-bc78-315ac4b401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-006c6dee-5724-4fcf-8582-38d931d3f189,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b994b515-401e-47a7-8a01-57f83213048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664324235-172.17.0.10-1597430390836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-68423b20-8d37-4734-b9c3-fd0c8e676cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-5015335f-8160-47a6-9d71-491543cbce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-090f1faf-70c0-43cc-983a-a4d91365dfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-15e2ec89-5526-4d0e-8660-5f1ca1b47f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-938c9016-c636-441a-bd03-9cebfe3a2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-8840ffa8-9af7-438c-b78f-d97c2ab04832,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-ff10b076-944b-469a-b895-1f5167877352,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-e06524bf-c851-4e1f-93a7-4317b88d57e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664324235-172.17.0.10-1597430390836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-68423b20-8d37-4734-b9c3-fd0c8e676cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-5015335f-8160-47a6-9d71-491543cbce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-090f1faf-70c0-43cc-983a-a4d91365dfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-15e2ec89-5526-4d0e-8660-5f1ca1b47f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-938c9016-c636-441a-bd03-9cebfe3a2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-8840ffa8-9af7-438c-b78f-d97c2ab04832,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-ff10b076-944b-469a-b895-1f5167877352,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-e06524bf-c851-4e1f-93a7-4317b88d57e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 4562
