reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986457783-172.17.0.18-1597385074051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-1f60bbc5-68a4-4e1b-83d2-f7d5760ceaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-553de085-1f13-4257-a836-a218bd983164,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-a886c848-d078-4ec6-a39d-464cb70a5611,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c22291ee-3206-433c-864f-4cffc1f23356,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-29cdec1d-5c11-4165-831d-76c74b67aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-6a589833-6d88-4618-8a2b-60ac1dbb6597,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-7b383e37-7b8c-4912-927b-97dc83023b45,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-77e11b21-08f1-4100-8f07-15f57d54f06d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986457783-172.17.0.18-1597385074051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-1f60bbc5-68a4-4e1b-83d2-f7d5760ceaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-553de085-1f13-4257-a836-a218bd983164,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-a886c848-d078-4ec6-a39d-464cb70a5611,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c22291ee-3206-433c-864f-4cffc1f23356,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-29cdec1d-5c11-4165-831d-76c74b67aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-6a589833-6d88-4618-8a2b-60ac1dbb6597,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-7b383e37-7b8c-4912-927b-97dc83023b45,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-77e11b21-08f1-4100-8f07-15f57d54f06d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348521358-172.17.0.18-1597385531144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35616,DS-75a531c3-abeb-45ab-9a12-438189a40c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-2a927a8b-0ba5-45a2-904e-7061d2747c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a056b72d-78b4-4b46-9af4-fd48f61049cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-d7b0000e-52bb-40ce-917a-359634580471,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-b7defbf9-b6ee-4b5d-b477-bd839bdebe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-529b9828-0718-4652-8480-b71531229971,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5b32035a-49d6-4854-aeae-c64ad43f6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-9bd66772-7654-4cd3-b3f7-dad9391f2831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348521358-172.17.0.18-1597385531144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35616,DS-75a531c3-abeb-45ab-9a12-438189a40c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-2a927a8b-0ba5-45a2-904e-7061d2747c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a056b72d-78b4-4b46-9af4-fd48f61049cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-d7b0000e-52bb-40ce-917a-359634580471,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-b7defbf9-b6ee-4b5d-b477-bd839bdebe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-529b9828-0718-4652-8480-b71531229971,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5b32035a-49d6-4854-aeae-c64ad43f6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-9bd66772-7654-4cd3-b3f7-dad9391f2831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674135847-172.17.0.18-1597385618056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-85886f3e-823a-48dd-a0f5-2195227b2a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d0990c4c-0607-4fe9-967a-5ef3a6b5bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-d1beae64-aa2f-4710-a201-d94a1c08e17b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-8b28afbb-1b84-46ec-a6c0-a9580fd17496,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-f498c985-fee5-42b5-ab1f-82b10148c6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-6abaa6b4-852d-484f-b692-b09d337603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-59a74983-9dc2-4a9c-a92e-a551c886b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-5b6cf0c7-de26-4e8e-9b60-bd3e54df071c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674135847-172.17.0.18-1597385618056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-85886f3e-823a-48dd-a0f5-2195227b2a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d0990c4c-0607-4fe9-967a-5ef3a6b5bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-d1beae64-aa2f-4710-a201-d94a1c08e17b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-8b28afbb-1b84-46ec-a6c0-a9580fd17496,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-f498c985-fee5-42b5-ab1f-82b10148c6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-6abaa6b4-852d-484f-b692-b09d337603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-59a74983-9dc2-4a9c-a92e-a551c886b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-5b6cf0c7-de26-4e8e-9b60-bd3e54df071c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319286532-172.17.0.18-1597385977572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-464cb66a-93cf-4e3e-afd3-dd4e2fb5b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-2f2d4f0e-3cac-40c0-8194-c74a25e22e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-501d50e4-2be2-45e7-83a1-df6aa24b6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-bacb4862-1afe-472a-8c65-44c700073689,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-44614887-47e6-4473-95e5-eb11c9988a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-1e6bba6d-43c0-4453-904f-57656bc59981,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c953e8fa-e0f2-4f8a-a24c-d8834043bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-b23ca843-5fa7-41f6-a697-ef73dd472b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319286532-172.17.0.18-1597385977572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-464cb66a-93cf-4e3e-afd3-dd4e2fb5b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-2f2d4f0e-3cac-40c0-8194-c74a25e22e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-501d50e4-2be2-45e7-83a1-df6aa24b6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-bacb4862-1afe-472a-8c65-44c700073689,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-44614887-47e6-4473-95e5-eb11c9988a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-1e6bba6d-43c0-4453-904f-57656bc59981,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c953e8fa-e0f2-4f8a-a24c-d8834043bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-b23ca843-5fa7-41f6-a697-ef73dd472b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972947312-172.17.0.18-1597386157019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-c73581a0-a7c2-42de-a721-7e00cdc5703a,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-fc58b12a-3558-4d4c-b0d6-51a5f01da4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-8f89bf91-1532-4717-9fa1-7efb98a48153,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-fe8805fc-8fc3-47af-bae2-efbb3862707d,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-5c7d0b0d-20ae-4c34-a5d4-709942bd6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-c4fde09e-8d42-49e7-82e8-7b2ded6210c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-a6f6d32a-f9ec-4e04-a73f-38b860e0eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-177ca2f3-b8dd-4913-bc3f-26a8cbadc66f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972947312-172.17.0.18-1597386157019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-c73581a0-a7c2-42de-a721-7e00cdc5703a,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-fc58b12a-3558-4d4c-b0d6-51a5f01da4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-8f89bf91-1532-4717-9fa1-7efb98a48153,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-fe8805fc-8fc3-47af-bae2-efbb3862707d,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-5c7d0b0d-20ae-4c34-a5d4-709942bd6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-c4fde09e-8d42-49e7-82e8-7b2ded6210c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-a6f6d32a-f9ec-4e04-a73f-38b860e0eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-177ca2f3-b8dd-4913-bc3f-26a8cbadc66f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487879225-172.17.0.18-1597386201524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41895,DS-c25b202b-243c-4b12-b2c8-6c9fb6ce8851,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-00a1af6d-fe4e-42ac-9d03-a5f497b1a01d,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-89af4522-8864-4609-abe3-73dd65a358d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-f8026e1f-628e-4a04-99a3-18daee33cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-33b667af-8e9a-4627-b610-fa308548ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-889a6cfa-f130-455d-81c5-2d4e30f4c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-8f59c72f-c858-43df-bdf1-2f83b3945851,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2d61fb3a-4043-43a9-b806-9934cef5602e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487879225-172.17.0.18-1597386201524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41895,DS-c25b202b-243c-4b12-b2c8-6c9fb6ce8851,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-00a1af6d-fe4e-42ac-9d03-a5f497b1a01d,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-89af4522-8864-4609-abe3-73dd65a358d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-f8026e1f-628e-4a04-99a3-18daee33cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-33b667af-8e9a-4627-b610-fa308548ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-889a6cfa-f130-455d-81c5-2d4e30f4c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-8f59c72f-c858-43df-bdf1-2f83b3945851,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2d61fb3a-4043-43a9-b806-9934cef5602e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356469150-172.17.0.18-1597386612552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-e9a1f38f-7998-4548-9565-c112fc3729e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-af5394f4-c102-4931-b503-7fd8ac2076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-168d0675-3a48-493b-867e-c6e2606079b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-27d1bf03-1f03-41d9-9629-7512b5fb8167,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-728ae5d9-fca0-42e7-a8dc-1a57dac0923e,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-ca94760b-478b-443b-a67c-8c22da4da001,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-19eeeba0-a131-4923-ad57-03f8c913849d,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-fed485e2-f10d-4e10-99c5-19ecc19385a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356469150-172.17.0.18-1597386612552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-e9a1f38f-7998-4548-9565-c112fc3729e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-af5394f4-c102-4931-b503-7fd8ac2076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-168d0675-3a48-493b-867e-c6e2606079b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-27d1bf03-1f03-41d9-9629-7512b5fb8167,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-728ae5d9-fca0-42e7-a8dc-1a57dac0923e,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-ca94760b-478b-443b-a67c-8c22da4da001,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-19eeeba0-a131-4923-ad57-03f8c913849d,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-fed485e2-f10d-4e10-99c5-19ecc19385a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648712922-172.17.0.18-1597386740068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-d50aed6c-6a89-4ada-9086-525dfe821af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2662cc8b-b0ee-460c-9ef3-c05204d92bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-0d5cca2b-cb6d-4054-87ee-5102cd94fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-648030c9-48d0-4bb7-9be0-68175fcd1852,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-a353d297-fded-483f-9798-f6eace825438,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-b84c4bd3-1b2d-4a77-82fe-645a5f21d350,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-536d3395-1ba5-4342-8547-e24c7471c493,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-8b592f27-8ecc-43d2-9a42-445e4a651201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648712922-172.17.0.18-1597386740068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-d50aed6c-6a89-4ada-9086-525dfe821af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2662cc8b-b0ee-460c-9ef3-c05204d92bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-0d5cca2b-cb6d-4054-87ee-5102cd94fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-648030c9-48d0-4bb7-9be0-68175fcd1852,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-a353d297-fded-483f-9798-f6eace825438,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-b84c4bd3-1b2d-4a77-82fe-645a5f21d350,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-536d3395-1ba5-4342-8547-e24c7471c493,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-8b592f27-8ecc-43d2-9a42-445e4a651201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817330372-172.17.0.18-1597386939249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-122fdec4-320d-4c92-afdd-d05d45451fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-16df8f4d-91af-44b1-bb84-3a079b57fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-089d2734-d7f5-46a1-9904-b58a35ca90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e5af10ac-37b3-4c64-8747-f23eb7b1225e,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-7d378721-a476-40ea-9628-9dab86cadeef,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a46cf1df-ef44-4e97-8a81-edb1003c7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-76b760f3-c815-47e3-9936-1d2a12d9332e,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-f732cf7f-8d20-4edf-bb43-e034eac8ae67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817330372-172.17.0.18-1597386939249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-122fdec4-320d-4c92-afdd-d05d45451fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-16df8f4d-91af-44b1-bb84-3a079b57fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-089d2734-d7f5-46a1-9904-b58a35ca90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e5af10ac-37b3-4c64-8747-f23eb7b1225e,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-7d378721-a476-40ea-9628-9dab86cadeef,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a46cf1df-ef44-4e97-8a81-edb1003c7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-76b760f3-c815-47e3-9936-1d2a12d9332e,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-f732cf7f-8d20-4edf-bb43-e034eac8ae67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67638182-172.17.0.18-1597387384547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46479,DS-f5e8d124-3f98-4891-bdc1-200a37e9da35,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-e88c138d-ec13-424e-a762-41ef0bc38ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-8859e00f-4d25-4c4c-8e99-470da4f5396a,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-feccde67-bd66-4b1a-915b-c1288e8ea37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-08833d5c-2313-481b-bca0-f7892b2d7145,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-04f6bc69-63ea-4134-9616-5a1c1b01a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a0ea9425-c25f-448a-9719-0b6f58df615a,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-31b74abb-62ce-4081-82a8-e6d340383b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67638182-172.17.0.18-1597387384547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46479,DS-f5e8d124-3f98-4891-bdc1-200a37e9da35,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-e88c138d-ec13-424e-a762-41ef0bc38ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-8859e00f-4d25-4c4c-8e99-470da4f5396a,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-feccde67-bd66-4b1a-915b-c1288e8ea37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-08833d5c-2313-481b-bca0-f7892b2d7145,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-04f6bc69-63ea-4134-9616-5a1c1b01a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a0ea9425-c25f-448a-9719-0b6f58df615a,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-31b74abb-62ce-4081-82a8-e6d340383b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492841932-172.17.0.18-1597388504771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-1037b4d2-1b15-4da6-81b9-3c1687ad998e,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-a395e6fc-1520-4f77-860a-8cf23b804971,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-93b80291-0bf0-4db2-ae56-6e31866af14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-19af0c64-c2b3-40b0-9c5f-917ae23088b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-6836e611-d3fa-404b-aa26-6b5fe08d2e07,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-9d83fd3a-6c2e-4eac-98e1-b25ef6f7bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-defb114c-3ce2-46aa-8efb-baecd8d3ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9e9cc388-5eb8-4f21-811f-c06b6ee13b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492841932-172.17.0.18-1597388504771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-1037b4d2-1b15-4da6-81b9-3c1687ad998e,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-a395e6fc-1520-4f77-860a-8cf23b804971,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-93b80291-0bf0-4db2-ae56-6e31866af14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-19af0c64-c2b3-40b0-9c5f-917ae23088b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-6836e611-d3fa-404b-aa26-6b5fe08d2e07,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-9d83fd3a-6c2e-4eac-98e1-b25ef6f7bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-defb114c-3ce2-46aa-8efb-baecd8d3ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9e9cc388-5eb8-4f21-811f-c06b6ee13b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857425696-172.17.0.18-1597388626828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-98acc359-b7cb-4df3-82dc-cdbca5aa93d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b5b2c291-7a33-4cd9-a8d9-3fa503fdf08b,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-645d818a-6c91-448f-b0a3-08d007d43225,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-caf73974-6a4f-4510-81ba-da19814a73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-52de85cd-3e62-4eef-ad5f-484bb2482c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-7f2aa9d3-649a-49d5-a246-df474d94356f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-496ff954-d5fd-4c18-8b8a-c79f6faebc25,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-fa49d0d5-a086-4225-8a5b-265d8807b5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857425696-172.17.0.18-1597388626828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-98acc359-b7cb-4df3-82dc-cdbca5aa93d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b5b2c291-7a33-4cd9-a8d9-3fa503fdf08b,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-645d818a-6c91-448f-b0a3-08d007d43225,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-caf73974-6a4f-4510-81ba-da19814a73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-52de85cd-3e62-4eef-ad5f-484bb2482c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-7f2aa9d3-649a-49d5-a246-df474d94356f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-496ff954-d5fd-4c18-8b8a-c79f6faebc25,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-fa49d0d5-a086-4225-8a5b-265d8807b5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759925721-172.17.0.18-1597388735621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-cfa7cdd5-6bd0-491f-a932-0572f3039907,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-99c26fa5-9711-4d8e-b4e3-33d11bcf00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-0b6aa5ed-1131-43af-bf58-a576fd13872b,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-c3ed2768-109f-4230-9fd8-f47de59e06bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-031872e0-d0b6-45fa-89e3-5ac57fa81cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-cfe45a05-a03f-4fdf-9a47-1e5831e88b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-26104192-2320-439d-8929-e7c50ffb8536,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f74c7b12-c1e8-48ea-9f69-8b2cbdc1a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759925721-172.17.0.18-1597388735621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-cfa7cdd5-6bd0-491f-a932-0572f3039907,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-99c26fa5-9711-4d8e-b4e3-33d11bcf00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-0b6aa5ed-1131-43af-bf58-a576fd13872b,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-c3ed2768-109f-4230-9fd8-f47de59e06bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-031872e0-d0b6-45fa-89e3-5ac57fa81cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-cfe45a05-a03f-4fdf-9a47-1e5831e88b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-26104192-2320-439d-8929-e7c50ffb8536,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f74c7b12-c1e8-48ea-9f69-8b2cbdc1a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634158656-172.17.0.18-1597388962138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-100e0421-07e9-4cd8-9783-d8889fe83233,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-79c0d117-a8e5-4a07-bdde-706d3800417d,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-20a870ab-70f1-4d27-8990-c597e0e7afad,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9872ee01-cdc0-4e22-98c8-5781de432233,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-02eecf02-fa8f-4f24-9e5d-d72c29b036aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-a027855e-d868-4b70-871f-43642e949c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-d4d49339-5260-48d2-927c-2cfc773d0753,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-1a2be114-bd9d-4396-ab1b-529d718a363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634158656-172.17.0.18-1597388962138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-100e0421-07e9-4cd8-9783-d8889fe83233,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-79c0d117-a8e5-4a07-bdde-706d3800417d,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-20a870ab-70f1-4d27-8990-c597e0e7afad,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9872ee01-cdc0-4e22-98c8-5781de432233,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-02eecf02-fa8f-4f24-9e5d-d72c29b036aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-a027855e-d868-4b70-871f-43642e949c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-d4d49339-5260-48d2-927c-2cfc773d0753,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-1a2be114-bd9d-4396-ab1b-529d718a363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451578651-172.17.0.18-1597389448360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-2cc2f9f3-353c-4de5-b824-a307b536a632,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-efd85b4f-cdfe-4b69-8838-d85c5f4bdbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-8337e429-44c9-4027-9e93-e5319c4d5206,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-2d8e0af3-7b4e-487b-874c-9461355586e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-5f5ce074-f11d-4c82-a215-1cb432079712,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-4a3ab2f3-942b-475a-90da-fc66b1d59f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-b8f33776-a24a-46b7-8d5b-585f9bb66399,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-fda06c1c-1287-4191-af01-a28f83ba9826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451578651-172.17.0.18-1597389448360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-2cc2f9f3-353c-4de5-b824-a307b536a632,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-efd85b4f-cdfe-4b69-8838-d85c5f4bdbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-8337e429-44c9-4027-9e93-e5319c4d5206,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-2d8e0af3-7b4e-487b-874c-9461355586e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-5f5ce074-f11d-4c82-a215-1cb432079712,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-4a3ab2f3-942b-475a-90da-fc66b1d59f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-b8f33776-a24a-46b7-8d5b-585f9bb66399,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-fda06c1c-1287-4191-af01-a28f83ba9826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478145444-172.17.0.18-1597389760012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-7180dd46-3b37-4b85-8616-47627acb9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-a02c2980-b3a2-4e20-8cc5-c1b040326d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-d4fe5ef3-96b5-48d4-8957-dbf87ec87359,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-9824320f-6938-4c7e-98d2-40b480e2cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-5df84fb0-a970-46a8-9e34-a401c68f3692,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d6bb175e-50c0-4c7e-aceb-89f3384cc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-7fd17602-d069-4683-a4d5-fcc02386176d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-dfd0fc96-8a07-4aee-acd4-d7d86d657f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478145444-172.17.0.18-1597389760012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-7180dd46-3b37-4b85-8616-47627acb9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-a02c2980-b3a2-4e20-8cc5-c1b040326d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-d4fe5ef3-96b5-48d4-8957-dbf87ec87359,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-9824320f-6938-4c7e-98d2-40b480e2cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-5df84fb0-a970-46a8-9e34-a401c68f3692,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d6bb175e-50c0-4c7e-aceb-89f3384cc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-7fd17602-d069-4683-a4d5-fcc02386176d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-dfd0fc96-8a07-4aee-acd4-d7d86d657f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5717
