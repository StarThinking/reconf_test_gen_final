reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500085226-172.17.0.10-1597754907773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40899,DS-dc90eb75-b175-4b04-925a-e15bdb8ce57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-280a7f19-b560-49c6-b290-50e77eb65d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-2ef2374b-aa4d-490b-b052-ed3a6df3be87,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-ed49d47e-0411-4945-828d-5d64fb6c0c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-930521b4-5302-4338-a3fa-242b8b9c08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-48b024cf-956c-43ed-b72b-1924579c69a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-bb07e0c5-121e-4c37-9b3e-db03e460f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-43401165-1f3b-45ab-a5d6-d89d27f8b2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500085226-172.17.0.10-1597754907773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40899,DS-dc90eb75-b175-4b04-925a-e15bdb8ce57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-280a7f19-b560-49c6-b290-50e77eb65d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-2ef2374b-aa4d-490b-b052-ed3a6df3be87,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-ed49d47e-0411-4945-828d-5d64fb6c0c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-930521b4-5302-4338-a3fa-242b8b9c08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-48b024cf-956c-43ed-b72b-1924579c69a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-bb07e0c5-121e-4c37-9b3e-db03e460f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-43401165-1f3b-45ab-a5d6-d89d27f8b2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228086385-172.17.0.10-1597754983662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-2cc5807b-50f7-4bf7-a855-9304a38d5244,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-403c3872-1e8f-4bad-a9b0-b198b86437b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-1519ced5-e8d4-4fd8-84a4-c57e93174919,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5c127ecd-42e3-4129-ae79-049dde4f0d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-3f15a089-e3d8-4289-afa2-0bbd33323ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7a13481b-6349-445a-9ba7-9a6a8b8bb060,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-61ff402b-63af-4249-af33-3eb4add3c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-f0e901dc-cb8c-49ce-9d1b-d46f9bda23b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228086385-172.17.0.10-1597754983662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-2cc5807b-50f7-4bf7-a855-9304a38d5244,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-403c3872-1e8f-4bad-a9b0-b198b86437b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-1519ced5-e8d4-4fd8-84a4-c57e93174919,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5c127ecd-42e3-4129-ae79-049dde4f0d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-3f15a089-e3d8-4289-afa2-0bbd33323ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7a13481b-6349-445a-9ba7-9a6a8b8bb060,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-61ff402b-63af-4249-af33-3eb4add3c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-f0e901dc-cb8c-49ce-9d1b-d46f9bda23b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460726052-172.17.0.10-1597755737473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-c75e6086-21fe-4873-a03a-b933eb6c4002,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-0a8a198a-f242-4242-aa76-ed79083e1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-3e2ed0b6-15b6-4f61-bb92-4bcd15303802,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-c7c6cced-5720-43f8-a722-2a4e9e12a98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-d0393e01-857c-4d6f-bb38-930d51a2b240,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-dd33dc6a-8b7e-4bc9-bd76-c27db7faf652,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-89e95e21-b989-445e-899f-4d2f24c1b153,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5fa43566-4fcb-4a62-b38a-fd80eab9f927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460726052-172.17.0.10-1597755737473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-c75e6086-21fe-4873-a03a-b933eb6c4002,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-0a8a198a-f242-4242-aa76-ed79083e1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-3e2ed0b6-15b6-4f61-bb92-4bcd15303802,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-c7c6cced-5720-43f8-a722-2a4e9e12a98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-d0393e01-857c-4d6f-bb38-930d51a2b240,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-dd33dc6a-8b7e-4bc9-bd76-c27db7faf652,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-89e95e21-b989-445e-899f-4d2f24c1b153,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5fa43566-4fcb-4a62-b38a-fd80eab9f927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060510287-172.17.0.10-1597756189600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-84f5532f-2f79-47cd-bc93-45caa803cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-cb8ce60c-d5f9-4e45-9efa-665141b2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8fe0333-1a8b-4f41-a58e-42b6599b9cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0afbcaa5-ac71-4b87-a29f-f4a220fcdb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8be0a805-b210-4cb7-8a86-a9d8a3d5afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-93897726-3819-4f47-8edb-905b6dde14a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-a14a6684-1d59-4294-a938-eca2b82a02cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-27f23a1a-e21f-4358-94da-35e092eaad9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060510287-172.17.0.10-1597756189600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-84f5532f-2f79-47cd-bc93-45caa803cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-cb8ce60c-d5f9-4e45-9efa-665141b2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8fe0333-1a8b-4f41-a58e-42b6599b9cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0afbcaa5-ac71-4b87-a29f-f4a220fcdb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8be0a805-b210-4cb7-8a86-a9d8a3d5afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-93897726-3819-4f47-8edb-905b6dde14a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-a14a6684-1d59-4294-a938-eca2b82a02cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-27f23a1a-e21f-4358-94da-35e092eaad9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864410857-172.17.0.10-1597756302486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-86b435f6-6d9e-40c8-a063-03f0ed9e880c,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-1242d240-9ccd-471b-9e08-014b501d7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-e1b4f84a-c978-4725-a90b-0216bfa1084a,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e77bd348-495a-47c4-abf5-503992f72966,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-19b0ec00-8ea4-4673-b3bd-9b8686706979,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-d92c8b6c-737e-4355-b0ab-20a3e31c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-6a5dcd5b-c492-49b3-9859-7cee317c348d,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-a729961d-e233-49a8-b393-79eba4dbe940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864410857-172.17.0.10-1597756302486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-86b435f6-6d9e-40c8-a063-03f0ed9e880c,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-1242d240-9ccd-471b-9e08-014b501d7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-e1b4f84a-c978-4725-a90b-0216bfa1084a,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e77bd348-495a-47c4-abf5-503992f72966,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-19b0ec00-8ea4-4673-b3bd-9b8686706979,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-d92c8b6c-737e-4355-b0ab-20a3e31c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-6a5dcd5b-c492-49b3-9859-7cee317c348d,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-a729961d-e233-49a8-b393-79eba4dbe940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091310069-172.17.0.10-1597756595894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-d248ac75-98e0-43cf-8a19-4fdfa6524928,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-d325637d-2895-4173-a08c-ad48834b436b,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-3fcb6216-5e6a-40d6-98b6-f35607204dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5c74f0ec-4dd5-474a-9dbc-a92b6e25460f,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-f2dd9e99-2043-4715-9fc7-11de405dca93,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-0fa98cf7-f4e0-4d36-b312-990276794c02,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-7c9da4bc-dc3e-4386-acd7-da6465708b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-df1f8487-3e40-4118-a1ae-14584aa9e299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091310069-172.17.0.10-1597756595894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-d248ac75-98e0-43cf-8a19-4fdfa6524928,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-d325637d-2895-4173-a08c-ad48834b436b,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-3fcb6216-5e6a-40d6-98b6-f35607204dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5c74f0ec-4dd5-474a-9dbc-a92b6e25460f,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-f2dd9e99-2043-4715-9fc7-11de405dca93,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-0fa98cf7-f4e0-4d36-b312-990276794c02,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-7c9da4bc-dc3e-4386-acd7-da6465708b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-df1f8487-3e40-4118-a1ae-14584aa9e299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288264109-172.17.0.10-1597756709852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-e9712016-0941-441a-a77f-6b4d4a126e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b2241ff4-8f53-4760-bed1-3fd9ff7db7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-054b4498-668e-48f7-8ef3-666a3a35cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-ee71b1fe-1033-4609-9f71-b4d907849df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-5439ad43-08d6-41b8-a376-e9baaccd8e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-01d52bf5-c53e-468b-9e94-7428469674ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-f4a8b5e5-c35a-4c72-80ae-c28333d17293,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-468c5d9a-fbfd-4e8e-85af-94d5d16989cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288264109-172.17.0.10-1597756709852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-e9712016-0941-441a-a77f-6b4d4a126e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b2241ff4-8f53-4760-bed1-3fd9ff7db7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-054b4498-668e-48f7-8ef3-666a3a35cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-ee71b1fe-1033-4609-9f71-b4d907849df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-5439ad43-08d6-41b8-a376-e9baaccd8e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-01d52bf5-c53e-468b-9e94-7428469674ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-f4a8b5e5-c35a-4c72-80ae-c28333d17293,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-468c5d9a-fbfd-4e8e-85af-94d5d16989cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171441066-172.17.0.10-1597757093944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-ddd88f47-5b32-41a5-84fc-c9e6d9a91118,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b5dab12b-b0a9-4271-8423-518ef53d72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-80a70334-0e9b-49dd-8de9-543f9313e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-1bf55e8d-1fa3-48a9-9bda-e009e657e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-b4c02572-1d0e-4323-9515-3166e5628f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-f8eb2127-cea0-43f2-85ab-36d97d5d08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-641657a2-fbe2-4e28-a809-6700a515c064,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-508b6d05-4355-476e-a187-13d657e048ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171441066-172.17.0.10-1597757093944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-ddd88f47-5b32-41a5-84fc-c9e6d9a91118,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b5dab12b-b0a9-4271-8423-518ef53d72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-80a70334-0e9b-49dd-8de9-543f9313e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-1bf55e8d-1fa3-48a9-9bda-e009e657e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-b4c02572-1d0e-4323-9515-3166e5628f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-f8eb2127-cea0-43f2-85ab-36d97d5d08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-641657a2-fbe2-4e28-a809-6700a515c064,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-508b6d05-4355-476e-a187-13d657e048ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940418959-172.17.0.10-1597757544305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-84e1472e-1868-4c6d-a11c-3e499644b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-a29aa2ef-efcf-4f65-b3e3-ada0a65bcb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-d4328076-ccfa-4cb4-a2d6-01d4d2a1c949,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-da0d3843-b7b5-43af-8d30-8bf08f74f418,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-7459db4e-8f15-442e-8862-035318726d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-bd30fba3-565a-4810-a6ac-596c87aea784,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-8d9d7ea5-fe01-49cd-95e4-34d309f2f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-7879c383-39b5-48af-a46b-a867a5472d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940418959-172.17.0.10-1597757544305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-84e1472e-1868-4c6d-a11c-3e499644b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-a29aa2ef-efcf-4f65-b3e3-ada0a65bcb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-d4328076-ccfa-4cb4-a2d6-01d4d2a1c949,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-da0d3843-b7b5-43af-8d30-8bf08f74f418,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-7459db4e-8f15-442e-8862-035318726d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-bd30fba3-565a-4810-a6ac-596c87aea784,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-8d9d7ea5-fe01-49cd-95e4-34d309f2f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-7879c383-39b5-48af-a46b-a867a5472d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038665883-172.17.0.10-1597757577074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-9490ee2f-8ade-4773-8f81-8e46cfe58cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-dec5b209-06be-4d1f-988e-ababe789db14,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bd7998ee-78e9-4a60-9f8d-647498a6844f,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-868fd56b-18c5-43fb-9930-65773998ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-e6a95044-4027-4d73-a9f8-4c452afcbdac,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-1f54f05c-8913-444d-824e-650e3cf97d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-bac8be18-e045-4170-afe4-7c95b08c38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-75af6df9-a38c-4b13-bfee-e8730412d313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038665883-172.17.0.10-1597757577074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-9490ee2f-8ade-4773-8f81-8e46cfe58cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-dec5b209-06be-4d1f-988e-ababe789db14,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bd7998ee-78e9-4a60-9f8d-647498a6844f,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-868fd56b-18c5-43fb-9930-65773998ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-e6a95044-4027-4d73-a9f8-4c452afcbdac,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-1f54f05c-8913-444d-824e-650e3cf97d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-bac8be18-e045-4170-afe4-7c95b08c38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-75af6df9-a38c-4b13-bfee-e8730412d313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269398981-172.17.0.10-1597757656393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-762ce281-e8e2-41c9-9833-fc5557bcabfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-dd08703e-efb1-4c23-a03c-7caf83ee2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-0aeb5f95-b19e-404d-a6ff-0c5f874939a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-1e5562a4-f2e9-401a-8c48-531b13e29573,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d687b6e2-3bd4-4d95-b99e-32fff71d991c,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-faf9c310-7597-4b89-b743-390fd4956fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-e37ec83b-9e2c-47f0-b8b1-4180c741d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-a3de9f47-b0b8-4d78-8575-14a991a5dbf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269398981-172.17.0.10-1597757656393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-762ce281-e8e2-41c9-9833-fc5557bcabfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-dd08703e-efb1-4c23-a03c-7caf83ee2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-0aeb5f95-b19e-404d-a6ff-0c5f874939a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-1e5562a4-f2e9-401a-8c48-531b13e29573,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d687b6e2-3bd4-4d95-b99e-32fff71d991c,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-faf9c310-7597-4b89-b743-390fd4956fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-e37ec83b-9e2c-47f0-b8b1-4180c741d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-a3de9f47-b0b8-4d78-8575-14a991a5dbf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006310954-172.17.0.10-1597757770888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39713,DS-7f74d3b1-1f84-40cd-b4eb-859e3648e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1759ef81-218f-4e41-afac-535c0cd94447,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-a8bbfa41-ee48-4655-8ecd-b01bd261b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-40b3b82f-9de7-41a7-bcc2-4a2ce0014a70,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9c1f50e9-d29d-42bc-a74c-e97ce764c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-5fe42c79-0555-4bd2-9b46-92659df854aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-6dba13e0-0677-4a78-a93e-55818d05ccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-12ee7c8a-90c2-4b22-a415-003bef27e773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006310954-172.17.0.10-1597757770888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39713,DS-7f74d3b1-1f84-40cd-b4eb-859e3648e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1759ef81-218f-4e41-afac-535c0cd94447,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-a8bbfa41-ee48-4655-8ecd-b01bd261b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-40b3b82f-9de7-41a7-bcc2-4a2ce0014a70,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9c1f50e9-d29d-42bc-a74c-e97ce764c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-5fe42c79-0555-4bd2-9b46-92659df854aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-6dba13e0-0677-4a78-a93e-55818d05ccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-12ee7c8a-90c2-4b22-a415-003bef27e773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279022060-172.17.0.10-1597757899547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-0c262cb5-9b83-4aeb-87a0-689ea128d182,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4b73ae0e-e845-4c4a-b3c9-e6949d7451b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-d8baceff-e63e-48f6-9fc3-786c114b5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-94f492fa-02a4-48d5-b3a0-91c942ced73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-9a8ad344-7c26-4798-941d-91e609312a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-675b1e60-4800-4fe7-a753-66452464f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-cfbf1c4f-92d0-4232-afff-8bfb73b0df36,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-766962a1-7d1e-4f05-9dd9-c48196b5c993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279022060-172.17.0.10-1597757899547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-0c262cb5-9b83-4aeb-87a0-689ea128d182,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4b73ae0e-e845-4c4a-b3c9-e6949d7451b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-d8baceff-e63e-48f6-9fc3-786c114b5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-94f492fa-02a4-48d5-b3a0-91c942ced73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-9a8ad344-7c26-4798-941d-91e609312a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-675b1e60-4800-4fe7-a753-66452464f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-cfbf1c4f-92d0-4232-afff-8bfb73b0df36,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-766962a1-7d1e-4f05-9dd9-c48196b5c993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012653146-172.17.0.10-1597758126695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-a5221ae4-36d9-4ec3-8cf7-f634ec5a5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-26d7b61e-ff12-4f49-ba94-9b585a126860,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-f012172c-0019-45b8-8341-591325ee97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c7a861ba-24a2-464e-bccc-39606790372b,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-2ee1dac4-a6ea-4b9f-ba49-41273bfd8923,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-0f1a5f17-4b41-4e20-9243-26fdd1999614,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-b96ad8ec-49a6-4dbb-a824-d21121a8aa60,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-8a275f4f-8919-4061-8877-fa729822f34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012653146-172.17.0.10-1597758126695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-a5221ae4-36d9-4ec3-8cf7-f634ec5a5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-26d7b61e-ff12-4f49-ba94-9b585a126860,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-f012172c-0019-45b8-8341-591325ee97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c7a861ba-24a2-464e-bccc-39606790372b,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-2ee1dac4-a6ea-4b9f-ba49-41273bfd8923,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-0f1a5f17-4b41-4e20-9243-26fdd1999614,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-b96ad8ec-49a6-4dbb-a824-d21121a8aa60,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-8a275f4f-8919-4061-8877-fa729822f34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267110643-172.17.0.10-1597758302083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-8d3dab32-446c-4a94-8ca4-a69c2d1e48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-9c9b7f12-5e14-44ef-80d5-3329a5021232,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b868bfc0-1164-47e1-a5d8-ea60fb59581d,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-15350b9e-0dc6-45eb-a34e-58e7eb282384,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-505e8055-e1d4-4429-bfe0-d197b3a45793,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-24a4cbe3-ba77-4065-90ab-d9c1ba80d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-a494c95d-6b8d-4590-a070-6de6d1b1d112,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-27c090f6-af66-4a5c-ab3f-4dcce7ad226a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267110643-172.17.0.10-1597758302083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-8d3dab32-446c-4a94-8ca4-a69c2d1e48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-9c9b7f12-5e14-44ef-80d5-3329a5021232,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b868bfc0-1164-47e1-a5d8-ea60fb59581d,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-15350b9e-0dc6-45eb-a34e-58e7eb282384,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-505e8055-e1d4-4429-bfe0-d197b3a45793,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-24a4cbe3-ba77-4065-90ab-d9c1ba80d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-a494c95d-6b8d-4590-a070-6de6d1b1d112,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-27c090f6-af66-4a5c-ab3f-4dcce7ad226a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353300822-172.17.0.10-1597758480906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-f0bf581d-d859-4744-b6d6-be97c3fdeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-fdc3c56d-5ec2-46c3-934b-0ded842156d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-20081ca7-fa05-4ef0-8764-b048aff3f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-3100948a-d80c-41c8-8442-39771e5974a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-7396f3cb-a2c1-496d-b555-a316c04bb7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-583bb167-3c03-49c9-ab2a-1f3a57250b08,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-fea0534b-190b-4b87-84b9-6c01e7a5d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-bd1a96b4-96f9-4ceb-8e37-5ebb69516b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353300822-172.17.0.10-1597758480906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-f0bf581d-d859-4744-b6d6-be97c3fdeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-fdc3c56d-5ec2-46c3-934b-0ded842156d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-20081ca7-fa05-4ef0-8764-b048aff3f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-3100948a-d80c-41c8-8442-39771e5974a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-7396f3cb-a2c1-496d-b555-a316c04bb7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-583bb167-3c03-49c9-ab2a-1f3a57250b08,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-fea0534b-190b-4b87-84b9-6c01e7a5d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-bd1a96b4-96f9-4ceb-8e37-5ebb69516b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706225350-172.17.0.10-1597758639771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-91eb6eb9-15ef-42f7-bf14-5b1a3958b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3a223696-8aa0-41b8-8739-74758d851853,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-ab6727e5-ab31-46c5-a2d6-c9f48dbf58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-82e2b455-cf95-4961-a56a-13efb1dde403,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d11ac146-b9ff-41ee-9025-ddcfe74a219e,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-03dbc7cb-95c4-4ca5-85c5-fcd2de39706e,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-052d91a8-5e9b-487d-8307-82c43d3a11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-9403e6c4-4c41-47ab-aa56-b3e9d4f8b827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706225350-172.17.0.10-1597758639771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-91eb6eb9-15ef-42f7-bf14-5b1a3958b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3a223696-8aa0-41b8-8739-74758d851853,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-ab6727e5-ab31-46c5-a2d6-c9f48dbf58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-82e2b455-cf95-4961-a56a-13efb1dde403,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d11ac146-b9ff-41ee-9025-ddcfe74a219e,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-03dbc7cb-95c4-4ca5-85c5-fcd2de39706e,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-052d91a8-5e9b-487d-8307-82c43d3a11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-9403e6c4-4c41-47ab-aa56-b3e9d4f8b827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569978776-172.17.0.10-1597758687964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-4f5d2b61-74b1-42ca-a24e-ecd5a7d86526,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-860edc22-5cd2-4a12-b6fb-a26bc46913a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-5d197f67-27b9-431c-8375-51395e7ad600,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-b253727e-075f-4948-8a83-8ad880bfc6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-8e0d33c8-6193-4717-98d1-411c3bff8da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0b6d1aca-12ca-49c4-bc7e-9d884492bf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-0e6f2e57-3ec1-4625-b3dd-6a50def4ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-e87c5924-a7da-41cc-b3a4-fb649128960c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569978776-172.17.0.10-1597758687964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-4f5d2b61-74b1-42ca-a24e-ecd5a7d86526,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-860edc22-5cd2-4a12-b6fb-a26bc46913a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-5d197f67-27b9-431c-8375-51395e7ad600,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-b253727e-075f-4948-8a83-8ad880bfc6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-8e0d33c8-6193-4717-98d1-411c3bff8da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0b6d1aca-12ca-49c4-bc7e-9d884492bf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-0e6f2e57-3ec1-4625-b3dd-6a50def4ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-e87c5924-a7da-41cc-b3a4-fb649128960c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 3988
