reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250814802-172.17.0.2-1597698711226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-9f9716ed-27db-439c-bb04-7092b5e82a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-21a47971-b4d2-4c55-962e-45488bf8c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-2d773406-c786-4910-83d5-43f5d144dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-4dfbf558-b8d9-49b0-935c-9c98e03c9997,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-cf24aae3-17e9-4c79-8ffb-1205d472771f,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-db5d4686-b2d7-4c67-9fa4-52bdcf1454f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-e59f1c26-a294-45ed-9653-1ffb6ca176d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-51d4a271-e3c9-456d-8e52-256bc2d21741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250814802-172.17.0.2-1597698711226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-9f9716ed-27db-439c-bb04-7092b5e82a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-21a47971-b4d2-4c55-962e-45488bf8c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-2d773406-c786-4910-83d5-43f5d144dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-4dfbf558-b8d9-49b0-935c-9c98e03c9997,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-cf24aae3-17e9-4c79-8ffb-1205d472771f,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-db5d4686-b2d7-4c67-9fa4-52bdcf1454f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-e59f1c26-a294-45ed-9653-1ffb6ca176d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-51d4a271-e3c9-456d-8e52-256bc2d21741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954052725-172.17.0.2-1597699582651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-c82ad4c1-a223-4e32-92df-ded3bb8d0087,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-8aaac2cb-0807-406a-ba1f-d635de3a8e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-cccdde1e-48b3-4776-9daa-b8b82fbcafab,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-659d8025-2c70-4d63-baa3-6ffef299d333,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-5357cbf6-eddd-4cc7-ad44-18ad0ec27ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-eed1790e-84a7-4753-994c-259fc3e81bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-05690f7e-9b4d-4d2b-bebb-e6dee8fe5f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-e95fc12d-8a2b-4023-91c8-9dfa40fb46f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954052725-172.17.0.2-1597699582651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-c82ad4c1-a223-4e32-92df-ded3bb8d0087,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-8aaac2cb-0807-406a-ba1f-d635de3a8e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-cccdde1e-48b3-4776-9daa-b8b82fbcafab,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-659d8025-2c70-4d63-baa3-6ffef299d333,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-5357cbf6-eddd-4cc7-ad44-18ad0ec27ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-eed1790e-84a7-4753-994c-259fc3e81bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-05690f7e-9b4d-4d2b-bebb-e6dee8fe5f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-e95fc12d-8a2b-4023-91c8-9dfa40fb46f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172548558-172.17.0.2-1597699999242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-2aa55811-c052-4594-ac09-4508c9c435bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-a38f57cc-c327-4879-a067-ee039e9154ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-e9e4d603-88f7-4f04-a427-a22330f4cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-add88ac8-8cda-4d91-b60a-91248b2182f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-849d944c-841d-4c03-b0f8-589d47c44c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c47d1a0f-b0d7-435a-8a41-83c22621afa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-3c4ffeab-81b6-4204-bdb2-a47750dc82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-942b69f6-2db7-4088-a2b1-61b2c5cabc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172548558-172.17.0.2-1597699999242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38724,DS-2aa55811-c052-4594-ac09-4508c9c435bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-a38f57cc-c327-4879-a067-ee039e9154ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-e9e4d603-88f7-4f04-a427-a22330f4cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-add88ac8-8cda-4d91-b60a-91248b2182f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-849d944c-841d-4c03-b0f8-589d47c44c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c47d1a0f-b0d7-435a-8a41-83c22621afa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-3c4ffeab-81b6-4204-bdb2-a47750dc82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-942b69f6-2db7-4088-a2b1-61b2c5cabc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102080397-172.17.0.2-1597700447198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-b021dbb4-f761-4f10-a63d-0a0de5d4d865,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-978122d2-aa12-49ec-91a0-13230678b842,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-4f220632-4429-4646-89a4-a4484d55b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-5e1fd27b-c018-43ea-a70c-e6b1df54612a,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-a68f8048-9cf4-48fe-84bf-00b7406d9ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-d4de3f9d-eb7c-4808-a54c-6432c5f7a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-354858df-6903-4bbb-a9f0-c923b126152e,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d3c6e532-cb45-4785-8a4a-a8a00f1cf1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102080397-172.17.0.2-1597700447198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-b021dbb4-f761-4f10-a63d-0a0de5d4d865,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-978122d2-aa12-49ec-91a0-13230678b842,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-4f220632-4429-4646-89a4-a4484d55b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-5e1fd27b-c018-43ea-a70c-e6b1df54612a,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-a68f8048-9cf4-48fe-84bf-00b7406d9ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-d4de3f9d-eb7c-4808-a54c-6432c5f7a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-354858df-6903-4bbb-a9f0-c923b126152e,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d3c6e532-cb45-4785-8a4a-a8a00f1cf1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219701430-172.17.0.2-1597700660024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-a9b5e966-01f4-412e-b431-eb012599c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-fdcceafc-5fb5-4178-8f43-0c41559147ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-da1a9e21-9cdd-40b3-867f-c0fe5fa8d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-372d6dcc-5f36-4986-9515-758e521b7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-6a80ff4a-c0ac-4df3-b701-0b161f0fc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-3077d715-367c-4b90-a9ac-b9094d7f8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-13f0ab47-37f6-4843-baa2-8022b0823a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-3fb7e27b-9409-40a6-a5c1-062867904364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219701430-172.17.0.2-1597700660024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-a9b5e966-01f4-412e-b431-eb012599c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-fdcceafc-5fb5-4178-8f43-0c41559147ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-da1a9e21-9cdd-40b3-867f-c0fe5fa8d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-372d6dcc-5f36-4986-9515-758e521b7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-6a80ff4a-c0ac-4df3-b701-0b161f0fc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-3077d715-367c-4b90-a9ac-b9094d7f8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-13f0ab47-37f6-4843-baa2-8022b0823a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-3fb7e27b-9409-40a6-a5c1-062867904364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450001537-172.17.0.2-1597701547870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-74b1eed7-caa7-48d1-af65-2676d9a41036,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-b5f6ff24-8556-4f32-b90a-cb70c80faef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-94d0ac46-bb47-4946-8f23-8bd28974cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2cbdd7f9-1da8-4e1a-bbb2-9028dcd74ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-765c544d-912a-4024-9d59-2b92cd4dead5,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-fa2c4ca4-35d8-469a-9779-2e29ca9010f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-cbffcee0-1a83-44c8-abf4-bd870a4b27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-8b896639-b350-4e8d-ac3b-b194c6675763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450001537-172.17.0.2-1597701547870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-74b1eed7-caa7-48d1-af65-2676d9a41036,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-b5f6ff24-8556-4f32-b90a-cb70c80faef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-94d0ac46-bb47-4946-8f23-8bd28974cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-2cbdd7f9-1da8-4e1a-bbb2-9028dcd74ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-765c544d-912a-4024-9d59-2b92cd4dead5,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-fa2c4ca4-35d8-469a-9779-2e29ca9010f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-cbffcee0-1a83-44c8-abf4-bd870a4b27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-8b896639-b350-4e8d-ac3b-b194c6675763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957462221-172.17.0.2-1597702438560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-433edb8c-c828-4071-9c1d-bcd085c2f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-a2ad8086-71c7-4d05-a063-0b2cbf99e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-4c74d6ff-4e61-4f6e-a2ee-a31649d22c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-0a5bb36b-df85-48aa-8b4b-120dca27232e,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-e4629a54-bc7d-4ca2-a8b9-84aa90dc9f02,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-97b5cb47-ad1f-48f9-8f21-730256bbf10b,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-28b41da8-7283-4164-9332-37c5a766c856,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-a2c612fd-5904-4aa3-924a-725312326f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957462221-172.17.0.2-1597702438560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-433edb8c-c828-4071-9c1d-bcd085c2f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-a2ad8086-71c7-4d05-a063-0b2cbf99e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-4c74d6ff-4e61-4f6e-a2ee-a31649d22c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-0a5bb36b-df85-48aa-8b4b-120dca27232e,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-e4629a54-bc7d-4ca2-a8b9-84aa90dc9f02,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-97b5cb47-ad1f-48f9-8f21-730256bbf10b,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-28b41da8-7283-4164-9332-37c5a766c856,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-a2c612fd-5904-4aa3-924a-725312326f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485891882-172.17.0.2-1597702523532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43495,DS-a7e1b428-51ba-46f3-90dd-d5c590b9d585,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-1b244aef-ea6a-49f2-912c-e851ace8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-41b3a85f-9845-4a06-8892-9757d0683315,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d7140698-b6dc-45e3-a004-c111eb71f329,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-5f3bdf5a-3d2f-4fcb-be26-3281c4201279,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-54ea5a11-c8bd-4645-aae8-50d90a874377,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-9d4c69b8-223d-452f-a33e-a0be431bfc09,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-3b7f21a2-2e54-48bb-aa26-91fd45a93024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485891882-172.17.0.2-1597702523532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43495,DS-a7e1b428-51ba-46f3-90dd-d5c590b9d585,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-1b244aef-ea6a-49f2-912c-e851ace8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-41b3a85f-9845-4a06-8892-9757d0683315,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d7140698-b6dc-45e3-a004-c111eb71f329,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-5f3bdf5a-3d2f-4fcb-be26-3281c4201279,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-54ea5a11-c8bd-4645-aae8-50d90a874377,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-9d4c69b8-223d-452f-a33e-a0be431bfc09,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-3b7f21a2-2e54-48bb-aa26-91fd45a93024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631059798-172.17.0.2-1597702599228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41213,DS-29270c59-53cc-49d2-8a98-6fb883068cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-95b94df7-6f34-4803-8e78-3f38e5418bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9ccdb0d6-e8dd-41e2-bfa3-76b0094e9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-d9cd0d44-b2cc-4f5f-a57e-93fa051629ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-a6b5404d-6d89-4ae6-adf1-7c68e40e4506,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-1801feea-4918-4339-bad5-dd304135a350,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-d5fe5a64-e8e2-4a77-bc37-4c96cd7e8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f26b3040-4faf-4983-bf4a-4f8fb50c9f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631059798-172.17.0.2-1597702599228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41213,DS-29270c59-53cc-49d2-8a98-6fb883068cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-95b94df7-6f34-4803-8e78-3f38e5418bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9ccdb0d6-e8dd-41e2-bfa3-76b0094e9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-d9cd0d44-b2cc-4f5f-a57e-93fa051629ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-a6b5404d-6d89-4ae6-adf1-7c68e40e4506,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-1801feea-4918-4339-bad5-dd304135a350,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-d5fe5a64-e8e2-4a77-bc37-4c96cd7e8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f26b3040-4faf-4983-bf4a-4f8fb50c9f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931204567-172.17.0.2-1597702671537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-d3fac89e-c504-4242-8be4-51965a72b159,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-10a20eac-3dc5-4fcd-8812-45cca1c3c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-7efe11df-8e6e-4142-b90b-ec1e47abfe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-2549d1bd-4ef6-4ffb-a7a3-318d8bddd488,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3c9b023e-4b95-4b63-90f0-0f727efd7786,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0cd3a42f-33bc-4b22-966b-db439f19a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-dbb9eea9-8d28-419a-b22d-a44c650eeb01,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-e4a947e8-882b-4ef4-b7ec-890e5cf4052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931204567-172.17.0.2-1597702671537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-d3fac89e-c504-4242-8be4-51965a72b159,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-10a20eac-3dc5-4fcd-8812-45cca1c3c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-7efe11df-8e6e-4142-b90b-ec1e47abfe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-2549d1bd-4ef6-4ffb-a7a3-318d8bddd488,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3c9b023e-4b95-4b63-90f0-0f727efd7786,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0cd3a42f-33bc-4b22-966b-db439f19a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-dbb9eea9-8d28-419a-b22d-a44c650eeb01,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-e4a947e8-882b-4ef4-b7ec-890e5cf4052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235453329-172.17.0.2-1597702920254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-a9b16d0b-3ba6-455d-ab3b-208e19121b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-18a9eadc-f938-4986-b502-afe94225005c,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-3d511d2b-45c8-427a-b3f0-211a107b3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-6f8f5c3c-8785-4c58-b200-a5476f1bc6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-cd9aae99-8880-4acb-91fb-afbd13928e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-e5502a55-c272-4a64-ae0a-6b0fc31623f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-9270d08f-e74d-4593-9d39-5fb040616782,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-ae9d9946-7b5a-4a26-af52-b46385e3ce40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235453329-172.17.0.2-1597702920254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-a9b16d0b-3ba6-455d-ab3b-208e19121b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-18a9eadc-f938-4986-b502-afe94225005c,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-3d511d2b-45c8-427a-b3f0-211a107b3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-6f8f5c3c-8785-4c58-b200-a5476f1bc6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-cd9aae99-8880-4acb-91fb-afbd13928e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-e5502a55-c272-4a64-ae0a-6b0fc31623f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-9270d08f-e74d-4593-9d39-5fb040616782,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-ae9d9946-7b5a-4a26-af52-b46385e3ce40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124751346-172.17.0.2-1597703482503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-7e1c523a-a359-44a2-bfb3-e8f191673134,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-04de984d-98be-4830-83aa-fe1965996470,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-3b7f9a1e-4f58-486a-956b-3a3a10b8fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-051a9c45-fbcd-4567-8664-455daf711b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d37916e8-2371-435f-9ba4-e5ac08fe525d,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-8cfc0ac8-e080-49f4-ace3-fb8766caefab,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-a09302d8-db54-4859-9809-fd5e483a2035,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9a09f923-fba4-4397-a259-4bb896305a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124751346-172.17.0.2-1597703482503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-7e1c523a-a359-44a2-bfb3-e8f191673134,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-04de984d-98be-4830-83aa-fe1965996470,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-3b7f9a1e-4f58-486a-956b-3a3a10b8fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-051a9c45-fbcd-4567-8664-455daf711b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d37916e8-2371-435f-9ba4-e5ac08fe525d,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-8cfc0ac8-e080-49f4-ace3-fb8766caefab,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-a09302d8-db54-4859-9809-fd5e483a2035,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9a09f923-fba4-4397-a259-4bb896305a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650776494-172.17.0.2-1597703777294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-e371917c-8969-4b7f-9bfe-6de83448b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-310fac43-2879-4060-ace3-2585363079e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-48290bbd-ad70-43a8-bd33-ef46afd796bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-8f1de92d-23e7-4fc0-a2b7-7e5fb5a04f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-f4919896-0007-4cc4-b612-587ac7e4b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-851ac0c9-eb2b-4b19-aedb-e819df0f4d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-4f30d8f9-ee53-412a-841e-a73a0a621d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-8dc97f1c-7dd9-4bc6-9f9b-a3882593e802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650776494-172.17.0.2-1597703777294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-e371917c-8969-4b7f-9bfe-6de83448b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-310fac43-2879-4060-ace3-2585363079e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-48290bbd-ad70-43a8-bd33-ef46afd796bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-8f1de92d-23e7-4fc0-a2b7-7e5fb5a04f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-f4919896-0007-4cc4-b612-587ac7e4b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-851ac0c9-eb2b-4b19-aedb-e819df0f4d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-4f30d8f9-ee53-412a-841e-a73a0a621d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-8dc97f1c-7dd9-4bc6-9f9b-a3882593e802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882470714-172.17.0.2-1597704227599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-f6ac4ccd-61d1-4542-a9ec-e7b194e49f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-0c5993bd-cfb9-4835-8336-22653b83e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-24b4c37b-681d-49b8-8408-e0b18b1ce359,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-c1a7fff8-4a5f-4f9a-b041-115c32e76560,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-05a544e9-d639-4e9c-a86f-bf193bb99548,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-53590d5e-ec26-4d04-b565-be2cbd02c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-652a1d13-0d0c-49ec-a678-19bf7dd63bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-8c314235-231d-4c98-9878-244839db7224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882470714-172.17.0.2-1597704227599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-f6ac4ccd-61d1-4542-a9ec-e7b194e49f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-0c5993bd-cfb9-4835-8336-22653b83e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-24b4c37b-681d-49b8-8408-e0b18b1ce359,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-c1a7fff8-4a5f-4f9a-b041-115c32e76560,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-05a544e9-d639-4e9c-a86f-bf193bb99548,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-53590d5e-ec26-4d04-b565-be2cbd02c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-652a1d13-0d0c-49ec-a678-19bf7dd63bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-8c314235-231d-4c98-9878-244839db7224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460780916-172.17.0.2-1597704421413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-27affc09-8c5a-46a1-aeba-ab1bd8c71f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1946a531-40ad-4c4d-bd9c-5776ead1c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-7176656a-ea90-437a-a1db-ec15ae1d56fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9f62507b-3dbb-45dd-ae03-e954814e17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-ef5b828e-3575-4151-ae46-c9a7c0209fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-ca3d13b7-f916-4b63-851d-1aaf2891c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-1b1a1775-38da-4147-a9fa-569b836e97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-0ea529fe-a331-492b-85ce-b9d90f916494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460780916-172.17.0.2-1597704421413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-27affc09-8c5a-46a1-aeba-ab1bd8c71f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1946a531-40ad-4c4d-bd9c-5776ead1c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-7176656a-ea90-437a-a1db-ec15ae1d56fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9f62507b-3dbb-45dd-ae03-e954814e17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-ef5b828e-3575-4151-ae46-c9a7c0209fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-ca3d13b7-f916-4b63-851d-1aaf2891c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-1b1a1775-38da-4147-a9fa-569b836e97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-0ea529fe-a331-492b-85ce-b9d90f916494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612382706-172.17.0.2-1597704457476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-a41f5923-4089-4700-987e-499443621f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-aace7e43-d23d-4368-9584-b0eb00c5c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-4bf6789e-46f7-42c5-aca3-06f3073f316d,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-5fda9f66-1300-4dea-bf37-407ff04d717b,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d14c0f49-070e-452e-b09d-2cdf4c446bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-873d9f04-193d-4f5c-913b-89c4e5834b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-0bed98f8-a189-4b16-ba8a-6c805b37be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-1a537917-38db-45ba-96aa-3c49a4c0e9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612382706-172.17.0.2-1597704457476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-a41f5923-4089-4700-987e-499443621f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-aace7e43-d23d-4368-9584-b0eb00c5c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-4bf6789e-46f7-42c5-aca3-06f3073f316d,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-5fda9f66-1300-4dea-bf37-407ff04d717b,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d14c0f49-070e-452e-b09d-2cdf4c446bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-873d9f04-193d-4f5c-913b-89c4e5834b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-0bed98f8-a189-4b16-ba8a-6c805b37be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-1a537917-38db-45ba-96aa-3c49a4c0e9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088675769-172.17.0.2-1597704530019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-97bd8b4d-d370-42f6-b572-15e2999d391f,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-94b2a038-6196-46e7-b0b8-30555ca399ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-898807b8-f1d5-4da4-aa91-885a04156f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-93bee6a5-a31c-40ca-854a-a7b322717d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-1bbed988-35b5-4d78-8754-6ea0bb9bfbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-3cfc6868-a276-4458-9512-2e1cc6a9d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-bab22f6f-1485-47b8-ab24-30ab9798255d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-74c578ad-0688-4f1b-b743-45a235a66619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088675769-172.17.0.2-1597704530019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-97bd8b4d-d370-42f6-b572-15e2999d391f,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-94b2a038-6196-46e7-b0b8-30555ca399ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-898807b8-f1d5-4da4-aa91-885a04156f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-93bee6a5-a31c-40ca-854a-a7b322717d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-1bbed988-35b5-4d78-8754-6ea0bb9bfbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-3cfc6868-a276-4458-9512-2e1cc6a9d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-bab22f6f-1485-47b8-ab24-30ab9798255d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-74c578ad-0688-4f1b-b743-45a235a66619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5857
