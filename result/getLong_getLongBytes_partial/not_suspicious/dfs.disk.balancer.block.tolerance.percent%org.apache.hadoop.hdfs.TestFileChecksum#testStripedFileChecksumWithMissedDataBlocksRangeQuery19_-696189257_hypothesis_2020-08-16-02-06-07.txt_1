reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289428363-172.17.0.6-1597544524772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-00edbe94-408a-4010-ab23-f2964f7d29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-943c0fcc-77c1-4951-afe4-c0ee2dbf04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-28fce52e-bc86-4e29-896e-b7bdc8bf018f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-0786142f-18a5-4325-8422-e0f9879d7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-73f94afb-4ba6-46ea-93ef-1945da25f519,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-9e71f75d-ce63-4a1c-927d-bc6295b4ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1a394240-57cc-46a0-989b-8722cd3c3978,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-be05b2af-5c0f-4f24-b9bd-9bfbefec8e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289428363-172.17.0.6-1597544524772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-00edbe94-408a-4010-ab23-f2964f7d29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-943c0fcc-77c1-4951-afe4-c0ee2dbf04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-28fce52e-bc86-4e29-896e-b7bdc8bf018f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-0786142f-18a5-4325-8422-e0f9879d7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-73f94afb-4ba6-46ea-93ef-1945da25f519,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-9e71f75d-ce63-4a1c-927d-bc6295b4ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1a394240-57cc-46a0-989b-8722cd3c3978,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-be05b2af-5c0f-4f24-b9bd-9bfbefec8e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174224283-172.17.0.6-1597545267091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-bd7ea291-0c7f-4066-93ce-568b76582054,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-21770ded-9245-4c55-a682-968bdc0e8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-5d85c152-dc86-4110-a549-52fa1e65cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-2a4ff5c4-bca1-472e-b883-6737ff4fd045,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f1de5a5d-dd12-449d-9862-b79f12183673,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-58c6184d-a835-4be3-8246-577226c03f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-904518fd-6d24-4d95-8652-d1f282f47fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-c4df8a49-be9d-4894-af75-1a1a0611c1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174224283-172.17.0.6-1597545267091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-bd7ea291-0c7f-4066-93ce-568b76582054,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-21770ded-9245-4c55-a682-968bdc0e8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-5d85c152-dc86-4110-a549-52fa1e65cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-2a4ff5c4-bca1-472e-b883-6737ff4fd045,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f1de5a5d-dd12-449d-9862-b79f12183673,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-58c6184d-a835-4be3-8246-577226c03f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-904518fd-6d24-4d95-8652-d1f282f47fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-c4df8a49-be9d-4894-af75-1a1a0611c1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100012420-172.17.0.6-1597545370264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43699,DS-e1a134bc-2e7e-41b9-9aa4-7b97f996c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-e6a62502-8b3a-4e5c-8827-93c0603a9c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-1fda8ab5-80f7-4bff-94e9-44a70a79f891,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7185cbf0-72a8-48d5-8681-f68bdf625a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-608b083a-a5f0-4c13-b660-f249c7b6cf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-83281930-4a7b-4d46-8708-ee4eea647c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-6969f3cb-50a1-4197-bdfa-e83beb2c7829,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f99b323a-970b-4799-920f-f46354dce46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100012420-172.17.0.6-1597545370264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43699,DS-e1a134bc-2e7e-41b9-9aa4-7b97f996c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-e6a62502-8b3a-4e5c-8827-93c0603a9c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-1fda8ab5-80f7-4bff-94e9-44a70a79f891,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7185cbf0-72a8-48d5-8681-f68bdf625a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-608b083a-a5f0-4c13-b660-f249c7b6cf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-83281930-4a7b-4d46-8708-ee4eea647c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-6969f3cb-50a1-4197-bdfa-e83beb2c7829,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f99b323a-970b-4799-920f-f46354dce46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852825954-172.17.0.6-1597545737690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-4e5c4fc3-7646-4bb0-bbfe-1f77ce82c78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-2f7d371c-a69f-41fb-8081-b54de6a3000d,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-5427b403-3283-47e4-b17f-ca65995d2777,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-162cebe3-a9c3-46ee-9c2d-87df7d315f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-46bf5a61-b70a-42fa-b774-4a9b28f7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-71053b6b-4798-48df-9da6-c8f66ef3e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-724145d3-cc3f-4480-b675-eea701a253b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-3b78af16-952f-4a98-9904-d3a5fe24ac08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852825954-172.17.0.6-1597545737690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-4e5c4fc3-7646-4bb0-bbfe-1f77ce82c78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-2f7d371c-a69f-41fb-8081-b54de6a3000d,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-5427b403-3283-47e4-b17f-ca65995d2777,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-162cebe3-a9c3-46ee-9c2d-87df7d315f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-46bf5a61-b70a-42fa-b774-4a9b28f7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-71053b6b-4798-48df-9da6-c8f66ef3e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-724145d3-cc3f-4480-b675-eea701a253b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-3b78af16-952f-4a98-9904-d3a5fe24ac08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977210824-172.17.0.6-1597546553919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-4143ea2f-789b-4d35-b633-58ae09c4963a,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-b343fb78-e073-40b2-9ba6-8fb5bdb0fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-40d5e52a-60b5-41bd-8969-cb108d38cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-2071c294-2c1d-4aef-959e-e94e653f9371,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c7dbc737-2ceb-4eff-9fe5-4d57032a422f,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-d3dfd814-273b-44b2-8d89-0e38074797ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-ac71715b-0284-4e56-a5d1-f5de3efe2f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-b800a43c-5520-407d-8999-7da38c94d7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977210824-172.17.0.6-1597546553919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-4143ea2f-789b-4d35-b633-58ae09c4963a,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-b343fb78-e073-40b2-9ba6-8fb5bdb0fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-40d5e52a-60b5-41bd-8969-cb108d38cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-2071c294-2c1d-4aef-959e-e94e653f9371,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c7dbc737-2ceb-4eff-9fe5-4d57032a422f,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-d3dfd814-273b-44b2-8d89-0e38074797ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-ac71715b-0284-4e56-a5d1-f5de3efe2f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-b800a43c-5520-407d-8999-7da38c94d7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338110690-172.17.0.6-1597547028129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-9ebd9734-5847-4a9f-941b-807377d9841a,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e3e08325-c8a0-4679-9224-f56edde3cb53,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-74e7fa89-8ed8-495f-bc2b-01cfe0191dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-d318bca1-ee2f-4b67-be1e-f8a1678553a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-5426d77f-2992-47da-a2b8-5344c9ffa283,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-3208f94b-0613-4840-8138-d6873394184f,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-c1b4493f-4f09-48a3-a50c-c283b4cb961a,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-589a7053-47f9-4d00-8ce6-0ef7b3bf00c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338110690-172.17.0.6-1597547028129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-9ebd9734-5847-4a9f-941b-807377d9841a,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e3e08325-c8a0-4679-9224-f56edde3cb53,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-74e7fa89-8ed8-495f-bc2b-01cfe0191dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-d318bca1-ee2f-4b67-be1e-f8a1678553a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-5426d77f-2992-47da-a2b8-5344c9ffa283,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-3208f94b-0613-4840-8138-d6873394184f,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-c1b4493f-4f09-48a3-a50c-c283b4cb961a,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-589a7053-47f9-4d00-8ce6-0ef7b3bf00c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436573333-172.17.0.6-1597547862839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45004,DS-bdcc4da6-8fa4-4597-bfcb-aa3fd3e06091,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-25278ccc-ca7d-4f75-96bf-5aa9e3dcf04e,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-55e6d7f6-d437-4d34-bff6-d3d91975ac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-bd25661c-6580-4e83-85f0-0d8dfd4184fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-47450031-5f28-452b-a4ed-fb35c282e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-bb3259f1-81c2-4e50-88c1-57316176e395,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-45c0e080-6f3a-40cd-be9c-41fc8ab27355,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a101a28d-b634-4a1e-b38f-f94645689472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436573333-172.17.0.6-1597547862839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45004,DS-bdcc4da6-8fa4-4597-bfcb-aa3fd3e06091,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-25278ccc-ca7d-4f75-96bf-5aa9e3dcf04e,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-55e6d7f6-d437-4d34-bff6-d3d91975ac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-bd25661c-6580-4e83-85f0-0d8dfd4184fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-47450031-5f28-452b-a4ed-fb35c282e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-bb3259f1-81c2-4e50-88c1-57316176e395,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-45c0e080-6f3a-40cd-be9c-41fc8ab27355,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a101a28d-b634-4a1e-b38f-f94645689472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968136974-172.17.0.6-1597548484421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-593da22b-b5d1-4760-b65e-b399060fb381,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-d5e5bcfe-39a0-448c-89af-a679fcd1de85,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-b2fac6c0-e008-4b90-b61e-0590036810fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-bbd83b51-27c5-4aa0-89d8-1670ce470657,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-33c9ce33-0631-491a-a6fc-a4a296280256,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-ae00bd4a-b674-40ff-bfe5-a1b97c3ae2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-6e3e9d24-08c8-4ff7-a47c-6fba0a2f87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-460f8631-2b2a-49a4-8cf1-5612d0e309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968136974-172.17.0.6-1597548484421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-593da22b-b5d1-4760-b65e-b399060fb381,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-d5e5bcfe-39a0-448c-89af-a679fcd1de85,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-b2fac6c0-e008-4b90-b61e-0590036810fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-bbd83b51-27c5-4aa0-89d8-1670ce470657,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-33c9ce33-0631-491a-a6fc-a4a296280256,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-ae00bd4a-b674-40ff-bfe5-a1b97c3ae2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-6e3e9d24-08c8-4ff7-a47c-6fba0a2f87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-460f8631-2b2a-49a4-8cf1-5612d0e309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550304487-172.17.0.6-1597548887164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-840bc187-b1b6-4ae0-9448-5b56ab11e114,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ab57be49-b822-40a2-bd6f-635e05082177,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-50f7738e-5540-4d5f-81b3-5e56adb79314,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-47419dde-ce65-4335-9749-de2b0ecc2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-71844b67-49b2-4b34-b0db-ec6ae26e2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3b691751-9a0c-4c08-afac-c64701269306,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e70cacde-ebd4-4f42-8f50-dd7b25159542,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-29110fe6-c806-498f-a67d-a3b58db3f721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550304487-172.17.0.6-1597548887164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-840bc187-b1b6-4ae0-9448-5b56ab11e114,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ab57be49-b822-40a2-bd6f-635e05082177,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-50f7738e-5540-4d5f-81b3-5e56adb79314,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-47419dde-ce65-4335-9749-de2b0ecc2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-71844b67-49b2-4b34-b0db-ec6ae26e2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3b691751-9a0c-4c08-afac-c64701269306,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e70cacde-ebd4-4f42-8f50-dd7b25159542,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-29110fe6-c806-498f-a67d-a3b58db3f721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5536
