reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011200765-172.17.0.14-1597301132279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-160fab7f-46fd-41ce-80f8-f7fa8a6ac334,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-110abf32-a083-42a3-8450-3f29fb4f42a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-14f399cf-f3f4-4a2f-8771-66d8891e5e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-e6fc3330-c323-4421-ada7-f2a81b854fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-f5d65a81-da78-421a-8118-0c1b5e82fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-83065178-5fde-4d3c-9a52-6e70dc19d75e,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-78ca536c-5bea-4a64-a83b-986d783b2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-a0c67921-3f9a-4486-a48a-8d13134a28d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011200765-172.17.0.14-1597301132279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-160fab7f-46fd-41ce-80f8-f7fa8a6ac334,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-110abf32-a083-42a3-8450-3f29fb4f42a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-14f399cf-f3f4-4a2f-8771-66d8891e5e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-e6fc3330-c323-4421-ada7-f2a81b854fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-f5d65a81-da78-421a-8118-0c1b5e82fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-83065178-5fde-4d3c-9a52-6e70dc19d75e,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-78ca536c-5bea-4a64-a83b-986d783b2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-a0c67921-3f9a-4486-a48a-8d13134a28d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811435876-172.17.0.14-1597301932934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-e64cee47-6298-4e66-adc8-01b0b3671419,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-de9ee67c-8512-4b06-a589-e42f2c4a8308,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-a389066c-09ad-4717-8f16-4720c5bbaad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7164ce6f-fef4-457e-9b42-32eccc6b7875,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-250bd8f2-062a-416c-be55-6ca55ad5dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-38eef25d-4da9-4ad8-bec2-892f773f6953,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-6f7c8b82-9c58-41e5-9db9-3644cc8c212f,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-efbd10e7-79aa-4a19-b53d-8c0b3c56d999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811435876-172.17.0.14-1597301932934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-e64cee47-6298-4e66-adc8-01b0b3671419,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-de9ee67c-8512-4b06-a589-e42f2c4a8308,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-a389066c-09ad-4717-8f16-4720c5bbaad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7164ce6f-fef4-457e-9b42-32eccc6b7875,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-250bd8f2-062a-416c-be55-6ca55ad5dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-38eef25d-4da9-4ad8-bec2-892f773f6953,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-6f7c8b82-9c58-41e5-9db9-3644cc8c212f,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-efbd10e7-79aa-4a19-b53d-8c0b3c56d999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054631834-172.17.0.14-1597302384964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34735,DS-5357f00f-4191-41df-a990-550b432ea235,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-77e52535-dc4e-4e1f-b30e-5a56e1d11139,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-bc77ce6e-0061-402f-84af-7471ea098b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-2f053d02-8bbf-462d-9340-c75b8f8d55be,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-877f8c71-fa6e-4a1e-a572-efa3543c3fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-22f476e9-6944-40cc-ac1c-4f59a5cf19b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-5970a2d7-45aa-47c3-8fe1-8f514875fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-91022ed9-178e-42ca-b10e-a21cf42f0b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054631834-172.17.0.14-1597302384964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34735,DS-5357f00f-4191-41df-a990-550b432ea235,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-77e52535-dc4e-4e1f-b30e-5a56e1d11139,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-bc77ce6e-0061-402f-84af-7471ea098b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-2f053d02-8bbf-462d-9340-c75b8f8d55be,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-877f8c71-fa6e-4a1e-a572-efa3543c3fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-22f476e9-6944-40cc-ac1c-4f59a5cf19b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-5970a2d7-45aa-47c3-8fe1-8f514875fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-91022ed9-178e-42ca-b10e-a21cf42f0b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858404135-172.17.0.14-1597302893893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45266,DS-d0a4f1a2-2e55-46f5-b055-b009b0cb6d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-3edaf41f-cbf2-491f-9063-242d809b32eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-b09ce9b1-49e7-40af-aea9-19c735d78c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-01985b9f-49f3-404d-8314-8ac5a1771481,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-f3f34b74-1650-4013-9584-599fc963ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-47a4ee67-09c7-4cd1-bc13-34cec04b6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e3c96220-660b-4ad3-86d0-b2d7360d64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-297b15a6-7dea-455b-b992-20745bb1b0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858404135-172.17.0.14-1597302893893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45266,DS-d0a4f1a2-2e55-46f5-b055-b009b0cb6d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-3edaf41f-cbf2-491f-9063-242d809b32eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-b09ce9b1-49e7-40af-aea9-19c735d78c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-01985b9f-49f3-404d-8314-8ac5a1771481,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-f3f34b74-1650-4013-9584-599fc963ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-47a4ee67-09c7-4cd1-bc13-34cec04b6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e3c96220-660b-4ad3-86d0-b2d7360d64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-297b15a6-7dea-455b-b992-20745bb1b0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587122883-172.17.0.14-1597303456688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-7d3049d3-920a-4ab9-a385-bc1bad7e3762,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-1268ee11-67ff-4123-8e8d-d95665c866af,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4045cd52-d3d8-4cc3-8caa-bd93d63e66f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-34e4980b-e842-4e65-925f-b8acf166fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-720ccec5-3daa-4a8f-89f1-1d90ed9452ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-2b6a03e1-21ef-4d5c-b729-49512bacda63,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-85c2ff5e-1e0a-464b-8e22-874411da9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-fc02a754-225f-4e86-ad5b-ea11690da3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587122883-172.17.0.14-1597303456688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-7d3049d3-920a-4ab9-a385-bc1bad7e3762,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-1268ee11-67ff-4123-8e8d-d95665c866af,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4045cd52-d3d8-4cc3-8caa-bd93d63e66f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-34e4980b-e842-4e65-925f-b8acf166fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-720ccec5-3daa-4a8f-89f1-1d90ed9452ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-2b6a03e1-21ef-4d5c-b729-49512bacda63,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-85c2ff5e-1e0a-464b-8e22-874411da9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-fc02a754-225f-4e86-ad5b-ea11690da3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307997174-172.17.0.14-1597303959090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-5ef6eed5-a7ab-4ac3-9f4b-5cb6e56966ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-02c688c6-41bf-48d9-9041-a87f6150e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-b81b3cca-f0b0-49db-92a7-545f035b30fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-e9b06faf-7a23-4699-9477-264c3bf099a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-e44e3027-cee9-4b07-a8fe-157c9870bade,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-f83cfcfd-f054-419d-abb4-5f10235a492e,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-a9ba325f-ac21-4dbc-95d8-73d079ed5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-71c34aee-d831-4616-8b73-13e50aadebf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307997174-172.17.0.14-1597303959090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-5ef6eed5-a7ab-4ac3-9f4b-5cb6e56966ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-02c688c6-41bf-48d9-9041-a87f6150e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-b81b3cca-f0b0-49db-92a7-545f035b30fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-e9b06faf-7a23-4699-9477-264c3bf099a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-e44e3027-cee9-4b07-a8fe-157c9870bade,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-f83cfcfd-f054-419d-abb4-5f10235a492e,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-a9ba325f-ac21-4dbc-95d8-73d079ed5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-71c34aee-d831-4616-8b73-13e50aadebf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953190720-172.17.0.14-1597304888135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-c7ec6947-270c-4033-b029-6ecb7a1d3086,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-f6811100-7cd1-449b-bed0-2bf7c2e1491d,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-06031d24-99c1-4450-a596-e453e23ea04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-457b7343-ea3f-4385-9d28-31a792e32a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-335b3683-1df9-4399-a126-99e82679b600,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-638e3fe9-323e-44eb-8050-36b3b4f7a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-f0f79d71-ae98-4ece-a8b8-6598b6308a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a7907b70-a9d7-453c-87bd-a7f10da42e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953190720-172.17.0.14-1597304888135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-c7ec6947-270c-4033-b029-6ecb7a1d3086,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-f6811100-7cd1-449b-bed0-2bf7c2e1491d,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-06031d24-99c1-4450-a596-e453e23ea04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-457b7343-ea3f-4385-9d28-31a792e32a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-335b3683-1df9-4399-a126-99e82679b600,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-638e3fe9-323e-44eb-8050-36b3b4f7a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-f0f79d71-ae98-4ece-a8b8-6598b6308a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a7907b70-a9d7-453c-87bd-a7f10da42e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241470794-172.17.0.14-1597305623190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-30cc7123-0419-4282-a8db-c0741667a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-fabac414-9155-4373-846e-c2de814a6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-d0e3df39-ff37-48a0-978d-3b4b10e993dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-50346c31-eb98-4240-8623-df194df43ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-ea5ed248-745f-4f7a-92a3-799fe3a9ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-9e1ce607-5cb6-41d1-a374-670b12316f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-81664b9a-8410-4669-a094-de0d83ea6176,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-2c910a02-3dc5-45ad-bb5c-3095af5256ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241470794-172.17.0.14-1597305623190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-30cc7123-0419-4282-a8db-c0741667a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-fabac414-9155-4373-846e-c2de814a6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-d0e3df39-ff37-48a0-978d-3b4b10e993dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-50346c31-eb98-4240-8623-df194df43ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-ea5ed248-745f-4f7a-92a3-799fe3a9ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-9e1ce607-5cb6-41d1-a374-670b12316f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-81664b9a-8410-4669-a094-de0d83ea6176,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-2c910a02-3dc5-45ad-bb5c-3095af5256ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5340
