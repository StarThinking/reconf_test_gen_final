reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166309319-172.17.0.11-1597746486032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-c4278a50-c6ce-4c26-8da8-ee4f1d2a0cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-eff1e114-a9d1-4baa-8d61-0bf6e62ff24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-10a149cd-2efd-44fc-bb73-ebce029ca343,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-df802894-d1b7-42b3-ba1d-339c6d8ce16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-f6c9e5c9-c6e1-4d11-aa07-4fee227f864b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-12d92bf4-418d-4c03-858e-34e979f672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-74b45b98-4e42-4187-a490-2a7254a8d520,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f149505-572d-4619-bd47-58765e723267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166309319-172.17.0.11-1597746486032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-c4278a50-c6ce-4c26-8da8-ee4f1d2a0cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-eff1e114-a9d1-4baa-8d61-0bf6e62ff24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-10a149cd-2efd-44fc-bb73-ebce029ca343,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-df802894-d1b7-42b3-ba1d-339c6d8ce16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-f6c9e5c9-c6e1-4d11-aa07-4fee227f864b,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-12d92bf4-418d-4c03-858e-34e979f672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-74b45b98-4e42-4187-a490-2a7254a8d520,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f149505-572d-4619-bd47-58765e723267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848445739-172.17.0.11-1597746584245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-b488eebf-138c-4741-a453-a474d7b928fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-d7cdb8b0-316f-4df2-bb8b-fb984e918751,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-b5dbfcc1-9419-4a68-aefc-837317d9ea91,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-4737f94d-27cd-4167-97a0-bf6de1a630f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-6be2efaf-08cc-415d-ad1a-e9cdeba642e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-020e5052-6e19-492b-a930-b744d9e5c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-2dbfd5be-67b9-4ac0-9fdf-618e60fbd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-52d4cdeb-5299-4dd7-a4c0-32045347633e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848445739-172.17.0.11-1597746584245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-b488eebf-138c-4741-a453-a474d7b928fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-d7cdb8b0-316f-4df2-bb8b-fb984e918751,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-b5dbfcc1-9419-4a68-aefc-837317d9ea91,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-4737f94d-27cd-4167-97a0-bf6de1a630f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-6be2efaf-08cc-415d-ad1a-e9cdeba642e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-020e5052-6e19-492b-a930-b744d9e5c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-2dbfd5be-67b9-4ac0-9fdf-618e60fbd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-52d4cdeb-5299-4dd7-a4c0-32045347633e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714696648-172.17.0.11-1597747033048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-ff115aac-cb59-4f78-bb25-0c0988d6e5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-3d7613c5-2bd7-4b86-afb7-1f96afa53ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-21b0d52b-160f-4f78-8967-759e94b5b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-7fd5ad75-0634-4a92-b245-8a95b953fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1580205b-a6b0-41e3-9908-00eae619b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-930f83a6-d6d4-46ef-b119-a2ed40fa0174,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-3ce18694-2a89-4b9c-a010-3bb2356d7587,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-8e06b369-cef0-4005-a3f5-96ca573b83fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714696648-172.17.0.11-1597747033048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-ff115aac-cb59-4f78-bb25-0c0988d6e5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-3d7613c5-2bd7-4b86-afb7-1f96afa53ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-21b0d52b-160f-4f78-8967-759e94b5b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-7fd5ad75-0634-4a92-b245-8a95b953fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1580205b-a6b0-41e3-9908-00eae619b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-930f83a6-d6d4-46ef-b119-a2ed40fa0174,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-3ce18694-2a89-4b9c-a010-3bb2356d7587,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-8e06b369-cef0-4005-a3f5-96ca573b83fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341303150-172.17.0.11-1597747076410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-da1f12c6-d6d6-4d77-b6d3-19de9b2879f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-5f807644-2a1c-4983-a259-103bcb831b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-42889473-4e33-497b-a13a-058d49d8001c,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-146e65d4-9ba7-4af4-92fb-cd60e693dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5321063e-0171-42d4-af82-d8a111d52723,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d0a941ee-6612-452a-ae0a-5b6e6f51966c,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-916509a8-dbb4-4fa3-9c05-185f92ef8b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-34d240cf-a73e-41e0-8f06-8be8e67606f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341303150-172.17.0.11-1597747076410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-da1f12c6-d6d6-4d77-b6d3-19de9b2879f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-5f807644-2a1c-4983-a259-103bcb831b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-42889473-4e33-497b-a13a-058d49d8001c,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-146e65d4-9ba7-4af4-92fb-cd60e693dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5321063e-0171-42d4-af82-d8a111d52723,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d0a941ee-6612-452a-ae0a-5b6e6f51966c,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-916509a8-dbb4-4fa3-9c05-185f92ef8b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-34d240cf-a73e-41e0-8f06-8be8e67606f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629474354-172.17.0.11-1597747217488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce755180-2e87-4b7a-9357-011e5770b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-9e0cc721-049a-4111-8ada-acff3da278de,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-0cde06d5-f9a0-4372-a073-cd19331e17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-a4eba2bc-3288-410c-a0e6-5e8a42e0aa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-9f6b4ded-c771-4b7e-a8a0-d7ce1e1de3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b4d1eb0d-8b55-4aca-9d3d-16a8d3e107b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-e81f4205-2ac7-4320-a762-28c9fba47fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-a07bde6d-732b-4740-bb21-36e4c4d4e0d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629474354-172.17.0.11-1597747217488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce755180-2e87-4b7a-9357-011e5770b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-9e0cc721-049a-4111-8ada-acff3da278de,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-0cde06d5-f9a0-4372-a073-cd19331e17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-a4eba2bc-3288-410c-a0e6-5e8a42e0aa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-9f6b4ded-c771-4b7e-a8a0-d7ce1e1de3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b4d1eb0d-8b55-4aca-9d3d-16a8d3e107b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-e81f4205-2ac7-4320-a762-28c9fba47fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-a07bde6d-732b-4740-bb21-36e4c4d4e0d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683553164-172.17.0.11-1597747573363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-d4442620-5298-4db8-9afe-5a193cdc3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-ac1d4678-647b-463e-800e-bb62db937b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-be41b28e-0cc0-46c5-a716-94af39f42c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-be3ea19c-a5ae-42ff-a7ff-3543e6b07f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-45ae6ce8-0c90-42ba-be29-e0cacee4af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-46264e61-66aa-4b0c-9079-d3da88a3bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-c48b04e9-486e-409b-871c-e5d14616bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-bb879ff1-9226-4d42-9b17-6baa1f306694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683553164-172.17.0.11-1597747573363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-d4442620-5298-4db8-9afe-5a193cdc3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-ac1d4678-647b-463e-800e-bb62db937b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-be41b28e-0cc0-46c5-a716-94af39f42c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-be3ea19c-a5ae-42ff-a7ff-3543e6b07f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-45ae6ce8-0c90-42ba-be29-e0cacee4af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-46264e61-66aa-4b0c-9079-d3da88a3bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-c48b04e9-486e-409b-871c-e5d14616bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-bb879ff1-9226-4d42-9b17-6baa1f306694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135108942-172.17.0.11-1597747675430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-6d67c3d3-d13a-4e63-838e-f1e2729e7cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-696be054-423c-452c-8563-79505d387efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-078f186f-c3df-48e1-bf11-4eaf33cefec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-b47ce21a-c18c-463c-a953-d9141b2f5e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-20dbd80a-4c5b-4cea-a288-6be88fc90b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-87ff5e3e-a763-4eb7-831f-7281a85883b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a51e5c3f-25c9-4df5-b6bd-be5394cac506,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-ab3a2a74-0cd0-438e-80cc-557b483ade63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135108942-172.17.0.11-1597747675430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-6d67c3d3-d13a-4e63-838e-f1e2729e7cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-696be054-423c-452c-8563-79505d387efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-078f186f-c3df-48e1-bf11-4eaf33cefec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-b47ce21a-c18c-463c-a953-d9141b2f5e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-20dbd80a-4c5b-4cea-a288-6be88fc90b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-87ff5e3e-a763-4eb7-831f-7281a85883b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a51e5c3f-25c9-4df5-b6bd-be5394cac506,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-ab3a2a74-0cd0-438e-80cc-557b483ade63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330780558-172.17.0.11-1597747962373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-ed164296-a5bd-4404-bb34-856e1a3d41e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-056756a6-abda-482c-beb8-8f386c987da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-debbe79f-5a25-4815-b93f-1a547e2f865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-e3e17d25-bc3c-4531-8b3d-917e13b23a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-667aba72-da37-44d0-9b4a-492b5d4c2811,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6f6bcc4e-955d-443c-8d6e-199bd09934d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-5b1cc8f1-3c9f-4274-91c2-a0e13a05ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-69e715f3-515c-47b3-acdf-3b2d54b6fcba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330780558-172.17.0.11-1597747962373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-ed164296-a5bd-4404-bb34-856e1a3d41e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-056756a6-abda-482c-beb8-8f386c987da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-debbe79f-5a25-4815-b93f-1a547e2f865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-e3e17d25-bc3c-4531-8b3d-917e13b23a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-667aba72-da37-44d0-9b4a-492b5d4c2811,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6f6bcc4e-955d-443c-8d6e-199bd09934d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-5b1cc8f1-3c9f-4274-91c2-a0e13a05ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-69e715f3-515c-47b3-acdf-3b2d54b6fcba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657802071-172.17.0.11-1597748190317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-a520b63b-9fda-4877-9afd-88022d95233a,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-243b593e-4412-4e50-b95d-56e4ab0fa16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-7293d2c0-78a9-4f01-ade4-32c336705d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-d4298179-ce09-48b5-933f-817d0f2b45de,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5ac86b4c-1944-4f8b-8e59-a7e1be25aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-3accf615-d34c-4dc0-963d-03c7097e5fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d9cc7ec0-301c-41b7-ae81-da7012f9782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-54521794-7d26-4afb-ba8e-39a1d0075359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657802071-172.17.0.11-1597748190317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-a520b63b-9fda-4877-9afd-88022d95233a,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-243b593e-4412-4e50-b95d-56e4ab0fa16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-7293d2c0-78a9-4f01-ade4-32c336705d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-d4298179-ce09-48b5-933f-817d0f2b45de,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5ac86b4c-1944-4f8b-8e59-a7e1be25aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-3accf615-d34c-4dc0-963d-03c7097e5fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d9cc7ec0-301c-41b7-ae81-da7012f9782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-54521794-7d26-4afb-ba8e-39a1d0075359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696830705-172.17.0.11-1597748607255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-0206eb7a-d62b-49a9-9b47-0ae7570c0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-bfd30f2a-e481-444a-ab3d-6a57746d04a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2e9b074a-5032-4cf8-aeda-7135187722be,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-391c1423-b1af-498d-8419-ed239014dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-39be711d-f831-45a4-a11b-638bb680eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-da72de5f-84d4-41a6-a6c7-ebdff16d0591,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-d6050aba-3e45-47a3-8d10-ab2df3be27eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-11a04890-a67f-492a-9cfd-38a9923b23c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696830705-172.17.0.11-1597748607255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-0206eb7a-d62b-49a9-9b47-0ae7570c0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-bfd30f2a-e481-444a-ab3d-6a57746d04a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-2e9b074a-5032-4cf8-aeda-7135187722be,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-391c1423-b1af-498d-8419-ed239014dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-39be711d-f831-45a4-a11b-638bb680eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-da72de5f-84d4-41a6-a6c7-ebdff16d0591,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-d6050aba-3e45-47a3-8d10-ab2df3be27eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-11a04890-a67f-492a-9cfd-38a9923b23c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804323441-172.17.0.11-1597748782074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-4fa50e94-4c91-4a9c-b6ea-3f9f727521a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-6b8fb8d5-1fed-4c7c-b6f9-9b5226da0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-8dfd869c-96bc-4c3d-bd22-e04400584bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-6cd7ca95-2e0c-4bac-b24b-ef5ec4d7eca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-89f289ec-4a75-48fb-8dcd-f2f5b223e253,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-fb3ab6a3-e6e4-46b1-a9f5-6f8d2c068d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-b10fb04e-f27e-4397-9d32-e45a360feb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-16dcf300-3704-45f8-81a6-8d8f621d70c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804323441-172.17.0.11-1597748782074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-4fa50e94-4c91-4a9c-b6ea-3f9f727521a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-6b8fb8d5-1fed-4c7c-b6f9-9b5226da0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-8dfd869c-96bc-4c3d-bd22-e04400584bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-6cd7ca95-2e0c-4bac-b24b-ef5ec4d7eca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-89f289ec-4a75-48fb-8dcd-f2f5b223e253,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-fb3ab6a3-e6e4-46b1-a9f5-6f8d2c068d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-b10fb04e-f27e-4397-9d32-e45a360feb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-16dcf300-3704-45f8-81a6-8d8f621d70c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787480777-172.17.0.11-1597748828701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-00aff81b-1b94-4a0a-96ec-ffb49d5147a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-81f38c8d-e396-46ef-907b-8cd2e1831b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-dcfee491-5076-4190-9f20-c355d4ea2320,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c7e3164b-fa81-48b8-9a87-83c105cac817,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-1c583d23-f4e2-4526-85c8-5e4f79862bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-719c4335-947a-4171-91e8-9f0aaf1fa445,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-e7b3ccf7-a070-4546-80f1-be2a783f2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-ba266544-1f1d-446c-b8b7-fa8f6624bd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787480777-172.17.0.11-1597748828701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-00aff81b-1b94-4a0a-96ec-ffb49d5147a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-81f38c8d-e396-46ef-907b-8cd2e1831b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-dcfee491-5076-4190-9f20-c355d4ea2320,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c7e3164b-fa81-48b8-9a87-83c105cac817,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-1c583d23-f4e2-4526-85c8-5e4f79862bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-719c4335-947a-4171-91e8-9f0aaf1fa445,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-e7b3ccf7-a070-4546-80f1-be2a783f2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-ba266544-1f1d-446c-b8b7-fa8f6624bd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313960227-172.17.0.11-1597748966332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45347,DS-d70ea9c7-9ab2-4f98-bce1-b4a64d89f087,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-406be9f2-d2e5-4f5a-9327-d05dc25cc871,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-2d9beb17-d126-4bc0-80b5-4e9f4505029f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-b516a56d-b78a-4b77-a3aa-20c6ef36021d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-5fe9799f-fc94-4b86-912e-bd571afe93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-f4a6ace5-c658-4e9a-9a18-bef1a0d5e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-21ece9bb-72ce-40c4-bc70-98e9583018b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e1da445c-b585-41bc-a3d6-6aef657d817b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313960227-172.17.0.11-1597748966332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45347,DS-d70ea9c7-9ab2-4f98-bce1-b4a64d89f087,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-406be9f2-d2e5-4f5a-9327-d05dc25cc871,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-2d9beb17-d126-4bc0-80b5-4e9f4505029f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-b516a56d-b78a-4b77-a3aa-20c6ef36021d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-5fe9799f-fc94-4b86-912e-bd571afe93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-f4a6ace5-c658-4e9a-9a18-bef1a0d5e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-21ece9bb-72ce-40c4-bc70-98e9583018b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e1da445c-b585-41bc-a3d6-6aef657d817b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953418579-172.17.0.11-1597749288582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-2da19978-367a-41c4-8d79-ad8934dd5707,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-48199017-bfcc-4a6a-b607-f66358cbd8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-40bacece-c01b-4b53-be1d-ea1f7a0ad082,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-a6c8f17e-df97-4b92-9d29-e6b132421b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-4841845a-1a1a-4e4b-8760-0758e9cb50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-e4c332c2-297a-4cef-bd77-b4a6a946bfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-b0eca892-796e-4aaf-92f1-3525ebd69aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-183ec7ac-5574-4870-b035-d60211189220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953418579-172.17.0.11-1597749288582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-2da19978-367a-41c4-8d79-ad8934dd5707,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-48199017-bfcc-4a6a-b607-f66358cbd8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-40bacece-c01b-4b53-be1d-ea1f7a0ad082,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-a6c8f17e-df97-4b92-9d29-e6b132421b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-4841845a-1a1a-4e4b-8760-0758e9cb50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-e4c332c2-297a-4cef-bd77-b4a6a946bfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-b0eca892-796e-4aaf-92f1-3525ebd69aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-183ec7ac-5574-4870-b035-d60211189220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265925311-172.17.0.11-1597749777284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-6a611443-9388-4ecb-9486-226dc986812f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-2647681b-085a-4307-845d-055fa2b15341,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-f991f4bc-cb5f-4ef6-a046-06159556072c,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-275ddbf7-4fba-4f7b-8a11-f69013706894,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-1f9e0f5c-8caa-4ac4-82f4-377ce60805c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-15b977e0-3c4a-4493-9d33-ca4af5c95f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-58a95c00-95b8-418d-a2e3-2c3374a66e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-3b306e26-81a0-4a17-a310-662e54869d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265925311-172.17.0.11-1597749777284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-6a611443-9388-4ecb-9486-226dc986812f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-2647681b-085a-4307-845d-055fa2b15341,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-f991f4bc-cb5f-4ef6-a046-06159556072c,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-275ddbf7-4fba-4f7b-8a11-f69013706894,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-1f9e0f5c-8caa-4ac4-82f4-377ce60805c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-15b977e0-3c4a-4493-9d33-ca4af5c95f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-58a95c00-95b8-418d-a2e3-2c3374a66e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-3b306e26-81a0-4a17-a310-662e54869d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59164017-172.17.0.11-1597750146984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-707b0968-ad60-4df3-9d77-07071503c6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-95d39cfc-706c-4476-8849-f51ef221dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-942f32c9-60a5-4829-b6ef-541cbf34c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-21f9068d-0e0a-4516-9fe4-24b949a1bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7f080ef0-b3a2-4cf2-b0c8-71eca0567d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ee73121a-1131-41cb-a644-9394700c9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-7016b769-051a-4d6d-aaa7-bbc99c836f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-86dbfce0-32ac-4462-b776-20c8d5705b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59164017-172.17.0.11-1597750146984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-707b0968-ad60-4df3-9d77-07071503c6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-95d39cfc-706c-4476-8849-f51ef221dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-942f32c9-60a5-4829-b6ef-541cbf34c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-21f9068d-0e0a-4516-9fe4-24b949a1bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7f080ef0-b3a2-4cf2-b0c8-71eca0567d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ee73121a-1131-41cb-a644-9394700c9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-7016b769-051a-4d6d-aaa7-bbc99c836f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-86dbfce0-32ac-4462-b776-20c8d5705b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116341621-172.17.0.11-1597750428337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39216,DS-9a23ef88-9d5a-4f37-8f2e-36f275717144,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cc86a29b-8bc6-4f74-beb9-c2b5cfea4c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-93b66621-ccf0-44e7-a0b4-a5f0b64c8147,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-76caaaca-5040-4296-9bde-729c087c0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-d9f8f817-da3f-4fbc-a202-e5a21915062c,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-78f3e638-1c41-4a43-8d8a-a1e06c6b983d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-375bd54b-3528-474d-8260-1c0de027320b,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-7052bcc3-d5d2-4234-8a88-1636f1482ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116341621-172.17.0.11-1597750428337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39216,DS-9a23ef88-9d5a-4f37-8f2e-36f275717144,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cc86a29b-8bc6-4f74-beb9-c2b5cfea4c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-93b66621-ccf0-44e7-a0b4-a5f0b64c8147,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-76caaaca-5040-4296-9bde-729c087c0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-d9f8f817-da3f-4fbc-a202-e5a21915062c,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-78f3e638-1c41-4a43-8d8a-a1e06c6b983d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-375bd54b-3528-474d-8260-1c0de027320b,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-7052bcc3-d5d2-4234-8a88-1636f1482ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047851929-172.17.0.11-1597751062399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-05181c23-a34a-4c79-aadb-77992f208bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-258bf516-f445-4286-bfc1-58d2af9b58c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-fb651a5b-ab12-4937-93fc-dce9d9295d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-b5f1efb4-4fc0-4d75-878f-3f9d7093dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-072d66f1-1be9-4823-a5c6-e2e9dd779b39,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-48360d77-8b9c-4702-a008-012f0eea869f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a5f3d986-c5ad-4d40-9d7b-b56ffc59e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-90f52604-e9d4-4e7f-a941-98a59ab8cac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047851929-172.17.0.11-1597751062399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-05181c23-a34a-4c79-aadb-77992f208bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-258bf516-f445-4286-bfc1-58d2af9b58c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-fb651a5b-ab12-4937-93fc-dce9d9295d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-b5f1efb4-4fc0-4d75-878f-3f9d7093dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-072d66f1-1be9-4823-a5c6-e2e9dd779b39,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-48360d77-8b9c-4702-a008-012f0eea869f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a5f3d986-c5ad-4d40-9d7b-b56ffc59e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-90f52604-e9d4-4e7f-a941-98a59ab8cac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430471783-172.17.0.11-1597752008110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-1115fe59-5822-45f9-9fee-bd956f9cf7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-07a01cd8-e02c-4524-890b-7e0b37ebab13,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-139adfda-586b-4bcd-b29c-9c05f1702d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-0353b8f5-6005-40ae-ad83-8759dc8302a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-14bc3ae0-a603-4a8c-a6da-35a69a1d506c,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-2b9114e9-3beb-416c-bca3-c7fd1fdd2f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-530eea8a-cf89-443b-b9c1-d92cb3b427ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d27cc184-9849-472c-a020-1f99f15a93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430471783-172.17.0.11-1597752008110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43887,DS-1115fe59-5822-45f9-9fee-bd956f9cf7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-07a01cd8-e02c-4524-890b-7e0b37ebab13,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-139adfda-586b-4bcd-b29c-9c05f1702d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-0353b8f5-6005-40ae-ad83-8759dc8302a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-14bc3ae0-a603-4a8c-a6da-35a69a1d506c,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-2b9114e9-3beb-416c-bca3-c7fd1fdd2f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-530eea8a-cf89-443b-b9c1-d92cb3b427ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d27cc184-9849-472c-a020-1f99f15a93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111579784-172.17.0.11-1597752196492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35388,DS-c515c4a6-767a-4437-9ed5-c1cf3f7830d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-10836568-b2fa-4759-be98-e9e033ff6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-d5f173db-938b-461d-8a89-ced83d85ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-b9f7cdc1-3564-4be7-b65c-5504c151ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-4316f196-b8dd-414b-92b4-d289f80655f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-f6c3d55e-7d5c-404c-b468-b00c82632fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-1bff43d2-e589-459c-a40f-04fe6c39dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-92833852-78fb-47b1-83f9-d42aeab932e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111579784-172.17.0.11-1597752196492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35388,DS-c515c4a6-767a-4437-9ed5-c1cf3f7830d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-10836568-b2fa-4759-be98-e9e033ff6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-d5f173db-938b-461d-8a89-ced83d85ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-b9f7cdc1-3564-4be7-b65c-5504c151ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-4316f196-b8dd-414b-92b4-d289f80655f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-f6c3d55e-7d5c-404c-b468-b00c82632fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-1bff43d2-e589-459c-a40f-04fe6c39dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-92833852-78fb-47b1-83f9-d42aeab932e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539223860-172.17.0.11-1597752477618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-ec0a3add-2264-437d-92d1-f4bb279af519,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-438fafd5-9610-4c6d-b57a-415b6628fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-9aaa88a4-97a8-43f1-aa20-240a1f90b120,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-56e36ee2-5481-4006-a599-04c2710ae869,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-ac345994-020a-4cf7-a366-93c114f8967f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f83b3665-f307-42ef-aff4-4e9363beb925,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-2907429f-df01-4127-9456-31bf48bbb059,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-059b7dc4-9d4f-44bd-a917-34cc1761b59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539223860-172.17.0.11-1597752477618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-ec0a3add-2264-437d-92d1-f4bb279af519,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-438fafd5-9610-4c6d-b57a-415b6628fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-9aaa88a4-97a8-43f1-aa20-240a1f90b120,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-56e36ee2-5481-4006-a599-04c2710ae869,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-ac345994-020a-4cf7-a366-93c114f8967f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f83b3665-f307-42ef-aff4-4e9363beb925,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-2907429f-df01-4127-9456-31bf48bbb059,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-059b7dc4-9d4f-44bd-a917-34cc1761b59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852338071-172.17.0.11-1597752812433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-efe8da73-c8d2-453b-93ed-91d8f3648b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-5a89e9d9-ad85-435a-99b8-926505967b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-686de096-2747-44e7-bfd1-a0a13b898400,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-1570b049-b261-48e9-b6cf-9f2b6ec4fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-2f49de86-4d9b-45eb-97a4-8fa9e75f3da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-420539a2-6495-428e-a8e0-f25b84f6809c,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ff1f48f2-dbff-41a7-88a8-496605f025cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-0111495e-5bbb-4082-8745-3fe1129944ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852338071-172.17.0.11-1597752812433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-efe8da73-c8d2-453b-93ed-91d8f3648b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-5a89e9d9-ad85-435a-99b8-926505967b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-686de096-2747-44e7-bfd1-a0a13b898400,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-1570b049-b261-48e9-b6cf-9f2b6ec4fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-2f49de86-4d9b-45eb-97a4-8fa9e75f3da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-420539a2-6495-428e-a8e0-f25b84f6809c,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ff1f48f2-dbff-41a7-88a8-496605f025cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-0111495e-5bbb-4082-8745-3fe1129944ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743636916-172.17.0.11-1597752942697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-51a1fdf6-5f7b-40ab-bc25-e58c4d643989,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-d1217da5-791f-4f9d-8c07-f98adb9f22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-9187cde6-3551-4e1d-a508-54a001cc7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-7fbf1a53-55bf-4886-bed4-686f67902852,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-41826555-5409-4b37-a65d-7849b371be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-d7f7fa2b-e826-41b1-b763-672bc29f001f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-50a6995b-895b-45c3-af17-8b7efd85c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f6b84f59-945b-427a-92ca-f9fd0bcd39ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743636916-172.17.0.11-1597752942697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-51a1fdf6-5f7b-40ab-bc25-e58c4d643989,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-d1217da5-791f-4f9d-8c07-f98adb9f22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-9187cde6-3551-4e1d-a508-54a001cc7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-7fbf1a53-55bf-4886-bed4-686f67902852,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-41826555-5409-4b37-a65d-7849b371be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-d7f7fa2b-e826-41b1-b763-672bc29f001f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-50a6995b-895b-45c3-af17-8b7efd85c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f6b84f59-945b-427a-92ca-f9fd0bcd39ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486225187-172.17.0.11-1597752983189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39565,DS-61c2dfb3-e68a-4f18-94c1-778618e56d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-69ac225e-36a2-49c8-ad5c-5346cc9fff89,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-0fa951f4-1879-4c75-968f-53ba397e008c,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-78809b95-0c30-49ba-9c53-8451ecf29205,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-be615dfd-8768-4b27-8dd8-784fad63e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-e42fa269-7d3b-4528-a2f1-a490894a20cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-87efec9a-4edd-49d6-a4b5-a9e0aa629083,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-b1427396-aec1-4993-b325-5481713ce99d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486225187-172.17.0.11-1597752983189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39565,DS-61c2dfb3-e68a-4f18-94c1-778618e56d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-69ac225e-36a2-49c8-ad5c-5346cc9fff89,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-0fa951f4-1879-4c75-968f-53ba397e008c,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-78809b95-0c30-49ba-9c53-8451ecf29205,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-be615dfd-8768-4b27-8dd8-784fad63e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-e42fa269-7d3b-4528-a2f1-a490894a20cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-87efec9a-4edd-49d6-a4b5-a9e0aa629083,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-b1427396-aec1-4993-b325-5481713ce99d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382428309-172.17.0.11-1597753289481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-46b594d3-9a5e-4655-bffb-1240f8d79082,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-0978f745-b3c5-423d-87cf-766e44fa3257,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-018c7124-337d-4bfc-ac39-cfdbcfa2ee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-af81a2be-b6ac-4965-8a54-9cf729edf47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e841ab87-3e05-47b4-9581-2462b69cbb30,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-b3abe960-fcb5-4b66-ba06-4ff12b3bbad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-a2cf053c-7636-4d6a-87fc-10981e4dee03,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-393dd7e4-f19e-46ae-9023-0440d9338eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382428309-172.17.0.11-1597753289481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-46b594d3-9a5e-4655-bffb-1240f8d79082,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-0978f745-b3c5-423d-87cf-766e44fa3257,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-018c7124-337d-4bfc-ac39-cfdbcfa2ee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-af81a2be-b6ac-4965-8a54-9cf729edf47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e841ab87-3e05-47b4-9581-2462b69cbb30,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-b3abe960-fcb5-4b66-ba06-4ff12b3bbad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-a2cf053c-7636-4d6a-87fc-10981e4dee03,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-393dd7e4-f19e-46ae-9023-0440d9338eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 7045
