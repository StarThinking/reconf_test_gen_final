reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342525188-172.17.0.5-1597349330774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-984d25b6-488b-4f6b-bc60-a813c0a4f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-71721ded-0ce2-4426-b942-e01ede0fcaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aa0dd693-a6b4-4c81-846f-1b946c78a417,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-0860409d-14af-49d2-9137-6b55f0c69bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-12f4849b-7579-4230-8745-38a58dff7efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-136734b1-94dc-47b2-9656-d24f61d590f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6b1ff9a7-280d-416b-a1ca-1aadb8d4651e,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8e10c41f-3245-4808-8f21-400c498d297b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342525188-172.17.0.5-1597349330774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-984d25b6-488b-4f6b-bc60-a813c0a4f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-71721ded-0ce2-4426-b942-e01ede0fcaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aa0dd693-a6b4-4c81-846f-1b946c78a417,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-0860409d-14af-49d2-9137-6b55f0c69bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-12f4849b-7579-4230-8745-38a58dff7efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-136734b1-94dc-47b2-9656-d24f61d590f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6b1ff9a7-280d-416b-a1ca-1aadb8d4651e,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-8e10c41f-3245-4808-8f21-400c498d297b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516705247-172.17.0.5-1597350097391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-eef81c93-691e-4170-b766-2a41c9cb3903,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-9b6e98d7-9959-49eb-9199-82b867e70818,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-bae4bab4-e6da-41c5-8dc0-03b45fd7bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-ec1af050-2fdf-4ad4-96d3-6eaf5792d782,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-f57249e3-5390-4565-99c7-7b900d2aa051,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-1ce849e8-8893-410f-a1a4-a479f8a8d463,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-c7572b78-64ba-4d30-9be9-fc2c86a2b657,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-52494cc2-f5c0-4bb2-9595-af605dc95f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516705247-172.17.0.5-1597350097391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-eef81c93-691e-4170-b766-2a41c9cb3903,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-9b6e98d7-9959-49eb-9199-82b867e70818,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-bae4bab4-e6da-41c5-8dc0-03b45fd7bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-ec1af050-2fdf-4ad4-96d3-6eaf5792d782,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-f57249e3-5390-4565-99c7-7b900d2aa051,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-1ce849e8-8893-410f-a1a4-a479f8a8d463,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-c7572b78-64ba-4d30-9be9-fc2c86a2b657,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-52494cc2-f5c0-4bb2-9595-af605dc95f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002292315-172.17.0.5-1597350248666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-0f070b2b-6c8c-4459-85c0-4c9f59e904cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-33010036-f2e7-4a34-a078-c200ba943261,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-fcf13a0f-9006-4b37-a498-87e1a893a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-733d8af7-78c0-43d0-99a3-397b327e1051,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-14b0b88c-a7f9-4747-b6df-ecc76fe62ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-4534de9e-e03b-46b2-a5ef-4aaa35b9a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-9b9bd110-dea2-422a-bdb9-1aad5d47d111,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-aac51937-cbcb-499e-8f10-98733da7b746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002292315-172.17.0.5-1597350248666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-0f070b2b-6c8c-4459-85c0-4c9f59e904cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-33010036-f2e7-4a34-a078-c200ba943261,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-fcf13a0f-9006-4b37-a498-87e1a893a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-733d8af7-78c0-43d0-99a3-397b327e1051,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-14b0b88c-a7f9-4747-b6df-ecc76fe62ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-4534de9e-e03b-46b2-a5ef-4aaa35b9a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-9b9bd110-dea2-422a-bdb9-1aad5d47d111,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-aac51937-cbcb-499e-8f10-98733da7b746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575544176-172.17.0.5-1597350563328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-a249c0e1-c879-4fca-8b12-a29eba8c21b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-134539ea-0482-4d5a-beec-fb1d2ce935c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-03c96081-8397-4a47-8b8c-acb3a29e3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c19cab63-090e-4bcb-aee9-10baecf0f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-65e2d59d-4ff2-4c1e-a380-8ab2a6853656,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-89c674b2-8667-43c9-a910-c63c2a49fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-f12597e3-6b88-4d28-8d59-bbcbeb294e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-fff16bb7-8f10-4554-8000-4caa66a9594c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575544176-172.17.0.5-1597350563328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-a249c0e1-c879-4fca-8b12-a29eba8c21b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-134539ea-0482-4d5a-beec-fb1d2ce935c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-03c96081-8397-4a47-8b8c-acb3a29e3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c19cab63-090e-4bcb-aee9-10baecf0f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-65e2d59d-4ff2-4c1e-a380-8ab2a6853656,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-89c674b2-8667-43c9-a910-c63c2a49fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-f12597e3-6b88-4d28-8d59-bbcbeb294e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-fff16bb7-8f10-4554-8000-4caa66a9594c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402858895-172.17.0.5-1597351041727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-eb89a260-5e10-4482-8c03-e5207fe50d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c491d786-fbff-44e4-ac8b-a16141bc000e,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-f9e7f286-03e4-4c26-b17b-c16fecf700a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-2610426e-1fdb-42db-a877-d0cc32910e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-8bdc9473-2339-4a04-b540-8d849f5d3980,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-60dce1ce-9d21-4b47-ae9b-c77298243179,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-db23fe3a-d06b-428f-8857-f37b94a96510,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-eb86873c-b16d-47ef-ab44-8cbb11a8c151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402858895-172.17.0.5-1597351041727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-eb89a260-5e10-4482-8c03-e5207fe50d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c491d786-fbff-44e4-ac8b-a16141bc000e,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-f9e7f286-03e4-4c26-b17b-c16fecf700a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-2610426e-1fdb-42db-a877-d0cc32910e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-8bdc9473-2339-4a04-b540-8d849f5d3980,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-60dce1ce-9d21-4b47-ae9b-c77298243179,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-db23fe3a-d06b-428f-8857-f37b94a96510,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-eb86873c-b16d-47ef-ab44-8cbb11a8c151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332437724-172.17.0.5-1597351299871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41617,DS-48b9c3e3-e7e3-479a-beb1-2309c5c7f706,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-0019a2a7-a4e6-4e2f-b53d-6e3a2f770517,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-84d13da1-5956-4b12-bde3-aac1a5e14f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-229101ff-2f14-4aad-9145-d3fd358aeb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-565b9f42-1e75-422c-a79e-060eaa958fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-fd6962d8-cfa0-4c7e-8671-4ad0b57357fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-412a8020-cea3-4ccc-b2e3-c71df75ba1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-7ff7fde6-8597-43af-8913-61a00a222d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332437724-172.17.0.5-1597351299871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41617,DS-48b9c3e3-e7e3-479a-beb1-2309c5c7f706,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-0019a2a7-a4e6-4e2f-b53d-6e3a2f770517,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-84d13da1-5956-4b12-bde3-aac1a5e14f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-229101ff-2f14-4aad-9145-d3fd358aeb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-565b9f42-1e75-422c-a79e-060eaa958fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-fd6962d8-cfa0-4c7e-8671-4ad0b57357fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-412a8020-cea3-4ccc-b2e3-c71df75ba1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-7ff7fde6-8597-43af-8913-61a00a222d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997702240-172.17.0.5-1597351411622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-ec37b87d-15dc-4419-b082-15f7bd16fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-743739b7-8c81-4b59-896d-31849bdad3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-38bada0d-69d0-4eab-b8b2-465e990b8188,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-8487ac49-d51b-4829-bef4-ed5f6938624a,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-9881810c-78a2-45a3-bba7-c6e9cb478267,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-23c8f8a2-ac54-4fed-b30e-9055553b62db,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-87e25c1b-b398-4c3c-b924-66fded7992fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-3ab15e96-39bf-44dd-94da-43ec50fe4463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997702240-172.17.0.5-1597351411622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-ec37b87d-15dc-4419-b082-15f7bd16fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-743739b7-8c81-4b59-896d-31849bdad3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-38bada0d-69d0-4eab-b8b2-465e990b8188,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-8487ac49-d51b-4829-bef4-ed5f6938624a,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-9881810c-78a2-45a3-bba7-c6e9cb478267,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-23c8f8a2-ac54-4fed-b30e-9055553b62db,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-87e25c1b-b398-4c3c-b924-66fded7992fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-3ab15e96-39bf-44dd-94da-43ec50fe4463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469892300-172.17.0.5-1597351737031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-91e7a0e2-7602-415d-9ba9-e4e6d81d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-d332341b-e945-4a89-b894-834979b900d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-6dba69b0-77c6-4d44-9021-a391b9340a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-9ce8c9a6-ec78-4196-84ac-3659f794cf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-357c0bd1-f60a-4872-8360-e66b9ddcd935,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-9bdcb8f6-e07f-4430-a47f-4de0a110c570,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-5fc8af52-1fd6-4ab3-a9ce-6583ff20d720,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-db55158c-f5c7-40b0-bf57-e627911f5239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469892300-172.17.0.5-1597351737031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-91e7a0e2-7602-415d-9ba9-e4e6d81d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-d332341b-e945-4a89-b894-834979b900d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-6dba69b0-77c6-4d44-9021-a391b9340a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-9ce8c9a6-ec78-4196-84ac-3659f794cf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-357c0bd1-f60a-4872-8360-e66b9ddcd935,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-9bdcb8f6-e07f-4430-a47f-4de0a110c570,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-5fc8af52-1fd6-4ab3-a9ce-6583ff20d720,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-db55158c-f5c7-40b0-bf57-e627911f5239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172218769-172.17.0.5-1597351805440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-1c8bce1d-e813-46a5-bc7e-a7da81c734f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-cb831c7d-8c51-47cf-ac64-6f1601602f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-fa4ee4fb-a35a-47c7-8632-a66bd35df576,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-471cb9ff-be39-41f6-9843-80a496d8b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-e25f9810-b659-4f94-9606-de17edada6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-1b8db507-a051-4d20-b621-66f3ebca0f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-f48471fb-165e-4f29-8c21-ebc88eadc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-ce55cc81-19fb-42ce-82ce-95b994a44295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172218769-172.17.0.5-1597351805440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-1c8bce1d-e813-46a5-bc7e-a7da81c734f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-cb831c7d-8c51-47cf-ac64-6f1601602f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-fa4ee4fb-a35a-47c7-8632-a66bd35df576,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-471cb9ff-be39-41f6-9843-80a496d8b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-e25f9810-b659-4f94-9606-de17edada6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-1b8db507-a051-4d20-b621-66f3ebca0f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-f48471fb-165e-4f29-8c21-ebc88eadc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-ce55cc81-19fb-42ce-82ce-95b994a44295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860322590-172.17.0.5-1597352109471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-0f27930a-43b6-4172-b505-496d049ee557,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-d9473d80-fafa-4791-9f61-ba94759a853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a2ae0a6a-db03-4da4-80fa-ff7ac24e60fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-f8facb8c-847b-4eef-926c-e8b50762ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-c595f896-0a98-4931-af44-ff0b5a04c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d3c3e40a-b54f-41e5-ac26-d52153b44f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-41633fdb-7e3a-4607-9dcd-30ce83cb9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-535d11af-ad33-44dc-b809-e0a78d233890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860322590-172.17.0.5-1597352109471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-0f27930a-43b6-4172-b505-496d049ee557,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-d9473d80-fafa-4791-9f61-ba94759a853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a2ae0a6a-db03-4da4-80fa-ff7ac24e60fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-f8facb8c-847b-4eef-926c-e8b50762ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-c595f896-0a98-4931-af44-ff0b5a04c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d3c3e40a-b54f-41e5-ac26-d52153b44f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-41633fdb-7e3a-4607-9dcd-30ce83cb9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-535d11af-ad33-44dc-b809-e0a78d233890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456075948-172.17.0.5-1597353267457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-82197c89-535c-4230-af5d-a31b7dee2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-d5a437dc-0224-4f8b-9900-431f07be57d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-ac25fd7d-7cd7-43e2-b568-68c2713259af,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-18f6d6cd-ac0b-435c-aa60-38d25eae34b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-37f50b6f-84d3-4ce5-88df-05fed7421f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-0643bd31-7a2c-48e6-a170-469ccbdc3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ed38bc8e-aadd-449e-a4ba-12ee43ef4906,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-b74856f8-b6f3-4c61-a877-8b371aa1176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456075948-172.17.0.5-1597353267457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-82197c89-535c-4230-af5d-a31b7dee2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-d5a437dc-0224-4f8b-9900-431f07be57d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-ac25fd7d-7cd7-43e2-b568-68c2713259af,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-18f6d6cd-ac0b-435c-aa60-38d25eae34b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-37f50b6f-84d3-4ce5-88df-05fed7421f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-0643bd31-7a2c-48e6-a170-469ccbdc3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ed38bc8e-aadd-449e-a4ba-12ee43ef4906,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-b74856f8-b6f3-4c61-a877-8b371aa1176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705878303-172.17.0.5-1597353694313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-28c73775-95ad-4306-b97a-953c87d21713,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-54710ae8-4547-473c-87b7-e51ae3e86ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-6dfb3233-8c12-4636-a008-2f1706455f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-206fe317-10c6-42c6-9482-d9b348463e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f8d69b27-b125-450d-aa5a-cde30bd44195,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-ac461370-d149-4dda-a72e-1de7165c15e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-c63c27dd-42c2-44d5-8571-19d5b108f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-1ef3d0b5-6379-4c09-8933-195130920264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705878303-172.17.0.5-1597353694313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-28c73775-95ad-4306-b97a-953c87d21713,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-54710ae8-4547-473c-87b7-e51ae3e86ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-6dfb3233-8c12-4636-a008-2f1706455f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-206fe317-10c6-42c6-9482-d9b348463e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f8d69b27-b125-450d-aa5a-cde30bd44195,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-ac461370-d149-4dda-a72e-1de7165c15e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-c63c27dd-42c2-44d5-8571-19d5b108f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-1ef3d0b5-6379-4c09-8933-195130920264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957779872-172.17.0.5-1597354258652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-f54149bb-8d05-4be2-ac34-46e46d7face6,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f429020f-7d15-4918-804a-cf5b1f473d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-672e3118-6eea-49c5-94e5-b5375499ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-11205c2b-f48c-47e5-9f2f-8f74cfc99013,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-26944da4-05a1-4965-a7f9-e960afe5d7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-58d19daf-dda5-45ee-92c4-66dbbdccfda9,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-67f44712-e2ee-4e50-baa0-a194d5039bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d9c67c7a-87ac-4f4d-95bf-244d23d36fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957779872-172.17.0.5-1597354258652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-f54149bb-8d05-4be2-ac34-46e46d7face6,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f429020f-7d15-4918-804a-cf5b1f473d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-672e3118-6eea-49c5-94e5-b5375499ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-11205c2b-f48c-47e5-9f2f-8f74cfc99013,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-26944da4-05a1-4965-a7f9-e960afe5d7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-58d19daf-dda5-45ee-92c4-66dbbdccfda9,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-67f44712-e2ee-4e50-baa0-a194d5039bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d9c67c7a-87ac-4f4d-95bf-244d23d36fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5604
