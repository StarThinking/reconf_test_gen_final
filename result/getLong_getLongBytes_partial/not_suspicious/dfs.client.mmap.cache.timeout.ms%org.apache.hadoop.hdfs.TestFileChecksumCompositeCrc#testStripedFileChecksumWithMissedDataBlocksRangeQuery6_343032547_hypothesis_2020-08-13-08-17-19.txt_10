reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826150996-172.17.0.4-1597306659515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-5e262f56-04e3-4f93-864a-4ec3c28e1edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-243851d5-8adf-4bd5-9a86-c0dda29cbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-be47e356-eb3b-4aa9-aa1f-1dbb60349e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-d90b51bb-a8a9-4d85-a2b3-254bb78cfe72,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b0445ff6-28a7-4377-832d-a9ad854ff82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-168160a1-55fe-4d21-9ce9-1e37a5f1d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-8204dc01-2f43-427e-baa7-0f8c5690fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-509effc6-11e9-47e3-9873-dddb4f7abbf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826150996-172.17.0.4-1597306659515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-5e262f56-04e3-4f93-864a-4ec3c28e1edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-243851d5-8adf-4bd5-9a86-c0dda29cbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-be47e356-eb3b-4aa9-aa1f-1dbb60349e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-d90b51bb-a8a9-4d85-a2b3-254bb78cfe72,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b0445ff6-28a7-4377-832d-a9ad854ff82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-168160a1-55fe-4d21-9ce9-1e37a5f1d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-8204dc01-2f43-427e-baa7-0f8c5690fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-509effc6-11e9-47e3-9873-dddb4f7abbf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906366750-172.17.0.4-1597306693690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34941,DS-7767675b-73e7-4c0e-b54e-6aa45f6d364e,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-5f5173d3-c7af-41e1-b9ec-205d27de0836,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4b334103-9d14-4cf4-9878-754aa941798a,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-c4887481-b216-4415-8982-a61156c56470,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d3a46506-9626-4fbf-9552-7a303ee85db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-43c9512c-4b4d-4714-9968-6ee6794af14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-95bda688-0cff-4001-a419-1be6495bc04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e68b1b37-5d7b-4514-9079-56e111c91e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906366750-172.17.0.4-1597306693690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34941,DS-7767675b-73e7-4c0e-b54e-6aa45f6d364e,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-5f5173d3-c7af-41e1-b9ec-205d27de0836,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4b334103-9d14-4cf4-9878-754aa941798a,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-c4887481-b216-4415-8982-a61156c56470,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d3a46506-9626-4fbf-9552-7a303ee85db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-43c9512c-4b4d-4714-9968-6ee6794af14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-95bda688-0cff-4001-a419-1be6495bc04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e68b1b37-5d7b-4514-9079-56e111c91e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644494858-172.17.0.4-1597306851463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-a85bf560-03e5-44d2-846b-92e081382dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-ea462d21-41ff-4177-8ec3-9a5ba551504b,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-1ea97523-a64f-44d8-86c6-ced32d6a0d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-ad5711a1-4a64-4245-8e6c-355f42dfe16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-1d591c5c-b92e-413a-84b7-1192155f20d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-a900d5b2-37a3-4f00-bb52-c61fa00d80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-28d8c7e2-8bc4-441a-b8eb-effee13cd7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-affb7abd-d4a3-4fe6-a078-79f2c0d6f466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644494858-172.17.0.4-1597306851463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-a85bf560-03e5-44d2-846b-92e081382dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-ea462d21-41ff-4177-8ec3-9a5ba551504b,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-1ea97523-a64f-44d8-86c6-ced32d6a0d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-ad5711a1-4a64-4245-8e6c-355f42dfe16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-1d591c5c-b92e-413a-84b7-1192155f20d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-a900d5b2-37a3-4f00-bb52-c61fa00d80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-28d8c7e2-8bc4-441a-b8eb-effee13cd7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-affb7abd-d4a3-4fe6-a078-79f2c0d6f466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722875931-172.17.0.4-1597306890277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-5c107f69-34e3-4084-b629-134f1c1da02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-c259ad3b-f9db-46db-914b-c71a37ebab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-81a56db2-576d-4639-abd1-3d4c003b75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-3aabce6b-4d09-486c-b064-429ffc9efafc,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-234d3c31-3dff-4a16-850e-dbd3f3b757f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-ddd9b771-0ede-41f6-ad76-fd4bec750452,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-365dfeb8-fe99-4cb7-8513-6b5836cdadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-48c10255-7d16-4806-a0fb-e4f0d36f9d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722875931-172.17.0.4-1597306890277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-5c107f69-34e3-4084-b629-134f1c1da02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-c259ad3b-f9db-46db-914b-c71a37ebab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-81a56db2-576d-4639-abd1-3d4c003b75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-3aabce6b-4d09-486c-b064-429ffc9efafc,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-234d3c31-3dff-4a16-850e-dbd3f3b757f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-ddd9b771-0ede-41f6-ad76-fd4bec750452,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-365dfeb8-fe99-4cb7-8513-6b5836cdadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-48c10255-7d16-4806-a0fb-e4f0d36f9d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735141728-172.17.0.4-1597306963355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-bc73da87-0816-4ab0-9962-31500ad211d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-d7548bef-51b7-494a-bf3e-548c51dc3bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-6cb65f28-fea2-4fb6-b77f-7c804c805787,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a8651fe5-e397-400e-8202-a004f2562e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-187ba291-42b6-432e-85a0-dde5d18cba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-b0639e2b-1bbc-45fe-9cfe-9bb521de56b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-e6a77103-63fb-40f5-8070-c3e1fcca4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-564bfa49-cac9-49a1-a240-306e62218663,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735141728-172.17.0.4-1597306963355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-bc73da87-0816-4ab0-9962-31500ad211d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-d7548bef-51b7-494a-bf3e-548c51dc3bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-6cb65f28-fea2-4fb6-b77f-7c804c805787,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a8651fe5-e397-400e-8202-a004f2562e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-187ba291-42b6-432e-85a0-dde5d18cba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-b0639e2b-1bbc-45fe-9cfe-9bb521de56b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-e6a77103-63fb-40f5-8070-c3e1fcca4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-564bfa49-cac9-49a1-a240-306e62218663,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777309753-172.17.0.4-1597307481738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-7877d753-8519-4f26-bfef-88189d6755b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-017f3dd3-2ad3-4cdd-b08f-441a2abb9e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ce15c90a-bf6e-40a1-8b8f-41d95b6d7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-e0d0ec79-69a5-4d09-886a-2cc21d9c90c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7801a683-e087-4b84-a75f-1b6a33b63d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-52b87a68-b3dd-41fa-95b6-ddb1f517ea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-97f28200-8ad2-4293-8bff-7780a4919e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d6ce008c-483c-45aa-b2ad-b474b10c9b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777309753-172.17.0.4-1597307481738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-7877d753-8519-4f26-bfef-88189d6755b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-017f3dd3-2ad3-4cdd-b08f-441a2abb9e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ce15c90a-bf6e-40a1-8b8f-41d95b6d7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-e0d0ec79-69a5-4d09-886a-2cc21d9c90c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7801a683-e087-4b84-a75f-1b6a33b63d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-52b87a68-b3dd-41fa-95b6-ddb1f517ea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-97f28200-8ad2-4293-8bff-7780a4919e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d6ce008c-483c-45aa-b2ad-b474b10c9b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061052761-172.17.0.4-1597307517158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36154,DS-c878f814-df3b-4cff-a643-7242c9634145,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-93ed4a58-2ebc-4046-be38-1b3b13a2b771,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a27df07e-f16b-4d85-987a-c6c36d9616ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-b45e3196-33b9-4f02-8553-ddf70085a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-4c48644e-e119-4a05-b7a3-954cf5697b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-36e8f4a7-2d5c-40af-bff9-c439ccf5ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-873cada5-955e-426e-ad11-7c0e6a41b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f4e39d4d-5ee7-4f09-a6c6-ed9b400f6f23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061052761-172.17.0.4-1597307517158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36154,DS-c878f814-df3b-4cff-a643-7242c9634145,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-93ed4a58-2ebc-4046-be38-1b3b13a2b771,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a27df07e-f16b-4d85-987a-c6c36d9616ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-b45e3196-33b9-4f02-8553-ddf70085a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-4c48644e-e119-4a05-b7a3-954cf5697b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-36e8f4a7-2d5c-40af-bff9-c439ccf5ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-873cada5-955e-426e-ad11-7c0e6a41b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f4e39d4d-5ee7-4f09-a6c6-ed9b400f6f23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750802245-172.17.0.4-1597307812245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-eca90e0a-539f-4629-ad87-e0163f26c713,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-786f0f1e-e0a9-40ce-8121-45cca4edbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-6bfd0beb-5624-4dd8-a38b-b88341d97621,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f7183ac1-e57f-4073-b2f4-0e3e1747240e,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-f1b1caa8-f0a6-4a21-b1d6-ba091917b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3f41a9bb-a65d-454a-b0a6-7f77cb16ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-c3ec560d-059e-4c1c-a3fa-8b8074f9c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ce8086ca-3b97-4411-9fe6-e199fdf13b43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750802245-172.17.0.4-1597307812245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-eca90e0a-539f-4629-ad87-e0163f26c713,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-786f0f1e-e0a9-40ce-8121-45cca4edbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-6bfd0beb-5624-4dd8-a38b-b88341d97621,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f7183ac1-e57f-4073-b2f4-0e3e1747240e,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-f1b1caa8-f0a6-4a21-b1d6-ba091917b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3f41a9bb-a65d-454a-b0a6-7f77cb16ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-c3ec560d-059e-4c1c-a3fa-8b8074f9c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ce8086ca-3b97-4411-9fe6-e199fdf13b43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248415690-172.17.0.4-1597307891499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-c2fd4789-506b-46e7-9c2c-c3b310432f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-94163b5d-62b1-432a-bb8a-d600d356c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-63ad25c6-9504-466c-91e0-55d46188dd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-36840c2e-f239-420a-b969-4e783e469e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-57a0aeed-9f7f-492d-b425-a89f82e4077b,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-271a7829-bca1-4fc5-b0cb-e23c8998f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-8a9f126d-add9-4329-acde-c72074c10953,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f452ceed-f011-49c7-a351-5b46b50150b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248415690-172.17.0.4-1597307891499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-c2fd4789-506b-46e7-9c2c-c3b310432f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-94163b5d-62b1-432a-bb8a-d600d356c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-63ad25c6-9504-466c-91e0-55d46188dd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-36840c2e-f239-420a-b969-4e783e469e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-57a0aeed-9f7f-492d-b425-a89f82e4077b,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-271a7829-bca1-4fc5-b0cb-e23c8998f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-8a9f126d-add9-4329-acde-c72074c10953,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f452ceed-f011-49c7-a351-5b46b50150b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716573093-172.17.0.4-1597308117134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35492,DS-54a05cbd-e40c-45c6-ae64-fe9e44708449,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-43647351-4865-4ac2-9fdb-c82e26d10bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c3550134-45c9-4681-9bf2-4ca0ecc3c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-48f5b27a-ddd3-4def-b258-edf9eee87078,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-cc862cd7-9c63-448c-aaf0-c7438db8733c,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-062ffae1-8911-4a52-b70a-441a1bba0323,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-69d28f24-f819-4c11-a862-1f73d9d05eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-ec2545f0-1ecb-4bde-8ac9-61ce3da5330a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716573093-172.17.0.4-1597308117134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35492,DS-54a05cbd-e40c-45c6-ae64-fe9e44708449,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-43647351-4865-4ac2-9fdb-c82e26d10bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c3550134-45c9-4681-9bf2-4ca0ecc3c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-48f5b27a-ddd3-4def-b258-edf9eee87078,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-cc862cd7-9c63-448c-aaf0-c7438db8733c,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-062ffae1-8911-4a52-b70a-441a1bba0323,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-69d28f24-f819-4c11-a862-1f73d9d05eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-ec2545f0-1ecb-4bde-8ac9-61ce3da5330a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230834587-172.17.0.4-1597308148518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-e97a5a15-57a3-41c3-afa3-b7af074a133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-9621e85c-d042-4804-9b9e-11a9e9b1cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-ea68381a-0cb9-4aac-9053-046617ba3e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a601673f-87b5-4253-aad5-8394bb1c9ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-f552b20f-7176-4070-8fcd-b5d2e518f7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-92995ba8-d7dd-4a19-ab37-a244b45965cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-1cfebd8f-3caa-45cc-bf0c-55ddf812b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-c58d98aa-a992-4f1b-9e80-55e6977d1a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230834587-172.17.0.4-1597308148518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-e97a5a15-57a3-41c3-afa3-b7af074a133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-9621e85c-d042-4804-9b9e-11a9e9b1cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-ea68381a-0cb9-4aac-9053-046617ba3e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a601673f-87b5-4253-aad5-8394bb1c9ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-f552b20f-7176-4070-8fcd-b5d2e518f7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-92995ba8-d7dd-4a19-ab37-a244b45965cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-1cfebd8f-3caa-45cc-bf0c-55ddf812b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-c58d98aa-a992-4f1b-9e80-55e6977d1a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709314904-172.17.0.4-1597308186710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-b2b1ab10-5ad8-491f-b3b0-a20bbf27e29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-64789252-a301-4e3c-955e-3e5ae96092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-6dc52fca-3ba1-45b1-a888-04b56b2b9831,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-098a422c-5d19-4810-8a9b-58644b2261ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-dafc0782-f7df-4476-8b56-87f768c71a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-8e3a9ef7-4d25-41ed-96ce-a46a0ef59432,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-875e0bef-41bf-41a2-b1e8-03ece07c434e,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-89eb750b-69ba-48f5-a1aa-447242cbf73d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709314904-172.17.0.4-1597308186710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-b2b1ab10-5ad8-491f-b3b0-a20bbf27e29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-64789252-a301-4e3c-955e-3e5ae96092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-6dc52fca-3ba1-45b1-a888-04b56b2b9831,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-098a422c-5d19-4810-8a9b-58644b2261ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-dafc0782-f7df-4476-8b56-87f768c71a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-8e3a9ef7-4d25-41ed-96ce-a46a0ef59432,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-875e0bef-41bf-41a2-b1e8-03ece07c434e,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-89eb750b-69ba-48f5-a1aa-447242cbf73d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091054169-172.17.0.4-1597308216105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-1f0964f9-9c8f-447f-8d46-eaf0f1bf4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-58f0caff-4f50-40b4-88d4-9bc35557eff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-39392109-1895-4d94-8eca-c5a2b5158cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-cbc15e70-a320-4599-bc13-aae577623fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-f22f72e2-0d95-4f56-827f-4659a0ad6850,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-0ec8ed60-bddd-41eb-af4c-b1de5c193087,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2a55c9b0-c523-4c7e-aa62-e5755f90b421,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-748ef2c1-7bab-43b7-ab17-05b9a60c1b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091054169-172.17.0.4-1597308216105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-1f0964f9-9c8f-447f-8d46-eaf0f1bf4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-58f0caff-4f50-40b4-88d4-9bc35557eff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-39392109-1895-4d94-8eca-c5a2b5158cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-cbc15e70-a320-4599-bc13-aae577623fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-f22f72e2-0d95-4f56-827f-4659a0ad6850,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-0ec8ed60-bddd-41eb-af4c-b1de5c193087,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2a55c9b0-c523-4c7e-aa62-e5755f90b421,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-748ef2c1-7bab-43b7-ab17-05b9a60c1b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627670811-172.17.0.4-1597308363863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-5d741703-3eaa-40e0-915a-3fe4815d43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-da7e2f1a-ad00-4818-b3fa-74b270da3353,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-e8362524-7675-4082-920d-da9216129aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-95058caf-b2c3-4cc3-aa15-4bd13c0ccd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-ac5f67cc-c44b-4b8c-aa30-72391f4f59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b3ddaf17-9f7d-488f-a9e1-594a8437ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-cc32dc39-d02f-41e6-ade8-ca17e958e372,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-2f03bcb9-d2e7-443f-a741-99d911312211,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627670811-172.17.0.4-1597308363863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-5d741703-3eaa-40e0-915a-3fe4815d43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-da7e2f1a-ad00-4818-b3fa-74b270da3353,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-e8362524-7675-4082-920d-da9216129aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-95058caf-b2c3-4cc3-aa15-4bd13c0ccd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-ac5f67cc-c44b-4b8c-aa30-72391f4f59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b3ddaf17-9f7d-488f-a9e1-594a8437ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-cc32dc39-d02f-41e6-ade8-ca17e958e372,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-2f03bcb9-d2e7-443f-a741-99d911312211,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676492287-172.17.0.4-1597308438423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-d96df0e6-4e2f-4d1e-9051-e95726016f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-39510878-0213-4445-a09d-da43ed3a25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-ba33681f-5075-42fa-831c-d92fc3acaf83,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-d9e2e7b5-435f-4886-8b51-67017177a685,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-042bbd47-1e22-4dbd-b690-ca65d3a1b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-5ee4209f-79d0-4dfa-a92f-c654a85865d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f6403046-eaad-4086-b896-396db38aa797,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-a6629195-ff56-41a4-aa39-ad19bcfabc24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676492287-172.17.0.4-1597308438423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-d96df0e6-4e2f-4d1e-9051-e95726016f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-39510878-0213-4445-a09d-da43ed3a25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-ba33681f-5075-42fa-831c-d92fc3acaf83,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-d9e2e7b5-435f-4886-8b51-67017177a685,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-042bbd47-1e22-4dbd-b690-ca65d3a1b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-5ee4209f-79d0-4dfa-a92f-c654a85865d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f6403046-eaad-4086-b896-396db38aa797,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-a6629195-ff56-41a4-aa39-ad19bcfabc24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346053957-172.17.0.4-1597308597076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-63affa1d-059a-489e-9659-cd6c462364b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-b6bc70c7-829d-410a-9b51-c3bfe787072e,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-face3895-d943-41ee-98fc-d6bf50e0790c,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-1768d5a7-a971-4b05-b3d8-0ce65a2a3a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-cb9ebe47-9649-4082-8680-992a8db72193,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-a8ba0a99-a65d-4dc3-ba92-d5b45bdb0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-1e15f8b1-1e66-439b-820d-abec2790c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-4c183c10-e0f4-45eb-b9e8-b772477a622e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346053957-172.17.0.4-1597308597076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-63affa1d-059a-489e-9659-cd6c462364b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-b6bc70c7-829d-410a-9b51-c3bfe787072e,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-face3895-d943-41ee-98fc-d6bf50e0790c,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-1768d5a7-a971-4b05-b3d8-0ce65a2a3a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-cb9ebe47-9649-4082-8680-992a8db72193,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-a8ba0a99-a65d-4dc3-ba92-d5b45bdb0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-1e15f8b1-1e66-439b-820d-abec2790c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-4c183c10-e0f4-45eb-b9e8-b772477a622e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267577583-172.17.0.4-1597309051565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-b1e8a6b9-384c-47d8-9ea8-b0c737b13da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-42e857c9-9bc6-4d18-b247-4b899cedabdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-75984afe-6750-4bf4-9304-ec767c8bb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-e77d9607-4d9e-4cc9-b68b-41b58cd7e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-6e1642b7-665f-4283-92d3-815019b17442,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-b93d35fd-1685-4e33-a568-d658e0c20df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-859469b5-528b-4e57-b58f-9703bcecd3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-e9987246-d931-4473-bd61-13fdcd04570b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267577583-172.17.0.4-1597309051565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-b1e8a6b9-384c-47d8-9ea8-b0c737b13da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-42e857c9-9bc6-4d18-b247-4b899cedabdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-75984afe-6750-4bf4-9304-ec767c8bb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-e77d9607-4d9e-4cc9-b68b-41b58cd7e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-6e1642b7-665f-4283-92d3-815019b17442,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-b93d35fd-1685-4e33-a568-d658e0c20df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-859469b5-528b-4e57-b58f-9703bcecd3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-e9987246-d931-4473-bd61-13fdcd04570b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903114093-172.17.0.4-1597309125102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-b74a14bf-677f-4835-b500-297f36aca87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-b3a58757-df14-4b73-921e-2587da23fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-9db1f0fd-fceb-4509-b7db-7e583b089f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4c41f530-e432-4c31-a9e8-6231dcb62c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-6c26f6eb-6f7c-4373-a0c0-ec1d14e72638,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b17d4382-d8b2-4900-8a3c-8af12aa3819e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4b364995-8514-4b63-80b4-af2d57591347,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a0b196d6-c094-4903-8940-6639750dcbeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903114093-172.17.0.4-1597309125102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-b74a14bf-677f-4835-b500-297f36aca87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-b3a58757-df14-4b73-921e-2587da23fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-9db1f0fd-fceb-4509-b7db-7e583b089f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4c41f530-e432-4c31-a9e8-6231dcb62c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-6c26f6eb-6f7c-4373-a0c0-ec1d14e72638,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b17d4382-d8b2-4900-8a3c-8af12aa3819e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4b364995-8514-4b63-80b4-af2d57591347,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a0b196d6-c094-4903-8940-6639750dcbeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594272499-172.17.0.4-1597309658789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-dbd8e458-591c-482e-b1d7-a60ae967951a,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-00cc3ec0-d332-4a45-8e27-39a1ce03be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-79e6e657-87e6-41dd-9c62-1e881ba44a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-9f46f0e6-bb73-402c-a483-c59ecba92eff,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-0f2b3829-0ef2-48c0-b9c5-d7aee8847f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-fad43095-7dbd-4e08-b1e6-b643ac15e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f893e188-97fc-413f-bb3d-fc5de12d71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-3658b59c-3d03-47a8-bbd1-fc37d0f075fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594272499-172.17.0.4-1597309658789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-dbd8e458-591c-482e-b1d7-a60ae967951a,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-00cc3ec0-d332-4a45-8e27-39a1ce03be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-79e6e657-87e6-41dd-9c62-1e881ba44a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-9f46f0e6-bb73-402c-a483-c59ecba92eff,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-0f2b3829-0ef2-48c0-b9c5-d7aee8847f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-fad43095-7dbd-4e08-b1e6-b643ac15e76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f893e188-97fc-413f-bb3d-fc5de12d71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-3658b59c-3d03-47a8-bbd1-fc37d0f075fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162913912-172.17.0.4-1597309902886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-ab135fc0-c2af-4a2e-bab9-93e339fa4e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-b79725d8-ce55-40f8-bd33-f5a52ea840e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-31e3ff46-a9f4-4128-9f75-fc6f7eaa2965,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-ea895b47-eca4-484a-b662-d791fd2f1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-51188674-966e-463f-88e2-dbb53547ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-371df795-5749-4dc2-916d-5d6ecec8ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-30162753-0e73-4855-874e-0b877175e669,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-369b5346-f38c-4d54-b2c5-6b81c7be8a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162913912-172.17.0.4-1597309902886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-ab135fc0-c2af-4a2e-bab9-93e339fa4e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-b79725d8-ce55-40f8-bd33-f5a52ea840e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-31e3ff46-a9f4-4128-9f75-fc6f7eaa2965,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-ea895b47-eca4-484a-b662-d791fd2f1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-51188674-966e-463f-88e2-dbb53547ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-371df795-5749-4dc2-916d-5d6ecec8ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-30162753-0e73-4855-874e-0b877175e669,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-369b5346-f38c-4d54-b2c5-6b81c7be8a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900251757-172.17.0.4-1597310003967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-270b8feb-21f6-4e88-a2da-846745ff86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e3f8f6ed-13ab-48c5-8488-f14c3f011c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-cc0bc7c8-ee8d-4cb2-8077-90d9777dd9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c19d57d6-a75a-4f5a-b200-a7cedef2f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-5b6c879a-35de-424a-82ce-3f15ec59436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f4383d75-e251-455f-8e10-9e5ea11fe088,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-dcb167c8-552c-45a7-a8e3-63b4928a8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-5fef4590-ac5b-47b0-a458-2bbab0604b63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900251757-172.17.0.4-1597310003967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-270b8feb-21f6-4e88-a2da-846745ff86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e3f8f6ed-13ab-48c5-8488-f14c3f011c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-cc0bc7c8-ee8d-4cb2-8077-90d9777dd9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c19d57d6-a75a-4f5a-b200-a7cedef2f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-5b6c879a-35de-424a-82ce-3f15ec59436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f4383d75-e251-455f-8e10-9e5ea11fe088,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-dcb167c8-552c-45a7-a8e3-63b4928a8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-5fef4590-ac5b-47b0-a458-2bbab0604b63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954428672-172.17.0.4-1597310274581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-f86ed301-b15a-4903-8009-82c923bb4671,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-a8ef0013-22cd-425a-a37d-b06df0c5b7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-27b1580d-9600-49c6-9276-64a6d443805e,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-8da6f757-5106-4b0b-b79d-61eb1c7b86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d2e6b225-4f29-4e3b-bf4d-7dd96d3069a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-54fafa1a-1e24-4640-9691-207ec39560e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-a0f64547-a1d7-4e45-902d-01396ad48ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-b3260f2e-64c0-42c5-835c-e509aff410fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954428672-172.17.0.4-1597310274581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-f86ed301-b15a-4903-8009-82c923bb4671,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-a8ef0013-22cd-425a-a37d-b06df0c5b7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-27b1580d-9600-49c6-9276-64a6d443805e,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-8da6f757-5106-4b0b-b79d-61eb1c7b86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d2e6b225-4f29-4e3b-bf4d-7dd96d3069a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-54fafa1a-1e24-4640-9691-207ec39560e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-a0f64547-a1d7-4e45-902d-01396ad48ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-b3260f2e-64c0-42c5-835c-e509aff410fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339443340-172.17.0.4-1597310352991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-df71adf0-632e-45b8-92d7-d2447218baef,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-65d699b6-acd0-43de-8509-f66fb2dcbffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-2c908833-07e0-4223-86e1-57abbe5446b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-66f2ce10-7c39-4a53-ada4-6bd208656b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-bfd3a5b8-23d5-431c-b0b9-6d06ee472063,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-c36454a5-a2ac-4b01-a81e-c59007e3d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-5b2dd926-47ea-49e8-9cad-52168ebb1719,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-47d1ddd2-3ad8-400a-8396-0a0409e3b85e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339443340-172.17.0.4-1597310352991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-df71adf0-632e-45b8-92d7-d2447218baef,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-65d699b6-acd0-43de-8509-f66fb2dcbffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-2c908833-07e0-4223-86e1-57abbe5446b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-66f2ce10-7c39-4a53-ada4-6bd208656b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-bfd3a5b8-23d5-431c-b0b9-6d06ee472063,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-c36454a5-a2ac-4b01-a81e-c59007e3d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-5b2dd926-47ea-49e8-9cad-52168ebb1719,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-47d1ddd2-3ad8-400a-8396-0a0409e3b85e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496992545-172.17.0.4-1597310458887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-a8d56cb4-07e2-4ac3-b36d-650bcb597786,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-e84251e8-6b19-454c-aa9c-752d5717a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-0c94657f-9f30-4c30-bdb5-7c2aef493c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-8b7b5bdd-fb67-44fa-8f5b-2999197704c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-96e4335f-6a8f-48c5-8efe-59613f77726d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-75baeaad-28c4-42e2-b897-59d21f6b1482,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5de552bc-31b7-417e-b191-c46a3c92fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-908848f9-ea52-481f-91cd-130ef98ac157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496992545-172.17.0.4-1597310458887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-a8d56cb4-07e2-4ac3-b36d-650bcb597786,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-e84251e8-6b19-454c-aa9c-752d5717a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-0c94657f-9f30-4c30-bdb5-7c2aef493c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-8b7b5bdd-fb67-44fa-8f5b-2999197704c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-96e4335f-6a8f-48c5-8efe-59613f77726d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-75baeaad-28c4-42e2-b897-59d21f6b1482,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5de552bc-31b7-417e-b191-c46a3c92fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-908848f9-ea52-481f-91cd-130ef98ac157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202372685-172.17.0.4-1597310892109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-771c4a1d-e46e-41f6-a518-0be80831a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-caebd6f3-288c-4a94-bd15-44007856e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-21538005-cf06-44b9-8354-e367549a7c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-98b7707d-542a-42b7-9313-f8c5ca3b4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-8cfdc48b-3449-4e79-86ef-182bd35b8a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-634603a1-3204-4a47-ba1e-390049e6f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-dc856dfc-a7b7-439d-8e12-51f830e093e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-0f7f5f56-70a7-4e2c-88e7-e6318c143d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202372685-172.17.0.4-1597310892109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-771c4a1d-e46e-41f6-a518-0be80831a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-caebd6f3-288c-4a94-bd15-44007856e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-21538005-cf06-44b9-8354-e367549a7c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-98b7707d-542a-42b7-9313-f8c5ca3b4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-8cfdc48b-3449-4e79-86ef-182bd35b8a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-634603a1-3204-4a47-ba1e-390049e6f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-dc856dfc-a7b7-439d-8e12-51f830e093e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-0f7f5f56-70a7-4e2c-88e7-e6318c143d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118009811-172.17.0.4-1597311154040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-b238fb88-df8a-448f-9f0e-79f84aaf380e,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c3129782-6baf-4ec8-a059-bd1fd4ce7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-0c439d05-ef38-40ba-89df-4863d2ecf417,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-abf0f027-135b-4854-8c20-25b3af2f4041,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-00315ac2-9e01-493a-89c9-c2edb1800bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-70852338-7bf6-4c5f-b8f1-f93ae546d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ca3ddb11-96cf-435c-ad16-af42e30986fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-40a392ec-0a8b-4016-a82e-58ff7c9293f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118009811-172.17.0.4-1597311154040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-b238fb88-df8a-448f-9f0e-79f84aaf380e,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c3129782-6baf-4ec8-a059-bd1fd4ce7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-0c439d05-ef38-40ba-89df-4863d2ecf417,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-abf0f027-135b-4854-8c20-25b3af2f4041,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-00315ac2-9e01-493a-89c9-c2edb1800bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-70852338-7bf6-4c5f-b8f1-f93ae546d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ca3ddb11-96cf-435c-ad16-af42e30986fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-40a392ec-0a8b-4016-a82e-58ff7c9293f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812864554-172.17.0.4-1597311365331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-ab0ac090-cc29-4d8a-ae29-008c3694c658,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-c855292a-82f7-49ea-8241-77d9c770ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-c472e01b-2a9c-4e98-890a-1fb0e02c7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-988988f2-945d-437c-8aa1-7708ed8bcca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-660b97dd-97eb-48aa-abf1-35b3c6f456cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-1948431e-9633-4c66-8ef8-d927fc69ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-073c8656-6100-4d06-a069-319c64f27e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-c31e323f-e408-436d-9f7e-2336832951dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812864554-172.17.0.4-1597311365331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-ab0ac090-cc29-4d8a-ae29-008c3694c658,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-c855292a-82f7-49ea-8241-77d9c770ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-c472e01b-2a9c-4e98-890a-1fb0e02c7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-988988f2-945d-437c-8aa1-7708ed8bcca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-660b97dd-97eb-48aa-abf1-35b3c6f456cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-1948431e-9633-4c66-8ef8-d927fc69ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-073c8656-6100-4d06-a069-319c64f27e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-c31e323f-e408-436d-9f7e-2336832951dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309435180-172.17.0.4-1597311433312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-dbf6df29-448a-4fe8-a28a-2ac1e923a231,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-58b118f6-ca53-4d0c-97b5-20362362260c,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-0a48a510-be55-4959-bf37-eba3ec4e8411,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-70df5ed1-9ade-4c3d-a79a-85a1ca826567,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-7b035a86-f1d8-4752-a08a-20155348d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-93050526-99ad-49a0-9ea9-04f726369f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-947f6eb1-92e3-4e56-8308-f5b78a4a9404,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-bef7c9c6-9932-4458-af18-982df365f097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309435180-172.17.0.4-1597311433312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-dbf6df29-448a-4fe8-a28a-2ac1e923a231,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-58b118f6-ca53-4d0c-97b5-20362362260c,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-0a48a510-be55-4959-bf37-eba3ec4e8411,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-70df5ed1-9ade-4c3d-a79a-85a1ca826567,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-7b035a86-f1d8-4752-a08a-20155348d9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-93050526-99ad-49a0-9ea9-04f726369f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-947f6eb1-92e3-4e56-8308-f5b78a4a9404,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-bef7c9c6-9932-4458-af18-982df365f097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047328716-172.17.0.4-1597312160594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-a45f02af-2d2a-4a1f-98e7-6c7dae8231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-76bfd1f2-e88c-4229-bf94-a7113948c5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-afe0c486-1dcf-4b37-8e89-ad9dcc811590,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-471ce96e-5bd8-4f4f-b442-9caefa40484b,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-c8ac55b2-855b-4891-9827-0a4c1592ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-93711cce-e935-44e4-b278-75db57d99a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-70a19061-7bf9-42a7-9fb1-260dab00746c,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e87b4446-8935-49c7-bbbb-16cad89b5460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047328716-172.17.0.4-1597312160594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-a45f02af-2d2a-4a1f-98e7-6c7dae8231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-76bfd1f2-e88c-4229-bf94-a7113948c5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-afe0c486-1dcf-4b37-8e89-ad9dcc811590,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-471ce96e-5bd8-4f4f-b442-9caefa40484b,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-c8ac55b2-855b-4891-9827-0a4c1592ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-93711cce-e935-44e4-b278-75db57d99a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-70a19061-7bf9-42a7-9fb1-260dab00746c,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e87b4446-8935-49c7-bbbb-16cad89b5460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5542
