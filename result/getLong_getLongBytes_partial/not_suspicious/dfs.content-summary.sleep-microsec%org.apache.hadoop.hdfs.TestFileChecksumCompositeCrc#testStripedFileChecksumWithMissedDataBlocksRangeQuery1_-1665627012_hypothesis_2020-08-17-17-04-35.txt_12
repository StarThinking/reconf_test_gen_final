reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687001068-172.17.0.21-1597683887456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-29c48148-55eb-4176-8e4c-640323d23baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-4798db72-f7a4-4b77-8ae5-332c90fdfde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-255a1534-83d0-4e80-a2d5-2bff4dabfaec,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-69e0c46c-b184-4035-ba83-7740502ea90a,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-71d4fd76-8f5c-4e1c-8fc6-4fbdb1710f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-ed5ad729-8093-4168-8ebc-281728ea8b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-6fa757f0-d10a-4e4e-ad6b-551df19b4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-574065f6-9acc-4cd2-9e40-6db8287979d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687001068-172.17.0.21-1597683887456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-29c48148-55eb-4176-8e4c-640323d23baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-4798db72-f7a4-4b77-8ae5-332c90fdfde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-255a1534-83d0-4e80-a2d5-2bff4dabfaec,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-69e0c46c-b184-4035-ba83-7740502ea90a,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-71d4fd76-8f5c-4e1c-8fc6-4fbdb1710f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-ed5ad729-8093-4168-8ebc-281728ea8b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-6fa757f0-d10a-4e4e-ad6b-551df19b4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-574065f6-9acc-4cd2-9e40-6db8287979d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588032078-172.17.0.21-1597684796857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-657c16f8-968a-4f92-8c34-77dcc2c4114d,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-e5b3bc2d-de5c-4fba-9eee-a5156feb6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-48eaef4f-3f93-48ba-adef-0c005953b2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bcdcc1bb-f856-4696-8428-e1512665e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-9fc44b90-a89e-4695-bf5f-9997e20a40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-30372442-3015-4cd0-a070-79147d513e04,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-826645a0-0532-41ce-9c9f-d1fa2967e9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3b1fa359-bc36-454c-b84b-818fa102530b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588032078-172.17.0.21-1597684796857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-657c16f8-968a-4f92-8c34-77dcc2c4114d,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-e5b3bc2d-de5c-4fba-9eee-a5156feb6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-48eaef4f-3f93-48ba-adef-0c005953b2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bcdcc1bb-f856-4696-8428-e1512665e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-9fc44b90-a89e-4695-bf5f-9997e20a40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-30372442-3015-4cd0-a070-79147d513e04,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-826645a0-0532-41ce-9c9f-d1fa2967e9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3b1fa359-bc36-454c-b84b-818fa102530b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860913351-172.17.0.21-1597685240947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40584,DS-f71be91c-74d5-4576-9f28-0cb0e8a45a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-43313b4d-e8f2-4cd3-85a8-a3a1218f08e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-b5f4b650-8fc7-4296-b282-ff0e5e5da988,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-7afa4f9a-c56d-43e9-b621-c019d32c829c,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-c3226d38-538d-4904-b484-40a163b7afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-c7f78090-2978-469e-8936-bf209e0fd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e7285ea4-0c21-484c-a97e-7a54d85ca972,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-8003a891-e07b-4d8a-95e9-ee0e1814f11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860913351-172.17.0.21-1597685240947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40584,DS-f71be91c-74d5-4576-9f28-0cb0e8a45a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-43313b4d-e8f2-4cd3-85a8-a3a1218f08e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-b5f4b650-8fc7-4296-b282-ff0e5e5da988,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-7afa4f9a-c56d-43e9-b621-c019d32c829c,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-c3226d38-538d-4904-b484-40a163b7afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-c7f78090-2978-469e-8936-bf209e0fd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e7285ea4-0c21-484c-a97e-7a54d85ca972,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-8003a891-e07b-4d8a-95e9-ee0e1814f11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177767527-172.17.0.21-1597685421372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-974e6ba1-06d8-40ed-b20a-ec50160d5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-c2c36773-2522-4c1c-98cf-5e7121f53329,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-5f8a5d8a-08a3-4204-94d4-d12799040a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-60b768af-11b8-4f4a-8dc4-8a40eab27c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-1bf99b6c-3d20-4f68-b656-45f0e622ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-037c9e38-721c-4485-ad41-8b6b72e05880,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-58b21511-c27d-4e90-b7f7-e10658d37df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-d025bdaf-36cb-4fa7-863e-86350023d62d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177767527-172.17.0.21-1597685421372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-974e6ba1-06d8-40ed-b20a-ec50160d5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-c2c36773-2522-4c1c-98cf-5e7121f53329,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-5f8a5d8a-08a3-4204-94d4-d12799040a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-60b768af-11b8-4f4a-8dc4-8a40eab27c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-1bf99b6c-3d20-4f68-b656-45f0e622ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-037c9e38-721c-4485-ad41-8b6b72e05880,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-58b21511-c27d-4e90-b7f7-e10658d37df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-d025bdaf-36cb-4fa7-863e-86350023d62d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747514842-172.17.0.21-1597686619493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-56ec9cee-c505-4b5c-99f5-bdfbcb096caf,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-b75fa313-b085-410a-a0fe-b7de925b0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-cd03b99c-7a51-43ba-9b1c-d9ef0819585f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-ebefe65b-abd1-4d9c-868b-fceb85b95abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-d8942e1b-b2f6-40c7-8869-8e3178478511,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-b5f72bd2-0f2e-4026-a2a0-fd06b4d9e774,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ad2edfd5-378a-499c-b6d2-f11c4c77e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-87590821-1618-4561-bc68-5604b133451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747514842-172.17.0.21-1597686619493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-56ec9cee-c505-4b5c-99f5-bdfbcb096caf,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-b75fa313-b085-410a-a0fe-b7de925b0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-cd03b99c-7a51-43ba-9b1c-d9ef0819585f,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-ebefe65b-abd1-4d9c-868b-fceb85b95abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-d8942e1b-b2f6-40c7-8869-8e3178478511,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-b5f72bd2-0f2e-4026-a2a0-fd06b4d9e774,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ad2edfd5-378a-499c-b6d2-f11c4c77e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-87590821-1618-4561-bc68-5604b133451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900177387-172.17.0.21-1597686820336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-f7f750d1-5c4c-4210-a590-80be038fc2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-3b46a4e3-32ed-4780-80f2-78f8f074b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e7acebc4-05d6-4766-b90c-7f47c5b6ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-0a4e1212-f818-41f6-b4c9-bcb49f3cb7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-92168d74-6ca9-4dae-a73f-b56876bf29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-dedb8978-a03c-4b52-bc0d-af4cbd581ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-017daa89-6761-430d-a7e3-70fc5964638a,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-773f43eb-5ac2-4ced-82e3-d295a5a443d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900177387-172.17.0.21-1597686820336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-f7f750d1-5c4c-4210-a590-80be038fc2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-3b46a4e3-32ed-4780-80f2-78f8f074b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e7acebc4-05d6-4766-b90c-7f47c5b6ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-0a4e1212-f818-41f6-b4c9-bcb49f3cb7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-92168d74-6ca9-4dae-a73f-b56876bf29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-dedb8978-a03c-4b52-bc0d-af4cbd581ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-017daa89-6761-430d-a7e3-70fc5964638a,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-773f43eb-5ac2-4ced-82e3-d295a5a443d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575551546-172.17.0.21-1597686858006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-c308ebef-ca42-48f9-8dd1-342073f33b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-1f5f2503-fb16-479e-9707-c7810a10d792,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-a029230e-3317-48d0-b097-52d9fc64088f,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-987cb610-560d-4fa5-ac9a-6f344772581d,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-18e0e523-9f2a-452e-8b75-3b01e173b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-754263b7-97d0-4383-ae8a-0f8df0da5899,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3a387a10-7021-438b-a673-92fa0bb929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-b4f20376-c15e-40a3-b82d-ae35cb6d2bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575551546-172.17.0.21-1597686858006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-c308ebef-ca42-48f9-8dd1-342073f33b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-1f5f2503-fb16-479e-9707-c7810a10d792,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-a029230e-3317-48d0-b097-52d9fc64088f,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-987cb610-560d-4fa5-ac9a-6f344772581d,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-18e0e523-9f2a-452e-8b75-3b01e173b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-754263b7-97d0-4383-ae8a-0f8df0da5899,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3a387a10-7021-438b-a673-92fa0bb929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-b4f20376-c15e-40a3-b82d-ae35cb6d2bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672250338-172.17.0.21-1597686932965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45718,DS-8e5c9ced-d48b-48a7-b459-9fd2cc192acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-491d5e13-1b96-4744-b3c3-f87dee28d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-e0e8ac33-1229-4bc8-ade3-cf3c470ef96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-9ba6418d-89c5-48fd-ba6a-2d71ec5712b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-7f46a920-f2ef-45ac-9cf5-6c8be4996a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7e628a46-cc97-4c73-a4b3-01933700fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-79e5e2a9-5d02-4d56-8758-36824cbb61b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-ca775dd3-2a3a-46a8-a6a0-388d0440d79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672250338-172.17.0.21-1597686932965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45718,DS-8e5c9ced-d48b-48a7-b459-9fd2cc192acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-491d5e13-1b96-4744-b3c3-f87dee28d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-e0e8ac33-1229-4bc8-ade3-cf3c470ef96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-9ba6418d-89c5-48fd-ba6a-2d71ec5712b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-7f46a920-f2ef-45ac-9cf5-6c8be4996a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7e628a46-cc97-4c73-a4b3-01933700fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-79e5e2a9-5d02-4d56-8758-36824cbb61b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-ca775dd3-2a3a-46a8-a6a0-388d0440d79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410200872-172.17.0.21-1597686969268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-4be01a18-cd28-4466-8810-17ad58a8d158,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-154724f5-a602-46c5-9e73-bb58705d9353,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-291a9fe7-8388-42a5-a4db-be35bb896c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-272c5d02-2567-40e1-a722-0c79ed60b662,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8de60e92-7f52-4010-8484-15fd38c5b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-dcddf829-b105-4907-bcec-0d193eb2eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-d2931f38-ea89-4915-b8fa-f3952e151566,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-917cd3bd-a155-4b0d-92eb-7a7e2dcf9045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410200872-172.17.0.21-1597686969268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-4be01a18-cd28-4466-8810-17ad58a8d158,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-154724f5-a602-46c5-9e73-bb58705d9353,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-291a9fe7-8388-42a5-a4db-be35bb896c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-272c5d02-2567-40e1-a722-0c79ed60b662,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8de60e92-7f52-4010-8484-15fd38c5b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-dcddf829-b105-4907-bcec-0d193eb2eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-d2931f38-ea89-4915-b8fa-f3952e151566,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-917cd3bd-a155-4b0d-92eb-7a7e2dcf9045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275614343-172.17.0.21-1597687002698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-60444753-37a3-4e6c-9300-d7d2543e1962,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-52a4f783-e0a5-4609-abdf-2dd01fae6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-453064f7-66dc-4928-ba1f-555e26663b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-466cf851-e256-41de-b4d7-bbf11df41493,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-4da87e74-571b-440e-b358-c02039ecb563,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-14dc9294-ee89-40e5-a41d-be383367096e,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f7cff5be-7bd6-479a-903b-2e4a03956c20,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-5deb5a22-2f39-4b2b-b9f4-4d06c98e3dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275614343-172.17.0.21-1597687002698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-60444753-37a3-4e6c-9300-d7d2543e1962,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-52a4f783-e0a5-4609-abdf-2dd01fae6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-453064f7-66dc-4928-ba1f-555e26663b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-466cf851-e256-41de-b4d7-bbf11df41493,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-4da87e74-571b-440e-b358-c02039ecb563,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-14dc9294-ee89-40e5-a41d-be383367096e,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f7cff5be-7bd6-479a-903b-2e4a03956c20,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-5deb5a22-2f39-4b2b-b9f4-4d06c98e3dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449013778-172.17.0.21-1597687103444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-2624a881-f4a8-4ab1-96a1-b4c3c62d8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-ae5c402b-bb25-441f-a497-1e0fa7973884,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-1ed6329c-6c5c-43bf-acfd-cf4c1519a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-89fbc51f-61dc-411d-8cb1-fc7388a99ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-8d4d236e-9ca7-4d49-8420-90dfffdd9417,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-624297a6-4794-44b2-9dfb-782f6f5933db,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-0e399113-5afc-4523-91f8-e3a41055a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-46eb5e30-6352-4e86-940b-b42e2fe57c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449013778-172.17.0.21-1597687103444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-2624a881-f4a8-4ab1-96a1-b4c3c62d8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-ae5c402b-bb25-441f-a497-1e0fa7973884,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-1ed6329c-6c5c-43bf-acfd-cf4c1519a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-89fbc51f-61dc-411d-8cb1-fc7388a99ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-8d4d236e-9ca7-4d49-8420-90dfffdd9417,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-624297a6-4794-44b2-9dfb-782f6f5933db,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-0e399113-5afc-4523-91f8-e3a41055a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-46eb5e30-6352-4e86-940b-b42e2fe57c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296169501-172.17.0.21-1597687535919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-7f6e7503-c275-4fda-a7bf-1ed26e854ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-44a42c0e-1d18-4f0d-a6f1-ad3f33cfd447,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-43a54fa1-aeb5-4c35-be0c-3e557a9514bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-549aa49f-20e0-4adb-81d8-9645ec39fdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-64e9bcd8-b182-4e38-8e74-b6289394ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-0d10d82d-be55-4c9d-8e14-702932cf1402,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-8ca91bd6-dfad-49ec-a979-e11f95c0701c,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-e41ce8d3-ff04-42de-ae66-3dbbd992c71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296169501-172.17.0.21-1597687535919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-7f6e7503-c275-4fda-a7bf-1ed26e854ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-44a42c0e-1d18-4f0d-a6f1-ad3f33cfd447,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-43a54fa1-aeb5-4c35-be0c-3e557a9514bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-549aa49f-20e0-4adb-81d8-9645ec39fdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-64e9bcd8-b182-4e38-8e74-b6289394ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-0d10d82d-be55-4c9d-8e14-702932cf1402,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-8ca91bd6-dfad-49ec-a979-e11f95c0701c,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-e41ce8d3-ff04-42de-ae66-3dbbd992c71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655238072-172.17.0.21-1597687684266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-77019b0c-da1c-4b12-80ab-3f7e6a45351c,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-143d3ee2-04ef-42b7-85ec-3fcef134cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-5ed0ae97-bb0e-42d8-b3c5-d387dbb4f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-95547bde-781d-47d9-ad58-701760cc2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-86f06d21-ef6d-4984-af3a-d80cd3fa2afc,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7d045aff-51b6-4ffb-be1a-8ceef5d551ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-f05f2206-7fa6-45d5-bac0-60d8ad759712,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-32fbe4c1-f2bb-4c82-a873-8009548a639d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655238072-172.17.0.21-1597687684266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-77019b0c-da1c-4b12-80ab-3f7e6a45351c,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-143d3ee2-04ef-42b7-85ec-3fcef134cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-5ed0ae97-bb0e-42d8-b3c5-d387dbb4f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-95547bde-781d-47d9-ad58-701760cc2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-86f06d21-ef6d-4984-af3a-d80cd3fa2afc,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7d045aff-51b6-4ffb-be1a-8ceef5d551ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-f05f2206-7fa6-45d5-bac0-60d8ad759712,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-32fbe4c1-f2bb-4c82-a873-8009548a639d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917669958-172.17.0.21-1597687757117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-20c01c79-c14b-4f2d-b049-d6cdefd45df6,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-5fa206bc-1074-401e-b20d-3b6a4652a4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9220a24c-3282-4b8a-9b35-cdab9b552714,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-f3159345-9853-49c3-a65b-c89541a7c761,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-a2bbe449-57d1-4e44-a6bf-b8eae8bda3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-0b49a4d5-4642-4277-af31-bb670a083db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-20165784-1a32-459c-bf8f-457a5ac25547,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-a63bab25-7eb3-4812-9f96-6c6738678889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917669958-172.17.0.21-1597687757117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-20c01c79-c14b-4f2d-b049-d6cdefd45df6,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-5fa206bc-1074-401e-b20d-3b6a4652a4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9220a24c-3282-4b8a-9b35-cdab9b552714,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-f3159345-9853-49c3-a65b-c89541a7c761,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-a2bbe449-57d1-4e44-a6bf-b8eae8bda3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-0b49a4d5-4642-4277-af31-bb670a083db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-20165784-1a32-459c-bf8f-457a5ac25547,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-a63bab25-7eb3-4812-9f96-6c6738678889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633031801-172.17.0.21-1597687965807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-14fb5ccb-dbd7-4bcc-98bf-563ad593db24,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-abe4661a-bba2-4351-ad74-6e50e2012c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-da1b989e-82a9-4fdd-a4f0-f76af58fff01,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-a0dd5c22-42d0-4edf-920f-33310977d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-7bd9d384-075c-4ce7-b828-f436cfdd6d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-fe6ebf6b-694f-406d-8aa8-3086915895c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-c94259ac-6ed4-48e0-bcf8-6e8b876abe58,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-ade4a04b-072b-439c-aa1d-2cd7f267ce78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633031801-172.17.0.21-1597687965807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-14fb5ccb-dbd7-4bcc-98bf-563ad593db24,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-abe4661a-bba2-4351-ad74-6e50e2012c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-da1b989e-82a9-4fdd-a4f0-f76af58fff01,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-a0dd5c22-42d0-4edf-920f-33310977d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-7bd9d384-075c-4ce7-b828-f436cfdd6d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-fe6ebf6b-694f-406d-8aa8-3086915895c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-c94259ac-6ed4-48e0-bcf8-6e8b876abe58,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-ade4a04b-072b-439c-aa1d-2cd7f267ce78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063786688-172.17.0.21-1597688159535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-7cf8a2ab-8938-4bb2-b519-725c2b78f470,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-3c1e0f73-f71b-4b00-a7b8-485698a79a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c8204a1e-ab5c-45ff-969e-ba0e8f3d761e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7310f7de-f550-4312-9211-472e44386aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-962a3534-1676-4f93-8f38-61c463e7b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-8e505782-f7f4-4376-b526-d19ed3c2c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-c7932476-1550-4b97-ae93-534758cb1904,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-5ff49ac3-bc75-4f85-8bd4-164214d5941a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063786688-172.17.0.21-1597688159535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-7cf8a2ab-8938-4bb2-b519-725c2b78f470,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-3c1e0f73-f71b-4b00-a7b8-485698a79a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c8204a1e-ab5c-45ff-969e-ba0e8f3d761e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7310f7de-f550-4312-9211-472e44386aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-962a3534-1676-4f93-8f38-61c463e7b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-8e505782-f7f4-4376-b526-d19ed3c2c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-c7932476-1550-4b97-ae93-534758cb1904,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-5ff49ac3-bc75-4f85-8bd4-164214d5941a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570772177-172.17.0.21-1597688196010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-8f0caf85-a91e-4ccb-9267-15c98af0d2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-7d860004-b896-46aa-9a57-cff9d6057f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-c90de042-d8eb-4d15-822d-c3fb343cf75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-108cde97-d3b4-41c8-a8ce-5da45a566e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-2b3831b7-efa6-4a71-b65c-ad6cc1b4a626,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-0b6ec43c-956d-4fe8-af20-e2c9734c993e,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-bbbfac02-eb24-4c87-8ac1-7c6c3e29c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-41af7866-43e2-4d84-b18f-b19137a4aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570772177-172.17.0.21-1597688196010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-8f0caf85-a91e-4ccb-9267-15c98af0d2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-7d860004-b896-46aa-9a57-cff9d6057f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-c90de042-d8eb-4d15-822d-c3fb343cf75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-108cde97-d3b4-41c8-a8ce-5da45a566e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-2b3831b7-efa6-4a71-b65c-ad6cc1b4a626,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-0b6ec43c-956d-4fe8-af20-e2c9734c993e,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-bbbfac02-eb24-4c87-8ac1-7c6c3e29c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-41af7866-43e2-4d84-b18f-b19137a4aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190505431-172.17.0.21-1597689104366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-a0d50650-6a0d-448e-98ca-46757de1fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-90dca527-816b-459c-bc0f-bd3c8c6a8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-62d28041-e005-4149-87bc-f2fad27aef64,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-38f15e7b-3823-42f7-a198-5b4fb23cd40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-5c1cadf4-46ac-4294-93c8-eea0693c0824,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-ad58f678-509b-4f26-aaf7-0eb5668bd042,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-fb7281fe-d682-4622-9151-97f2f6b0046f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-4e00778f-f5e5-4894-a608-77013cf67965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190505431-172.17.0.21-1597689104366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-a0d50650-6a0d-448e-98ca-46757de1fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-90dca527-816b-459c-bc0f-bd3c8c6a8ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-62d28041-e005-4149-87bc-f2fad27aef64,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-38f15e7b-3823-42f7-a198-5b4fb23cd40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-5c1cadf4-46ac-4294-93c8-eea0693c0824,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-ad58f678-509b-4f26-aaf7-0eb5668bd042,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-fb7281fe-d682-4622-9151-97f2f6b0046f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-4e00778f-f5e5-4894-a608-77013cf67965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5257
