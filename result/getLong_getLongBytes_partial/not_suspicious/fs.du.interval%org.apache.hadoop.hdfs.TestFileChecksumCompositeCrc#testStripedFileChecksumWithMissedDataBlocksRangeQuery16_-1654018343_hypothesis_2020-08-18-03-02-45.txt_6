reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376304669-172.17.0.8-1597720247088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-da19ae76-d19a-47d7-b462-af155119265b,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-7d08e2bb-c0c8-4476-8928-978ec50a8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ca3b45fb-fc3e-4ab7-852d-ec14e33bfd87,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-46a8787b-aec3-4c01-9968-72062caff67f,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-96b4ba84-8bcf-4253-bbeb-e38fedbec39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-729048c2-5c0c-4e53-a4e3-a5121f4fb2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b2e57293-6b64-499f-a739-4a32979c51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-fb60f59c-efb7-4624-af82-a956f44a007a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376304669-172.17.0.8-1597720247088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-da19ae76-d19a-47d7-b462-af155119265b,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-7d08e2bb-c0c8-4476-8928-978ec50a8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ca3b45fb-fc3e-4ab7-852d-ec14e33bfd87,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-46a8787b-aec3-4c01-9968-72062caff67f,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-96b4ba84-8bcf-4253-bbeb-e38fedbec39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-729048c2-5c0c-4e53-a4e3-a5121f4fb2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b2e57293-6b64-499f-a739-4a32979c51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-fb60f59c-efb7-4624-af82-a956f44a007a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741739019-172.17.0.8-1597720360736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-176fe31b-2ce6-4d4c-b818-b11663935428,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-00ac69ee-ac83-4240-b4ee-c288c59d6050,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f99f9ee3-cab0-43c1-8105-ded1e39a8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-8b1b9f69-1987-4a71-98bb-87d15602c378,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-0a9f389e-1e9c-4151-91a3-8878464b6719,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-ca290667-884a-4020-8a9e-6cd6acf34fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-860019e3-8ba1-4ec7-8d2b-9168a4106da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-314b02a6-915b-4e2b-aa04-5bf454249849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741739019-172.17.0.8-1597720360736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-176fe31b-2ce6-4d4c-b818-b11663935428,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-00ac69ee-ac83-4240-b4ee-c288c59d6050,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f99f9ee3-cab0-43c1-8105-ded1e39a8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-8b1b9f69-1987-4a71-98bb-87d15602c378,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-0a9f389e-1e9c-4151-91a3-8878464b6719,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-ca290667-884a-4020-8a9e-6cd6acf34fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-860019e3-8ba1-4ec7-8d2b-9168a4106da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-314b02a6-915b-4e2b-aa04-5bf454249849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714854543-172.17.0.8-1597720537039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-3225ffe6-45df-44b4-bd65-57e85f9d5407,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-026b6a52-eb3c-4da2-9b01-3894697e23cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-6eb616b2-30ee-43ad-bb9e-77385e7c6273,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-4a52ae4f-bccb-4c9b-9fd0-301e6f8118b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-104e703e-6393-42e7-a6d2-528c73801754,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-27e4d1c9-daf3-4046-aab4-a77fdb5e92ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-94d92552-17c0-4c2c-b655-302358c29657,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-f71a0080-9e98-4b79-9b23-53395f0be21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714854543-172.17.0.8-1597720537039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-3225ffe6-45df-44b4-bd65-57e85f9d5407,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-026b6a52-eb3c-4da2-9b01-3894697e23cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-6eb616b2-30ee-43ad-bb9e-77385e7c6273,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-4a52ae4f-bccb-4c9b-9fd0-301e6f8118b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-104e703e-6393-42e7-a6d2-528c73801754,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-27e4d1c9-daf3-4046-aab4-a77fdb5e92ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-94d92552-17c0-4c2c-b655-302358c29657,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-f71a0080-9e98-4b79-9b23-53395f0be21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767991379-172.17.0.8-1597720678713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-7d744330-2c0f-4456-bf52-9e5e8c463aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-e1e714ee-5a47-4096-b174-30d150eb25ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-d1308353-9a86-4079-92b5-9577f60e059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-30386cfb-f92e-43b3-a133-17d9597ba8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3631c0cb-8ca7-4a63-838a-8f590d8871b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-f0d44f19-e6f9-4769-9ca0-38d979734ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-525b1e49-0ac2-4fab-ae28-d1c32c922086,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-16d397f1-b920-443f-b0af-7b9cfe8fb13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767991379-172.17.0.8-1597720678713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-7d744330-2c0f-4456-bf52-9e5e8c463aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-e1e714ee-5a47-4096-b174-30d150eb25ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-d1308353-9a86-4079-92b5-9577f60e059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-30386cfb-f92e-43b3-a133-17d9597ba8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3631c0cb-8ca7-4a63-838a-8f590d8871b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-f0d44f19-e6f9-4769-9ca0-38d979734ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-525b1e49-0ac2-4fab-ae28-d1c32c922086,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-16d397f1-b920-443f-b0af-7b9cfe8fb13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191765535-172.17.0.8-1597721515943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-6b845d88-ba0e-4692-af58-478f871b6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-cc3d0285-7dfe-463e-8145-d50e93991216,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-5bfdb81d-e422-4b98-acfa-f38f97824718,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-90609d41-279b-4f37-9a71-8a382be6c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-b96b11f6-3aa7-49c5-bced-ec2e4fdb6fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-3e7ead83-431d-47bb-9201-07d05657de31,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-da0d2f29-9a42-46c1-beec-9f87a140aec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-c8e95939-826a-4f7a-af25-1976b6a6492f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191765535-172.17.0.8-1597721515943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-6b845d88-ba0e-4692-af58-478f871b6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-cc3d0285-7dfe-463e-8145-d50e93991216,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-5bfdb81d-e422-4b98-acfa-f38f97824718,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-90609d41-279b-4f37-9a71-8a382be6c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-b96b11f6-3aa7-49c5-bced-ec2e4fdb6fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-3e7ead83-431d-47bb-9201-07d05657de31,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-da0d2f29-9a42-46c1-beec-9f87a140aec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-c8e95939-826a-4f7a-af25-1976b6a6492f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332144029-172.17.0.8-1597721789511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-733b3a98-adbe-485b-81d3-255399433b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-a2df5638-9737-4467-96e8-a980eae751fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-186125f2-0251-4d62-a7f4-69f6e6f78511,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-711dd8f4-1b3c-413f-8eea-2c896bd94f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-eca6c246-2a6a-4d3f-828e-747d80666ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-55c81b57-8e02-4d64-9895-fcea6d6358f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-b2d30195-a3a3-4a55-afc0-1ddf1f6c3fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-e2faba09-922e-4282-9f11-556a7c67949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332144029-172.17.0.8-1597721789511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-733b3a98-adbe-485b-81d3-255399433b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-a2df5638-9737-4467-96e8-a980eae751fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-186125f2-0251-4d62-a7f4-69f6e6f78511,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-711dd8f4-1b3c-413f-8eea-2c896bd94f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-eca6c246-2a6a-4d3f-828e-747d80666ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-55c81b57-8e02-4d64-9895-fcea6d6358f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-b2d30195-a3a3-4a55-afc0-1ddf1f6c3fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-e2faba09-922e-4282-9f11-556a7c67949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065435155-172.17.0.8-1597722097985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41843,DS-32a305e8-af11-42c3-9d5b-99daddb53f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ecc6d26c-27b3-4e65-9574-fb046b17efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-70083988-7dd6-43af-9869-9ea7bf1cd7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-8a5b0441-ff9c-4bcb-8812-e390055c9381,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-ebab3935-40ed-44bf-914c-c44ab1493c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-260ef69b-cbd9-44b0-882b-521c94608857,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-21cfa877-c3dc-41dd-a8dc-5af9e4a54ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c1132885-213f-4ad6-bac3-544416b87440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065435155-172.17.0.8-1597722097985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41843,DS-32a305e8-af11-42c3-9d5b-99daddb53f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ecc6d26c-27b3-4e65-9574-fb046b17efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-70083988-7dd6-43af-9869-9ea7bf1cd7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-8a5b0441-ff9c-4bcb-8812-e390055c9381,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-ebab3935-40ed-44bf-914c-c44ab1493c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-260ef69b-cbd9-44b0-882b-521c94608857,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-21cfa877-c3dc-41dd-a8dc-5af9e4a54ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c1132885-213f-4ad6-bac3-544416b87440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236666486-172.17.0.8-1597722431425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35912,DS-b2688622-123f-4616-bd58-ccb81b704aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fbe0ad50-c1e6-448e-bb7a-4cff8895d816,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-e80d123b-9a2d-4926-b2ee-f9ddf0dae40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-189f1665-230e-4dae-acbe-b39836997ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-a96b1304-f34e-4b60-9fd9-7fa6f75707f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-4a2699c8-5cc7-4c39-af1e-422e4b37ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-5faf0702-4313-4920-b682-d2eda4e097c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-bbc238bb-6f9c-4034-9144-d5c47f0c9aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236666486-172.17.0.8-1597722431425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35912,DS-b2688622-123f-4616-bd58-ccb81b704aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fbe0ad50-c1e6-448e-bb7a-4cff8895d816,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-e80d123b-9a2d-4926-b2ee-f9ddf0dae40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-189f1665-230e-4dae-acbe-b39836997ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-a96b1304-f34e-4b60-9fd9-7fa6f75707f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-4a2699c8-5cc7-4c39-af1e-422e4b37ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-5faf0702-4313-4920-b682-d2eda4e097c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-bbc238bb-6f9c-4034-9144-d5c47f0c9aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796069145-172.17.0.8-1597723349948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-d4091f53-b95d-4e6c-af23-1f8c120a5609,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9d6e92fa-e27f-4b6b-ae5d-bb92f318eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-5b1e2db5-8b27-4a76-80f8-ff811bfade81,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-5d6f26bb-fe7d-4309-ad3a-ab1bce2d9d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-2907046a-1523-4c87-aaa0-a40b777582bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-870d00e2-8f0d-44c7-9346-84c005f4ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c7902e75-d58a-4d95-acba-dfc6451ceb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-bd79c349-af12-4d0a-8bac-7b1e847328ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796069145-172.17.0.8-1597723349948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-d4091f53-b95d-4e6c-af23-1f8c120a5609,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9d6e92fa-e27f-4b6b-ae5d-bb92f318eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-5b1e2db5-8b27-4a76-80f8-ff811bfade81,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-5d6f26bb-fe7d-4309-ad3a-ab1bce2d9d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-2907046a-1523-4c87-aaa0-a40b777582bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-870d00e2-8f0d-44c7-9346-84c005f4ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c7902e75-d58a-4d95-acba-dfc6451ceb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-bd79c349-af12-4d0a-8bac-7b1e847328ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146675065-172.17.0.8-1597723927013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-b497d66c-4c69-4964-81e2-eeff581efc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-30c9870d-3382-4e2c-9c2f-43a6421d0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-77574743-fbc8-46ad-ab29-2fa003282114,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-43a6ab16-4fca-4310-8d84-771040a8567b,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-debafceb-a7c9-433d-ae13-e4d33401ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-6daa9b51-5a4f-4cc8-b4d2-b2b064023ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-c1785605-cd73-44c7-bcb1-4ee7d7ee8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-6580293c-9a35-405e-9170-67fcddd07481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146675065-172.17.0.8-1597723927013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-b497d66c-4c69-4964-81e2-eeff581efc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-30c9870d-3382-4e2c-9c2f-43a6421d0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-77574743-fbc8-46ad-ab29-2fa003282114,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-43a6ab16-4fca-4310-8d84-771040a8567b,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-debafceb-a7c9-433d-ae13-e4d33401ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-6daa9b51-5a4f-4cc8-b4d2-b2b064023ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-c1785605-cd73-44c7-bcb1-4ee7d7ee8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-6580293c-9a35-405e-9170-67fcddd07481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476271357-172.17.0.8-1597724233135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-4f02f019-d7b5-4589-b8ab-25983aa72745,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-1c0cba48-14c9-4a14-86ee-7cdb5df88089,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3aa0eb1c-fd92-4b20-a2ee-dec2909cb9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-2606a6ae-ca89-486a-bdf3-3f8552624d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-62dbce68-bf8e-4046-90fe-419d5894345c,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-28665771-a844-4507-a7f9-7d0fb389e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-b80ff3e6-dd5d-4dc0-9bf9-809d091f9186,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6a94afe1-320f-4745-91b2-1779d06b61f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476271357-172.17.0.8-1597724233135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-4f02f019-d7b5-4589-b8ab-25983aa72745,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-1c0cba48-14c9-4a14-86ee-7cdb5df88089,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3aa0eb1c-fd92-4b20-a2ee-dec2909cb9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-2606a6ae-ca89-486a-bdf3-3f8552624d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-62dbce68-bf8e-4046-90fe-419d5894345c,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-28665771-a844-4507-a7f9-7d0fb389e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-b80ff3e6-dd5d-4dc0-9bf9-809d091f9186,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6a94afe1-320f-4745-91b2-1779d06b61f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134322807-172.17.0.8-1597725003819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-8281807e-4190-4645-ad07-2d645db528ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-64a37c42-a989-45c5-adca-c81785b88940,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6b1592f0-83bf-4ba7-8871-b87e477ec79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-fe8d84a1-d49b-491f-a662-555b954e7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-6b49a555-d8a1-4e82-8680-3a9af542b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e1fe845b-aab7-488a-ad79-a03d26cf439a,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-b5a89a92-f3af-4d1c-ab3d-40c3b33cad40,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-a387f6aa-c19e-445d-8fe0-f37143a1a86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134322807-172.17.0.8-1597725003819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-8281807e-4190-4645-ad07-2d645db528ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-64a37c42-a989-45c5-adca-c81785b88940,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6b1592f0-83bf-4ba7-8871-b87e477ec79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-fe8d84a1-d49b-491f-a662-555b954e7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-6b49a555-d8a1-4e82-8680-3a9af542b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e1fe845b-aab7-488a-ad79-a03d26cf439a,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-b5a89a92-f3af-4d1c-ab3d-40c3b33cad40,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-a387f6aa-c19e-445d-8fe0-f37143a1a86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5585
