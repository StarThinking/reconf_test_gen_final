reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697363461-172.17.0.11-1597707502203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36617,DS-9515dc74-d027-4583-939f-6d7ae0594061,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-13f025ca-8da4-4bf9-a733-66f10194d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-dd51d211-5294-403c-8862-320122c8a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-345894b0-5eaa-4142-a5ae-dd7f99c06342,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-64d08e85-4746-46cf-a3c6-2c5930fbf6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-69f3ba3e-73ec-4f66-9715-c287f374fad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-235022da-a60c-4c01-8d61-b198062dc095,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-f9cf6a82-d706-46f7-af3e-afbe087cc242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697363461-172.17.0.11-1597707502203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36617,DS-9515dc74-d027-4583-939f-6d7ae0594061,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-13f025ca-8da4-4bf9-a733-66f10194d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-dd51d211-5294-403c-8862-320122c8a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-345894b0-5eaa-4142-a5ae-dd7f99c06342,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-64d08e85-4746-46cf-a3c6-2c5930fbf6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-69f3ba3e-73ec-4f66-9715-c287f374fad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-235022da-a60c-4c01-8d61-b198062dc095,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-f9cf6a82-d706-46f7-af3e-afbe087cc242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731917004-172.17.0.11-1597708025707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-a7d05b11-e4af-47a5-bcbe-0185da595390,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-a167de0b-f351-4be2-8e1d-87798e6a7631,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-a5c6ce9c-1059-496c-9f22-39d48e418f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-3620155a-41f4-4166-8b5c-c67935734202,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-bfd6b72a-888b-41e4-ace1-dd7b73ab637d,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-191b3795-cb82-4d43-b166-4b8098deb9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-51f07a12-cc1f-4b68-9a9b-71bde98294e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bc2ccdfb-f322-4a3c-9bc0-03b54577f402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731917004-172.17.0.11-1597708025707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-a7d05b11-e4af-47a5-bcbe-0185da595390,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-a167de0b-f351-4be2-8e1d-87798e6a7631,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-a5c6ce9c-1059-496c-9f22-39d48e418f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-3620155a-41f4-4166-8b5c-c67935734202,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-bfd6b72a-888b-41e4-ace1-dd7b73ab637d,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-191b3795-cb82-4d43-b166-4b8098deb9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-51f07a12-cc1f-4b68-9a9b-71bde98294e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bc2ccdfb-f322-4a3c-9bc0-03b54577f402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991159439-172.17.0.11-1597708605720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-833b31e8-87db-417b-8a54-7a12958f0bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-b9bfbf3c-8c3d-4a6e-9ea0-0bf5ed7e09a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c52073e4-748a-437e-8953-bf3fdae6f178,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-591ba75e-7cad-4abd-bfe9-ae0621a21bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-652729a0-ab5a-4661-bb82-677b5251c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-fb940a82-a0e0-4e3d-9d88-b63762cf8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-e7d39cf2-c3ae-4666-9b03-a799bbe0de93,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-3f2e52cb-1b4d-4d71-a73e-f1c00f8a4c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991159439-172.17.0.11-1597708605720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-833b31e8-87db-417b-8a54-7a12958f0bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-b9bfbf3c-8c3d-4a6e-9ea0-0bf5ed7e09a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c52073e4-748a-437e-8953-bf3fdae6f178,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-591ba75e-7cad-4abd-bfe9-ae0621a21bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-652729a0-ab5a-4661-bb82-677b5251c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-fb940a82-a0e0-4e3d-9d88-b63762cf8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-e7d39cf2-c3ae-4666-9b03-a799bbe0de93,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-3f2e52cb-1b4d-4d71-a73e-f1c00f8a4c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169675790-172.17.0.11-1597708651732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32879,DS-18cc3fc3-fd19-4a31-877b-71c75929c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f56fa4bb-4da8-4f1e-a192-cc86bfe33302,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-abc40d63-0415-4832-ae8e-1fb952146779,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-fb0e587d-4ad3-444b-97f8-834ea9d9f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ad9a4c2b-8f4c-49bf-9fa3-d877593ea242,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-63387c6b-016c-42ff-96e3-9c4ee6826008,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-3d6f67c1-24e4-4733-bae9-b4bc220a29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-a3d0d3c6-a02c-4db6-b01e-a1f5c36ab438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169675790-172.17.0.11-1597708651732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32879,DS-18cc3fc3-fd19-4a31-877b-71c75929c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f56fa4bb-4da8-4f1e-a192-cc86bfe33302,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-abc40d63-0415-4832-ae8e-1fb952146779,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-fb0e587d-4ad3-444b-97f8-834ea9d9f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ad9a4c2b-8f4c-49bf-9fa3-d877593ea242,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-63387c6b-016c-42ff-96e3-9c4ee6826008,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-3d6f67c1-24e4-4733-bae9-b4bc220a29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-a3d0d3c6-a02c-4db6-b01e-a1f5c36ab438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771544624-172.17.0.11-1597709268622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-505de505-c277-49c0-9874-ff968c09cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-e1bd00b3-dd4e-412f-9f9f-de5caea3a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-2b30e91a-6de0-4faf-a736-aed552bf8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-14acc42c-291c-40cb-8a07-d1a9117099c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-61c03e73-6940-4f3c-8be7-63c0ab43afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-69d2bcdf-6fd3-4708-8f98-e4ef68a05de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-258a8e81-1f54-471d-916c-a7db4086bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-75b21c23-98c8-410a-8f80-a99f69a885b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771544624-172.17.0.11-1597709268622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-505de505-c277-49c0-9874-ff968c09cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-e1bd00b3-dd4e-412f-9f9f-de5caea3a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-2b30e91a-6de0-4faf-a736-aed552bf8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-14acc42c-291c-40cb-8a07-d1a9117099c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-61c03e73-6940-4f3c-8be7-63c0ab43afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-69d2bcdf-6fd3-4708-8f98-e4ef68a05de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-258a8e81-1f54-471d-916c-a7db4086bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-75b21c23-98c8-410a-8f80-a99f69a885b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123104763-172.17.0.11-1597709467167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39938,DS-8562772e-2720-460e-876d-c98c4d845d95,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-e9893293-3335-49fa-bfc2-7ca48510b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-14931153-045a-4a8a-9b6a-350401ab0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-6a82b3cf-bf18-4d80-8f8f-fe48e79c0f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7f62d2de-d2a6-4a92-98b4-e9e14863e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-dcea43f7-371f-4344-8d41-14e62ee172fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-cc60aa60-2fdd-41cb-b2a8-b7a2d3c9b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-2eab4113-6d71-4b3e-bff7-d5f803e42e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123104763-172.17.0.11-1597709467167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39938,DS-8562772e-2720-460e-876d-c98c4d845d95,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-e9893293-3335-49fa-bfc2-7ca48510b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-14931153-045a-4a8a-9b6a-350401ab0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-6a82b3cf-bf18-4d80-8f8f-fe48e79c0f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7f62d2de-d2a6-4a92-98b4-e9e14863e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-dcea43f7-371f-4344-8d41-14e62ee172fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-cc60aa60-2fdd-41cb-b2a8-b7a2d3c9b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-2eab4113-6d71-4b3e-bff7-d5f803e42e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023942997-172.17.0.11-1597709785328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-76d9115c-0cc4-4ace-8931-f7e5a7226e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-ca9d487e-a6e4-4cff-a2e3-f3776d856f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-4bf56308-dc8e-4caa-a362-1dc2ffaac579,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-10bbaaf4-b513-484d-99f9-8156d0e71ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-2c8ca9d8-8217-4cd4-b2f8-8d4850ec45c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-9acc0590-8151-4cd8-b321-6cbfbb75067e,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e0777598-b94a-4ed6-b5cb-2ed3473083bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-7ef2dde1-2323-470a-8ad1-d5057109a633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023942997-172.17.0.11-1597709785328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-76d9115c-0cc4-4ace-8931-f7e5a7226e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-ca9d487e-a6e4-4cff-a2e3-f3776d856f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-4bf56308-dc8e-4caa-a362-1dc2ffaac579,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-10bbaaf4-b513-484d-99f9-8156d0e71ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-2c8ca9d8-8217-4cd4-b2f8-8d4850ec45c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-9acc0590-8151-4cd8-b321-6cbfbb75067e,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e0777598-b94a-4ed6-b5cb-2ed3473083bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-7ef2dde1-2323-470a-8ad1-d5057109a633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085904003-172.17.0.11-1597709817392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37102,DS-0dae5f3f-6bc5-48db-8639-bc01ba1351f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-2b03bf57-f173-4898-b75d-bea416252e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-56ff05e8-8d03-40ca-a88e-f87f4a831a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-60ab83c3-197c-40e4-8224-c3b19bc786d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-ffb622a0-27d7-4bba-af9e-2a6db07f4075,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-176588dd-97d1-4bff-9a63-6342467e3917,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-366580c2-f5fc-4239-aae1-5741570bc357,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-1223e0ca-470e-4f16-97cf-2fe5bc90cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085904003-172.17.0.11-1597709817392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37102,DS-0dae5f3f-6bc5-48db-8639-bc01ba1351f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-2b03bf57-f173-4898-b75d-bea416252e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-56ff05e8-8d03-40ca-a88e-f87f4a831a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-60ab83c3-197c-40e4-8224-c3b19bc786d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-ffb622a0-27d7-4bba-af9e-2a6db07f4075,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-176588dd-97d1-4bff-9a63-6342467e3917,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-366580c2-f5fc-4239-aae1-5741570bc357,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-1223e0ca-470e-4f16-97cf-2fe5bc90cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696597213-172.17.0.11-1597710030347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-11fadb8e-68bb-49d6-8a0a-01e9fb6b5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-6483dbab-87d8-444f-be74-70bad4a9fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-6f204ebf-8f72-4928-9ddd-f91d0a30f0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-cf339b3f-4710-40fe-bd06-1060927f60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-30a83d9f-80e8-4778-b382-3f47ea84c886,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-465cdea7-5234-4912-927b-dc78cc86a76d,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-4faf6d54-2934-4718-855f-8a9453219cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-2967e272-4516-4e53-963b-639b9a7a414e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696597213-172.17.0.11-1597710030347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-11fadb8e-68bb-49d6-8a0a-01e9fb6b5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-6483dbab-87d8-444f-be74-70bad4a9fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-6f204ebf-8f72-4928-9ddd-f91d0a30f0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-cf339b3f-4710-40fe-bd06-1060927f60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-30a83d9f-80e8-4778-b382-3f47ea84c886,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-465cdea7-5234-4912-927b-dc78cc86a76d,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-4faf6d54-2934-4718-855f-8a9453219cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-2967e272-4516-4e53-963b-639b9a7a414e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123382169-172.17.0.11-1597710386190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-a9cc19cd-0fe9-40e7-bdb2-77a11c99de76,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7388e17b-e1f9-45c2-b110-16a7e1444ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-385a5457-10d3-4647-b58e-5b0723138fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-b629e637-ab5f-4cca-a48b-3d95d0c631c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-56b91f1b-31aa-4c4d-9838-c99ee3c7661c,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-dbcf00e1-aa4d-4600-8a35-0c1f04c31b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1e958e09-f484-4a6e-9e29-ff7ddbcdb02e,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-cd2f32e6-d165-41bc-b351-d821cae5c6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123382169-172.17.0.11-1597710386190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-a9cc19cd-0fe9-40e7-bdb2-77a11c99de76,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7388e17b-e1f9-45c2-b110-16a7e1444ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-385a5457-10d3-4647-b58e-5b0723138fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-b629e637-ab5f-4cca-a48b-3d95d0c631c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-56b91f1b-31aa-4c4d-9838-c99ee3c7661c,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-dbcf00e1-aa4d-4600-8a35-0c1f04c31b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1e958e09-f484-4a6e-9e29-ff7ddbcdb02e,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-cd2f32e6-d165-41bc-b351-d821cae5c6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038565191-172.17.0.11-1597710603741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-b444d212-93d6-4c99-97b3-ee69dd66d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-38ac997b-be5f-4fb5-923a-f3156790eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-902e4def-ed3e-4046-84b7-de918c8dd7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-e3b35652-0545-4722-9299-4e7b4dfffa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-132db801-7eb5-4866-ab9e-84b1092e310c,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-f5b77adc-6256-4b38-a3c7-9ec757d24233,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-a5c0ecfe-a526-4996-bc5a-37c1189bf8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-5a44b45a-8ad7-4033-9a98-fe92b0317493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038565191-172.17.0.11-1597710603741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-b444d212-93d6-4c99-97b3-ee69dd66d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-38ac997b-be5f-4fb5-923a-f3156790eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-902e4def-ed3e-4046-84b7-de918c8dd7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-e3b35652-0545-4722-9299-4e7b4dfffa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-132db801-7eb5-4866-ab9e-84b1092e310c,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-f5b77adc-6256-4b38-a3c7-9ec757d24233,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-a5c0ecfe-a526-4996-bc5a-37c1189bf8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-5a44b45a-8ad7-4033-9a98-fe92b0317493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003649319-172.17.0.11-1597711138729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-026023dc-db04-4fae-ab61-67a498e01598,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-95dc624e-691b-40e6-adb4-50346ca5df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-8924e5e3-cbd5-4616-8b7a-7b0d986e557f,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-32f77525-0f3a-47fe-92f9-9f776a69eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-1afe13fc-0814-43d1-b45e-a7e6fc59819c,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-32eed226-5e7f-478c-809d-828b7b9299e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a74d657f-8c86-452c-bd81-500e607330ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-f30c86ca-8e4c-4aa0-a289-6c73607777b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003649319-172.17.0.11-1597711138729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-026023dc-db04-4fae-ab61-67a498e01598,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-95dc624e-691b-40e6-adb4-50346ca5df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-8924e5e3-cbd5-4616-8b7a-7b0d986e557f,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-32f77525-0f3a-47fe-92f9-9f776a69eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-1afe13fc-0814-43d1-b45e-a7e6fc59819c,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-32eed226-5e7f-478c-809d-828b7b9299e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a74d657f-8c86-452c-bd81-500e607330ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-f30c86ca-8e4c-4aa0-a289-6c73607777b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051427686-172.17.0.11-1597711242884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-adcad786-da18-43fb-a638-d18b4d34dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-81cdc570-7cbe-42d7-9cf8-0ca8cb33cfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-1629be25-d5ee-42a0-9e4f-125e0dff4158,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-e78c1ce3-03e4-444d-9bd5-1164a86dc08d,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-9def1f26-2a7a-4ca5-a74c-ab1ab805a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-3cf26e47-c80c-4927-a1a3-d6a2c9df30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-912dd09c-43c9-4a8c-bcc3-d12f9be56bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-cc4a7f14-121a-428b-9d05-6ffcb2325484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051427686-172.17.0.11-1597711242884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-adcad786-da18-43fb-a638-d18b4d34dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-81cdc570-7cbe-42d7-9cf8-0ca8cb33cfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-1629be25-d5ee-42a0-9e4f-125e0dff4158,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-e78c1ce3-03e4-444d-9bd5-1164a86dc08d,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-9def1f26-2a7a-4ca5-a74c-ab1ab805a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-3cf26e47-c80c-4927-a1a3-d6a2c9df30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-912dd09c-43c9-4a8c-bcc3-d12f9be56bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-cc4a7f14-121a-428b-9d05-6ffcb2325484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419807592-172.17.0.11-1597711393198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-0d41b892-014a-4322-8953-38af1f5eafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-097e7499-461f-4930-9189-19a2456ea6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-2d5e2259-5c93-4b76-857f-6c5a07cc187d,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-29ebdf42-f210-4b86-a275-cfb4a820aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-2f9de3c4-e155-40c7-8963-d4f542f84ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-c49f6086-d163-463b-ac22-0cfda8bc5d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-e30c5688-c57d-48cb-9756-74bda3f114b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-df332be6-720e-476a-8bde-80a542088cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419807592-172.17.0.11-1597711393198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-0d41b892-014a-4322-8953-38af1f5eafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-097e7499-461f-4930-9189-19a2456ea6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-2d5e2259-5c93-4b76-857f-6c5a07cc187d,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-29ebdf42-f210-4b86-a275-cfb4a820aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-2f9de3c4-e155-40c7-8963-d4f542f84ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-c49f6086-d163-463b-ac22-0cfda8bc5d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-e30c5688-c57d-48cb-9756-74bda3f114b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-df332be6-720e-476a-8bde-80a542088cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096621370-172.17.0.11-1597711527954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-72621640-ffad-447d-bb32-638192ce9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-826e79de-fa37-4162-ab46-9b6964818eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ea3f22d0-4e2e-4058-8a0f-c224214e25b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-aa5f0faa-a4cb-481a-b17e-c5c1fe470288,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-2a48184a-af8b-4e33-b87f-bd3ab9915c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-5133a6fb-6318-45b0-8ec2-00a9f386f127,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-5b23445d-bcc1-4fc9-8925-74898125b280,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-532d884b-ca33-4a86-be3c-42eaa77bd07c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096621370-172.17.0.11-1597711527954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-72621640-ffad-447d-bb32-638192ce9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-826e79de-fa37-4162-ab46-9b6964818eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ea3f22d0-4e2e-4058-8a0f-c224214e25b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-aa5f0faa-a4cb-481a-b17e-c5c1fe470288,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-2a48184a-af8b-4e33-b87f-bd3ab9915c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-5133a6fb-6318-45b0-8ec2-00a9f386f127,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-5b23445d-bcc1-4fc9-8925-74898125b280,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-532d884b-ca33-4a86-be3c-42eaa77bd07c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097289597-172.17.0.11-1597711606905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-ade8891d-6c95-43be-8b44-244b0b89e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-e4c5d8c8-3fcc-457f-9f6b-fb5364de2aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-344a954a-b2cc-4436-af37-17165516179f,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-6a4f42c9-4451-40f2-ad34-34c168e82576,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-8c683279-359a-4503-98de-97adcdc5ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-fb94dbcc-55db-4c2b-b5fd-ac8824fc5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-929a136b-5226-437e-bef7-b98cd1ca7450,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-277c4303-fc95-48c8-a6d7-5f1c4adf8e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097289597-172.17.0.11-1597711606905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-ade8891d-6c95-43be-8b44-244b0b89e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-e4c5d8c8-3fcc-457f-9f6b-fb5364de2aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-344a954a-b2cc-4436-af37-17165516179f,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-6a4f42c9-4451-40f2-ad34-34c168e82576,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-8c683279-359a-4503-98de-97adcdc5ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-fb94dbcc-55db-4c2b-b5fd-ac8824fc5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-929a136b-5226-437e-bef7-b98cd1ca7450,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-277c4303-fc95-48c8-a6d7-5f1c4adf8e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849180776-172.17.0.11-1597711720696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-5af531d4-467c-44e0-81da-2e9e7f32c472,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c8cc098d-7c0c-48f8-9d30-e1a748d4c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-168071bb-dc49-45ea-b873-9177a6c49610,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a71a65e4-25bf-4707-a2db-eb0d36a19bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-69e577e6-4b8a-40b9-9e10-7e2ba27d4763,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-e43c8c52-ec0e-43ed-b4d5-a34ad8e5fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-0a6cb73f-aec0-48c0-b3a5-7cd58170be61,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-fd0ea880-60c8-4afe-9f2d-b8100d6f8d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849180776-172.17.0.11-1597711720696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-5af531d4-467c-44e0-81da-2e9e7f32c472,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c8cc098d-7c0c-48f8-9d30-e1a748d4c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-168071bb-dc49-45ea-b873-9177a6c49610,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a71a65e4-25bf-4707-a2db-eb0d36a19bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-69e577e6-4b8a-40b9-9e10-7e2ba27d4763,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-e43c8c52-ec0e-43ed-b4d5-a34ad8e5fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-0a6cb73f-aec0-48c0-b3a5-7cd58170be61,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-fd0ea880-60c8-4afe-9f2d-b8100d6f8d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861837495-172.17.0.11-1597712145044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-c7f4bc15-4b41-4529-9dee-35cc3eb46c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-ef99e102-4048-407a-94a3-5d98f12ead75,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e0b8da1e-e499-4cdc-aedd-d10cc6f306e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-de4a0612-89c0-4ac2-909c-76e6e9be2471,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-63ceedc7-ad7f-4a30-b489-2005eb084ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-461b4fdc-4968-45b5-bb51-444f0cd7654d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-67ce2e03-7ff8-440f-be72-80b083eb53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-9e092b6b-8403-4906-b7ea-32d50fc41daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861837495-172.17.0.11-1597712145044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-c7f4bc15-4b41-4529-9dee-35cc3eb46c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-ef99e102-4048-407a-94a3-5d98f12ead75,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-e0b8da1e-e499-4cdc-aedd-d10cc6f306e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-de4a0612-89c0-4ac2-909c-76e6e9be2471,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-63ceedc7-ad7f-4a30-b489-2005eb084ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-461b4fdc-4968-45b5-bb51-444f0cd7654d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-67ce2e03-7ff8-440f-be72-80b083eb53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-9e092b6b-8403-4906-b7ea-32d50fc41daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957430031-172.17.0.11-1597712230309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-b5e7ad3f-108e-4bc2-9bd5-04d15f7d313f,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d90c4b3c-68fc-4e63-9c71-478b621be8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-1af7f696-6146-405c-a4b6-0962c5600751,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-1e02ab0b-09a1-46f5-87e4-366a60b24151,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-ed185d07-1c87-42ea-92c1-69c90e66ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-ab9c46d0-2d32-4cc0-a728-424d407ab14f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-915ecd8d-08dc-4257-a03e-faf903234ede,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e2ad1cf4-7a5d-433f-8483-a77c34e4ebf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957430031-172.17.0.11-1597712230309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-b5e7ad3f-108e-4bc2-9bd5-04d15f7d313f,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d90c4b3c-68fc-4e63-9c71-478b621be8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-1af7f696-6146-405c-a4b6-0962c5600751,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-1e02ab0b-09a1-46f5-87e4-366a60b24151,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-ed185d07-1c87-42ea-92c1-69c90e66ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-ab9c46d0-2d32-4cc0-a728-424d407ab14f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-915ecd8d-08dc-4257-a03e-faf903234ede,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e2ad1cf4-7a5d-433f-8483-a77c34e4ebf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537513253-172.17.0.11-1597712422805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-14d34308-1199-4b99-8672-268d0686761e,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-6f220987-72c6-4c78-848d-c9dac997c421,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-51c4448f-db8b-45c6-a8ed-5ebdc1b71f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-c7cf2b61-8c44-4779-af36-53ccac4a68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-645c51f1-6572-4a42-9ae2-8ab11a622f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-607c3b9d-825d-4485-9181-987bfdd34418,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-c9a2073a-e6ad-4773-ad9f-0a3c4659c527,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ebad6c21-3a7d-4835-b7c1-380014e41224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537513253-172.17.0.11-1597712422805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-14d34308-1199-4b99-8672-268d0686761e,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-6f220987-72c6-4c78-848d-c9dac997c421,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-51c4448f-db8b-45c6-a8ed-5ebdc1b71f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-c7cf2b61-8c44-4779-af36-53ccac4a68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-645c51f1-6572-4a42-9ae2-8ab11a622f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-607c3b9d-825d-4485-9181-987bfdd34418,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-c9a2073a-e6ad-4773-ad9f-0a3c4659c527,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-ebad6c21-3a7d-4835-b7c1-380014e41224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698994943-172.17.0.11-1597712580970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-fb49677c-127c-4458-80d2-3dd1af6fd438,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-8e00ab8c-da79-4bfc-9f96-d851001466b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-2977283b-2afa-4264-974b-97dd55fefd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-1bd0bc09-d5d9-4f9f-98c1-a6e6ae1b0473,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-a3d78c8c-427c-40af-bcb4-e373f5403362,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-bbfbcf5e-5a16-4b3e-9e01-ae7bd9d72606,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-f4e74bbd-942d-4f1e-89f9-a7b97ff42197,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-65487ce7-8217-47cc-894a-475ef760858a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698994943-172.17.0.11-1597712580970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-fb49677c-127c-4458-80d2-3dd1af6fd438,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-8e00ab8c-da79-4bfc-9f96-d851001466b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-2977283b-2afa-4264-974b-97dd55fefd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-1bd0bc09-d5d9-4f9f-98c1-a6e6ae1b0473,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-a3d78c8c-427c-40af-bcb4-e373f5403362,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-bbfbcf5e-5a16-4b3e-9e01-ae7bd9d72606,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-f4e74bbd-942d-4f1e-89f9-a7b97ff42197,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-65487ce7-8217-47cc-894a-475ef760858a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954178881-172.17.0.11-1597713046254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-7b7e3838-4e7c-4911-a6c0-dc1ca975bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e877f77e-38f9-4b31-95cd-b663d912c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-096ac7c1-b843-4859-8b7b-039fff3ef7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-08487c64-d014-48a9-8369-5ab98593213b,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-f1eab892-c54b-4b60-82c4-a49f1c4cfc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-132e4f4f-335f-41f5-8d5e-50b43355132e,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-4bd89f8b-50ef-4622-80d1-927989b98e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-a194b5af-f789-4529-9d6b-226bcc03fbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954178881-172.17.0.11-1597713046254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-7b7e3838-4e7c-4911-a6c0-dc1ca975bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e877f77e-38f9-4b31-95cd-b663d912c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-096ac7c1-b843-4859-8b7b-039fff3ef7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-08487c64-d014-48a9-8369-5ab98593213b,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-f1eab892-c54b-4b60-82c4-a49f1c4cfc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-132e4f4f-335f-41f5-8d5e-50b43355132e,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-4bd89f8b-50ef-4622-80d1-927989b98e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-a194b5af-f789-4529-9d6b-226bcc03fbcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5662
