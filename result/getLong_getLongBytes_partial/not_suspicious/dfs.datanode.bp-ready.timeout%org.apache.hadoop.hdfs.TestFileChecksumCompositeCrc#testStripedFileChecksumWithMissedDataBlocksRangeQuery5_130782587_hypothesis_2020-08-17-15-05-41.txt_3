reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871284939-172.17.0.18-1597676839342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-198621b2-727d-44b0-b705-faaf3f5510d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-aab98bdd-6bb9-45f2-a12c-1e143c7b384a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-f06a1775-cfbf-4fb8-9932-98abacea95cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-91747c96-df08-444b-a315-3118765c9244,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-6d2c81ef-0c57-44a9-86ec-7faf9cfc5701,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-281398e3-843f-4292-b98c-087fafdf5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5feea4bb-08c5-4aa1-a8be-3d4e311171ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-5a87114f-2316-4c59-88a8-b844f51d02f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871284939-172.17.0.18-1597676839342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-198621b2-727d-44b0-b705-faaf3f5510d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-aab98bdd-6bb9-45f2-a12c-1e143c7b384a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-f06a1775-cfbf-4fb8-9932-98abacea95cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-91747c96-df08-444b-a315-3118765c9244,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-6d2c81ef-0c57-44a9-86ec-7faf9cfc5701,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-281398e3-843f-4292-b98c-087fafdf5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5feea4bb-08c5-4aa1-a8be-3d4e311171ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-5a87114f-2316-4c59-88a8-b844f51d02f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929967680-172.17.0.18-1597677047243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46042,DS-bdbe5aa3-e741-4c97-aa3f-022eb990ca13,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-c124ff58-d923-44c3-89cc-5ef6d0b6777b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-b31e10c0-4b8f-4da4-8f13-564bf885cc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-dc90bda5-d92a-45bf-8c90-752b23ba2651,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-58b61d01-556d-46f1-a465-10d0edbf78c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-00662596-d1cc-4b3f-9b5e-9717beae4083,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-4b8119c3-9c5d-47ec-bf90-c2abc58db04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-76839bf7-1685-4518-8a90-cb97340e7719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929967680-172.17.0.18-1597677047243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46042,DS-bdbe5aa3-e741-4c97-aa3f-022eb990ca13,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-c124ff58-d923-44c3-89cc-5ef6d0b6777b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-b31e10c0-4b8f-4da4-8f13-564bf885cc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-dc90bda5-d92a-45bf-8c90-752b23ba2651,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-58b61d01-556d-46f1-a465-10d0edbf78c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-00662596-d1cc-4b3f-9b5e-9717beae4083,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-4b8119c3-9c5d-47ec-bf90-c2abc58db04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-76839bf7-1685-4518-8a90-cb97340e7719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104347094-172.17.0.18-1597677086486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-2c09c4a4-8704-419d-aab2-851aaf8ccd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-3b6405b3-70d4-42af-9aea-436ebd655c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ba7c89c5-50d6-4802-887c-6ec950032594,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-67a2d23a-4615-4f03-bbdf-f1bab171fb60,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-9fffda0f-b274-4fa4-bd32-0ff1683ae920,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-ac14d0b2-1c71-44de-9844-2d8bb24d53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-b08022d4-e757-4903-aabe-cc63da978db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-886df296-c589-43a4-bfe8-3ea0c9271460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104347094-172.17.0.18-1597677086486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-2c09c4a4-8704-419d-aab2-851aaf8ccd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-3b6405b3-70d4-42af-9aea-436ebd655c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ba7c89c5-50d6-4802-887c-6ec950032594,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-67a2d23a-4615-4f03-bbdf-f1bab171fb60,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-9fffda0f-b274-4fa4-bd32-0ff1683ae920,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-ac14d0b2-1c71-44de-9844-2d8bb24d53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-b08022d4-e757-4903-aabe-cc63da978db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-886df296-c589-43a4-bfe8-3ea0c9271460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792405178-172.17.0.18-1597677840804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42927,DS-7800df0a-cd4f-4df5-b17c-dca954269023,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-bd938385-649f-4769-847d-a885e7024b13,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-419c8a86-d6b8-4d00-a9bc-f2cba6e6b6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-e4e321c0-f151-45c4-b99b-7e09fbc9a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f0ae0013-a75e-4a7d-becf-5a83f788995b,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-62f2daae-3829-4c90-8a89-327e427423a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-36d9b31a-992d-4827-af87-4d350d62f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-e562e626-d5e0-4b10-bf9f-f84c2c92a18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792405178-172.17.0.18-1597677840804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42927,DS-7800df0a-cd4f-4df5-b17c-dca954269023,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-bd938385-649f-4769-847d-a885e7024b13,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-419c8a86-d6b8-4d00-a9bc-f2cba6e6b6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-e4e321c0-f151-45c4-b99b-7e09fbc9a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f0ae0013-a75e-4a7d-becf-5a83f788995b,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-62f2daae-3829-4c90-8a89-327e427423a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-36d9b31a-992d-4827-af87-4d350d62f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-e562e626-d5e0-4b10-bf9f-f84c2c92a18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483942784-172.17.0.18-1597677924071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43465,DS-10e66e38-6765-4a9b-a941-c6fce8650a99,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-3eca25b7-69c8-4535-ae7d-28560f8688b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-f1633641-5fc8-4a16-8fb6-8aadef96b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-1870622e-c89d-4b56-8569-69392ff7d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-b75d966c-d985-4c00-8a30-be04435fe8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-69d9c5bd-ca61-45a5-a100-9a8a8b873456,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-8361b1db-0c48-4638-8df4-21f5a9fcd009,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-9bd8c677-db52-4b8e-a9d4-d87d00bd20a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483942784-172.17.0.18-1597677924071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43465,DS-10e66e38-6765-4a9b-a941-c6fce8650a99,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-3eca25b7-69c8-4535-ae7d-28560f8688b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-f1633641-5fc8-4a16-8fb6-8aadef96b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-1870622e-c89d-4b56-8569-69392ff7d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-b75d966c-d985-4c00-8a30-be04435fe8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-69d9c5bd-ca61-45a5-a100-9a8a8b873456,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-8361b1db-0c48-4638-8df4-21f5a9fcd009,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-9bd8c677-db52-4b8e-a9d4-d87d00bd20a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378585272-172.17.0.18-1597677999265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44568,DS-c6efef1d-a1e9-4704-a2b1-3acf5a362ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-87c115e2-e401-4b5b-bb36-e24a7282c952,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-197cbc5e-01e0-4a28-a5a5-dc5b6f22e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-107eb6c7-c0e5-4166-b91e-b81cadbd9bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-33e6d6a7-a5ee-4dcd-a039-bae8bdeedbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-b36d4f6d-c3d0-46d8-a601-cd67d65b725d,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-94999864-fbe2-44f7-b6b7-b21ad2b2e91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-910d5653-b970-497f-afab-4b1600d52f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378585272-172.17.0.18-1597677999265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44568,DS-c6efef1d-a1e9-4704-a2b1-3acf5a362ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-87c115e2-e401-4b5b-bb36-e24a7282c952,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-197cbc5e-01e0-4a28-a5a5-dc5b6f22e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-107eb6c7-c0e5-4166-b91e-b81cadbd9bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-33e6d6a7-a5ee-4dcd-a039-bae8bdeedbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-b36d4f6d-c3d0-46d8-a601-cd67d65b725d,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-94999864-fbe2-44f7-b6b7-b21ad2b2e91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-910d5653-b970-497f-afab-4b1600d52f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291468049-172.17.0.18-1597678153774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-21e05ba6-b784-4808-8d65-168c383d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b86562b3-c593-4d91-8bc4-a2670c0b2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-99e9c20e-8600-4439-b3e2-1dacd2898c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-7b2c300b-cf90-4711-8fd5-b7b9e0c1ba75,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-f493c183-34f9-4ec6-b3fe-9b57c8e07b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-1d6369dd-5d51-43fc-9144-1f44ceaac604,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-90145f59-cc6d-4d4d-80c6-8e43403367d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-091889a6-f589-453d-816d-3896ece975e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291468049-172.17.0.18-1597678153774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-21e05ba6-b784-4808-8d65-168c383d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b86562b3-c593-4d91-8bc4-a2670c0b2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-99e9c20e-8600-4439-b3e2-1dacd2898c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-7b2c300b-cf90-4711-8fd5-b7b9e0c1ba75,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-f493c183-34f9-4ec6-b3fe-9b57c8e07b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-1d6369dd-5d51-43fc-9144-1f44ceaac604,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-90145f59-cc6d-4d4d-80c6-8e43403367d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-091889a6-f589-453d-816d-3896ece975e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224567656-172.17.0.18-1597678705726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-c3ca245b-97a2-4e81-af2d-dca61933137b,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-447adf10-01d7-4f7a-83c0-4bf88de8c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6b96993e-ffbc-4539-97a7-999a912e2662,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-f9bcf9e3-d813-4f2f-94e4-dd8795aa8764,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-15190295-1800-425c-9155-374a52b2ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-05d115ab-482b-4904-b7a5-c78200dfdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-48e2b804-6f4d-4639-a1c7-d3ce3428c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0f8c1759-75aa-4af3-ad69-f00e7243bbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224567656-172.17.0.18-1597678705726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-c3ca245b-97a2-4e81-af2d-dca61933137b,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-447adf10-01d7-4f7a-83c0-4bf88de8c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6b96993e-ffbc-4539-97a7-999a912e2662,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-f9bcf9e3-d813-4f2f-94e4-dd8795aa8764,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-15190295-1800-425c-9155-374a52b2ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-05d115ab-482b-4904-b7a5-c78200dfdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-48e2b804-6f4d-4639-a1c7-d3ce3428c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0f8c1759-75aa-4af3-ad69-f00e7243bbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540570540-172.17.0.18-1597678784005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-fca83889-297a-496b-a058-58c50f5e4fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-416e7d91-2f1b-48c7-9b7c-489ee7c3a576,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-343c50ae-a6c2-453d-b26f-e2efb395c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b756b3ba-9abf-4fd2-ae71-ffca6c01861e,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-2910537a-4341-4da6-be3a-c0661dcb4861,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-d55861e3-c877-46a7-9af0-7f488f22be66,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5ed8e315-4d91-4cc8-a3ed-6188bd84e544,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-217ae26e-ed07-4776-9998-893eeca6e2e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540570540-172.17.0.18-1597678784005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-fca83889-297a-496b-a058-58c50f5e4fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-416e7d91-2f1b-48c7-9b7c-489ee7c3a576,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-343c50ae-a6c2-453d-b26f-e2efb395c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b756b3ba-9abf-4fd2-ae71-ffca6c01861e,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-2910537a-4341-4da6-be3a-c0661dcb4861,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-d55861e3-c877-46a7-9af0-7f488f22be66,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5ed8e315-4d91-4cc8-a3ed-6188bd84e544,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-217ae26e-ed07-4776-9998-893eeca6e2e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304398257-172.17.0.18-1597679552037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-734704fb-3eb1-4286-94a1-3e4b2a5ca4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-4ee72b17-0251-4e52-947a-61cb39bdade6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-6f3a606a-2ffb-46cb-9a60-6634ccae6f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-4bb8419f-c193-4c28-87f1-46a552338a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-00cf2214-d3ae-4491-97e9-6dc20bfb77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-3b23fe85-79df-4181-8879-f3353ac21779,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-f69be51a-96d7-4f6e-8da8-1ab0dc723a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1baff741-fb16-4ca3-94e4-51681fde79f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304398257-172.17.0.18-1597679552037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-734704fb-3eb1-4286-94a1-3e4b2a5ca4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-4ee72b17-0251-4e52-947a-61cb39bdade6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-6f3a606a-2ffb-46cb-9a60-6634ccae6f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-4bb8419f-c193-4c28-87f1-46a552338a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-00cf2214-d3ae-4491-97e9-6dc20bfb77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-3b23fe85-79df-4181-8879-f3353ac21779,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-f69be51a-96d7-4f6e-8da8-1ab0dc723a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1baff741-fb16-4ca3-94e4-51681fde79f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162978227-172.17.0.18-1597680398908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-0b989025-0b67-47b3-a42e-37f06bc8304e,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4ee4e16f-922a-4abc-b8cd-4502e66fd5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-30bb8f93-e469-49f4-84fb-d248d97053fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-7bcfe621-a233-421f-a200-58bd0b338e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-e58a32b7-bb65-4727-844b-bc8f4cc43851,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f10565fe-f0d9-4766-87d7-54365f99b5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-8f28ccbf-f0a9-4acc-9f7a-40128fe743ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-672230b6-4925-404d-92dc-ac1a45a55455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162978227-172.17.0.18-1597680398908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-0b989025-0b67-47b3-a42e-37f06bc8304e,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4ee4e16f-922a-4abc-b8cd-4502e66fd5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-30bb8f93-e469-49f4-84fb-d248d97053fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-7bcfe621-a233-421f-a200-58bd0b338e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-e58a32b7-bb65-4727-844b-bc8f4cc43851,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f10565fe-f0d9-4766-87d7-54365f99b5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-8f28ccbf-f0a9-4acc-9f7a-40128fe743ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-672230b6-4925-404d-92dc-ac1a45a55455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317151005-172.17.0.18-1597680592968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-f7e3c5dd-68a4-4a4f-8843-2f87ef79205d,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-08cc5d5f-bd62-4759-834e-cb9cee2e09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-508c9f21-0f77-456c-8ea7-a1693cfc32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a0fe3deb-ec27-459d-9b2f-8e9f5ef81403,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-831c034c-cf7c-4ac0-9727-a5183d6f2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-fb16350a-de04-4ea5-8aaf-f01a855b748f,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-db6fa4ca-bfb6-4371-8400-d5ccae222049,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-94773647-72b2-42a3-add6-24ef367a2db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317151005-172.17.0.18-1597680592968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-f7e3c5dd-68a4-4a4f-8843-2f87ef79205d,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-08cc5d5f-bd62-4759-834e-cb9cee2e09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-508c9f21-0f77-456c-8ea7-a1693cfc32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a0fe3deb-ec27-459d-9b2f-8e9f5ef81403,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-831c034c-cf7c-4ac0-9727-a5183d6f2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-fb16350a-de04-4ea5-8aaf-f01a855b748f,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-db6fa4ca-bfb6-4371-8400-d5ccae222049,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-94773647-72b2-42a3-add6-24ef367a2db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648911278-172.17.0.18-1597680632310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-b1f1a210-76af-4ff6-b52b-df1c6da5d493,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-75cc567f-3826-4de1-845b-14f9459aaa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-a983f287-e34e-4847-a0c4-1811a6141643,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-86b3c177-d520-4519-a7ba-5a0afc4d4906,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-55696f66-bd7a-461f-b6dd-4ff33b9685f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-06407aed-7ab9-49f6-8bbd-b26fdc49bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-875e0caf-f3cc-406c-b148-fd93ab5554a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-7a6b78a5-2751-47e9-93a8-f081e8d30097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648911278-172.17.0.18-1597680632310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-b1f1a210-76af-4ff6-b52b-df1c6da5d493,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-75cc567f-3826-4de1-845b-14f9459aaa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-a983f287-e34e-4847-a0c4-1811a6141643,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-86b3c177-d520-4519-a7ba-5a0afc4d4906,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-55696f66-bd7a-461f-b6dd-4ff33b9685f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-06407aed-7ab9-49f6-8bbd-b26fdc49bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-875e0caf-f3cc-406c-b148-fd93ab5554a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-7a6b78a5-2751-47e9-93a8-f081e8d30097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528103377-172.17.0.18-1597680748879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-72c82327-913e-4143-888f-454d2fb04d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-8b0126d8-676c-402b-b414-b3fda2258148,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-f75ab0bf-a472-4104-8342-bf401f41b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e8c51943-9b38-42da-b8de-cdf1738af454,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-8c0dea9b-9b0e-4f0c-b987-53c1442fb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-869aa0f6-1a38-4a37-81f1-a09aaf112db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-b90adbbf-650f-4d21-a3af-229417442c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-aa6abc96-8430-4ec6-a427-e56fdd2bbca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528103377-172.17.0.18-1597680748879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-72c82327-913e-4143-888f-454d2fb04d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-8b0126d8-676c-402b-b414-b3fda2258148,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-f75ab0bf-a472-4104-8342-bf401f41b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e8c51943-9b38-42da-b8de-cdf1738af454,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-8c0dea9b-9b0e-4f0c-b987-53c1442fb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-869aa0f6-1a38-4a37-81f1-a09aaf112db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-b90adbbf-650f-4d21-a3af-229417442c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-aa6abc96-8430-4ec6-a427-e56fdd2bbca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008269236-172.17.0.18-1597680865550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36295,DS-16e73aca-5e7a-42cb-8015-fd8d9810ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-5da35a85-8f7f-4d94-9759-46cc16340784,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-578d378a-907f-4d4c-86dd-9b7f050c5b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-6bc1d673-b722-4479-a97e-e950ea4ef09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-33ca939f-d44e-45d3-a4e6-430d462de991,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-26dd24e5-8796-440e-9648-47c06e8264f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0f1c688b-5dec-4eca-8b93-c6f21bcd3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-5772f9af-e194-469e-89cf-fae68a910760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008269236-172.17.0.18-1597680865550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36295,DS-16e73aca-5e7a-42cb-8015-fd8d9810ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-5da35a85-8f7f-4d94-9759-46cc16340784,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-578d378a-907f-4d4c-86dd-9b7f050c5b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-6bc1d673-b722-4479-a97e-e950ea4ef09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-33ca939f-d44e-45d3-a4e6-430d462de991,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-26dd24e5-8796-440e-9648-47c06e8264f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0f1c688b-5dec-4eca-8b93-c6f21bcd3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-5772f9af-e194-469e-89cf-fae68a910760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345555313-172.17.0.18-1597681021777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-7a5954f2-170b-4d91-8349-cce238f2fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-d41293b3-4340-43de-ac92-aeec7455b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-7b28af88-61a6-499d-961d-e3293bc43e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-a8fed283-e109-4fc3-ba77-550ed557d766,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-502bd54a-895f-4e1c-88c8-94b7a5333269,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-929026c8-c3ad-4dd2-8e7d-5e9c85663e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-5acb0430-705d-4791-9027-f2ad90e0c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-9607ab09-4e86-489c-a76b-2a077eb2191f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345555313-172.17.0.18-1597681021777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-7a5954f2-170b-4d91-8349-cce238f2fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-d41293b3-4340-43de-ac92-aeec7455b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-7b28af88-61a6-499d-961d-e3293bc43e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-a8fed283-e109-4fc3-ba77-550ed557d766,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-502bd54a-895f-4e1c-88c8-94b7a5333269,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-929026c8-c3ad-4dd2-8e7d-5e9c85663e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-5acb0430-705d-4791-9027-f2ad90e0c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-9607ab09-4e86-489c-a76b-2a077eb2191f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826895556-172.17.0.18-1597681175182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-3a9b4fd5-a24d-49c2-8517-fd9a922cd321,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-35fb4b84-b2d2-4cb4-b93b-584d06c56062,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-d661eb4b-5686-4edd-9b2a-268cb5f62545,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-254d2469-2c23-4ab7-b735-dd4590b06f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-95284a89-4469-49d4-92e8-042793df4ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-d58f96dc-a862-4f57-9d76-7689a3b97597,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-f6ee33ac-1c55-4f21-9b3c-b3c451d271f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-2fd2bf38-175b-4ccf-a434-3228c70e5a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826895556-172.17.0.18-1597681175182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-3a9b4fd5-a24d-49c2-8517-fd9a922cd321,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-35fb4b84-b2d2-4cb4-b93b-584d06c56062,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-d661eb4b-5686-4edd-9b2a-268cb5f62545,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-254d2469-2c23-4ab7-b735-dd4590b06f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-95284a89-4469-49d4-92e8-042793df4ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-d58f96dc-a862-4f57-9d76-7689a3b97597,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-f6ee33ac-1c55-4f21-9b3c-b3c451d271f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-2fd2bf38-175b-4ccf-a434-3228c70e5a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276389305-172.17.0.18-1597681415853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-d3ccc706-3ea7-4d42-8c79-280318dac218,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-821e8da3-e322-48c3-9609-09ad7a114ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-645d5aed-398a-4bb2-a154-8afdc87cb357,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-5a3cd61d-f660-4ae8-a102-4cca51d5a07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-441be90f-3ed0-4fbb-b8f4-59d19cef8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-ea8d61f1-a372-4a22-b8ae-c62c005935f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-f75c4157-0cac-4bab-bd75-5c37e1623d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-0d242f83-03be-4ce8-8690-61011ef5cd18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276389305-172.17.0.18-1597681415853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-d3ccc706-3ea7-4d42-8c79-280318dac218,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-821e8da3-e322-48c3-9609-09ad7a114ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-645d5aed-398a-4bb2-a154-8afdc87cb357,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-5a3cd61d-f660-4ae8-a102-4cca51d5a07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-441be90f-3ed0-4fbb-b8f4-59d19cef8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-ea8d61f1-a372-4a22-b8ae-c62c005935f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-f75c4157-0cac-4bab-bd75-5c37e1623d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-0d242f83-03be-4ce8-8690-61011ef5cd18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240131488-172.17.0.18-1597681964138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-2a9457e3-1761-4a3f-8d22-317fba0afe35,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-3dca53a5-65d1-487b-9395-b8adc70f9928,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-5cfaebe8-e98b-4190-9999-b6266b1abcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-de75d903-6268-4394-b49d-c35eb68b064e,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-886ba6ec-51c8-49d3-9a4a-798ee04ca12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-67ea21b6-b747-4558-827c-2720608a80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-2d6e9374-fb7a-4d19-bb54-81ae4c3bd986,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-67614690-165e-4d30-83e7-db4b5ef0faaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240131488-172.17.0.18-1597681964138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-2a9457e3-1761-4a3f-8d22-317fba0afe35,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-3dca53a5-65d1-487b-9395-b8adc70f9928,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-5cfaebe8-e98b-4190-9999-b6266b1abcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-de75d903-6268-4394-b49d-c35eb68b064e,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-886ba6ec-51c8-49d3-9a4a-798ee04ca12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-67ea21b6-b747-4558-827c-2720608a80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-2d6e9374-fb7a-4d19-bb54-81ae4c3bd986,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-67614690-165e-4d30-83e7-db4b5ef0faaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5748
