reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349828629-172.17.0.21-1597329215937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-6b56484d-1f08-4cbf-a338-2c87db26a377,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e9fe5f83-e57d-4df4-bf3a-29c3e647c297,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-faedc87b-294f-414b-84a5-30ede685a979,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-8d8acb9f-0646-4903-86a4-1403e62eb953,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-94504179-a7ad-4e08-bb0b-ac2032d9fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-00a69fd2-21f1-45cf-8236-a3e0dc999f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-b5ae8f9e-9d34-4130-a3ce-0c2be7af26a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-e50faf1a-be3c-4af9-8d6e-b20541de772e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349828629-172.17.0.21-1597329215937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-6b56484d-1f08-4cbf-a338-2c87db26a377,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e9fe5f83-e57d-4df4-bf3a-29c3e647c297,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-faedc87b-294f-414b-84a5-30ede685a979,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-8d8acb9f-0646-4903-86a4-1403e62eb953,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-94504179-a7ad-4e08-bb0b-ac2032d9fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-00a69fd2-21f1-45cf-8236-a3e0dc999f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-b5ae8f9e-9d34-4130-a3ce-0c2be7af26a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-e50faf1a-be3c-4af9-8d6e-b20541de772e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367289009-172.17.0.21-1597329332287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-2c5b1c3a-e6cb-4cce-8cec-be31b0129e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-dacc18af-1b9f-4fad-b72e-5564208a117a,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-8e9e285d-e274-4f77-b202-047c9cc0cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-fa9a8819-8d5c-4fa9-aa1a-e5ecc06d8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-9af38591-0a22-4403-8227-5a42c2a16f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-af31e490-7d6d-4f4a-9b70-0466683caff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-dddee785-f964-4527-9ff9-249086762d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-4ad779b5-8950-403b-9c48-44c70c6d28b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367289009-172.17.0.21-1597329332287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-2c5b1c3a-e6cb-4cce-8cec-be31b0129e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-dacc18af-1b9f-4fad-b72e-5564208a117a,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-8e9e285d-e274-4f77-b202-047c9cc0cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-fa9a8819-8d5c-4fa9-aa1a-e5ecc06d8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-9af38591-0a22-4403-8227-5a42c2a16f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-af31e490-7d6d-4f4a-9b70-0466683caff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-dddee785-f964-4527-9ff9-249086762d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-4ad779b5-8950-403b-9c48-44c70c6d28b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083306403-172.17.0.21-1597330054806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-9cc8fc94-342a-44c7-804f-a851ea233e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-08ecae57-9332-45b5-a771-4d86f9a69282,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-ef03eede-7e3e-484b-9a32-11fe0905e6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-cca0f8c8-53a0-4472-851f-e65fac2ef50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-d18a0c57-caf2-4403-b75e-a30142807869,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-28bfb15e-768a-4fcf-ae52-abbdf8d80665,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-5a9ae5a9-51b2-47f9-bcb8-4f856902f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-713ea3e9-befe-46c3-b474-636d03d248da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083306403-172.17.0.21-1597330054806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-9cc8fc94-342a-44c7-804f-a851ea233e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-08ecae57-9332-45b5-a771-4d86f9a69282,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-ef03eede-7e3e-484b-9a32-11fe0905e6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-cca0f8c8-53a0-4472-851f-e65fac2ef50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-d18a0c57-caf2-4403-b75e-a30142807869,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-28bfb15e-768a-4fcf-ae52-abbdf8d80665,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-5a9ae5a9-51b2-47f9-bcb8-4f856902f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-713ea3e9-befe-46c3-b474-636d03d248da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939355321-172.17.0.21-1597330131413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-d8059af3-2033-40a3-9cf4-4dea2f7fc124,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-2e5fa5d8-e60c-4882-affc-b2d3871aba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-26fb1724-1a2b-4093-ab29-3d469f684437,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-2761412a-0e91-4b8b-973e-a2f60be9d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-c4b987b2-70fb-4dc3-9bb9-9c843e13b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-19e30545-965e-4f83-9490-0df4aad19ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-a811f566-7778-4208-9df7-ffa5c1290c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4bb4b116-9010-4d0c-86bb-8769ea90c53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939355321-172.17.0.21-1597330131413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-d8059af3-2033-40a3-9cf4-4dea2f7fc124,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-2e5fa5d8-e60c-4882-affc-b2d3871aba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-26fb1724-1a2b-4093-ab29-3d469f684437,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-2761412a-0e91-4b8b-973e-a2f60be9d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-c4b987b2-70fb-4dc3-9bb9-9c843e13b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-19e30545-965e-4f83-9490-0df4aad19ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-a811f566-7778-4208-9df7-ffa5c1290c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4bb4b116-9010-4d0c-86bb-8769ea90c53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121969873-172.17.0.21-1597330850647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-837b1d92-46c1-4c45-b261-36c9199d3646,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-9bf12955-f7a8-46ec-9c0f-81488ff07787,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-bc3c46b7-b936-4a19-981e-2f8343b6dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-b459bc3c-c231-4352-bd65-2d1d6412efac,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2392965d-e196-42cd-be82-7bf013aec60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-31733367-32df-4ca2-82f4-8db76a437ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-9bea9244-6a28-45fe-8839-7268e74f8071,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-41facb77-fc2c-48f2-aed3-f0b960d78e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121969873-172.17.0.21-1597330850647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-837b1d92-46c1-4c45-b261-36c9199d3646,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-9bf12955-f7a8-46ec-9c0f-81488ff07787,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-bc3c46b7-b936-4a19-981e-2f8343b6dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-b459bc3c-c231-4352-bd65-2d1d6412efac,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2392965d-e196-42cd-be82-7bf013aec60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-31733367-32df-4ca2-82f4-8db76a437ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-9bea9244-6a28-45fe-8839-7268e74f8071,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-41facb77-fc2c-48f2-aed3-f0b960d78e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273483980-172.17.0.21-1597331401347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45391,DS-b4ababcf-c58a-40b1-b269-83392905e797,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-bea89bfd-aac7-465f-b2ae-815481662e64,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-6ea36f51-b21c-4dde-86e8-048608e54169,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-402151df-51c7-4279-aecd-e62f41f4c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-4adb2854-b012-42e5-a6be-f5f9f2644162,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-c939105f-b1d3-47a9-a9db-c9caf5d8a17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-e287208d-efd0-41f5-af4a-614d507c3ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-c410d8e2-82ed-4d3d-9cf8-ca7e14f66a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273483980-172.17.0.21-1597331401347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45391,DS-b4ababcf-c58a-40b1-b269-83392905e797,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-bea89bfd-aac7-465f-b2ae-815481662e64,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-6ea36f51-b21c-4dde-86e8-048608e54169,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-402151df-51c7-4279-aecd-e62f41f4c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-4adb2854-b012-42e5-a6be-f5f9f2644162,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-c939105f-b1d3-47a9-a9db-c9caf5d8a17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-e287208d-efd0-41f5-af4a-614d507c3ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-c410d8e2-82ed-4d3d-9cf8-ca7e14f66a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598590038-172.17.0.21-1597331641386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-fae48f6c-4291-438f-a72d-a94655152525,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-73bc708d-9f0f-4d46-b385-6af1f1737767,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-4142b499-a7c6-467f-b452-c476b6448987,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-9ac6054a-4df9-4ba8-9376-352faf577ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-c1f66ea3-f6a0-4663-83ad-c0621a8ec5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-1ed028a7-cbb6-4920-a3b0-355c72ff9793,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-cc89e004-436d-4b8d-930e-b12b6c26a300,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-d136294b-00b1-45f4-aa61-21cf4c44acea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598590038-172.17.0.21-1597331641386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-fae48f6c-4291-438f-a72d-a94655152525,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-73bc708d-9f0f-4d46-b385-6af1f1737767,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-4142b499-a7c6-467f-b452-c476b6448987,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-9ac6054a-4df9-4ba8-9376-352faf577ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-c1f66ea3-f6a0-4663-83ad-c0621a8ec5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-1ed028a7-cbb6-4920-a3b0-355c72ff9793,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-cc89e004-436d-4b8d-930e-b12b6c26a300,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-d136294b-00b1-45f4-aa61-21cf4c44acea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809229034-172.17.0.21-1597331683595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-dbcbb79f-41f5-4e9a-9736-b7b68ccc4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d40ce471-a141-4dd3-8013-539937c083ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-da8a2818-8040-4a5f-b21a-6b825c3cbf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-bb88d657-cc88-496a-803c-73121d24bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-6c8ddfef-c5fb-4067-93d5-b206011b0caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f9a816b8-8a89-433c-94c4-d9b3764b8189,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-ce9a22b3-25a9-44ce-a147-542cbd6d6973,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-258aae6b-41e2-496d-bee7-f5a6e5c65279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809229034-172.17.0.21-1597331683595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-dbcbb79f-41f5-4e9a-9736-b7b68ccc4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d40ce471-a141-4dd3-8013-539937c083ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-da8a2818-8040-4a5f-b21a-6b825c3cbf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-bb88d657-cc88-496a-803c-73121d24bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-6c8ddfef-c5fb-4067-93d5-b206011b0caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f9a816b8-8a89-433c-94c4-d9b3764b8189,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-ce9a22b3-25a9-44ce-a147-542cbd6d6973,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-258aae6b-41e2-496d-bee7-f5a6e5c65279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109748439-172.17.0.21-1597332260606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-8e3d765b-caab-4bd1-b1d8-a532fd6c6475,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-636d2060-82bb-4a84-83a2-15eeeab5cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6130644e-d62f-48b0-82dc-d3ea2870c918,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-089bc76f-3ec5-44d1-9d66-cb4a794c0a56,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-887b358b-5405-44fb-a534-ef9ad3cbac33,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-cb039835-6737-4535-be06-707542e8f582,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-2da6f990-8c88-4eca-b034-ff524dab642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-50bee80b-83bc-45b2-813d-c339f8a8149d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109748439-172.17.0.21-1597332260606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-8e3d765b-caab-4bd1-b1d8-a532fd6c6475,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-636d2060-82bb-4a84-83a2-15eeeab5cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6130644e-d62f-48b0-82dc-d3ea2870c918,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-089bc76f-3ec5-44d1-9d66-cb4a794c0a56,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-887b358b-5405-44fb-a534-ef9ad3cbac33,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-cb039835-6737-4535-be06-707542e8f582,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-2da6f990-8c88-4eca-b034-ff524dab642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-50bee80b-83bc-45b2-813d-c339f8a8149d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700961277-172.17.0.21-1597332306552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-f8c4fe53-9b4c-4c6e-b030-45f54e42f3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c76930ff-8fb4-4f69-b893-92a740f8bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-516dfd2f-3479-4c19-bc1d-6f6284caae18,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-0214d8b2-ebba-4509-b719-a8ccca95048f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-df8e0cec-5658-4c85-b819-f13b89356d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-08ab78ba-4dd1-4775-85d0-26e2de098da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-208cf739-62b5-4ef6-a328-305433fdb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-c0995760-8e85-45f4-bbb5-390c30266e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700961277-172.17.0.21-1597332306552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-f8c4fe53-9b4c-4c6e-b030-45f54e42f3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c76930ff-8fb4-4f69-b893-92a740f8bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-516dfd2f-3479-4c19-bc1d-6f6284caae18,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-0214d8b2-ebba-4509-b719-a8ccca95048f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-df8e0cec-5658-4c85-b819-f13b89356d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-08ab78ba-4dd1-4775-85d0-26e2de098da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-208cf739-62b5-4ef6-a328-305433fdb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-c0995760-8e85-45f4-bbb5-390c30266e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618291486-172.17.0.21-1597332384296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42157,DS-dcacf506-c208-45e7-a7d3-5c8ad6be5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-f2ed0ba1-6105-46d5-8dec-6856bea0244c,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-87e40f1e-2035-42a8-ae65-3afe66f86b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-186c5608-5752-4f52-b927-fc4c402bdead,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-99db4d69-170b-4655-a82f-7f3aed8f512a,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-5db8f23a-d513-49f5-8d82-372dc4a0bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-64b555cb-531f-470d-847a-c0ebc82378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-2aa24a3c-bad0-4373-9541-ff6805622517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618291486-172.17.0.21-1597332384296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42157,DS-dcacf506-c208-45e7-a7d3-5c8ad6be5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-f2ed0ba1-6105-46d5-8dec-6856bea0244c,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-87e40f1e-2035-42a8-ae65-3afe66f86b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-186c5608-5752-4f52-b927-fc4c402bdead,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-99db4d69-170b-4655-a82f-7f3aed8f512a,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-5db8f23a-d513-49f5-8d82-372dc4a0bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-64b555cb-531f-470d-847a-c0ebc82378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-2aa24a3c-bad0-4373-9541-ff6805622517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684787928-172.17.0.21-1597332584943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-c33e8259-0e93-4e8e-a491-511be2c6855a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-ee45fc55-5232-46c4-88f6-b18456076374,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-b260c968-ce31-4295-9d81-4d054443296b,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-840c3188-5f23-42d5-b57f-9d7c88da9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-9ae8504e-7509-4473-bc5d-85ed1ad59923,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-42045e5d-44d9-43f8-86bb-ae4fc0921660,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-53ab4368-ef9a-428d-89a5-84165f2b884a,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-3890d6bb-6967-43b1-815e-956e3f9237f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684787928-172.17.0.21-1597332584943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-c33e8259-0e93-4e8e-a491-511be2c6855a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-ee45fc55-5232-46c4-88f6-b18456076374,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-b260c968-ce31-4295-9d81-4d054443296b,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-840c3188-5f23-42d5-b57f-9d7c88da9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-9ae8504e-7509-4473-bc5d-85ed1ad59923,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-42045e5d-44d9-43f8-86bb-ae4fc0921660,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-53ab4368-ef9a-428d-89a5-84165f2b884a,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-3890d6bb-6967-43b1-815e-956e3f9237f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247083048-172.17.0.21-1597333082974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46667,DS-74e05d88-7b8e-4d59-9c0a-9f7645731cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-8e0ee46b-9421-4a1b-a869-f66daabad5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-9947bd77-30b4-47eb-b7b2-cb3b1d5e00da,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-0034e468-5c40-4f2e-bd90-4644e6a585b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-aacc4fad-3238-4e9d-936d-69d3caa84ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-d479e031-dc2a-4a72-b58e-ecc9ff68789b,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-87e063e4-0ef0-41f2-997e-ffc952ee21e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-9508a543-d027-4482-9cc4-52f944f4b46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247083048-172.17.0.21-1597333082974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46667,DS-74e05d88-7b8e-4d59-9c0a-9f7645731cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-8e0ee46b-9421-4a1b-a869-f66daabad5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-9947bd77-30b4-47eb-b7b2-cb3b1d5e00da,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-0034e468-5c40-4f2e-bd90-4644e6a585b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-aacc4fad-3238-4e9d-936d-69d3caa84ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-d479e031-dc2a-4a72-b58e-ecc9ff68789b,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-87e063e4-0ef0-41f2-997e-ffc952ee21e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-9508a543-d027-4482-9cc4-52f944f4b46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702340631-172.17.0.21-1597333202585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-487f53e0-a7d6-44a5-9d4d-cdc363afef56,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-c647ead7-9c68-45f0-b957-c4b09c4629d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-33744262-c46e-40a1-ab70-eecae54cb016,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-25a87f40-9e03-46dd-9bbe-7385f3f8e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-6818b583-be88-4d8c-aa04-ffd3c273aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-a658b87a-9cbe-42e9-9b95-1b4abd7b546f,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-b32fc66f-3f0d-468e-b16e-2125f4ec9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-cbcf5b2b-093e-4070-875e-5ec678cc2e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702340631-172.17.0.21-1597333202585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-487f53e0-a7d6-44a5-9d4d-cdc363afef56,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-c647ead7-9c68-45f0-b957-c4b09c4629d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-33744262-c46e-40a1-ab70-eecae54cb016,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-25a87f40-9e03-46dd-9bbe-7385f3f8e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-6818b583-be88-4d8c-aa04-ffd3c273aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-a658b87a-9cbe-42e9-9b95-1b4abd7b546f,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-b32fc66f-3f0d-468e-b16e-2125f4ec9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-cbcf5b2b-093e-4070-875e-5ec678cc2e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942416077-172.17.0.21-1597333767759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-88e861b4-c122-4fe6-85a5-554fc7fcd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-be96f0ee-42aa-48b6-b32d-0e98db8df4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-dcd1dfbe-2912-4ce2-aaeb-3c3819e7e587,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-e3a776ce-f268-4479-a2ce-109b188c62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-2768dd13-bd2e-4b55-84d3-b5745294473b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3359a953-7ece-4678-b02f-3c9cd50ff01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-8ce36ec5-c5e1-4042-9e93-32fb87cefaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-59f19ca8-67c6-472d-9fd2-e55227c9566e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942416077-172.17.0.21-1597333767759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-88e861b4-c122-4fe6-85a5-554fc7fcd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-be96f0ee-42aa-48b6-b32d-0e98db8df4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-dcd1dfbe-2912-4ce2-aaeb-3c3819e7e587,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-e3a776ce-f268-4479-a2ce-109b188c62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-2768dd13-bd2e-4b55-84d3-b5745294473b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3359a953-7ece-4678-b02f-3c9cd50ff01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-8ce36ec5-c5e1-4042-9e93-32fb87cefaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-59f19ca8-67c6-472d-9fd2-e55227c9566e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183308831-172.17.0.21-1597333799685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38388,DS-72964e0b-60fe-4bb2-a24b-508cd22e07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9ff3cb75-40c1-47d9-9e9d-13549cc643ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-aa9a50f6-6272-4c79-b1cd-06fd72326681,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-5eb39134-42bb-4bf4-a89f-38792c95c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-7546e86f-fff3-41a0-a521-a5697ef19a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-1f82ba48-a1a0-4bca-afd4-528907e21052,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-9bf98811-008c-4d43-99d1-1f7d1d20b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-48c7fdab-dadb-454b-ab64-0946a913e495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183308831-172.17.0.21-1597333799685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38388,DS-72964e0b-60fe-4bb2-a24b-508cd22e07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9ff3cb75-40c1-47d9-9e9d-13549cc643ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-aa9a50f6-6272-4c79-b1cd-06fd72326681,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-5eb39134-42bb-4bf4-a89f-38792c95c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-7546e86f-fff3-41a0-a521-a5697ef19a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-1f82ba48-a1a0-4bca-afd4-528907e21052,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-9bf98811-008c-4d43-99d1-1f7d1d20b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-48c7fdab-dadb-454b-ab64-0946a913e495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978797262-172.17.0.21-1597333905902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-a6d1facc-9b63-4673-88d7-04c2572244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-7032849c-a634-4cc4-bce1-3fe8aa0da586,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-eab38c6f-df11-4f4c-9b85-db4ca9c70dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-1e926712-253e-487a-968a-0401e866bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-03ec887f-f269-423d-b5ce-3dea23eee658,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f3118c0a-0dce-41e8-94a1-d3c75d9f31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-85c2edbd-72e3-4774-875c-ed32573a9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-cca23762-33b3-49c0-9f4a-5b9ab8ffdc08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978797262-172.17.0.21-1597333905902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-a6d1facc-9b63-4673-88d7-04c2572244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-7032849c-a634-4cc4-bce1-3fe8aa0da586,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-eab38c6f-df11-4f4c-9b85-db4ca9c70dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-1e926712-253e-487a-968a-0401e866bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-03ec887f-f269-423d-b5ce-3dea23eee658,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f3118c0a-0dce-41e8-94a1-d3c75d9f31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-85c2edbd-72e3-4774-875c-ed32573a9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-cca23762-33b3-49c0-9f4a-5b9ab8ffdc08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259491463-172.17.0.21-1597334020661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-244e44ce-fe96-4106-a54c-671debf77138,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1c8887ed-f244-468b-a959-b34b925fe342,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-e69095f3-ead9-4e82-82ed-f99571dfe89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-8478a85c-51a2-4d78-97ad-cae4cecd076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-6ca8c8ab-828a-4802-bea5-c0f4d8783f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-cd69444a-2ff2-47d3-b3d5-7d74a198878c,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-ae2cafe5-a65a-4073-89d3-e6acc67e9639,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-7f6764ca-c4bd-4fbc-bca3-fd61ec1c02a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259491463-172.17.0.21-1597334020661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-244e44ce-fe96-4106-a54c-671debf77138,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1c8887ed-f244-468b-a959-b34b925fe342,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-e69095f3-ead9-4e82-82ed-f99571dfe89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-8478a85c-51a2-4d78-97ad-cae4cecd076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-6ca8c8ab-828a-4802-bea5-c0f4d8783f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-cd69444a-2ff2-47d3-b3d5-7d74a198878c,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-ae2cafe5-a65a-4073-89d3-e6acc67e9639,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-7f6764ca-c4bd-4fbc-bca3-fd61ec1c02a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425970936-172.17.0.21-1597334319360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-f3af1b57-00e9-4953-a5b9-249d9956bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-4fea84e2-09cc-4f09-bce3-162f8033947e,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-9cbbc2ad-26c4-4b43-a9c9-28059645d138,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-75e4e1ea-9100-4267-bf8c-e00a6186caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-2fb7e3bf-4e89-4e4e-8d2a-989ede9d4016,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-e9fd9459-9f4c-44d0-8c68-411a9a0e4790,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-d5ebe6e9-48b6-418f-ace1-409397f06c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-5c1b0b41-80cf-48d2-8e1e-8e8203185f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425970936-172.17.0.21-1597334319360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-f3af1b57-00e9-4953-a5b9-249d9956bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-4fea84e2-09cc-4f09-bce3-162f8033947e,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-9cbbc2ad-26c4-4b43-a9c9-28059645d138,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-75e4e1ea-9100-4267-bf8c-e00a6186caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-2fb7e3bf-4e89-4e4e-8d2a-989ede9d4016,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-e9fd9459-9f4c-44d0-8c68-411a9a0e4790,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-d5ebe6e9-48b6-418f-ace1-409397f06c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-5c1b0b41-80cf-48d2-8e1e-8e8203185f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888299106-172.17.0.21-1597334472110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45311,DS-3f332ff2-3984-40d9-a1a2-2a541db556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-d7aa8d2d-e918-428e-992b-b4bc0b6d1545,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-50cfa8a1-02fd-43f0-952b-1d2a7bd37423,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-8d2b60ee-9c60-4bc2-876c-d1fab66964f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-bf2ecd8f-1e09-4324-ad57-f82372e2086f,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-0e035a54-a633-44f9-88c5-83d665b3b82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-e5bde766-c18a-4156-b9e8-5b89190aa266,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-68efd8ff-83a1-466b-baf0-830061db3976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888299106-172.17.0.21-1597334472110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45311,DS-3f332ff2-3984-40d9-a1a2-2a541db556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-d7aa8d2d-e918-428e-992b-b4bc0b6d1545,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-50cfa8a1-02fd-43f0-952b-1d2a7bd37423,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-8d2b60ee-9c60-4bc2-876c-d1fab66964f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-bf2ecd8f-1e09-4324-ad57-f82372e2086f,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-0e035a54-a633-44f9-88c5-83d665b3b82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-e5bde766-c18a-4156-b9e8-5b89190aa266,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-68efd8ff-83a1-466b-baf0-830061db3976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817032773-172.17.0.21-1597334740099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-28311984-7900-4cb3-80a8-093e879ac1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-14cb4eb9-6e80-407d-a9a8-0a4eb9757425,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-0305a033-1ab0-4d00-9dd4-fdcbcb739075,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-91a6f916-4886-49d6-b930-6ed14c905813,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-1c74281c-d0c5-458a-a3b4-bcfd09e4b049,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-09bbb5fd-ffbe-4870-9c68-1edcf0aec587,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-9ebfb299-c74c-479e-a3c1-fa2e88a459f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e3f0108f-e9a8-4c24-b55c-cef3b03ca57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817032773-172.17.0.21-1597334740099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-28311984-7900-4cb3-80a8-093e879ac1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-14cb4eb9-6e80-407d-a9a8-0a4eb9757425,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-0305a033-1ab0-4d00-9dd4-fdcbcb739075,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-91a6f916-4886-49d6-b930-6ed14c905813,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-1c74281c-d0c5-458a-a3b4-bcfd09e4b049,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-09bbb5fd-ffbe-4870-9c68-1edcf0aec587,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-9ebfb299-c74c-479e-a3c1-fa2e88a459f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e3f0108f-e9a8-4c24-b55c-cef3b03ca57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5752
