reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302958771-172.17.0.11-1597466244975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-086b5a03-c4c3-443a-b1b2-05a1c82001e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-c2114b80-a530-4c32-84a7-93bc25a49cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-d8fb162d-49de-49b7-a532-ef5bed235501,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-6be7236a-dabb-47e5-99ac-f585e5655bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-459b656d-d174-486a-9c17-0be8740bcb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-dbfe29d5-0176-4b0c-8a97-d8c03d172a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-eafd71c1-273c-4683-ad66-bbd8c152e380,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-cf19fdc1-8e4c-4315-b501-c092edfcc0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302958771-172.17.0.11-1597466244975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-086b5a03-c4c3-443a-b1b2-05a1c82001e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-c2114b80-a530-4c32-84a7-93bc25a49cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-d8fb162d-49de-49b7-a532-ef5bed235501,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-6be7236a-dabb-47e5-99ac-f585e5655bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-459b656d-d174-486a-9c17-0be8740bcb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-dbfe29d5-0176-4b0c-8a97-d8c03d172a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-eafd71c1-273c-4683-ad66-bbd8c152e380,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-cf19fdc1-8e4c-4315-b501-c092edfcc0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085224523-172.17.0.11-1597466629205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-befdabbd-985f-45d0-bc5b-43bd34d74208,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-843b349b-ab41-4c21-a231-6dce40cc2178,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e104530f-7383-4599-94e5-f600b80b9457,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-66490abc-63ab-4ddf-a3d0-dd79d2d20368,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-1ebe836d-d240-4bf6-9a78-cca97bdd6f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-0c6e30ee-87f1-4230-8a40-9d98038b552c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-f711e88a-5148-4a5a-878c-a172be346f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-a9709ee7-0657-42b7-8435-4582773fda29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085224523-172.17.0.11-1597466629205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-befdabbd-985f-45d0-bc5b-43bd34d74208,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-843b349b-ab41-4c21-a231-6dce40cc2178,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e104530f-7383-4599-94e5-f600b80b9457,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-66490abc-63ab-4ddf-a3d0-dd79d2d20368,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-1ebe836d-d240-4bf6-9a78-cca97bdd6f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-0c6e30ee-87f1-4230-8a40-9d98038b552c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-f711e88a-5148-4a5a-878c-a172be346f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-a9709ee7-0657-42b7-8435-4582773fda29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058638120-172.17.0.11-1597467176849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-8239fd42-9dcb-46dd-80db-1481f53ca6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-551f911f-1157-4697-b719-4dc7a79979b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-0df5bee2-9d3e-40ce-b5a6-d1d5ce39bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-e216cd2d-5bac-45c5-b508-8a52ba23577c,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-ec7bdfe5-d0de-41fe-91a4-282a4ad86c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-68a77aff-0858-42ae-90ff-adce1180dc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-8ee1c2d8-8879-4fcc-b8af-d81050dbcfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-da146bcb-03c3-4bd2-9f73-0f9fd0ff5892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058638120-172.17.0.11-1597467176849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-8239fd42-9dcb-46dd-80db-1481f53ca6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-551f911f-1157-4697-b719-4dc7a79979b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-0df5bee2-9d3e-40ce-b5a6-d1d5ce39bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-e216cd2d-5bac-45c5-b508-8a52ba23577c,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-ec7bdfe5-d0de-41fe-91a4-282a4ad86c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-68a77aff-0858-42ae-90ff-adce1180dc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-8ee1c2d8-8879-4fcc-b8af-d81050dbcfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-da146bcb-03c3-4bd2-9f73-0f9fd0ff5892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79026577-172.17.0.11-1597467250293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-ac1aa961-d6d9-4b76-b0b9-5705bbffdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-57fc1d8c-d424-4ed9-a9c2-1af37944d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-406da6b6-627a-454c-bbe1-afe2dd54abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0cd08d05-105b-48ec-a908-6757a1b91f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-43cfd884-fc9d-4d66-9179-75fbd3a494dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-c30754e4-088a-4f98-8edb-13311c3b4901,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5738501e-5cc9-4166-9096-7ae9bfbd0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-2e30867e-a471-460e-bdb1-66661ad91899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79026577-172.17.0.11-1597467250293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-ac1aa961-d6d9-4b76-b0b9-5705bbffdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-57fc1d8c-d424-4ed9-a9c2-1af37944d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-406da6b6-627a-454c-bbe1-afe2dd54abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0cd08d05-105b-48ec-a908-6757a1b91f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-43cfd884-fc9d-4d66-9179-75fbd3a494dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-c30754e4-088a-4f98-8edb-13311c3b4901,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5738501e-5cc9-4166-9096-7ae9bfbd0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-2e30867e-a471-460e-bdb1-66661ad91899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214071511-172.17.0.11-1597469441948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-924de176-5a2c-494d-92fb-dc102f7a8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-c554a4fe-72fb-406e-ad6b-7e00e37972b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-abe41bf2-e3d2-49b4-87c7-cd3276fe76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-7386cf14-62c1-43c3-a5c1-5de2108ec9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-c098ab1b-56b7-4309-85cc-5d651673c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-e108aedb-c118-47fa-8710-9ba7846f8287,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-42bbb590-da1e-4969-a818-968dad7e6ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e93f8e18-8ae0-4c45-bd97-a52afaf2cb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214071511-172.17.0.11-1597469441948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-924de176-5a2c-494d-92fb-dc102f7a8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-c554a4fe-72fb-406e-ad6b-7e00e37972b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-abe41bf2-e3d2-49b4-87c7-cd3276fe76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-7386cf14-62c1-43c3-a5c1-5de2108ec9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-c098ab1b-56b7-4309-85cc-5d651673c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-e108aedb-c118-47fa-8710-9ba7846f8287,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-42bbb590-da1e-4969-a818-968dad7e6ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e93f8e18-8ae0-4c45-bd97-a52afaf2cb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496270914-172.17.0.11-1597469556669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-261f5ec6-9f4a-4f5d-8615-fc91c71e5d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-0818d699-828c-4e12-a72a-8f3c16a2d0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-5cf7e9d1-53e9-494d-88ee-738652e14026,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-683627bf-d1b6-4d80-8d80-83cc4b7e46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-dc17dee4-aa98-4cb9-a84f-3321418e32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a90911c0-4dba-42c9-af86-c3e2ac55c120,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-097a3b52-3282-4aee-a168-0a7892b9698a,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-3ba8dccb-84ef-4b11-b76f-40a9a0dbb43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496270914-172.17.0.11-1597469556669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-261f5ec6-9f4a-4f5d-8615-fc91c71e5d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-0818d699-828c-4e12-a72a-8f3c16a2d0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-5cf7e9d1-53e9-494d-88ee-738652e14026,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-683627bf-d1b6-4d80-8d80-83cc4b7e46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-dc17dee4-aa98-4cb9-a84f-3321418e32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a90911c0-4dba-42c9-af86-c3e2ac55c120,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-097a3b52-3282-4aee-a168-0a7892b9698a,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-3ba8dccb-84ef-4b11-b76f-40a9a0dbb43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745231227-172.17.0.11-1597469789905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46746,DS-f7b0fb91-cf37-48ad-94ad-c9fb951cdfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-bdf93b22-c4f6-4ed5-857d-94c16542433a,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-e871c212-e7b3-4df3-9540-810c45cbcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-9b19279f-fcbd-4803-86ec-5f72420450aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-74ee53a1-ab56-4fe4-8c00-3705680438e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-687c1f73-8e9a-48d4-8f33-1c1e0bbc53db,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-832f7984-b923-4fd0-ab40-e6acad9dfd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-96f82ce9-8d12-4dc3-bc45-82bb652c9871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745231227-172.17.0.11-1597469789905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46746,DS-f7b0fb91-cf37-48ad-94ad-c9fb951cdfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-bdf93b22-c4f6-4ed5-857d-94c16542433a,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-e871c212-e7b3-4df3-9540-810c45cbcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-9b19279f-fcbd-4803-86ec-5f72420450aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-74ee53a1-ab56-4fe4-8c00-3705680438e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-687c1f73-8e9a-48d4-8f33-1c1e0bbc53db,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-832f7984-b923-4fd0-ab40-e6acad9dfd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-96f82ce9-8d12-4dc3-bc45-82bb652c9871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494956659-172.17.0.11-1597470041813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-d201bba5-11a4-471a-b461-f881327e3671,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-ff4d1f15-d250-4abd-bf46-e11f7571c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ef96aa1e-0063-4f82-939d-d5577ff26873,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-f6e5de03-11a7-46d3-b13c-4478a2406098,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-647d28cd-ac80-4077-87b4-20801ac699b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d516c250-206a-4077-b577-ec2beff8dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-abcd9a3b-2742-4767-81d0-7bc6921dfc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-9a6a4b39-ce91-4844-be5b-75710c681cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494956659-172.17.0.11-1597470041813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-d201bba5-11a4-471a-b461-f881327e3671,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-ff4d1f15-d250-4abd-bf46-e11f7571c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ef96aa1e-0063-4f82-939d-d5577ff26873,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-f6e5de03-11a7-46d3-b13c-4478a2406098,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-647d28cd-ac80-4077-87b4-20801ac699b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d516c250-206a-4077-b577-ec2beff8dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-abcd9a3b-2742-4767-81d0-7bc6921dfc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-9a6a4b39-ce91-4844-be5b-75710c681cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041131288-172.17.0.11-1597470224816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-1eb09cf4-ba92-4e89-87a1-4d6b2a249cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-802b85e6-366e-4588-8c2c-a432dd6a2457,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-27798386-f6cd-4f37-a006-e76e7c393983,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-c790d6d2-0ebc-45c6-8579-173602de7c36,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-96fe48e3-98bc-4a11-9256-4d8766c347f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-e7a9cfa9-3843-427a-af11-e6276802a426,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-24f11777-fd84-418b-b1e3-073ff4d9b015,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-8b1abd46-f1c8-49df-ba38-0750ed72bffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041131288-172.17.0.11-1597470224816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-1eb09cf4-ba92-4e89-87a1-4d6b2a249cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-802b85e6-366e-4588-8c2c-a432dd6a2457,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-27798386-f6cd-4f37-a006-e76e7c393983,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-c790d6d2-0ebc-45c6-8579-173602de7c36,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-96fe48e3-98bc-4a11-9256-4d8766c347f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-e7a9cfa9-3843-427a-af11-e6276802a426,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-24f11777-fd84-418b-b1e3-073ff4d9b015,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-8b1abd46-f1c8-49df-ba38-0750ed72bffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117742196-172.17.0.11-1597470517603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-c3715062-24c1-498f-aed5-8b4183f02478,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-b5eca62b-aed7-4d0c-92cb-e06bc670c869,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-472caafe-8342-4586-8ae4-93808ab8131d,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-1563efaa-71c4-4409-b084-356792ebe117,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-385a5d08-7eeb-4ed4-95d0-294a91a6e570,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-6c0671bf-1927-4919-be68-c40b9e227194,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-b18142b4-3d92-401a-8720-4888f1eb906f,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-6307ce21-0235-4664-b100-15d6a99bb429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117742196-172.17.0.11-1597470517603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-c3715062-24c1-498f-aed5-8b4183f02478,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-b5eca62b-aed7-4d0c-92cb-e06bc670c869,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-472caafe-8342-4586-8ae4-93808ab8131d,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-1563efaa-71c4-4409-b084-356792ebe117,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-385a5d08-7eeb-4ed4-95d0-294a91a6e570,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-6c0671bf-1927-4919-be68-c40b9e227194,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-b18142b4-3d92-401a-8720-4888f1eb906f,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-6307ce21-0235-4664-b100-15d6a99bb429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145830160-172.17.0.11-1597470669175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-7dad8840-f566-4ef6-8a8e-e9ddf3ee4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f02ba843-2965-480a-8c0c-3b238eadac16,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-25266123-a35c-4d2e-a061-e87e93231e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-f4fd9e63-64b6-4a76-8185-3a9eff127d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-3b6781c0-6893-428a-9aa0-db8e224c7336,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-f7642cb3-3ce1-42c4-8a78-0d719c0e37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-4a589595-f3a6-4dae-8490-71e38d25131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-cafad0fa-cf4c-4790-a5d8-37a7a1bb3b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145830160-172.17.0.11-1597470669175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-7dad8840-f566-4ef6-8a8e-e9ddf3ee4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f02ba843-2965-480a-8c0c-3b238eadac16,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-25266123-a35c-4d2e-a061-e87e93231e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-f4fd9e63-64b6-4a76-8185-3a9eff127d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-3b6781c0-6893-428a-9aa0-db8e224c7336,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-f7642cb3-3ce1-42c4-8a78-0d719c0e37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-4a589595-f3a6-4dae-8490-71e38d25131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-cafad0fa-cf4c-4790-a5d8-37a7a1bb3b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175289274-172.17.0.11-1597470826159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-51ff9eb3-a33d-49f5-8a11-4f54b21ab07d,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-c812145f-b17a-4062-ad0e-251e674390be,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-c7f492c8-e284-44ef-af5f-ab61f218000d,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-34045b4d-45a3-4c49-83e0-da27dc9f35da,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-f95422b8-af08-43da-8a5f-a0285389c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-66206914-05eb-4ba4-8c26-f85339bbb226,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-d4d4f7b6-123a-4fd4-acb4-3f2fba318381,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-2ef0ebdf-039a-42bc-914a-eb0406c66c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175289274-172.17.0.11-1597470826159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-51ff9eb3-a33d-49f5-8a11-4f54b21ab07d,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-c812145f-b17a-4062-ad0e-251e674390be,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-c7f492c8-e284-44ef-af5f-ab61f218000d,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-34045b4d-45a3-4c49-83e0-da27dc9f35da,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-f95422b8-af08-43da-8a5f-a0285389c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-66206914-05eb-4ba4-8c26-f85339bbb226,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-d4d4f7b6-123a-4fd4-acb4-3f2fba318381,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-2ef0ebdf-039a-42bc-914a-eb0406c66c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109325475-172.17.0.11-1597471029839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-83a7a159-b61a-4a2b-8e5e-20b5bbe94ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-e76b203f-a084-4644-8649-6b617dd06f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-412a84a9-a8b3-42a7-bb3c-104a7e3cebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-b3e5063b-1fda-43ac-af7c-d6fcbdf014fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-04986b55-adc2-4122-956c-4d052940dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-02a8bb4b-d68a-4144-80f2-18316efb6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-76388d58-d26f-4751-803d-983ac0111c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-834cd98e-3875-45fb-aca8-8ba5e6bbce08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109325475-172.17.0.11-1597471029839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-83a7a159-b61a-4a2b-8e5e-20b5bbe94ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-e76b203f-a084-4644-8649-6b617dd06f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-412a84a9-a8b3-42a7-bb3c-104a7e3cebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-b3e5063b-1fda-43ac-af7c-d6fcbdf014fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-04986b55-adc2-4122-956c-4d052940dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-02a8bb4b-d68a-4144-80f2-18316efb6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-76388d58-d26f-4751-803d-983ac0111c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-834cd98e-3875-45fb-aca8-8ba5e6bbce08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5381
