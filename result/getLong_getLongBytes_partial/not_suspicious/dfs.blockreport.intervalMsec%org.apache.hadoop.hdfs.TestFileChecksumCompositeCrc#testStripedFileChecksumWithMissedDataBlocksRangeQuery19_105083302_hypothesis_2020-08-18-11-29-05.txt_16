reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526859534-172.17.0.8-1597751077006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-d7754b33-315f-46f1-8ba0-acf349cb22e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-169e124b-6a33-453c-86ce-4e555db486b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-25ee8ad4-6a19-4dc6-ab68-b28fa3ae0614,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3e1b420-0186-4e8a-9b10-391c3dba5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54d194c1-6205-4214-8965-65d792053a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-a4ae60ed-ae10-4478-92bc-6626dab5eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b379253f-60ec-459f-8e31-b08c392ced57,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-58b30f1c-ca55-4bd5-a399-8383b4c653b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526859534-172.17.0.8-1597751077006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-d7754b33-315f-46f1-8ba0-acf349cb22e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-169e124b-6a33-453c-86ce-4e555db486b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-25ee8ad4-6a19-4dc6-ab68-b28fa3ae0614,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3e1b420-0186-4e8a-9b10-391c3dba5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54d194c1-6205-4214-8965-65d792053a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-a4ae60ed-ae10-4478-92bc-6626dab5eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-b379253f-60ec-459f-8e31-b08c392ced57,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-58b30f1c-ca55-4bd5-a399-8383b4c653b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78752687-172.17.0.8-1597751396587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-fdb18e97-1378-49e3-a2c4-c1e3d8d51e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-4899bea0-0c1e-45f1-9767-a553df6d74d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-29e04f2a-bb52-4bcc-94e4-8211c1129b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-d921fb76-a4c7-4334-8148-c8fe870a4d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-509020d1-75f4-47b8-b0ea-f5b449d784b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-8fe0b6e2-e624-4e7d-b929-2d743f442884,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-90c962bc-4e6e-4a98-abdc-8fc0d444e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9ccc0129-722c-4881-bc88-e3c48c6e8ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78752687-172.17.0.8-1597751396587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-fdb18e97-1378-49e3-a2c4-c1e3d8d51e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-4899bea0-0c1e-45f1-9767-a553df6d74d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-29e04f2a-bb52-4bcc-94e4-8211c1129b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-d921fb76-a4c7-4334-8148-c8fe870a4d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-509020d1-75f4-47b8-b0ea-f5b449d784b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-8fe0b6e2-e624-4e7d-b929-2d743f442884,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-90c962bc-4e6e-4a98-abdc-8fc0d444e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-9ccc0129-722c-4881-bc88-e3c48c6e8ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291949691-172.17.0.8-1597751588680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-f161f8e9-7339-47e5-99c0-b6dfe0336812,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c44f5761-6c0d-404c-8c16-d0b4a216fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-bec585df-5cd1-47b8-b7dd-f71e780c494d,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-3c2bb36c-c558-438f-9dd6-23e8c7e89c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-e6720140-f0fb-41cf-b9ca-e63b4f92b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-7f6c5288-2aa7-423e-b1b8-fa313606b16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-1a224282-a4a9-4a4d-b3f9-1729239b2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-d50d1a98-bfb4-4b87-a736-dbf8cb062ac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291949691-172.17.0.8-1597751588680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-f161f8e9-7339-47e5-99c0-b6dfe0336812,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c44f5761-6c0d-404c-8c16-d0b4a216fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-bec585df-5cd1-47b8-b7dd-f71e780c494d,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-3c2bb36c-c558-438f-9dd6-23e8c7e89c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-e6720140-f0fb-41cf-b9ca-e63b4f92b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-7f6c5288-2aa7-423e-b1b8-fa313606b16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-1a224282-a4a9-4a4d-b3f9-1729239b2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-d50d1a98-bfb4-4b87-a736-dbf8cb062ac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763033986-172.17.0.8-1597751720942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-ecae1aee-c184-4872-8a05-13a1e40d70df,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-62ba6076-e465-4bb5-ae1f-25c348fe168a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-1562b9ae-1813-41d3-9278-7faa493b1605,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-36fb5b98-1191-4fa2-82a8-1d18ff8ce493,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-875e3451-6256-473f-baca-ecde7aa7caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-369ef04d-35b3-45de-b2d2-ca649ad48727,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-070fdfd6-c8d5-4fd5-96b0-082903cc5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-b448136c-2a5c-4f24-b4b2-430afb350812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763033986-172.17.0.8-1597751720942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-ecae1aee-c184-4872-8a05-13a1e40d70df,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-62ba6076-e465-4bb5-ae1f-25c348fe168a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-1562b9ae-1813-41d3-9278-7faa493b1605,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-36fb5b98-1191-4fa2-82a8-1d18ff8ce493,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-875e3451-6256-473f-baca-ecde7aa7caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-369ef04d-35b3-45de-b2d2-ca649ad48727,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-070fdfd6-c8d5-4fd5-96b0-082903cc5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-b448136c-2a5c-4f24-b4b2-430afb350812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51818853-172.17.0.8-1597752546563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-d1b5be0b-a9ad-43d0-ba01-dde071a3795c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-e7df62fe-3c12-4268-ae5b-eea49dc78c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-7ea1affd-2e95-4138-81b4-0979e96197bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-3112508b-4a17-4bd2-813e-098ccbf3383b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8e8532fa-4ab0-45fc-985b-ffa1de6c1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-5cd26353-80c1-49cd-bf8c-7c8345fbd504,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-1a7ae073-e78b-41b5-9851-f28b489473dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-170ee3ad-93df-4b55-a620-364ea2c53507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51818853-172.17.0.8-1597752546563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-d1b5be0b-a9ad-43d0-ba01-dde071a3795c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-e7df62fe-3c12-4268-ae5b-eea49dc78c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-7ea1affd-2e95-4138-81b4-0979e96197bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-3112508b-4a17-4bd2-813e-098ccbf3383b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8e8532fa-4ab0-45fc-985b-ffa1de6c1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-5cd26353-80c1-49cd-bf8c-7c8345fbd504,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-1a7ae073-e78b-41b5-9851-f28b489473dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-170ee3ad-93df-4b55-a620-364ea2c53507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306429229-172.17.0.8-1597752779028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-8cbc5536-f591-411c-8b0a-1280d6162728,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-e60195e4-4a11-44a6-a0f1-888afce091b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-1624f2dc-a313-4600-9113-9a1c65548e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-7b5b0b79-ce3e-44ad-8e6b-8be9070b6826,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-6b3d7b1c-9d5f-45e0-bd4f-f0b519c8ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-1f894b15-6e31-44b5-861e-ea893aebbe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-4337ed17-2b57-4af9-98f9-c9e5bf29e90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-bc945f9b-3214-407e-9716-46c2e93a00d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306429229-172.17.0.8-1597752779028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-8cbc5536-f591-411c-8b0a-1280d6162728,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-e60195e4-4a11-44a6-a0f1-888afce091b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-1624f2dc-a313-4600-9113-9a1c65548e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-7b5b0b79-ce3e-44ad-8e6b-8be9070b6826,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-6b3d7b1c-9d5f-45e0-bd4f-f0b519c8ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-1f894b15-6e31-44b5-861e-ea893aebbe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-4337ed17-2b57-4af9-98f9-c9e5bf29e90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-bc945f9b-3214-407e-9716-46c2e93a00d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014359620-172.17.0.8-1597753221219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-bda7d2fa-0679-4534-a8b9-f3d9cdb6f327,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9980f49d-2977-4707-b917-42bd5f09bb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-b60ffdc0-9a39-43fb-a5c0-a322d69074b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-0d7c9824-703f-4e81-b383-bd62c8e87281,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-568462a7-50a2-4d9e-941e-f7376d790327,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-ed23cab8-ea3f-43b9-a8d8-7ae9b999677e,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-13016abe-9f7e-470c-a0ec-4e432fe5a339,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-f4ff0bab-0e6f-4ece-b7b6-5bdfd0f5ee64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014359620-172.17.0.8-1597753221219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-bda7d2fa-0679-4534-a8b9-f3d9cdb6f327,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9980f49d-2977-4707-b917-42bd5f09bb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-b60ffdc0-9a39-43fb-a5c0-a322d69074b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-0d7c9824-703f-4e81-b383-bd62c8e87281,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-568462a7-50a2-4d9e-941e-f7376d790327,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-ed23cab8-ea3f-43b9-a8d8-7ae9b999677e,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-13016abe-9f7e-470c-a0ec-4e432fe5a339,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-f4ff0bab-0e6f-4ece-b7b6-5bdfd0f5ee64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686249742-172.17.0.8-1597753548664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-00351d70-7e5c-471d-808d-052f6012b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d84d6ffc-3ea6-46bb-93d3-ada5db5a4713,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-1eec67e7-84ad-4cfb-97bf-5ae132bbf800,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-5a9728c0-d4c4-40e6-a57a-e8373d997048,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c2f5b8ac-df39-478d-97f9-a042fdd4d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-8d73686e-2ed5-4e73-b406-dd1db156c248,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-25cbed9d-7bae-426a-ab7f-75fe01ee1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-aeb75820-9416-4c75-a6f4-b58118246c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686249742-172.17.0.8-1597753548664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-00351d70-7e5c-471d-808d-052f6012b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d84d6ffc-3ea6-46bb-93d3-ada5db5a4713,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-1eec67e7-84ad-4cfb-97bf-5ae132bbf800,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-5a9728c0-d4c4-40e6-a57a-e8373d997048,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c2f5b8ac-df39-478d-97f9-a042fdd4d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-8d73686e-2ed5-4e73-b406-dd1db156c248,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-25cbed9d-7bae-426a-ab7f-75fe01ee1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-aeb75820-9416-4c75-a6f4-b58118246c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107192016-172.17.0.8-1597753593111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-4f1a3edc-6e5b-489d-9223-a9e88ef4784d,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-10026a76-2cdc-40e2-96e0-d0348c9c3897,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-f6bd5e6b-3216-4d98-9ded-e26d0c61ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-1d2df71a-792c-411e-8153-8d1b91e01f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-350ec951-2a3d-4c6a-9775-c03c5e212e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-e5bc2b10-eda2-48c6-9bf2-ba101e41cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-738bf1e8-d65b-47ba-a19f-0c0694192913,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-2743260a-77aa-4e74-8e3c-84ad548f2822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107192016-172.17.0.8-1597753593111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-4f1a3edc-6e5b-489d-9223-a9e88ef4784d,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-10026a76-2cdc-40e2-96e0-d0348c9c3897,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-f6bd5e6b-3216-4d98-9ded-e26d0c61ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-1d2df71a-792c-411e-8153-8d1b91e01f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-350ec951-2a3d-4c6a-9775-c03c5e212e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-e5bc2b10-eda2-48c6-9bf2-ba101e41cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-738bf1e8-d65b-47ba-a19f-0c0694192913,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-2743260a-77aa-4e74-8e3c-84ad548f2822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761869282-172.17.0.8-1597753811050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46696,DS-2dca5ced-ab95-4f5b-96bd-19bbc8f7c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d7ac404d-3f7f-40d7-b068-b4470e87d84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-2e910ce8-2da2-4d5d-b3f1-b8f56f83b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-5af4b221-cad5-4f7d-9b5a-99ce759c70a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-49bbdc10-9f6e-46f2-bd96-ccb67838c147,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-85579b02-7733-467e-a057-427cf1b4e249,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-320c6456-a0b3-4e98-b05f-8f050aada692,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-50a90040-f8c1-4e03-9c1b-decf12d921eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761869282-172.17.0.8-1597753811050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46696,DS-2dca5ced-ab95-4f5b-96bd-19bbc8f7c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d7ac404d-3f7f-40d7-b068-b4470e87d84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-2e910ce8-2da2-4d5d-b3f1-b8f56f83b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-5af4b221-cad5-4f7d-9b5a-99ce759c70a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-49bbdc10-9f6e-46f2-bd96-ccb67838c147,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-85579b02-7733-467e-a057-427cf1b4e249,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-320c6456-a0b3-4e98-b05f-8f050aada692,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-50a90040-f8c1-4e03-9c1b-decf12d921eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452826617-172.17.0.8-1597754375856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-dc650bc4-c415-4cf6-9dbd-14803b58e649,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-3334f9f2-e534-4a28-abf4-0577a6bba82d,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-3a9dc89a-eee7-4413-ada1-af9a4b5dab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-1e0a67c6-6359-4c26-8d00-f78b67dae3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-5af59689-b7ba-48d8-9aa0-d6ba0cd80399,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-191e3769-d353-4856-a706-53f87104628c,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-81c3522e-a2c7-42f1-abea-1272d6a36b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2caeb8af-a7c2-4929-8d1c-a5499fc0d700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452826617-172.17.0.8-1597754375856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-dc650bc4-c415-4cf6-9dbd-14803b58e649,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-3334f9f2-e534-4a28-abf4-0577a6bba82d,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-3a9dc89a-eee7-4413-ada1-af9a4b5dab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-1e0a67c6-6359-4c26-8d00-f78b67dae3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-5af59689-b7ba-48d8-9aa0-d6ba0cd80399,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-191e3769-d353-4856-a706-53f87104628c,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-81c3522e-a2c7-42f1-abea-1272d6a36b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2caeb8af-a7c2-4929-8d1c-a5499fc0d700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994466213-172.17.0.8-1597754598456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33531,DS-9a88847b-1b56-4ecf-8f32-c9a233039d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-6f1dd745-59d7-49b8-899c-e82fc0a42aab,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0a433669-b92f-49e2-877b-147db15cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-908c939d-dd63-460c-a582-cfbbb19a17cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-933eea0d-a2eb-42fc-9581-20135b026280,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-81bc979e-a002-4203-8db0-96670b4b42a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-1e701f11-f35d-4d5c-a650-e857daf4d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-f6992c02-ccec-4a8e-9253-595472169d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994466213-172.17.0.8-1597754598456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33531,DS-9a88847b-1b56-4ecf-8f32-c9a233039d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-6f1dd745-59d7-49b8-899c-e82fc0a42aab,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0a433669-b92f-49e2-877b-147db15cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-908c939d-dd63-460c-a582-cfbbb19a17cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-933eea0d-a2eb-42fc-9581-20135b026280,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-81bc979e-a002-4203-8db0-96670b4b42a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-1e701f11-f35d-4d5c-a650-e857daf4d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-f6992c02-ccec-4a8e-9253-595472169d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533402978-172.17.0.8-1597754646246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-1aa695f0-292e-4bbc-a501-b9765246d851,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f41692db-8876-4c03-8850-7834628799ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-89d7d93f-beac-4af0-bb5b-08afeba6976f,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-5cf62436-4be4-4356-b9a8-626c1b182dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-71a3d048-d517-4a17-ac52-26bee115fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-070a2136-aa61-4e53-9d24-2cd045b3e967,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-b3d51798-e771-4d3a-98a6-32b8e4542677,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7c20d6a6-b9d2-4be3-9237-e22b5fcf8575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533402978-172.17.0.8-1597754646246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-1aa695f0-292e-4bbc-a501-b9765246d851,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f41692db-8876-4c03-8850-7834628799ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-89d7d93f-beac-4af0-bb5b-08afeba6976f,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-5cf62436-4be4-4356-b9a8-626c1b182dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-71a3d048-d517-4a17-ac52-26bee115fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-070a2136-aa61-4e53-9d24-2cd045b3e967,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-b3d51798-e771-4d3a-98a6-32b8e4542677,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7c20d6a6-b9d2-4be3-9237-e22b5fcf8575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227849772-172.17.0.8-1597755127550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36962,DS-7fab62ff-95a3-4868-987a-2813a13202db,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-8d3434de-d186-4d3e-b519-1475b40f2d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-07236edc-8f82-408d-a96c-f737e7f0a189,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-cb691e4b-2a24-4f5b-9ae2-c0d8b1ad40f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-63541fe5-07b9-4602-9835-8b5f541e3771,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-77f6946d-52ea-4f5b-b665-9b88808b3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-9edcf11e-a610-4c0a-888a-d2fed6028bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-a5ade192-8f82-4c80-83f9-d2f96101fe92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227849772-172.17.0.8-1597755127550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36962,DS-7fab62ff-95a3-4868-987a-2813a13202db,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-8d3434de-d186-4d3e-b519-1475b40f2d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-07236edc-8f82-408d-a96c-f737e7f0a189,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-cb691e4b-2a24-4f5b-9ae2-c0d8b1ad40f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-63541fe5-07b9-4602-9835-8b5f541e3771,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-77f6946d-52ea-4f5b-b665-9b88808b3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-9edcf11e-a610-4c0a-888a-d2fed6028bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-a5ade192-8f82-4c80-83f9-d2f96101fe92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608486601-172.17.0.8-1597755166371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-c9af2cc2-1eac-4b1a-baea-23cabfa0a394,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-e8ae6875-cf3d-48a2-be3d-e1d1764d14bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-23b15579-11ee-400b-8a1d-ac10d45a3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0f0bdd57-1557-4593-a8cf-108dc7c9d141,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-4ffd8556-6ec4-4974-ab32-9e94f7e89649,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-d266ddd8-0034-4ea2-82de-c69216003f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-3473a1bc-407a-46a8-9b2e-e21f46dbde62,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-d04e2422-f944-4a72-8802-22676c35f53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608486601-172.17.0.8-1597755166371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-c9af2cc2-1eac-4b1a-baea-23cabfa0a394,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-e8ae6875-cf3d-48a2-be3d-e1d1764d14bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-23b15579-11ee-400b-8a1d-ac10d45a3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0f0bdd57-1557-4593-a8cf-108dc7c9d141,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-4ffd8556-6ec4-4974-ab32-9e94f7e89649,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-d266ddd8-0034-4ea2-82de-c69216003f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-3473a1bc-407a-46a8-9b2e-e21f46dbde62,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-d04e2422-f944-4a72-8802-22676c35f53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238662184-172.17.0.8-1597755472080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35569,DS-23e67fd9-5712-4ad9-9be5-4119d2a0410c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-70837904-ab94-4cd4-8a83-71f0a88e29db,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-94422a80-9f2b-4846-bcf0-5caffa62e046,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-8410145f-a5bd-4083-b670-5dc0da310e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-b32bd5bb-28a7-45f0-83b7-8ba8e3e91b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-45c7d067-518d-47f5-b3cd-c6b080e53a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-77bb203d-7338-4c47-ad36-9904725885b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-ced6e6b3-7e64-46d7-b001-f48ea1b97617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238662184-172.17.0.8-1597755472080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35569,DS-23e67fd9-5712-4ad9-9be5-4119d2a0410c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-70837904-ab94-4cd4-8a83-71f0a88e29db,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-94422a80-9f2b-4846-bcf0-5caffa62e046,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-8410145f-a5bd-4083-b670-5dc0da310e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-b32bd5bb-28a7-45f0-83b7-8ba8e3e91b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-45c7d067-518d-47f5-b3cd-c6b080e53a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-77bb203d-7338-4c47-ad36-9904725885b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-ced6e6b3-7e64-46d7-b001-f48ea1b97617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334750589-172.17.0.8-1597755776802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-86936230-6b1f-45b1-9b9e-abd839cf211f,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-73a61467-afc9-4c8d-9a33-b257199e81b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bb4be816-8194-4b76-bf0b-850d4d19c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-38bea92b-522d-43f8-8eb3-86741e3a9b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-4172c23f-0c8c-4ef7-a824-d67874de0a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-8425aca1-9673-4f93-b15e-80d650c324cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-bcc26caf-9061-49b3-816d-2854a0bcf43f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-2d7cb7e2-c42a-4b59-8b8a-1cbbed3a7d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334750589-172.17.0.8-1597755776802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-86936230-6b1f-45b1-9b9e-abd839cf211f,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-73a61467-afc9-4c8d-9a33-b257199e81b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bb4be816-8194-4b76-bf0b-850d4d19c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-38bea92b-522d-43f8-8eb3-86741e3a9b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-4172c23f-0c8c-4ef7-a824-d67874de0a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-8425aca1-9673-4f93-b15e-80d650c324cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-bcc26caf-9061-49b3-816d-2854a0bcf43f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-2d7cb7e2-c42a-4b59-8b8a-1cbbed3a7d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790898908-172.17.0.8-1597756314575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-e27cf729-1955-4ee5-9a0e-3bb43c0cc722,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-7cc76cd6-8c66-4637-8f67-e9120f9d7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-fe7b7c33-7247-4a4a-a379-6363f6b4cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-38751ee5-1efd-479f-b52c-ab1d8e8c4acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-9bbf72ce-fb72-4ee1-aad6-6a7efbe72373,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-15635098-5d29-4b2a-a11c-c31978f5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-78ed51e7-dea0-493e-9553-7bd8e489d175,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-17a7993e-e275-4b7c-8511-5b8c53fce13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790898908-172.17.0.8-1597756314575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-e27cf729-1955-4ee5-9a0e-3bb43c0cc722,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-7cc76cd6-8c66-4637-8f67-e9120f9d7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-fe7b7c33-7247-4a4a-a379-6363f6b4cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-38751ee5-1efd-479f-b52c-ab1d8e8c4acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-9bbf72ce-fb72-4ee1-aad6-6a7efbe72373,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-15635098-5d29-4b2a-a11c-c31978f5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-78ed51e7-dea0-493e-9553-7bd8e489d175,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-17a7993e-e275-4b7c-8511-5b8c53fce13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 216
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606638630-172.17.0.8-1597756536535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-81207cae-9cf7-416e-8699-4c870c25eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-c673a0a9-328f-4b5f-8987-8de64fa1a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-9ac205e0-b5d9-40c8-89d0-0f7b5eee819f,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-244a33e1-bc03-41ca-a442-65ed7dc21024,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-28835334-5444-4914-bf91-ec8f2dd17aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-6f905201-56a1-4283-8052-d5a49d6b5453,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-7d86d476-5a0d-4811-93aa-27ed94c769bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-06b8a9a8-cb18-4db4-af49-624ce7e1d8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606638630-172.17.0.8-1597756536535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-81207cae-9cf7-416e-8699-4c870c25eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-c673a0a9-328f-4b5f-8987-8de64fa1a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-9ac205e0-b5d9-40c8-89d0-0f7b5eee819f,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-244a33e1-bc03-41ca-a442-65ed7dc21024,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-28835334-5444-4914-bf91-ec8f2dd17aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-6f905201-56a1-4283-8052-d5a49d6b5453,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-7d86d476-5a0d-4811-93aa-27ed94c769bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-06b8a9a8-cb18-4db4-af49-624ce7e1d8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6539
