reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595890390-172.17.0.10-1597460039481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45202,DS-72be2ca6-ffb2-46dd-952d-2ec6379a00f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-b1670559-44bb-4abd-916f-5a7c8b44fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-b31567ea-1df5-414c-82bf-23deab058c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-66d569ae-2b81-4270-9a36-b954fbe5b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-01e6e359-14d3-4a20-b6bb-ff87459fc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-51fabb5e-78c7-439b-9dfe-8b614f90a787,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-823d9a03-d970-4783-8e92-306faa5e2d28,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-559df978-b454-4ad1-abfc-171edc8e39f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595890390-172.17.0.10-1597460039481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45202,DS-72be2ca6-ffb2-46dd-952d-2ec6379a00f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-b1670559-44bb-4abd-916f-5a7c8b44fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-b31567ea-1df5-414c-82bf-23deab058c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-66d569ae-2b81-4270-9a36-b954fbe5b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-01e6e359-14d3-4a20-b6bb-ff87459fc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-51fabb5e-78c7-439b-9dfe-8b614f90a787,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-823d9a03-d970-4783-8e92-306faa5e2d28,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-559df978-b454-4ad1-abfc-171edc8e39f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52541754-172.17.0.10-1597460084501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-68aa0b79-7ffb-49bc-85a1-7c247b46baa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-46cce6d4-3b72-4f48-9d20-0d7ea8222755,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-141dd4d1-3b00-4284-9895-72029a16d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-1b4b49b4-bfa5-4e51-ba75-72302e7e02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-415478e1-3527-47b6-84ff-a9f88d1dd3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-fec49105-d3b7-4211-94a4-b3b2eda2d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-71930dba-aebc-4682-8250-f68ad05637f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-5d397524-dbed-4c1f-bd80-c4f16120a30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52541754-172.17.0.10-1597460084501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-68aa0b79-7ffb-49bc-85a1-7c247b46baa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-46cce6d4-3b72-4f48-9d20-0d7ea8222755,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-141dd4d1-3b00-4284-9895-72029a16d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-1b4b49b4-bfa5-4e51-ba75-72302e7e02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-415478e1-3527-47b6-84ff-a9f88d1dd3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-fec49105-d3b7-4211-94a4-b3b2eda2d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-71930dba-aebc-4682-8250-f68ad05637f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-5d397524-dbed-4c1f-bd80-c4f16120a30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541167067-172.17.0.10-1597460143215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-21f8d093-7dc8-4aac-971b-701ac5d09369,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-ddf6e5b6-f226-4b13-90eb-dba50e2b7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-e26b04c5-95c2-4b3a-b554-94b942a8ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-a4cf6b46-51fa-4485-b91d-5c18276c27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-36b47fe6-107e-4772-a681-46c273991665,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-d0eb6b02-9a40-454d-a8a4-eb87c0660a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-d00f2a88-74cf-4f8c-b0a8-d11cbf8fc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-ef651dc6-31f5-4aab-9378-5c5f7504c84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541167067-172.17.0.10-1597460143215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-21f8d093-7dc8-4aac-971b-701ac5d09369,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-ddf6e5b6-f226-4b13-90eb-dba50e2b7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-e26b04c5-95c2-4b3a-b554-94b942a8ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-a4cf6b46-51fa-4485-b91d-5c18276c27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-36b47fe6-107e-4772-a681-46c273991665,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-d0eb6b02-9a40-454d-a8a4-eb87c0660a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-d00f2a88-74cf-4f8c-b0a8-d11cbf8fc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-ef651dc6-31f5-4aab-9378-5c5f7504c84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224000159-172.17.0.10-1597460278828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-ac690f08-f598-40bb-902d-58cc41e7ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-3208f0f6-de97-49ed-bdf5-4483ee64746e,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-badbc8d7-dc82-46a6-ab99-7be813100992,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-224b7158-04b1-4f23-b439-4da48635d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-0869e50f-d756-447c-a72c-1feb7e0bde13,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-2a02cdff-8685-4ee8-bf08-7874682ee756,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-7696b635-b13f-42b0-bb6d-0b271df1e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-914fab51-b0d9-449e-94fa-072babe20d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224000159-172.17.0.10-1597460278828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-ac690f08-f598-40bb-902d-58cc41e7ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-3208f0f6-de97-49ed-bdf5-4483ee64746e,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-badbc8d7-dc82-46a6-ab99-7be813100992,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-224b7158-04b1-4f23-b439-4da48635d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-0869e50f-d756-447c-a72c-1feb7e0bde13,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-2a02cdff-8685-4ee8-bf08-7874682ee756,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-7696b635-b13f-42b0-bb6d-0b271df1e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-914fab51-b0d9-449e-94fa-072babe20d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009748766-172.17.0.10-1597460410608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-50e3e4b7-f11b-4649-8779-27b9eb49d520,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-5f06083e-fe17-4447-931f-6cd586816a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-b0df6886-7b7e-4c1c-babc-b96a2dadccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-88dca911-a971-4a47-8548-9373924f37b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-e92518ff-d3c8-48bd-9e92-8119ec401f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-144b9af0-2f07-4871-bc24-8f37b250edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-78a77e57-b82e-4ab0-b17d-dd93b053adf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-0ba75bbd-f54a-4db5-8f2a-3987b247e073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009748766-172.17.0.10-1597460410608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-50e3e4b7-f11b-4649-8779-27b9eb49d520,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-5f06083e-fe17-4447-931f-6cd586816a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-b0df6886-7b7e-4c1c-babc-b96a2dadccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-88dca911-a971-4a47-8548-9373924f37b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-e92518ff-d3c8-48bd-9e92-8119ec401f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-144b9af0-2f07-4871-bc24-8f37b250edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-78a77e57-b82e-4ab0-b17d-dd93b053adf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-0ba75bbd-f54a-4db5-8f2a-3987b247e073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565110107-172.17.0.10-1597460823807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-ab8c976b-cc87-478e-97ca-d1717a91b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-a68f6f5d-1b7c-4036-8533-9c9aecfe0f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f8c0cf9a-6106-41f7-a013-2946e5717b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-369b7baa-41e2-4286-941f-e630bea1e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-60140482-2dd5-4d7e-984d-f7df44a0efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-9c6589a9-20a5-452e-a880-88cc3d8237b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d87bb4e0-d935-4466-ab54-65036e10348f,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c86283d6-3607-40d0-bb5f-038fe2e99712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565110107-172.17.0.10-1597460823807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-ab8c976b-cc87-478e-97ca-d1717a91b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-a68f6f5d-1b7c-4036-8533-9c9aecfe0f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f8c0cf9a-6106-41f7-a013-2946e5717b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-369b7baa-41e2-4286-941f-e630bea1e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-60140482-2dd5-4d7e-984d-f7df44a0efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-9c6589a9-20a5-452e-a880-88cc3d8237b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d87bb4e0-d935-4466-ab54-65036e10348f,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c86283d6-3607-40d0-bb5f-038fe2e99712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779438034-172.17.0.10-1597460874985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46493,DS-90d06a3d-634d-4c7d-9f9c-6916ed461f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-caa0c1ba-3e9c-4993-9a1b-c958a7652a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-add533cb-3b92-4582-9274-b6fe0525c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d072a363-6948-460c-af1e-d05b6a1babf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-3e5bb08c-fb6d-49c9-9d20-3346332381bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3604b7fa-29e9-4cfd-901f-2a7c8243ebb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-a25373b8-b8de-4205-9f9c-c7819cf57d42,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-87e9c1b0-fcb1-4bc5-a418-d8077f8bd65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779438034-172.17.0.10-1597460874985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46493,DS-90d06a3d-634d-4c7d-9f9c-6916ed461f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-caa0c1ba-3e9c-4993-9a1b-c958a7652a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-add533cb-3b92-4582-9274-b6fe0525c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d072a363-6948-460c-af1e-d05b6a1babf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-3e5bb08c-fb6d-49c9-9d20-3346332381bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3604b7fa-29e9-4cfd-901f-2a7c8243ebb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-a25373b8-b8de-4205-9f9c-c7819cf57d42,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-87e9c1b0-fcb1-4bc5-a418-d8077f8bd65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218074032-172.17.0.10-1597461207143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43439,DS-0ff16951-ea8a-4046-b472-c61078bdc635,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-eaf14699-2941-44d3-a004-81aebbee3239,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7c289376-e3c2-45d3-82cf-945b24ccced0,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-3cf5ade0-08db-4ff9-bf82-dd1a93c5a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-e724daa5-aa60-42ef-a5b6-f88a0fc6aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1bb7a8d2-fd1d-4aa5-aae0-ac0f8f9cca31,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-bd8f1726-6556-4c97-9fea-901d4318f373,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-d61ae5df-8509-4ad0-84c1-5f1350408358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218074032-172.17.0.10-1597461207143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43439,DS-0ff16951-ea8a-4046-b472-c61078bdc635,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-eaf14699-2941-44d3-a004-81aebbee3239,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7c289376-e3c2-45d3-82cf-945b24ccced0,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-3cf5ade0-08db-4ff9-bf82-dd1a93c5a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-e724daa5-aa60-42ef-a5b6-f88a0fc6aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1bb7a8d2-fd1d-4aa5-aae0-ac0f8f9cca31,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-bd8f1726-6556-4c97-9fea-901d4318f373,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-d61ae5df-8509-4ad0-84c1-5f1350408358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872815540-172.17.0.10-1597461528235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39769,DS-786b2e44-3b0e-4521-989c-205d0856dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-52057cf4-58ec-4be2-870e-96e6e434ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-347db329-8f02-4f12-ac03-752d7dcfbbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-ec7d45c2-42a6-4441-ae69-175d488ef104,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-4e164eff-42c5-4277-90f5-8c15dfd1b162,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-2ada7b11-691a-4280-8d19-87ed99f95402,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-d25053e7-259e-4f2c-b5fc-d3ba7a2cb692,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-0b24f818-5647-4434-9566-c499c872a6e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872815540-172.17.0.10-1597461528235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39769,DS-786b2e44-3b0e-4521-989c-205d0856dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-52057cf4-58ec-4be2-870e-96e6e434ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-347db329-8f02-4f12-ac03-752d7dcfbbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-ec7d45c2-42a6-4441-ae69-175d488ef104,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-4e164eff-42c5-4277-90f5-8c15dfd1b162,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-2ada7b11-691a-4280-8d19-87ed99f95402,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-d25053e7-259e-4f2c-b5fc-d3ba7a2cb692,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-0b24f818-5647-4434-9566-c499c872a6e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292324143-172.17.0.10-1597462432287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-a4b09c0f-4dff-470f-839a-e0a49df4e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-3e6d159d-b770-42ce-8899-39c3fb44a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-abbf84ce-b9cb-4b35-940f-4961e153bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4996888e-5139-4765-924f-5e02c9a3d116,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-1d65ea85-ec9c-4212-b253-daf7ef6ba45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-b7d02f2b-6936-4ff8-822b-fb3b12e79d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-8e2c06aa-b48e-4d94-a156-a87d0a35324c,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-aa473b07-60d5-465c-8b4b-bae042c0a74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292324143-172.17.0.10-1597462432287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-a4b09c0f-4dff-470f-839a-e0a49df4e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-3e6d159d-b770-42ce-8899-39c3fb44a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-abbf84ce-b9cb-4b35-940f-4961e153bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4996888e-5139-4765-924f-5e02c9a3d116,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-1d65ea85-ec9c-4212-b253-daf7ef6ba45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-b7d02f2b-6936-4ff8-822b-fb3b12e79d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-8e2c06aa-b48e-4d94-a156-a87d0a35324c,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-aa473b07-60d5-465c-8b4b-bae042c0a74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981464310-172.17.0.10-1597462478235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-337134ea-59c0-4db7-b43a-194d312e31fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-27b092d0-150b-4bf0-ad54-c736dbdb06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7ef25074-20b9-4b08-b811-075b51265fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-7b1f3030-858a-4804-898c-7e90866946e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-e05eba7b-8e1b-451c-b2c7-ca7f86b23dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-9ab8a34a-0b2b-452e-b8cb-b3da86594107,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ca884148-5429-43ee-bb6e-513d10efd328,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-bd5ec056-8d1e-4228-b6b5-ea14af47a006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981464310-172.17.0.10-1597462478235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-337134ea-59c0-4db7-b43a-194d312e31fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-27b092d0-150b-4bf0-ad54-c736dbdb06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7ef25074-20b9-4b08-b811-075b51265fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-7b1f3030-858a-4804-898c-7e90866946e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-e05eba7b-8e1b-451c-b2c7-ca7f86b23dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-9ab8a34a-0b2b-452e-b8cb-b3da86594107,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ca884148-5429-43ee-bb6e-513d10efd328,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-bd5ec056-8d1e-4228-b6b5-ea14af47a006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323409890-172.17.0.10-1597462791550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35787,DS-9fd3796f-bff8-4988-a25f-178f21728bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-3a21bb45-4dd7-4aa1-8e3c-0e1a69434b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c43f8c8b-8c24-4db5-918a-ff2abafa0813,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6f47fc47-684e-43e7-81b2-9c08d5bd04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-1c806256-64cb-4d87-b7e0-ab5a10853d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-28d5cd33-1168-4280-a235-90695587db57,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-667e262e-043c-4eea-8809-bb2739fccbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-56b5c081-cdb7-4c1a-bb1f-d3079d8d37db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323409890-172.17.0.10-1597462791550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35787,DS-9fd3796f-bff8-4988-a25f-178f21728bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-3a21bb45-4dd7-4aa1-8e3c-0e1a69434b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c43f8c8b-8c24-4db5-918a-ff2abafa0813,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6f47fc47-684e-43e7-81b2-9c08d5bd04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-1c806256-64cb-4d87-b7e0-ab5a10853d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-28d5cd33-1168-4280-a235-90695587db57,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-667e262e-043c-4eea-8809-bb2739fccbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-56b5c081-cdb7-4c1a-bb1f-d3079d8d37db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032560347-172.17.0.10-1597463205821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-9728f093-a30c-4e0a-9fe5-9fe54232cf60,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-4e681f3e-3b6d-4ed4-8401-99cddc6127b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-cd04ce15-0096-4209-b7a5-4f549283b346,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ae03329c-075a-4c99-bf1a-2b9534fef1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-17ebf784-ac56-44b3-ab82-05c32ae833a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-60a48e96-175a-4c3b-89bb-2878c73be0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-c528acf2-e968-44e7-bfa1-c3e7e066d420,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-756ee323-2b45-4e78-a01c-ddf4f821bde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032560347-172.17.0.10-1597463205821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-9728f093-a30c-4e0a-9fe5-9fe54232cf60,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-4e681f3e-3b6d-4ed4-8401-99cddc6127b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-cd04ce15-0096-4209-b7a5-4f549283b346,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ae03329c-075a-4c99-bf1a-2b9534fef1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-17ebf784-ac56-44b3-ab82-05c32ae833a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-60a48e96-175a-4c3b-89bb-2878c73be0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-c528acf2-e968-44e7-bfa1-c3e7e066d420,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-756ee323-2b45-4e78-a01c-ddf4f821bde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650401697-172.17.0.10-1597463448440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-79f23e22-4524-4567-b636-272513bf77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-7460372a-6a0d-4571-9c98-5b7332c72dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b66d2fb8-e5db-4266-8f3a-96a6fafde3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-b347d65a-e479-4f4d-94e0-39715e2e0754,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-9029bffa-3176-4c55-8bff-661e1d3105a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-307a421c-44b3-42d2-b62b-db5b731c8634,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-285d86fe-060b-4299-8af0-028c98ca2f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-5d56b21d-9f3e-4ad3-b365-48ae8a8081b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650401697-172.17.0.10-1597463448440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-79f23e22-4524-4567-b636-272513bf77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-7460372a-6a0d-4571-9c98-5b7332c72dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b66d2fb8-e5db-4266-8f3a-96a6fafde3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-b347d65a-e479-4f4d-94e0-39715e2e0754,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-9029bffa-3176-4c55-8bff-661e1d3105a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-307a421c-44b3-42d2-b62b-db5b731c8634,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-285d86fe-060b-4299-8af0-028c98ca2f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-5d56b21d-9f3e-4ad3-b365-48ae8a8081b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514583369-172.17.0.10-1597463493201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44909,DS-68e1fd6f-4bca-4cb0-bbb3-4aae11d8f365,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-7ee0498d-dbdd-4177-a84d-c20beb2e8382,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-c780d86c-9de9-41fb-a8b5-7d8a8c044c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-7120944a-a094-4123-a58d-50025a625d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-ac25e2a6-0fe2-45db-aa6e-1c4f413d9676,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-7f5c1a65-06db-4be0-8cbb-1acfc8866745,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-133c9347-1548-46f3-b7df-09075024e649,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-31dc9111-6d44-47af-a6ba-86f83b2e684b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514583369-172.17.0.10-1597463493201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44909,DS-68e1fd6f-4bca-4cb0-bbb3-4aae11d8f365,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-7ee0498d-dbdd-4177-a84d-c20beb2e8382,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-c780d86c-9de9-41fb-a8b5-7d8a8c044c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-7120944a-a094-4123-a58d-50025a625d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-ac25e2a6-0fe2-45db-aa6e-1c4f413d9676,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-7f5c1a65-06db-4be0-8cbb-1acfc8866745,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-133c9347-1548-46f3-b7df-09075024e649,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-31dc9111-6d44-47af-a6ba-86f83b2e684b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202594596-172.17.0.10-1597463584576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45475,DS-c1534050-b7b1-4e11-94d3-4bf763cd97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-4de85932-e4b8-4f6b-9aa3-11e74d0f9248,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-87f41bbb-480c-4214-8cc9-ebea2975606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-2f48857e-1357-4713-bee1-051c27753ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-e6620adf-e74a-4828-9abd-49916ae574d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ab2a38cb-85aa-4735-8b05-6d5c51f12cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-97a64cd4-468d-45f2-93ca-16bf0e1cbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-7c0e1972-336c-41cc-848d-1ac43b9e9f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202594596-172.17.0.10-1597463584576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45475,DS-c1534050-b7b1-4e11-94d3-4bf763cd97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-4de85932-e4b8-4f6b-9aa3-11e74d0f9248,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-87f41bbb-480c-4214-8cc9-ebea2975606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-2f48857e-1357-4713-bee1-051c27753ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-e6620adf-e74a-4828-9abd-49916ae574d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ab2a38cb-85aa-4735-8b05-6d5c51f12cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-97a64cd4-468d-45f2-93ca-16bf0e1cbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-7c0e1972-336c-41cc-848d-1ac43b9e9f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119997268-172.17.0.10-1597463828082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-e96f0fe5-e578-4e7e-8a0d-111e6f5f608f,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-0d572f6a-59dc-4e83-8116-b305c33c3486,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-82317928-fcc0-4f6b-b3cc-8d2cbb44fece,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b0a51ead-ac0a-46ae-8d41-b358bf1a2386,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-40a442ea-bfa4-44da-beb9-a3cca574d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-05ba1cab-de9e-4abd-b0ff-6570711a52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-98c55375-350b-433f-a424-299185df5976,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-54437359-ae6f-42de-b6df-7dc0ac81c9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119997268-172.17.0.10-1597463828082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-e96f0fe5-e578-4e7e-8a0d-111e6f5f608f,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-0d572f6a-59dc-4e83-8116-b305c33c3486,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-82317928-fcc0-4f6b-b3cc-8d2cbb44fece,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b0a51ead-ac0a-46ae-8d41-b358bf1a2386,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-40a442ea-bfa4-44da-beb9-a3cca574d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-05ba1cab-de9e-4abd-b0ff-6570711a52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-98c55375-350b-433f-a424-299185df5976,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-54437359-ae6f-42de-b6df-7dc0ac81c9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448933802-172.17.0.10-1597463921451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40564,DS-e590ec82-11a5-4a4a-92e3-3543f5cff685,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-03c62322-de4e-4c40-bd44-190b30339265,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-3a99b689-2e12-43f8-9d8d-4b084eda8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-89373310-cbe1-4e79-a905-8c85e4038cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-92425a5e-96e3-4ba3-8214-a3f621294a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-71cf3709-60c7-440b-9f72-bbac6780627d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-f7b3764f-9e7c-4d8a-878b-9747256e9d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-de7513ed-3bc6-4b75-a1fd-354e9c701163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448933802-172.17.0.10-1597463921451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40564,DS-e590ec82-11a5-4a4a-92e3-3543f5cff685,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-03c62322-de4e-4c40-bd44-190b30339265,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-3a99b689-2e12-43f8-9d8d-4b084eda8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-89373310-cbe1-4e79-a905-8c85e4038cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-92425a5e-96e3-4ba3-8214-a3f621294a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-71cf3709-60c7-440b-9f72-bbac6780627d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-f7b3764f-9e7c-4d8a-878b-9747256e9d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-de7513ed-3bc6-4b75-a1fd-354e9c701163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387372101-172.17.0.10-1597464058498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45821,DS-6c4a9b05-f75b-4628-8822-d84b2b75a043,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-9e0406c4-471f-4d55-abe0-44d997509f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-18037efd-e064-4a72-911e-911cdc80730c,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-55df128c-5ce4-48d1-8aa1-311da0206727,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-34415329-71e2-4d4f-a87b-ecec4b81823f,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7395f1f8-1bf3-4576-bbbb-42c1d3f66c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-9fc64ce6-f9c3-49b9-a67c-507ed56e3389,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-757e2abc-a68b-4ac3-9cad-3aaf47c325ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387372101-172.17.0.10-1597464058498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45821,DS-6c4a9b05-f75b-4628-8822-d84b2b75a043,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-9e0406c4-471f-4d55-abe0-44d997509f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-18037efd-e064-4a72-911e-911cdc80730c,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-55df128c-5ce4-48d1-8aa1-311da0206727,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-34415329-71e2-4d4f-a87b-ecec4b81823f,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7395f1f8-1bf3-4576-bbbb-42c1d3f66c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-9fc64ce6-f9c3-49b9-a67c-507ed56e3389,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-757e2abc-a68b-4ac3-9cad-3aaf47c325ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145713605-172.17.0.10-1597464194879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-83dd288e-90c4-40c1-ae2f-6ceb1224e733,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-07202efd-2aaf-4543-8571-aad1ed872c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-eb65ca34-0c27-416c-8f42-101243f598f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f58d80a1-9763-42e8-9eb0-7cbdd58336a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-02619fac-f1e8-455e-9a54-aba008db14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-75c40d30-b896-44bf-acd4-d411d91a3a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-794494bf-8ac0-414e-9e98-841d53528368,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a32d0740-1e4e-4178-b8b6-3bc6346fa91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145713605-172.17.0.10-1597464194879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-83dd288e-90c4-40c1-ae2f-6ceb1224e733,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-07202efd-2aaf-4543-8571-aad1ed872c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-eb65ca34-0c27-416c-8f42-101243f598f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-f58d80a1-9763-42e8-9eb0-7cbdd58336a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-02619fac-f1e8-455e-9a54-aba008db14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-75c40d30-b896-44bf-acd4-d411d91a3a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-794494bf-8ac0-414e-9e98-841d53528368,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a32d0740-1e4e-4178-b8b6-3bc6346fa91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423304875-172.17.0.10-1597464339151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-131939af-4cd0-4cda-9d3b-e967e25c0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9d02656b-c464-4faf-b723-461be0997852,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-809771fc-b1a7-4ef6-9245-3696a958689a,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-b47184e1-4f4c-4b41-815e-1ba2e92b9fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-904bc568-b672-4ef6-b71e-b36a1b5f15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-bb03640b-0d2a-4b6b-b55f-024777aa7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b19b933e-27da-4444-aafd-d2c5533d28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-726f18ae-f45a-4947-aaa5-60a09ec61503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423304875-172.17.0.10-1597464339151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-131939af-4cd0-4cda-9d3b-e967e25c0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9d02656b-c464-4faf-b723-461be0997852,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-809771fc-b1a7-4ef6-9245-3696a958689a,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-b47184e1-4f4c-4b41-815e-1ba2e92b9fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-904bc568-b672-4ef6-b71e-b36a1b5f15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-bb03640b-0d2a-4b6b-b55f-024777aa7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b19b933e-27da-4444-aafd-d2c5533d28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-726f18ae-f45a-4947-aaa5-60a09ec61503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884574928-172.17.0.10-1597464516426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-37dfdc99-d2bb-4f79-bf62-989fd49316d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-5ce93f7d-2069-4763-baa2-323b9a6fb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-936b934e-dd7c-46cd-9776-9681a883032f,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-17f8f8bd-1261-4eaf-9843-51b070f70687,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-5723f04f-0e94-47fe-94a9-17d31be73db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-2c1eaaf7-c677-444a-ae95-2a23cd59c666,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-091a5cb6-319e-4094-8803-25c03cfbd654,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-540655c7-f20f-4588-baf5-bdec1771adb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884574928-172.17.0.10-1597464516426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-37dfdc99-d2bb-4f79-bf62-989fd49316d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-5ce93f7d-2069-4763-baa2-323b9a6fb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-936b934e-dd7c-46cd-9776-9681a883032f,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-17f8f8bd-1261-4eaf-9843-51b070f70687,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-5723f04f-0e94-47fe-94a9-17d31be73db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-2c1eaaf7-c677-444a-ae95-2a23cd59c666,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-091a5cb6-319e-4094-8803-25c03cfbd654,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-540655c7-f20f-4588-baf5-bdec1771adb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696957311-172.17.0.10-1597464614843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-8ac6edf8-d94f-4128-b82c-716365aaa179,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-4d86c1f5-01d1-4bf1-b981-f4f4e5119f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c15f7edc-d018-4e52-9f8e-195f12172abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-b6235cd4-fd7d-41bf-b171-f365fd9e6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4ba286a6-9d6d-4926-b719-206dfb8b0872,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-15f57a92-2182-4adf-a77b-9f8afd71f960,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-dd9a6b57-d7f3-4356-bd61-b29ed7bdda8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-ee1d92c2-c959-428e-8a0c-8c00428e7902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696957311-172.17.0.10-1597464614843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-8ac6edf8-d94f-4128-b82c-716365aaa179,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-4d86c1f5-01d1-4bf1-b981-f4f4e5119f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c15f7edc-d018-4e52-9f8e-195f12172abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-b6235cd4-fd7d-41bf-b171-f365fd9e6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4ba286a6-9d6d-4926-b719-206dfb8b0872,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-15f57a92-2182-4adf-a77b-9f8afd71f960,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-dd9a6b57-d7f3-4356-bd61-b29ed7bdda8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-ee1d92c2-c959-428e-8a0c-8c00428e7902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437714554-172.17.0.10-1597464851341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-7f9b0ffc-134d-45a9-b822-21988235d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-7fc45bf5-9337-4834-a479-f15d409a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-0a964da3-ca5c-4725-a9d0-f7f4333500bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-ee540ec7-3a2e-4514-9dac-b016c999f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-b028e5e3-7d8d-40ac-a97e-9379a7a23552,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-9c92c75e-0499-43cb-8f25-b948211a1399,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-062bfff2-93b5-44a6-83b7-f646903cc350,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-8f82bd13-ba83-45f3-acd1-06ed6ddc8ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437714554-172.17.0.10-1597464851341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-7f9b0ffc-134d-45a9-b822-21988235d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-7fc45bf5-9337-4834-a479-f15d409a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-0a964da3-ca5c-4725-a9d0-f7f4333500bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-ee540ec7-3a2e-4514-9dac-b016c999f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-b028e5e3-7d8d-40ac-a97e-9379a7a23552,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-9c92c75e-0499-43cb-8f25-b948211a1399,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-062bfff2-93b5-44a6-83b7-f646903cc350,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-8f82bd13-ba83-45f3-acd1-06ed6ddc8ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140850336-172.17.0.10-1597465098772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-d233a520-e81e-48d2-852f-5aa1b69de98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-1b1a8fa6-11e5-4ec5-bd78-9eb989446503,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-5886706c-5923-47bd-9002-ee7791254714,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-43ac621e-945e-44cf-8cb9-3f7ddb017ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-ab837b03-c2b1-48a0-a373-bf5c32c16730,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-24a234e7-7de4-4b9d-8d32-d8c406015366,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-d7b46050-8302-4895-89b0-43afab1174c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-489f9843-54dd-4388-80d2-8415aacbcce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140850336-172.17.0.10-1597465098772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-d233a520-e81e-48d2-852f-5aa1b69de98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-1b1a8fa6-11e5-4ec5-bd78-9eb989446503,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-5886706c-5923-47bd-9002-ee7791254714,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-43ac621e-945e-44cf-8cb9-3f7ddb017ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-ab837b03-c2b1-48a0-a373-bf5c32c16730,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-24a234e7-7de4-4b9d-8d32-d8c406015366,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-d7b46050-8302-4895-89b0-43afab1174c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-489f9843-54dd-4388-80d2-8415aacbcce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135661855-172.17.0.10-1597466147178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-ca859437-6e49-4737-8156-e5d7a360b092,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-5602b238-74e1-42a2-973c-8ada61e6fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-f15fe964-a2ec-49f0-9b98-9ec5ebd5248a,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1596bd19-64f1-4b94-8fc8-49b4fec0dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-a2bfb34c-2c48-4319-a278-66e5abf17c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-5d6af8bc-abe0-4703-87e3-17ee1b00560c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-f2b2d9aa-4a27-4d7e-81cf-5c498d18fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-28a0ca29-8de5-4e0a-916c-6d21af0f8fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135661855-172.17.0.10-1597466147178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-ca859437-6e49-4737-8156-e5d7a360b092,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-5602b238-74e1-42a2-973c-8ada61e6fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-f15fe964-a2ec-49f0-9b98-9ec5ebd5248a,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1596bd19-64f1-4b94-8fc8-49b4fec0dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-a2bfb34c-2c48-4319-a278-66e5abf17c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-5d6af8bc-abe0-4703-87e3-17ee1b00560c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-f2b2d9aa-4a27-4d7e-81cf-5c498d18fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-28a0ca29-8de5-4e0a-916c-6d21af0f8fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288950897-172.17.0.10-1597466375993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-a30a0bce-f66a-46b9-90d7-ee7c9320d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7a9b2e36-f311-4b1a-b98a-7160a7a7b910,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0bd9f70d-0f0a-4ce4-9e07-3b1e16a60c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-4acfbb13-0756-4f17-bd5b-982102df9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-4744862c-1323-4aec-9ec2-2902bce00bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-65231f7b-1846-4bb4-b022-27cd1e8e0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-625cbd03-21e0-4cb8-97a2-7a0c7edd1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-396d08ad-b055-4662-9683-8215ac118c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288950897-172.17.0.10-1597466375993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-a30a0bce-f66a-46b9-90d7-ee7c9320d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7a9b2e36-f311-4b1a-b98a-7160a7a7b910,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0bd9f70d-0f0a-4ce4-9e07-3b1e16a60c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-4acfbb13-0756-4f17-bd5b-982102df9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-4744862c-1323-4aec-9ec2-2902bce00bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-65231f7b-1846-4bb4-b022-27cd1e8e0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-625cbd03-21e0-4cb8-97a2-7a0c7edd1ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-396d08ad-b055-4662-9683-8215ac118c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258036829-172.17.0.10-1597466878972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-747ff002-0f48-4829-8e88-9cce3d07678f,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-a25bc53e-989d-4e09-aca5-d065371e7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-93ad4b3d-d138-4f99-9d06-cc25365183b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-fcf2b470-8e55-4f44-a138-d50876351d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ad0b410d-d1c5-4f1b-acdd-3af5205ac5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-a6408f37-8450-4247-b2b4-712e8fd31448,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-c8e711a8-2cf2-4e4f-9001-8e76c335299e,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-a6647f4b-422d-4a2a-a5c6-41649152c6a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258036829-172.17.0.10-1597466878972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-747ff002-0f48-4829-8e88-9cce3d07678f,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-a25bc53e-989d-4e09-aca5-d065371e7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-93ad4b3d-d138-4f99-9d06-cc25365183b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-fcf2b470-8e55-4f44-a138-d50876351d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ad0b410d-d1c5-4f1b-acdd-3af5205ac5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-a6408f37-8450-4247-b2b4-712e8fd31448,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-c8e711a8-2cf2-4e4f-9001-8e76c335299e,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-a6647f4b-422d-4a2a-a5c6-41649152c6a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 6973
