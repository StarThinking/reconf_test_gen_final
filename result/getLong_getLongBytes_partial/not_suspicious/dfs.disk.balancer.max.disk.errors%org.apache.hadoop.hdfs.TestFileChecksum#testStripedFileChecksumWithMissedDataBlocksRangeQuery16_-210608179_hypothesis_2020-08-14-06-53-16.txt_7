reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397936313-172.17.0.18-1597388136511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-3d35c9a2-045e-4395-b718-72f87ac8f201,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-bf0bbb54-cb34-4fe0-aa16-407107062ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-06f3566e-5fee-4de2-8c92-fd79a18a8375,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-31534254-ece1-46da-9711-c187f72197b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a70fb7c9-a1e4-4d44-9c04-e44f2e8aedfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-a03c7fe5-4fe4-4459-836c-21b9da0b4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-a56bf03e-3d1d-4379-90a5-be5fb6611610,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-68a7977b-957b-4544-b386-8c7a8fd1840d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397936313-172.17.0.18-1597388136511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-3d35c9a2-045e-4395-b718-72f87ac8f201,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-bf0bbb54-cb34-4fe0-aa16-407107062ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-06f3566e-5fee-4de2-8c92-fd79a18a8375,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-31534254-ece1-46da-9711-c187f72197b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a70fb7c9-a1e4-4d44-9c04-e44f2e8aedfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-a03c7fe5-4fe4-4459-836c-21b9da0b4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-a56bf03e-3d1d-4379-90a5-be5fb6611610,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-68a7977b-957b-4544-b386-8c7a8fd1840d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528522226-172.17.0.18-1597388285577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-d272cc83-ea45-445f-b178-d4ffa33b5859,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-e8b69b91-e95c-481f-8604-29d50d973575,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-3055bc71-f941-4c1d-8c48-21c18cc0849f,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-9dd111b9-c413-4598-a3db-aedfc21a4979,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-fff8fb5d-1ba3-49db-8464-ae24bef8c0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-fa2a16f7-68b8-4194-b117-5816129e1066,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-225dcc62-2962-4acf-a223-eea06219bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-d08861c4-69ec-43cf-bf26-8cb91d7be402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528522226-172.17.0.18-1597388285577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-d272cc83-ea45-445f-b178-d4ffa33b5859,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-e8b69b91-e95c-481f-8604-29d50d973575,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-3055bc71-f941-4c1d-8c48-21c18cc0849f,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-9dd111b9-c413-4598-a3db-aedfc21a4979,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-fff8fb5d-1ba3-49db-8464-ae24bef8c0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-fa2a16f7-68b8-4194-b117-5816129e1066,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-225dcc62-2962-4acf-a223-eea06219bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-d08861c4-69ec-43cf-bf26-8cb91d7be402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431762754-172.17.0.18-1597388381493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-66db6f33-e926-4344-87bc-863f1b04995a,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-35ce1bab-aee5-41ae-9212-6060503f6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-150603cb-7b0a-4ee6-bc7b-e2ac84feb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-b9fc6a68-a7f7-4c3c-9471-59b0a1df7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-13fae532-3a9d-4f69-a1af-465f3cfa99eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-703a6c41-eaf3-48fb-a6ef-02b9d46fe8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-e028eb64-fecc-42df-b2fc-20619ce85c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-0335fdc1-7175-4a5b-8839-2af3851a7fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431762754-172.17.0.18-1597388381493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-66db6f33-e926-4344-87bc-863f1b04995a,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-35ce1bab-aee5-41ae-9212-6060503f6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-150603cb-7b0a-4ee6-bc7b-e2ac84feb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-b9fc6a68-a7f7-4c3c-9471-59b0a1df7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-13fae532-3a9d-4f69-a1af-465f3cfa99eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-703a6c41-eaf3-48fb-a6ef-02b9d46fe8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-e028eb64-fecc-42df-b2fc-20619ce85c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-0335fdc1-7175-4a5b-8839-2af3851a7fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88414262-172.17.0.18-1597388650129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-3210fadb-7578-47d9-8f60-a9b3c719f4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-89ddcd8d-08eb-496e-8d1d-d18878621edc,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-f7a80b90-90af-4d27-8364-cc4cc77999b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-38a9d9df-a4d0-41e7-b43c-0587aef04f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d10de4d1-35ab-4392-b2aa-446cb280e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-81c50553-acae-4884-ab92-30d9f24d1f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-536ad19e-e712-4886-8d24-cc31beb36efa,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-f8e1d03c-bf5f-4ca6-bfa1-2d997617513b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88414262-172.17.0.18-1597388650129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-3210fadb-7578-47d9-8f60-a9b3c719f4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-89ddcd8d-08eb-496e-8d1d-d18878621edc,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-f7a80b90-90af-4d27-8364-cc4cc77999b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-38a9d9df-a4d0-41e7-b43c-0587aef04f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d10de4d1-35ab-4392-b2aa-446cb280e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-81c50553-acae-4884-ab92-30d9f24d1f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-536ad19e-e712-4886-8d24-cc31beb36efa,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-f8e1d03c-bf5f-4ca6-bfa1-2d997617513b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759599365-172.17.0.18-1597388925654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-7b0daa03-3e97-4283-a490-eac5ac152584,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-e95abadf-f171-4bea-94a3-220d8c16602a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-27524a96-3ec0-4b6d-8f1c-c73c0cd18f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-621723c6-fe74-4b20-af32-5c438fc1021b,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-cdfab2ca-64a3-424e-914c-6eec8394d936,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-394f7650-1e61-4740-b09d-d5a09f670ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-5daaee69-9e04-402a-b6e4-f6072666c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-638df3f2-3c5e-48ec-ba48-8314ec27c878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759599365-172.17.0.18-1597388925654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-7b0daa03-3e97-4283-a490-eac5ac152584,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-e95abadf-f171-4bea-94a3-220d8c16602a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-27524a96-3ec0-4b6d-8f1c-c73c0cd18f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-621723c6-fe74-4b20-af32-5c438fc1021b,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-cdfab2ca-64a3-424e-914c-6eec8394d936,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-394f7650-1e61-4740-b09d-d5a09f670ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-5daaee69-9e04-402a-b6e4-f6072666c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-638df3f2-3c5e-48ec-ba48-8314ec27c878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756933986-172.17.0.18-1597389369974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-deda245d-1307-4cca-a5ae-92c357fcb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-3c3fdded-622b-4ad2-b1af-245d2d55ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-74601d89-5d35-496f-9969-44cea9695a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-c7b12739-fe2f-4430-9d3d-474dda224927,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-ae2a110a-40e4-440f-be64-967c02145c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-0df4989b-b07e-4053-a0fa-f9b615ae975f,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-631e274f-0a60-471c-b1c3-a26d1578dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-22ec9b3e-5811-47fe-bd1f-35efc5f70e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756933986-172.17.0.18-1597389369974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-deda245d-1307-4cca-a5ae-92c357fcb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-3c3fdded-622b-4ad2-b1af-245d2d55ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-74601d89-5d35-496f-9969-44cea9695a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-c7b12739-fe2f-4430-9d3d-474dda224927,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-ae2a110a-40e4-440f-be64-967c02145c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-0df4989b-b07e-4053-a0fa-f9b615ae975f,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-631e274f-0a60-471c-b1c3-a26d1578dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-22ec9b3e-5811-47fe-bd1f-35efc5f70e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80661626-172.17.0.18-1597389420330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33375,DS-d2e8fb07-46db-43a8-b90d-2ff7e700a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a02d5ae7-f5a0-48b6-a475-a2bc4124c809,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-80138538-6a97-4b9e-bc16-3b7aa14cb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e0a1a594-e4d6-4e0c-b51a-cc456598e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-46afab49-f49d-4bd6-97d7-57eb01f10b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-143b9c85-84ee-4673-b492-8f83fa01b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-f247182f-6b09-49d4-9dc0-b9fb59d432d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-909bddd1-09a8-40ca-ae3a-18963174050d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80661626-172.17.0.18-1597389420330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33375,DS-d2e8fb07-46db-43a8-b90d-2ff7e700a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a02d5ae7-f5a0-48b6-a475-a2bc4124c809,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-80138538-6a97-4b9e-bc16-3b7aa14cb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e0a1a594-e4d6-4e0c-b51a-cc456598e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-46afab49-f49d-4bd6-97d7-57eb01f10b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-143b9c85-84ee-4673-b492-8f83fa01b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-f247182f-6b09-49d4-9dc0-b9fb59d432d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-909bddd1-09a8-40ca-ae3a-18963174050d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501577801-172.17.0.18-1597390178747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-ea4ababa-d67f-4691-bcd8-d1f932bdfda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-44e1bd01-46db-4f2b-82b6-e5a74b4146d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-e90ba4b4-628c-4cd0-9ef2-5cd3d52f5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-8c1f47ec-15ac-44e2-aa9c-66fd7897d59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-a735e296-800d-4607-b6ad-988b057cd589,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-1db7fa2b-611f-4e7b-b632-5569288edc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-106a0f03-88f4-42c8-9664-dd20586efaea,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-487ab735-b29c-4f01-bbc2-b3d49efd3fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501577801-172.17.0.18-1597390178747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-ea4ababa-d67f-4691-bcd8-d1f932bdfda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-44e1bd01-46db-4f2b-82b6-e5a74b4146d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-e90ba4b4-628c-4cd0-9ef2-5cd3d52f5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-8c1f47ec-15ac-44e2-aa9c-66fd7897d59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-a735e296-800d-4607-b6ad-988b057cd589,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-1db7fa2b-611f-4e7b-b632-5569288edc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-106a0f03-88f4-42c8-9664-dd20586efaea,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-487ab735-b29c-4f01-bbc2-b3d49efd3fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033043665-172.17.0.18-1597390893483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-be3166df-8290-4898-b9d6-923d88b1ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-7d890e20-565b-4c37-8362-8b56e829ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-ef9afd4c-e504-4a17-b4af-dfb3b1319b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f62beaa0-6faa-4ac4-9e2f-a1e0f371e022,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-fc2412fe-cf62-4d33-9f8b-01f95012d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-85c59982-2fc5-4d60-8b13-405a0f9cd7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-918b46b0-42bc-4654-9d0e-01b80f85f585,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-b2d9599d-e94e-4990-9be1-a83566e529ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033043665-172.17.0.18-1597390893483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-be3166df-8290-4898-b9d6-923d88b1ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-7d890e20-565b-4c37-8362-8b56e829ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-ef9afd4c-e504-4a17-b4af-dfb3b1319b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f62beaa0-6faa-4ac4-9e2f-a1e0f371e022,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-fc2412fe-cf62-4d33-9f8b-01f95012d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-85c59982-2fc5-4d60-8b13-405a0f9cd7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-918b46b0-42bc-4654-9d0e-01b80f85f585,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-b2d9599d-e94e-4990-9be1-a83566e529ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479994297-172.17.0.18-1597391157117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-72a28084-13dc-4237-a47b-7b9408920799,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-42aee655-fff3-46f0-8354-5f067029aac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-0e4bf3a9-a59b-4320-b66f-544845018449,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e45ae315-f7e9-4aa8-b2cf-aba8d1bd09c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-8fb877ea-d076-4994-81b0-f151472c55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-d37ee8a8-46d0-4670-a15b-dcc5bcc24ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-fb758b73-f0d5-43e9-8dd5-c64a697859f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-6592b933-a0f0-423d-944e-8645776ed776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479994297-172.17.0.18-1597391157117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-72a28084-13dc-4237-a47b-7b9408920799,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-42aee655-fff3-46f0-8354-5f067029aac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-0e4bf3a9-a59b-4320-b66f-544845018449,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e45ae315-f7e9-4aa8-b2cf-aba8d1bd09c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-8fb877ea-d076-4994-81b0-f151472c55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-d37ee8a8-46d0-4670-a15b-dcc5bcc24ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-fb758b73-f0d5-43e9-8dd5-c64a697859f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-6592b933-a0f0-423d-944e-8645776ed776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171048952-172.17.0.18-1597391471056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-5e236799-4a82-4017-95cb-0e5785a51f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-9c9cb897-fa17-4418-bb70-f20a84264c89,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-57904bc8-cc60-4480-adfa-e6584d0b15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0f31e9ba-87c0-4f1d-98d4-937289566d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-e243823a-7ffc-4e70-891c-68b17fb98123,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0f9bf13b-6a28-4e39-acb2-7695e7c88752,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-3db842c4-7145-46d2-ad3a-e680e80f1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-e2859ca3-1fde-4562-be80-adbf084ad1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171048952-172.17.0.18-1597391471056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-5e236799-4a82-4017-95cb-0e5785a51f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-9c9cb897-fa17-4418-bb70-f20a84264c89,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-57904bc8-cc60-4480-adfa-e6584d0b15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0f31e9ba-87c0-4f1d-98d4-937289566d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-e243823a-7ffc-4e70-891c-68b17fb98123,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0f9bf13b-6a28-4e39-acb2-7695e7c88752,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-3db842c4-7145-46d2-ad3a-e680e80f1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-e2859ca3-1fde-4562-be80-adbf084ad1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261023168-172.17.0.18-1597391790594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-f935f90b-8e2c-4c6f-afcb-a1fb65a09806,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b59ee418-bc71-465e-9110-082c927facde,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-886f9830-6d0c-43e3-9e25-60b547321ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-056bdffe-069e-4f38-bedc-b8ee8ff2ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-d3f06fcb-be46-48eb-b5ab-eed5cbdc2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-4fc846a5-c333-4c83-ba7c-c0b92dff9051,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-a69df70c-2134-4bfc-ad20-3e55b9488964,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-c7ca2d37-450b-44e5-878c-09510be78abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261023168-172.17.0.18-1597391790594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-f935f90b-8e2c-4c6f-afcb-a1fb65a09806,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b59ee418-bc71-465e-9110-082c927facde,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-886f9830-6d0c-43e3-9e25-60b547321ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-056bdffe-069e-4f38-bedc-b8ee8ff2ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-d3f06fcb-be46-48eb-b5ab-eed5cbdc2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-4fc846a5-c333-4c83-ba7c-c0b92dff9051,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-a69df70c-2134-4bfc-ad20-3e55b9488964,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-c7ca2d37-450b-44e5-878c-09510be78abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188295940-172.17.0.18-1597392198959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-5616a38b-21f0-48c0-b674-9f2305196a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-f5ee38f4-56a0-4109-87ba-bd46b4f3a313,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-beedf5f6-3493-409c-8efe-100906acb8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-fb5c7a35-d1db-417f-9633-0418a7ab0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-b7d22ed9-854f-4ad2-87bc-4ad37a0fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e6160e75-71c0-4efa-a98d-eec5566dc4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-5b47022f-26e9-4303-90d0-e51fa3fb1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-203aa112-0c08-47e0-a49b-742a99dfe42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188295940-172.17.0.18-1597392198959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-5616a38b-21f0-48c0-b674-9f2305196a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-f5ee38f4-56a0-4109-87ba-bd46b4f3a313,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-beedf5f6-3493-409c-8efe-100906acb8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-fb5c7a35-d1db-417f-9633-0418a7ab0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-b7d22ed9-854f-4ad2-87bc-4ad37a0fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e6160e75-71c0-4efa-a98d-eec5566dc4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-5b47022f-26e9-4303-90d0-e51fa3fb1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-203aa112-0c08-47e0-a49b-742a99dfe42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486890908-172.17.0.18-1597392690776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-bedf48d3-629b-4914-af7b-2ea1936c1454,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-705a0e89-e19a-4611-ba2b-24203fa8fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-57a600f6-a2a4-4afc-81c5-0cc8266ebaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-506e132f-e2d6-4c2d-aec4-a69cf9410cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-924ba421-bee3-45b1-888a-26d5542845bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c2df9628-46ec-48ba-8e7f-98f3886ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-d5bc3f4d-c0eb-41d5-a57b-d3cfb7882d27,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-e54bfb8e-2de4-40e5-b141-927bba4b2837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486890908-172.17.0.18-1597392690776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-bedf48d3-629b-4914-af7b-2ea1936c1454,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-705a0e89-e19a-4611-ba2b-24203fa8fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-57a600f6-a2a4-4afc-81c5-0cc8266ebaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-506e132f-e2d6-4c2d-aec4-a69cf9410cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-924ba421-bee3-45b1-888a-26d5542845bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c2df9628-46ec-48ba-8e7f-98f3886ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-d5bc3f4d-c0eb-41d5-a57b-d3cfb7882d27,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-e54bfb8e-2de4-40e5-b141-927bba4b2837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214530070-172.17.0.18-1597392871436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-ab37ec4f-071a-4f13-a444-7b107a669a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-f22a3742-1009-4612-8f0c-b62b28de3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-b0b58891-c568-4491-b5e1-4036d97f4478,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ac5d3b0a-ce46-4fb1-a6e9-1103a0840d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-6ab731bf-07a8-4439-9489-5afcd0b3ba19,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-9a6f1295-bb32-47f1-83a9-3f860ed15345,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-9820c89e-358d-48b9-9b1e-e62c7f02f934,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-25186eb7-f91a-40d4-b100-9602a3bb6cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214530070-172.17.0.18-1597392871436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-ab37ec4f-071a-4f13-a444-7b107a669a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-f22a3742-1009-4612-8f0c-b62b28de3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-b0b58891-c568-4491-b5e1-4036d97f4478,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ac5d3b0a-ce46-4fb1-a6e9-1103a0840d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-6ab731bf-07a8-4439-9489-5afcd0b3ba19,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-9a6f1295-bb32-47f1-83a9-3f860ed15345,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-9820c89e-358d-48b9-9b1e-e62c7f02f934,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-25186eb7-f91a-40d4-b100-9602a3bb6cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680710140-172.17.0.18-1597393333206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-ca59d090-da68-4896-8197-6cec04d1ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-8245db91-e1f9-4ed7-a70e-ac919fa3fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-03851a20-ffa9-45ce-8f19-7271a62fd08e,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-c68a1e0f-c7d1-44fd-a790-2e70f705422c,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-06589d53-d28a-48c6-b998-9f538f57aad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-97602b0b-0a93-4eae-8aa4-d374ff5f786c,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-0c779d21-2545-4dd5-a636-228281b38635,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-65b0e17a-2aab-4152-bc99-fd48d77db447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680710140-172.17.0.18-1597393333206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-ca59d090-da68-4896-8197-6cec04d1ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-8245db91-e1f9-4ed7-a70e-ac919fa3fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-03851a20-ffa9-45ce-8f19-7271a62fd08e,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-c68a1e0f-c7d1-44fd-a790-2e70f705422c,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-06589d53-d28a-48c6-b998-9f538f57aad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-97602b0b-0a93-4eae-8aa4-d374ff5f786c,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-0c779d21-2545-4dd5-a636-228281b38635,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-65b0e17a-2aab-4152-bc99-fd48d77db447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879927505-172.17.0.18-1597393375865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-0ee16cc6-519b-43f8-bf1b-5b3a517c1e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3fc0edd8-f642-4724-b828-46e88c1a4831,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-d296757e-837f-417d-9da1-eb8dfeb1a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-b9546dc6-d75e-4030-8043-d8ba0f162026,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29217908-c363-4166-b7ab-60dfc730b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-a92f5370-f62a-404d-a242-bfee3b438509,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-3f450f0e-e7d1-42c6-9086-ee74bc318b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-6361e508-2f4b-42ec-827c-22fc98d8fff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879927505-172.17.0.18-1597393375865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-0ee16cc6-519b-43f8-bf1b-5b3a517c1e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3fc0edd8-f642-4724-b828-46e88c1a4831,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-d296757e-837f-417d-9da1-eb8dfeb1a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-b9546dc6-d75e-4030-8043-d8ba0f162026,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29217908-c363-4166-b7ab-60dfc730b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-a92f5370-f62a-404d-a242-bfee3b438509,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-3f450f0e-e7d1-42c6-9086-ee74bc318b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-6361e508-2f4b-42ec-827c-22fc98d8fff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558536061-172.17.0.18-1597393746872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-e189b237-752f-41f3-98b1-abc64ee82f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-51530555-d998-4828-9688-a2d5b5fe1292,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-4f90f742-a01e-4519-bc89-18cb52b7687d,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-25e028fd-0a27-421d-90ea-6577d510d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-0eed9b5f-288c-4f1a-9f91-af5293cc4808,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-0257f60a-343b-465d-a2f2-4e470decff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-49dc607e-021a-4c5b-ac0f-f98e90311a66,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8d36b66f-9e06-4e45-b992-e2bf620308fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558536061-172.17.0.18-1597393746872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-e189b237-752f-41f3-98b1-abc64ee82f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-51530555-d998-4828-9688-a2d5b5fe1292,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-4f90f742-a01e-4519-bc89-18cb52b7687d,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-25e028fd-0a27-421d-90ea-6577d510d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-0eed9b5f-288c-4f1a-9f91-af5293cc4808,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-0257f60a-343b-465d-a2f2-4e470decff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-49dc607e-021a-4c5b-ac0f-f98e90311a66,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8d36b66f-9e06-4e45-b992-e2bf620308fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522785296-172.17.0.18-1597394392518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38074,DS-ae33bc85-f00c-4159-9565-3d8d0c79c193,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-b0345cdf-8852-4b8c-bf81-501076fbfc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-06cdde5e-396b-4f31-8aea-94f06abe3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-dc68e748-79ad-43c9-85ba-f06cc1007feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-324a2306-0a6e-4141-aed1-1720f877ff55,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-76092f18-bc28-4ded-97cb-9aed546295e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-401a809b-5389-4775-813b-66a270552e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-adefcaae-8d66-478d-ae79-8fc9b0aa8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522785296-172.17.0.18-1597394392518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38074,DS-ae33bc85-f00c-4159-9565-3d8d0c79c193,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-b0345cdf-8852-4b8c-bf81-501076fbfc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-06cdde5e-396b-4f31-8aea-94f06abe3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-dc68e748-79ad-43c9-85ba-f06cc1007feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-324a2306-0a6e-4141-aed1-1720f877ff55,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-76092f18-bc28-4ded-97cb-9aed546295e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-401a809b-5389-4775-813b-66a270552e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-adefcaae-8d66-478d-ae79-8fc9b0aa8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781481459-172.17.0.18-1597394657900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-82afaec0-3687-457d-8a56-6cf7321f5456,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f2bbb003-a8b9-4f1b-acb6-67e7876e7714,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3370db89-653a-42ae-a197-4a986d83e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-1ec07e72-9bce-4c09-936e-90da5fca91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-db3111c6-15ff-4733-a797-531f2f94c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-621ce0ba-9c9f-4e4a-a2f5-5de2208deaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-81464400-78bd-4bb8-a1b8-88f10851c415,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-839ab71e-71ed-41d4-80d4-6c494f570afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781481459-172.17.0.18-1597394657900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-82afaec0-3687-457d-8a56-6cf7321f5456,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f2bbb003-a8b9-4f1b-acb6-67e7876e7714,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3370db89-653a-42ae-a197-4a986d83e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-1ec07e72-9bce-4c09-936e-90da5fca91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-db3111c6-15ff-4733-a797-531f2f94c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-621ce0ba-9c9f-4e4a-a2f5-5de2208deaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-81464400-78bd-4bb8-a1b8-88f10851c415,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-839ab71e-71ed-41d4-80d4-6c494f570afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6736
