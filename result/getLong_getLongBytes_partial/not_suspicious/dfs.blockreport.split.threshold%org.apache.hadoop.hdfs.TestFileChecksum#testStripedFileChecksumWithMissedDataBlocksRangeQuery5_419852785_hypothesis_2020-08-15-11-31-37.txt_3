reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105008405-172.17.0.2-1597491396163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-80927343-67c0-467c-86fa-8ba7095bb122,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-130e10d7-61d0-4108-8654-6728c7842297,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-f07eadf7-b3cb-4f1b-ba9c-db4964119d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-e735c567-7c2c-476d-9194-1970546e7e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-adc8e6c1-efc6-42b0-b896-ee46fe3dee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-6671faa0-fbf6-43e1-ab64-94b29ee4ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-92d44df4-0c9c-47e2-a04e-b7014b4b7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-845e115c-6418-4ef8-8f1f-c0429d40f3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105008405-172.17.0.2-1597491396163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-80927343-67c0-467c-86fa-8ba7095bb122,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-130e10d7-61d0-4108-8654-6728c7842297,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-f07eadf7-b3cb-4f1b-ba9c-db4964119d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-e735c567-7c2c-476d-9194-1970546e7e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-adc8e6c1-efc6-42b0-b896-ee46fe3dee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-6671faa0-fbf6-43e1-ab64-94b29ee4ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-92d44df4-0c9c-47e2-a04e-b7014b4b7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-845e115c-6418-4ef8-8f1f-c0429d40f3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626019009-172.17.0.2-1597491506067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42463,DS-cc779b2c-8c3d-405c-984c-0dd7200ef1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-da6412ee-b033-40f3-bbc6-983e02497c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-918bda64-594b-4b09-b17f-8c90cce1be39,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-bb764dda-deba-4980-a1b2-ea37b1079ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-4bb322c2-f619-4492-a577-4a8f968da939,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-0a24a576-1565-4e4d-b790-dc9f4b503f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-01120d84-a526-4358-a815-c935ffcfa25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-7200aa74-343a-4428-9ec7-1437df546a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626019009-172.17.0.2-1597491506067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42463,DS-cc779b2c-8c3d-405c-984c-0dd7200ef1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-da6412ee-b033-40f3-bbc6-983e02497c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-918bda64-594b-4b09-b17f-8c90cce1be39,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-bb764dda-deba-4980-a1b2-ea37b1079ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-4bb322c2-f619-4492-a577-4a8f968da939,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-0a24a576-1565-4e4d-b790-dc9f4b503f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-01120d84-a526-4358-a815-c935ffcfa25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-7200aa74-343a-4428-9ec7-1437df546a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860500352-172.17.0.2-1597491831989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-614097af-9eeb-4737-acd0-3d7af20d1524,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-9a4d0693-f8cd-4301-b7a1-0e86657a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-e958401c-2722-4889-b53a-8467aefc76dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-aebcb90f-c6f3-49c0-8450-4c35dc3f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-b385e29c-12fd-419b-895f-d4bfd0e41e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-73ad5a2f-f848-4a50-ab17-735992f0753c,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-2adfa2a2-ec74-4110-a01b-4516766e6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-312a31cc-99ae-4b16-8d45-819ad0baee9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860500352-172.17.0.2-1597491831989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-614097af-9eeb-4737-acd0-3d7af20d1524,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-9a4d0693-f8cd-4301-b7a1-0e86657a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-e958401c-2722-4889-b53a-8467aefc76dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-aebcb90f-c6f3-49c0-8450-4c35dc3f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-b385e29c-12fd-419b-895f-d4bfd0e41e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-73ad5a2f-f848-4a50-ab17-735992f0753c,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-2adfa2a2-ec74-4110-a01b-4516766e6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-312a31cc-99ae-4b16-8d45-819ad0baee9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307860480-172.17.0.2-1597493282414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-ac0aede1-8b02-457f-beaf-fd3c5c18b6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d8c9eb6f-d8b8-4ff3-97e5-789732eb9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-9690d5ab-2898-401e-9f2c-36509baf0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-d42c06b0-c4e6-4843-b0c4-3845e30afc74,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-2954ba6d-b32a-46b6-b912-4bab61df5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-75374486-81e5-4c8e-ac58-52fe849ff4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-d3af6e52-c0b4-45dd-a298-050cc977c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-3f457a1f-07fe-42e0-a778-185a4e027405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307860480-172.17.0.2-1597493282414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-ac0aede1-8b02-457f-beaf-fd3c5c18b6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d8c9eb6f-d8b8-4ff3-97e5-789732eb9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-9690d5ab-2898-401e-9f2c-36509baf0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-d42c06b0-c4e6-4843-b0c4-3845e30afc74,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-2954ba6d-b32a-46b6-b912-4bab61df5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-75374486-81e5-4c8e-ac58-52fe849ff4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-d3af6e52-c0b4-45dd-a298-050cc977c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-3f457a1f-07fe-42e0-a778-185a4e027405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157628602-172.17.0.2-1597493316380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35833,DS-b96ddfde-f53c-4cd7-9f27-d4be37ab041c,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-5ed17dcc-4a71-45cd-b151-1c57d689d07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-c8b58195-26ee-400f-8678-8d4f8443853f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-fb79805d-5911-4af8-a7eb-d251228f25df,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-d5c60307-b4f0-41c0-8a89-8367d4fed1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c76c17c4-1882-4001-a15c-c7d764a8899b,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-0d342779-9355-4a19-87fe-2041d4c98a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-2cb3743e-e50f-4ff6-964b-bfe753f2a8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157628602-172.17.0.2-1597493316380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35833,DS-b96ddfde-f53c-4cd7-9f27-d4be37ab041c,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-5ed17dcc-4a71-45cd-b151-1c57d689d07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-c8b58195-26ee-400f-8678-8d4f8443853f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-fb79805d-5911-4af8-a7eb-d251228f25df,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-d5c60307-b4f0-41c0-8a89-8367d4fed1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c76c17c4-1882-4001-a15c-c7d764a8899b,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-0d342779-9355-4a19-87fe-2041d4c98a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-2cb3743e-e50f-4ff6-964b-bfe753f2a8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410584529-172.17.0.2-1597493516303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-649291f6-8b45-4591-b4b3-7af92369cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-b3b6bcd7-e849-41b3-b6ef-cf0eff1d2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-fb4ee692-f253-4c9a-9d4b-42e281157ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-f04cb630-5897-4600-acf0-e6f32ed5c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-bdb04891-356a-4659-8cf4-1dc74e1c3347,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-48b959e7-ba65-4f36-aa4a-bbfc12460b73,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-51d2e3ee-881e-4495-a988-2641b7e395e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-793c41a9-dc8c-4982-a86a-cd9f301b1a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410584529-172.17.0.2-1597493516303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-649291f6-8b45-4591-b4b3-7af92369cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-b3b6bcd7-e849-41b3-b6ef-cf0eff1d2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-fb4ee692-f253-4c9a-9d4b-42e281157ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-f04cb630-5897-4600-acf0-e6f32ed5c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-bdb04891-356a-4659-8cf4-1dc74e1c3347,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-48b959e7-ba65-4f36-aa4a-bbfc12460b73,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-51d2e3ee-881e-4495-a988-2641b7e395e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-793c41a9-dc8c-4982-a86a-cd9f301b1a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358367823-172.17.0.2-1597493814783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44754,DS-c82591b8-b5b3-4d6d-bd1d-01df9c9ff15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-40127fa0-78dd-428a-9ec5-cd6dbb9e9612,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-36edbedf-d8f8-4a64-845c-c21ad4e53ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-4716d200-4860-4ad5-935f-d708952c7f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-4a3ff192-4edf-4cc7-a524-0f4fc245cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-6f560c90-b06d-4753-9304-d1f49f180027,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-1a7bad1b-cc1e-49c6-9fc3-8496a1912e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-d7c1f70c-8a29-4472-8eba-781c6409dc49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358367823-172.17.0.2-1597493814783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44754,DS-c82591b8-b5b3-4d6d-bd1d-01df9c9ff15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-40127fa0-78dd-428a-9ec5-cd6dbb9e9612,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-36edbedf-d8f8-4a64-845c-c21ad4e53ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-4716d200-4860-4ad5-935f-d708952c7f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-4a3ff192-4edf-4cc7-a524-0f4fc245cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-6f560c90-b06d-4753-9304-d1f49f180027,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-1a7bad1b-cc1e-49c6-9fc3-8496a1912e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-d7c1f70c-8a29-4472-8eba-781c6409dc49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152565041-172.17.0.2-1597493854929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-5a54d148-95bc-4235-a59b-852088e52f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-8e7b5482-0a1d-47e0-bd08-89b8d706193d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-465b67f0-e137-49ab-bd65-498793714ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-ff303674-ed71-4d00-a510-d02c938c504b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-b12b3374-2f16-45fe-8dce-db142d40259a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-87a25c1b-73e9-4c36-a869-0bd0fa3f080f,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-71cdf313-e298-4904-a189-689d41dccffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cb1fa96a-5db0-47e9-82a8-459695a93da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152565041-172.17.0.2-1597493854929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-5a54d148-95bc-4235-a59b-852088e52f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-8e7b5482-0a1d-47e0-bd08-89b8d706193d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-465b67f0-e137-49ab-bd65-498793714ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-ff303674-ed71-4d00-a510-d02c938c504b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-b12b3374-2f16-45fe-8dce-db142d40259a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-87a25c1b-73e9-4c36-a869-0bd0fa3f080f,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-71cdf313-e298-4904-a189-689d41dccffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cb1fa96a-5db0-47e9-82a8-459695a93da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861948222-172.17.0.2-1597494586901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42879,DS-41d8548f-443c-4d5c-b9ae-097196d9671f,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-c3281faf-7573-47f7-aa03-ab727741aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-6a05b785-f91c-444b-b48b-d5c5792c7477,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-74ad096f-42e6-4a5d-9d9b-9e6a6bbecb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-b1747c1d-3994-43ee-9c25-f383f70ba556,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-3582710b-5300-4952-8b01-f4cb74ea9665,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-2dcda66f-2450-4a98-bdc4-8f96ac762b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-1f676a23-568f-419c-8f64-cc26054ccf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861948222-172.17.0.2-1597494586901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42879,DS-41d8548f-443c-4d5c-b9ae-097196d9671f,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-c3281faf-7573-47f7-aa03-ab727741aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-6a05b785-f91c-444b-b48b-d5c5792c7477,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-74ad096f-42e6-4a5d-9d9b-9e6a6bbecb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-b1747c1d-3994-43ee-9c25-f383f70ba556,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-3582710b-5300-4952-8b01-f4cb74ea9665,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-2dcda66f-2450-4a98-bdc4-8f96ac762b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-1f676a23-568f-419c-8f64-cc26054ccf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208645083-172.17.0.2-1597495081652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-35882268-7685-439a-a489-7397af057b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-951b2707-66d2-42e4-8a50-2082cc804b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-5384f40e-04bf-4fd3-970d-0473cd55d0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-23db2cd7-6de8-49f8-bcda-eadda9a9de74,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-28e22e49-d2e2-4917-9102-a9423aee1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-2e781dbd-f0fd-4305-9d55-cc801169af97,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-00dd1b78-9196-40d4-a5d2-4e2dca97d911,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c627c347-d9b3-401f-8190-9784892a706b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208645083-172.17.0.2-1597495081652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-35882268-7685-439a-a489-7397af057b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-951b2707-66d2-42e4-8a50-2082cc804b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-5384f40e-04bf-4fd3-970d-0473cd55d0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-23db2cd7-6de8-49f8-bcda-eadda9a9de74,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-28e22e49-d2e2-4917-9102-a9423aee1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-2e781dbd-f0fd-4305-9d55-cc801169af97,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-00dd1b78-9196-40d4-a5d2-4e2dca97d911,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c627c347-d9b3-401f-8190-9784892a706b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811570676-172.17.0.2-1597495345679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-0d231ebe-b935-47e3-9ee2-3992192a8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-e7b69116-5e8f-4bc5-a683-e97ff54d555f,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-83d57ae1-a561-4d7d-8255-c62bf756321f,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-d3ed524f-05cc-4aae-b123-ad771beeee52,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-a9ebc371-a05a-422c-b850-61c5a902465d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-30658238-5747-42b3-9ce2-87ee17dd064f,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-02a86ba5-c8f3-4b90-bdea-12dc2a42d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-13007ece-6796-49b2-8971-419910f2b9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811570676-172.17.0.2-1597495345679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-0d231ebe-b935-47e3-9ee2-3992192a8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-e7b69116-5e8f-4bc5-a683-e97ff54d555f,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-83d57ae1-a561-4d7d-8255-c62bf756321f,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-d3ed524f-05cc-4aae-b123-ad771beeee52,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-a9ebc371-a05a-422c-b850-61c5a902465d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-30658238-5747-42b3-9ce2-87ee17dd064f,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-02a86ba5-c8f3-4b90-bdea-12dc2a42d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-13007ece-6796-49b2-8971-419910f2b9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243682423-172.17.0.2-1597495680617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-991724b4-3d3c-4fc3-8300-d233b9df5c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-da1783c1-0af6-4b66-a339-b54092b718ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-ca705144-77c2-4f8c-aa12-f1779d61df50,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-58d30eb5-24cb-47e7-bea4-4795db32fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-fda05554-c403-489e-b33c-04a4cbcee966,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-14b7f70b-9947-49ee-85d1-1aa31b5e58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-a9d3fae6-c42b-4ab4-9b88-ae6afe164d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-841dc153-8b9e-4e3f-9d3f-a2dfda09a101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243682423-172.17.0.2-1597495680617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-991724b4-3d3c-4fc3-8300-d233b9df5c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-da1783c1-0af6-4b66-a339-b54092b718ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-ca705144-77c2-4f8c-aa12-f1779d61df50,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-58d30eb5-24cb-47e7-bea4-4795db32fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-fda05554-c403-489e-b33c-04a4cbcee966,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-14b7f70b-9947-49ee-85d1-1aa31b5e58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-a9d3fae6-c42b-4ab4-9b88-ae6afe164d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-841dc153-8b9e-4e3f-9d3f-a2dfda09a101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510468160-172.17.0.2-1597495715532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-8fc63c88-8ad3-4c64-8b3e-d48e84f0e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-2082e33b-151f-4b7b-b678-51bb95f310b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-5f13d295-66c9-47af-b91d-823a54593738,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-655ba4d8-253d-4cca-8366-ec470bc8adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-9680a10a-2bc2-43ab-93e6-977a7f616b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-e7d1e1f6-9573-43bd-bff4-a037c1234be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-6815889e-847f-4280-b0b3-2d5168eb9172,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-0f4593fc-f6d2-4654-9fd4-8f0f062dd522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510468160-172.17.0.2-1597495715532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-8fc63c88-8ad3-4c64-8b3e-d48e84f0e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-2082e33b-151f-4b7b-b678-51bb95f310b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-5f13d295-66c9-47af-b91d-823a54593738,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-655ba4d8-253d-4cca-8366-ec470bc8adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-9680a10a-2bc2-43ab-93e6-977a7f616b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-e7d1e1f6-9573-43bd-bff4-a037c1234be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-6815889e-847f-4280-b0b3-2d5168eb9172,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-0f4593fc-f6d2-4654-9fd4-8f0f062dd522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217780314-172.17.0.2-1597495906178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-e5e5c9b4-8bc7-4bdb-b113-eb20fadcde63,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-74198eaa-0b13-4646-8d3d-1d7ff5494737,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-d1c7dc17-4cf8-4882-babd-cb988492e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-fe88d754-ab55-4994-b2b0-58975b75428b,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-6bc3239c-602b-4a86-8681-45b87861c934,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-065e0508-b2bd-49c5-9b4a-e42c4c2bf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e15ea33a-7613-453c-9303-2eb604f5e07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-1a0d4a41-fa95-433a-99d2-3d780141d6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217780314-172.17.0.2-1597495906178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-e5e5c9b4-8bc7-4bdb-b113-eb20fadcde63,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-74198eaa-0b13-4646-8d3d-1d7ff5494737,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-d1c7dc17-4cf8-4882-babd-cb988492e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-fe88d754-ab55-4994-b2b0-58975b75428b,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-6bc3239c-602b-4a86-8681-45b87861c934,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-065e0508-b2bd-49c5-9b4a-e42c4c2bf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e15ea33a-7613-453c-9303-2eb604f5e07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-1a0d4a41-fa95-433a-99d2-3d780141d6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 2
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602695563-172.17.0.2-1597496015479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40751,DS-910d0d2f-088c-4358-a3c2-bd2788cac614,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c1131e87-96ac-4427-b1a5-0ea1ba917b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-9c483e20-f816-4429-937e-d2565efd4749,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-e02d8fdd-3e65-4f32-ac5f-6bc66ba91dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-4272417d-ac16-4ab5-ac73-e50dad7236d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-748fe498-de12-484d-94a5-0d7db177c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-734e8418-8def-4ad5-a0fd-4ab1aaac587d,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-785900d7-93e9-4f34-8cc1-094cbb581375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602695563-172.17.0.2-1597496015479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40751,DS-910d0d2f-088c-4358-a3c2-bd2788cac614,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c1131e87-96ac-4427-b1a5-0ea1ba917b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-9c483e20-f816-4429-937e-d2565efd4749,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-e02d8fdd-3e65-4f32-ac5f-6bc66ba91dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-4272417d-ac16-4ab5-ac73-e50dad7236d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-748fe498-de12-484d-94a5-0d7db177c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-734e8418-8def-4ad5-a0fd-4ab1aaac587d,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-785900d7-93e9-4f34-8cc1-094cbb581375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5637
