reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856408572-172.17.0.5-1597671941994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-48a5b2dc-8a0e-48d9-9b70-aba4aa7a9193,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-31abd375-9b46-4e2a-96dc-f9ace1d63787,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-8320e83f-0ad9-437a-96dc-be5ab9b387d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-2d3ec6ad-7a76-43e8-8c84-8eaab5904f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-4d20ddc2-f740-4359-b204-6c18e050666f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-8140d37e-068f-4ab6-818b-25f8337a8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-738d6759-86a2-401e-82f9-18fbc062ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-2a1384ef-62c7-4331-a8e1-b0ae10afa116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856408572-172.17.0.5-1597671941994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-48a5b2dc-8a0e-48d9-9b70-aba4aa7a9193,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-31abd375-9b46-4e2a-96dc-f9ace1d63787,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-8320e83f-0ad9-437a-96dc-be5ab9b387d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-2d3ec6ad-7a76-43e8-8c84-8eaab5904f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-4d20ddc2-f740-4359-b204-6c18e050666f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-8140d37e-068f-4ab6-818b-25f8337a8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-738d6759-86a2-401e-82f9-18fbc062ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-2a1384ef-62c7-4331-a8e1-b0ae10afa116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950352919-172.17.0.5-1597672245242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36440,DS-2fa8d5e0-94be-4369-b0ee-9fb88f060aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-fda13558-0020-44d1-b903-aaad85b20618,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-a4e745b6-d5b8-4b2e-8662-ec886fa0efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-01ac9f42-0ef2-4113-9cd6-ffd538c7dc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-1986bfdb-cef9-4758-b5f8-00405d94767d,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-f27e453b-ce62-4391-b433-2e3b7f6252fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-bbc20a98-d186-442c-a727-612f5039c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-d2c649f7-93b5-48f1-a0e0-655847c29772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950352919-172.17.0.5-1597672245242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36440,DS-2fa8d5e0-94be-4369-b0ee-9fb88f060aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-fda13558-0020-44d1-b903-aaad85b20618,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-a4e745b6-d5b8-4b2e-8662-ec886fa0efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-01ac9f42-0ef2-4113-9cd6-ffd538c7dc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-1986bfdb-cef9-4758-b5f8-00405d94767d,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-f27e453b-ce62-4391-b433-2e3b7f6252fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-bbc20a98-d186-442c-a727-612f5039c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-d2c649f7-93b5-48f1-a0e0-655847c29772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518197802-172.17.0.5-1597672975039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-0222d5f8-8dcf-4422-89eb-227f62c9928f,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-16edfb53-ba5e-4d6f-a48b-bee998878e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-d71a4be3-f41b-4296-a56e-071b58a0b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-ff758b61-29c3-4103-bfe5-e95c2e8f1505,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-e1cbfdbe-08f0-46cb-b16b-0ac340a88473,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-39079973-e10b-4b49-9086-41394d9d03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ae26820b-940d-48e5-b317-5a47c352d50a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-34ec7344-4bd8-462d-84b3-ea59602a94b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518197802-172.17.0.5-1597672975039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-0222d5f8-8dcf-4422-89eb-227f62c9928f,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-16edfb53-ba5e-4d6f-a48b-bee998878e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-d71a4be3-f41b-4296-a56e-071b58a0b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-ff758b61-29c3-4103-bfe5-e95c2e8f1505,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-e1cbfdbe-08f0-46cb-b16b-0ac340a88473,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-39079973-e10b-4b49-9086-41394d9d03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ae26820b-940d-48e5-b317-5a47c352d50a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-34ec7344-4bd8-462d-84b3-ea59602a94b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828425762-172.17.0.5-1597673050730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-e62079ad-1677-4be8-9b53-79e2a8ee6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-f64772d4-a412-418e-9e90-1cfc5c0e7797,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-04c2933c-65e9-4138-8687-b16e21e55c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-04e19233-465f-455d-b464-ddb3333452bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-956c4e61-cfcf-454a-8a43-80658dd932d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b18ee79f-7e54-4a69-aef2-03948058af37,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e6721643-44fa-414f-aa2c-a1984e27c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-445c4193-9e81-41be-b92d-afcfb13467e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828425762-172.17.0.5-1597673050730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-e62079ad-1677-4be8-9b53-79e2a8ee6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-f64772d4-a412-418e-9e90-1cfc5c0e7797,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-04c2933c-65e9-4138-8687-b16e21e55c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-04e19233-465f-455d-b464-ddb3333452bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-956c4e61-cfcf-454a-8a43-80658dd932d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b18ee79f-7e54-4a69-aef2-03948058af37,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e6721643-44fa-414f-aa2c-a1984e27c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-445c4193-9e81-41be-b92d-afcfb13467e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336569485-172.17.0.5-1597673649468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-64963199-d412-4a92-80b9-e8404caf912d,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-0ee681af-5bce-490e-9762-0e3d3f7eb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-54d97df9-ca9e-4a63-8a92-41c05c91dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-93e2b2cd-0551-4ac6-a729-397d12d37a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-a362ef6f-22ed-4af5-baea-a20166d8887b,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-58de0f0c-55ab-492d-9f93-b3fb1bfeecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-d1a81f6c-2554-4d33-8936-de8b3032f881,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-bc7b43b7-a27b-49b9-ba2b-e61a32084f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336569485-172.17.0.5-1597673649468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-64963199-d412-4a92-80b9-e8404caf912d,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-0ee681af-5bce-490e-9762-0e3d3f7eb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-54d97df9-ca9e-4a63-8a92-41c05c91dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-93e2b2cd-0551-4ac6-a729-397d12d37a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-a362ef6f-22ed-4af5-baea-a20166d8887b,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-58de0f0c-55ab-492d-9f93-b3fb1bfeecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-d1a81f6c-2554-4d33-8936-de8b3032f881,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-bc7b43b7-a27b-49b9-ba2b-e61a32084f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46688483-172.17.0.5-1597674196462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45792,DS-a6822f45-9be3-40bc-8ea3-244273968001,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-c205e8c4-8188-491b-afde-0e1151b0fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-f41e607c-642b-4448-ae97-e292869b61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b4d6f8f1-8e6f-4438-a20d-443012dc4687,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-c3d573c7-6c23-4154-9f9f-b3c4100a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-8cb565c2-6cf3-4ae2-a8b4-2dd3dbe78ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-00510fcd-fbe4-4f47-96b6-88e4250d3286,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-6930f1e5-c2bb-485c-b748-682dd32dfb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46688483-172.17.0.5-1597674196462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45792,DS-a6822f45-9be3-40bc-8ea3-244273968001,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-c205e8c4-8188-491b-afde-0e1151b0fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-f41e607c-642b-4448-ae97-e292869b61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b4d6f8f1-8e6f-4438-a20d-443012dc4687,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-c3d573c7-6c23-4154-9f9f-b3c4100a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-8cb565c2-6cf3-4ae2-a8b4-2dd3dbe78ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-00510fcd-fbe4-4f47-96b6-88e4250d3286,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-6930f1e5-c2bb-485c-b748-682dd32dfb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120800245-172.17.0.5-1597674837385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-b9fcc955-f5d5-4a9c-ad8a-ac0d51b3cadc,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-94890a12-1827-42be-984f-f6d5c79f4143,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-73784abb-7172-40d7-ab00-57953c9957eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-98ab3d48-fa43-45ee-84ad-d39b0c5fa5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-39a64dc1-75c6-4915-888c-7492bcd165a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-fbedce95-e1e6-41ea-8da1-f361194b14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-dd1512f2-e26b-45a5-9154-73144a1278a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-db6dbb44-eb9c-44a9-82f5-9e83b4aa5912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120800245-172.17.0.5-1597674837385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-b9fcc955-f5d5-4a9c-ad8a-ac0d51b3cadc,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-94890a12-1827-42be-984f-f6d5c79f4143,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-73784abb-7172-40d7-ab00-57953c9957eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-98ab3d48-fa43-45ee-84ad-d39b0c5fa5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-39a64dc1-75c6-4915-888c-7492bcd165a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-fbedce95-e1e6-41ea-8da1-f361194b14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-dd1512f2-e26b-45a5-9154-73144a1278a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-db6dbb44-eb9c-44a9-82f5-9e83b4aa5912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457807754-172.17.0.5-1597675935978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-42cd09ac-9eeb-4926-a9f6-c09e470cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-4e6db58f-7335-418d-b758-cabb5bee786c,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-248d95f8-469c-4758-a58c-39f69f4d4896,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-41ed9441-2025-40f2-8161-52d06694b921,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ba94eb6f-de0a-4e8f-be84-bde3a8331c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-b5e92baa-d4c2-4fc3-8bfe-e1fc334d035f,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-842ea2ea-0ddf-45e3-a4bf-8756228266df,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e4c20a0a-f689-4037-a03e-829f270ab7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457807754-172.17.0.5-1597675935978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-42cd09ac-9eeb-4926-a9f6-c09e470cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-4e6db58f-7335-418d-b758-cabb5bee786c,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-248d95f8-469c-4758-a58c-39f69f4d4896,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-41ed9441-2025-40f2-8161-52d06694b921,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ba94eb6f-de0a-4e8f-be84-bde3a8331c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-b5e92baa-d4c2-4fc3-8bfe-e1fc334d035f,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-842ea2ea-0ddf-45e3-a4bf-8756228266df,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e4c20a0a-f689-4037-a03e-829f270ab7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110801943-172.17.0.5-1597676009197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41894,DS-5da39e3d-54fb-4b68-900d-54eeda73cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-7d3d078d-9322-4cfc-922e-6873195f6840,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-ff096970-c8f5-4954-b19a-8bc876224eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-66ead851-3277-4dfe-a3ca-0da25e145c44,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-33c82eca-bad4-4d7a-8fd2-1b85c316454b,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-21e238cc-8a03-4865-9188-43ede7298a09,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-903c0aec-da8c-48a5-9534-137ab6ad4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-4b3928ab-ad0a-4aee-822d-bea19295299c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110801943-172.17.0.5-1597676009197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41894,DS-5da39e3d-54fb-4b68-900d-54eeda73cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-7d3d078d-9322-4cfc-922e-6873195f6840,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-ff096970-c8f5-4954-b19a-8bc876224eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-66ead851-3277-4dfe-a3ca-0da25e145c44,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-33c82eca-bad4-4d7a-8fd2-1b85c316454b,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-21e238cc-8a03-4865-9188-43ede7298a09,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-903c0aec-da8c-48a5-9534-137ab6ad4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-4b3928ab-ad0a-4aee-822d-bea19295299c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764814353-172.17.0.5-1597676071352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-4b14a5be-c4fb-4789-8781-7a34f99018a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-683c4bb7-363c-440d-bfc2-bc2912e5390b,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-1525aaee-a9a5-43d0-9704-58f069d7ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-e8b95cdd-cf23-4d5b-99e5-cc8858e836e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-b0bc2e17-ffcf-4adb-927e-3d1eb9bb5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5aa6febc-7507-4cf4-9e3f-0ad05f6bf9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-822afeaa-2e0b-4f23-9ce3-637352201fac,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c970d654-f430-4338-87ef-fcf8a2d64074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764814353-172.17.0.5-1597676071352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-4b14a5be-c4fb-4789-8781-7a34f99018a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-683c4bb7-363c-440d-bfc2-bc2912e5390b,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-1525aaee-a9a5-43d0-9704-58f069d7ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-e8b95cdd-cf23-4d5b-99e5-cc8858e836e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-b0bc2e17-ffcf-4adb-927e-3d1eb9bb5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5aa6febc-7507-4cf4-9e3f-0ad05f6bf9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-822afeaa-2e0b-4f23-9ce3-637352201fac,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c970d654-f430-4338-87ef-fcf8a2d64074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234560101-172.17.0.5-1597676483058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-40e4ad8c-872b-4ed9-9e00-9701ce1804f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-97153589-bdd2-4e1f-8747-a97e030811b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-6d057a9e-8cbd-42f7-81db-24b396b5f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-301d1490-2f93-48be-ac6f-286f853a3989,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-a4b51834-98ba-4b46-867b-da6e7794d6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-a403bc13-f233-4b1b-be19-265bcf31d3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-5d2635c7-fd08-4366-bb3f-8cf62fc92a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-07a405e6-f4a2-4227-a991-03f80d6a035a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234560101-172.17.0.5-1597676483058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-40e4ad8c-872b-4ed9-9e00-9701ce1804f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-97153589-bdd2-4e1f-8747-a97e030811b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-6d057a9e-8cbd-42f7-81db-24b396b5f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-301d1490-2f93-48be-ac6f-286f853a3989,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-a4b51834-98ba-4b46-867b-da6e7794d6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-a403bc13-f233-4b1b-be19-265bcf31d3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-5d2635c7-fd08-4366-bb3f-8cf62fc92a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-07a405e6-f4a2-4227-a991-03f80d6a035a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137987172-172.17.0.5-1597676973015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-da8e453e-0ae4-439c-85a6-74338e737940,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-f63c6d2a-0bd3-4623-94be-6022cd9c0580,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-ce19f8e7-97e4-4549-a61f-bb2c4a7b113f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-6fb2b7b6-9bac-46f8-baf0-1f537ba22aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-a4171484-1da6-4785-b816-a0e58e3f355a,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-f860f404-918c-4643-a07d-32f52e05f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-291a341a-0a24-40c4-9e75-997329119e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-048284d4-78d3-49cd-9f53-0c6a2c276a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137987172-172.17.0.5-1597676973015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-da8e453e-0ae4-439c-85a6-74338e737940,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-f63c6d2a-0bd3-4623-94be-6022cd9c0580,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-ce19f8e7-97e4-4549-a61f-bb2c4a7b113f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-6fb2b7b6-9bac-46f8-baf0-1f537ba22aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-a4171484-1da6-4785-b816-a0e58e3f355a,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-f860f404-918c-4643-a07d-32f52e05f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-291a341a-0a24-40c4-9e75-997329119e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-048284d4-78d3-49cd-9f53-0c6a2c276a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5459
