reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541035078-172.17.0.2-1597700251102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-291bece3-c7c6-44cb-9adf-5221dddf3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-cc2e2749-7263-44d0-9ee6-63323ec62c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ee8f122e-7854-4683-b48d-84d121d57da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-9dfa9598-ccf4-4b49-bc74-f4a4aeb0dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-3150010c-0695-489a-bf94-b13bc9fa4075,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-92f76d03-07fb-4030-bf3b-a82971b99ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-acb02b6c-d00f-455e-8278-fafb45ea3e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-a4994097-6090-4406-9190-4004037e45af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541035078-172.17.0.2-1597700251102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-291bece3-c7c6-44cb-9adf-5221dddf3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-cc2e2749-7263-44d0-9ee6-63323ec62c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ee8f122e-7854-4683-b48d-84d121d57da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-9dfa9598-ccf4-4b49-bc74-f4a4aeb0dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-3150010c-0695-489a-bf94-b13bc9fa4075,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-92f76d03-07fb-4030-bf3b-a82971b99ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-acb02b6c-d00f-455e-8278-fafb45ea3e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-a4994097-6090-4406-9190-4004037e45af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923598375-172.17.0.2-1597700326867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-dc5ed25c-4e0e-4f57-9ff1-495687c796ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-4751fda8-a8f2-4a9b-9406-741d08c595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-3162bd1a-1b94-411b-81c1-78854b5f5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-557da963-4401-4440-a85d-78a38d607f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-5e5a4c83-7764-47ac-a6be-6dc384921d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a66697b1-9757-4b20-bb4c-26f484495de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-15e63671-de3a-4597-8c4f-694a7ec09d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-d7c652f4-16c9-47c9-8ccc-31a919cf0b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923598375-172.17.0.2-1597700326867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-dc5ed25c-4e0e-4f57-9ff1-495687c796ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-4751fda8-a8f2-4a9b-9406-741d08c595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-3162bd1a-1b94-411b-81c1-78854b5f5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-557da963-4401-4440-a85d-78a38d607f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-5e5a4c83-7764-47ac-a6be-6dc384921d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a66697b1-9757-4b20-bb4c-26f484495de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-15e63671-de3a-4597-8c4f-694a7ec09d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-d7c652f4-16c9-47c9-8ccc-31a919cf0b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137124101-172.17.0.2-1597700393663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-806c3539-f1fe-4884-8bcc-d49e40646537,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-75a52337-2080-4812-8b5e-1544e7ee1393,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-5d49ace2-ed15-42d7-83d7-0cdd601ac0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-05fdea0f-bd65-42bf-bcef-f45107c4701f,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f97d8117-9713-4f67-bdba-355a888fb10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-6cebe02b-96f9-471c-b297-315ae67cd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-06e7a988-b25b-44d8-ab0f-8fd18e76b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-523a1ead-424a-4206-82f8-4a9c7c888ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137124101-172.17.0.2-1597700393663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-806c3539-f1fe-4884-8bcc-d49e40646537,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-75a52337-2080-4812-8b5e-1544e7ee1393,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-5d49ace2-ed15-42d7-83d7-0cdd601ac0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-05fdea0f-bd65-42bf-bcef-f45107c4701f,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f97d8117-9713-4f67-bdba-355a888fb10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-6cebe02b-96f9-471c-b297-315ae67cd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-06e7a988-b25b-44d8-ab0f-8fd18e76b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-523a1ead-424a-4206-82f8-4a9c7c888ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331321877-172.17.0.2-1597701471548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-50c2b492-bcfe-4af8-9c75-fa76da982941,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-640301e3-238b-4b16-8795-70c65f40aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-51c9900b-e72f-4e93-9f57-27d084d08ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-59d138c0-734f-413b-9351-21e04a35d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-a2fb651d-d8e8-4ad9-94b5-3dccd54291dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-ad22a48c-355f-4072-af79-c64a03f6da99,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-d092a6a1-9941-46d6-949f-0165d49d23da,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d4af6803-1628-4bb7-be6b-781ee2c07d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331321877-172.17.0.2-1597701471548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-50c2b492-bcfe-4af8-9c75-fa76da982941,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-640301e3-238b-4b16-8795-70c65f40aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-51c9900b-e72f-4e93-9f57-27d084d08ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-59d138c0-734f-413b-9351-21e04a35d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-a2fb651d-d8e8-4ad9-94b5-3dccd54291dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-ad22a48c-355f-4072-af79-c64a03f6da99,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-d092a6a1-9941-46d6-949f-0165d49d23da,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d4af6803-1628-4bb7-be6b-781ee2c07d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975528989-172.17.0.2-1597701625326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-0db398d7-953a-4c68-8fb8-e10a7b2a3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-a1ee74d9-8d19-4eb8-9a93-3a38619f18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-cd2edcd2-91ef-4802-9d60-7c1890a991eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fb653a19-c0aa-43c6-bce1-ef4c7aafa40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d6052f66-1987-4f93-b1c7-3f98e75e1f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-dffb6453-af4a-48f6-b41b-05d6104fd37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-7217db5f-0b18-408b-b5e0-68d454e16da9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-8c3b5caf-fa33-4b18-911c-4600761ceeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975528989-172.17.0.2-1597701625326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-0db398d7-953a-4c68-8fb8-e10a7b2a3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-a1ee74d9-8d19-4eb8-9a93-3a38619f18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-cd2edcd2-91ef-4802-9d60-7c1890a991eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fb653a19-c0aa-43c6-bce1-ef4c7aafa40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d6052f66-1987-4f93-b1c7-3f98e75e1f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-dffb6453-af4a-48f6-b41b-05d6104fd37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-7217db5f-0b18-408b-b5e0-68d454e16da9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-8c3b5caf-fa33-4b18-911c-4600761ceeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658099647-172.17.0.2-1597702560241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-439ee809-d6b7-4b08-b379-22bc5466ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-c2808fc2-1362-477c-aec9-893ecd9a79cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-01d20ddd-f2a0-404a-aaf6-4fd0aa1b43ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-4852d6b8-e0d4-43ba-a0c9-f3a66f015b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-8c3ed68b-f980-4e11-853b-7e99328e79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-f9dbd862-f961-41b9-b425-638c2a2e92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-61e390b5-c8b2-4446-9a45-ae184ea07562,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-2c02adb2-d33a-42b4-b35c-a8ff84562d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658099647-172.17.0.2-1597702560241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-439ee809-d6b7-4b08-b379-22bc5466ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-c2808fc2-1362-477c-aec9-893ecd9a79cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-01d20ddd-f2a0-404a-aaf6-4fd0aa1b43ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-4852d6b8-e0d4-43ba-a0c9-f3a66f015b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-8c3ed68b-f980-4e11-853b-7e99328e79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-f9dbd862-f961-41b9-b425-638c2a2e92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-61e390b5-c8b2-4446-9a45-ae184ea07562,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-2c02adb2-d33a-42b4-b35c-a8ff84562d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899122181-172.17.0.2-1597702861138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-a2f5ff87-0a2a-48f7-9164-ab76042fdc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-642164c1-cc87-48c8-b3d1-13b71996c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-a37af19d-cbef-48ac-8f99-60fbb7088f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f1e1ed61-9c1f-48bb-b33a-a95c389ff6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-1540d60b-c724-42ba-a414-533dc47f34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-36c9f637-3036-454b-a751-f3cd5c5b5112,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-fc46cb69-304b-4ae7-ac45-e045576badec,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-36a1ef2e-4846-458f-af96-92c9f2b2076c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899122181-172.17.0.2-1597702861138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-a2f5ff87-0a2a-48f7-9164-ab76042fdc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-642164c1-cc87-48c8-b3d1-13b71996c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-a37af19d-cbef-48ac-8f99-60fbb7088f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f1e1ed61-9c1f-48bb-b33a-a95c389ff6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-1540d60b-c724-42ba-a414-533dc47f34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-36c9f637-3036-454b-a751-f3cd5c5b5112,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-fc46cb69-304b-4ae7-ac45-e045576badec,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-36a1ef2e-4846-458f-af96-92c9f2b2076c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183133744-172.17.0.2-1597703351441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-406857cf-1fa9-4bee-aff4-d267f481cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-53676f85-0d73-4435-86a4-3e2c61424cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-95aa4114-610e-484f-9a2d-5bacfd11ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8953a364-2459-4e42-882a-05447c74509b,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-01268a9c-8be8-4e0a-9d45-5955bea25dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-7bc6a6cd-8558-4dc2-8275-60f070ebcd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-acae931c-f8ee-4cdf-8e90-915e80e1fcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-56b1b681-33ec-4bee-a2a3-d43644355c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183133744-172.17.0.2-1597703351441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-406857cf-1fa9-4bee-aff4-d267f481cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-53676f85-0d73-4435-86a4-3e2c61424cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-95aa4114-610e-484f-9a2d-5bacfd11ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8953a364-2459-4e42-882a-05447c74509b,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-01268a9c-8be8-4e0a-9d45-5955bea25dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-7bc6a6cd-8558-4dc2-8275-60f070ebcd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-acae931c-f8ee-4cdf-8e90-915e80e1fcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-56b1b681-33ec-4bee-a2a3-d43644355c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920491982-172.17.0.2-1597703495491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-8023ed02-bc20-4a3b-9ac6-9c57791b55b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-308c24d1-5d8a-4c98-98d7-ed88e63edf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-825d7802-9751-4c99-8511-91a687a9d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-fe65cb1d-eec8-451e-8f47-ddfd2595ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-f4095a3b-c915-4d9f-af28-56576623ec48,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-6b708931-ad5b-468a-aa37-66c2a97da835,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-7d6b648b-c26a-4738-9a20-feedf8d08750,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-26ea8d02-8cb0-4131-b17a-ac3959c1850e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920491982-172.17.0.2-1597703495491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-8023ed02-bc20-4a3b-9ac6-9c57791b55b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-308c24d1-5d8a-4c98-98d7-ed88e63edf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-825d7802-9751-4c99-8511-91a687a9d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-fe65cb1d-eec8-451e-8f47-ddfd2595ea42,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-f4095a3b-c915-4d9f-af28-56576623ec48,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-6b708931-ad5b-468a-aa37-66c2a97da835,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-7d6b648b-c26a-4738-9a20-feedf8d08750,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-26ea8d02-8cb0-4131-b17a-ac3959c1850e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430034350-172.17.0.2-1597703617077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-27713293-c15c-4b47-9d8d-9ad2c6f6d9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-e879cecc-5029-437b-b02e-a1491fcf7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-b116113b-b50b-4063-80ab-5aab217877d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-3d9f50fa-e052-42c5-b7f9-e117843be994,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-7bf71a98-94a2-4910-9448-ff1363cbe307,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-5c2cdc2e-c0c6-4624-a0e7-a88978e973ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-3717e074-1c94-4a4e-8aa2-fa15c40ffc28,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-bd6c504a-d7cc-48ba-bc6f-d48838685b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430034350-172.17.0.2-1597703617077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-27713293-c15c-4b47-9d8d-9ad2c6f6d9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-e879cecc-5029-437b-b02e-a1491fcf7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-b116113b-b50b-4063-80ab-5aab217877d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-3d9f50fa-e052-42c5-b7f9-e117843be994,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-7bf71a98-94a2-4910-9448-ff1363cbe307,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-5c2cdc2e-c0c6-4624-a0e7-a88978e973ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-3717e074-1c94-4a4e-8aa2-fa15c40ffc28,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-bd6c504a-d7cc-48ba-bc6f-d48838685b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23450099-172.17.0.2-1597703677968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-31ef1046-494d-4767-a2aa-6329e0f6ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-965518df-3a7a-4653-b193-e6a89c109866,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3fae10cb-b4c0-4114-bccc-c1f9e2178ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-c13c40c8-a83e-4414-b9a0-10a9071d4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-eebd9533-7b43-473a-89a5-2abcfb4e3516,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-17f9677f-5fbe-4401-82a5-a061360a2422,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-eed11e7d-d09b-4f93-8f53-bc85061372ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-e6312cd1-a9ef-4b14-aee2-041dac8dc0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23450099-172.17.0.2-1597703677968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-31ef1046-494d-4767-a2aa-6329e0f6ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-965518df-3a7a-4653-b193-e6a89c109866,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3fae10cb-b4c0-4114-bccc-c1f9e2178ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-c13c40c8-a83e-4414-b9a0-10a9071d4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-eebd9533-7b43-473a-89a5-2abcfb4e3516,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-17f9677f-5fbe-4401-82a5-a061360a2422,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-eed11e7d-d09b-4f93-8f53-bc85061372ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-e6312cd1-a9ef-4b14-aee2-041dac8dc0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277243560-172.17.0.2-1597703786991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-5bd2dc14-40a9-4c58-94fb-2386a1a5a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ed5dab97-d8b7-42bf-8bb3-60b5c7f6b704,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-3f339ceb-23d8-431a-80ff-08d8f2476ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-67e3b6d0-a346-40c8-8ec6-9e88ede70328,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-16dd42a1-97e1-4e2f-96ab-23fe8972cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-642b0014-1722-4440-a7b5-93a21a1965cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-fa0969b9-065a-4395-ae25-4bf9fb1db0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-99566c4d-a5cb-4751-ab53-c6e4887b0a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277243560-172.17.0.2-1597703786991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-5bd2dc14-40a9-4c58-94fb-2386a1a5a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ed5dab97-d8b7-42bf-8bb3-60b5c7f6b704,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-3f339ceb-23d8-431a-80ff-08d8f2476ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-67e3b6d0-a346-40c8-8ec6-9e88ede70328,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-16dd42a1-97e1-4e2f-96ab-23fe8972cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-642b0014-1722-4440-a7b5-93a21a1965cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-fa0969b9-065a-4395-ae25-4bf9fb1db0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-99566c4d-a5cb-4751-ab53-c6e4887b0a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 50
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146858161-172.17.0.2-1597705371483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-f10bb1cf-aeeb-43cb-b55d-b1e38d0eec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-6c4f64af-d46d-4666-9035-af9e56e35295,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-3bf443c9-5425-42b8-9fa2-b2765fba6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-60002b37-c4b0-4d60-aacb-aa2b60f59526,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f01f75c5-e429-4f43-90fb-abe2cdac08ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-1b63b515-9810-498f-afbc-c1e6c25ef354,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-3faa2e81-4273-4b8f-a5ae-a632368bfcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-f7ac3e00-3c94-42b6-bb6c-a7cc9c52d612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146858161-172.17.0.2-1597705371483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-f10bb1cf-aeeb-43cb-b55d-b1e38d0eec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-6c4f64af-d46d-4666-9035-af9e56e35295,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-3bf443c9-5425-42b8-9fa2-b2765fba6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-60002b37-c4b0-4d60-aacb-aa2b60f59526,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f01f75c5-e429-4f43-90fb-abe2cdac08ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-1b63b515-9810-498f-afbc-c1e6c25ef354,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-3faa2e81-4273-4b8f-a5ae-a632368bfcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-f7ac3e00-3c94-42b6-bb6c-a7cc9c52d612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5580
