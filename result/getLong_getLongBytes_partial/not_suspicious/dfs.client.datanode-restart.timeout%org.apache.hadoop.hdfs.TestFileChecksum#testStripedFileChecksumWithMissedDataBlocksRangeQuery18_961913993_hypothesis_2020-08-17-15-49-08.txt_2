reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815924892-172.17.0.17-1597679407595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-72851f76-e652-4b20-8dce-b7dce472e929,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-65147351-8d1c-4bae-853b-ca8aca3a1065,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-eacca958-699f-410f-b133-5ea7da809c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-8467fbb2-493b-4aee-a9bd-5877a60432e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-e2066d30-27a4-4f63-8a85-5e190654fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-d997bc91-43e7-44b5-ac85-db09fa902c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-2ef499eb-b0e4-46aa-bc2a-51ea49dba1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-e432e5cd-a168-4f49-adf6-b0ccb2147ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815924892-172.17.0.17-1597679407595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-72851f76-e652-4b20-8dce-b7dce472e929,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-65147351-8d1c-4bae-853b-ca8aca3a1065,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-eacca958-699f-410f-b133-5ea7da809c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-8467fbb2-493b-4aee-a9bd-5877a60432e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-e2066d30-27a4-4f63-8a85-5e190654fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-d997bc91-43e7-44b5-ac85-db09fa902c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-2ef499eb-b0e4-46aa-bc2a-51ea49dba1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-e432e5cd-a168-4f49-adf6-b0ccb2147ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135489819-172.17.0.17-1597679717039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-25c244f4-4c37-4d00-a3de-aa02c922fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0596767f-475e-412e-83d9-69c7e07984ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-9aae0f42-9598-4144-81c0-e01c0da28edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-ad94fd34-e25b-4708-b835-c02cad98b611,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-1b560b50-8d5e-43ad-bf1e-adeea592a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-c8e24220-e55e-4f3f-8649-ba58e3d10f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8d11a3cd-a4e1-4b73-9b1e-c1e39e94cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-501f1248-64a7-4cb4-923b-7b534208fcbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135489819-172.17.0.17-1597679717039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-25c244f4-4c37-4d00-a3de-aa02c922fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0596767f-475e-412e-83d9-69c7e07984ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-9aae0f42-9598-4144-81c0-e01c0da28edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-ad94fd34-e25b-4708-b835-c02cad98b611,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-1b560b50-8d5e-43ad-bf1e-adeea592a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-c8e24220-e55e-4f3f-8649-ba58e3d10f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8d11a3cd-a4e1-4b73-9b1e-c1e39e94cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-501f1248-64a7-4cb4-923b-7b534208fcbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316889594-172.17.0.17-1597679751792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-430f47ad-a3cb-4039-891b-9736492281ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-6255edaf-ff16-4d6e-a894-345a6dca5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-5b002f71-0a6b-445b-acb8-871ed35314ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-1cb04920-bef4-4ee2-a8d2-5f1219f0e383,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-3f9b4341-8def-4a40-a696-38eb9a89cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-6d8ea994-b539-450b-a885-aef8b502c397,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ecb76e87-a6a5-4253-a6c5-b4de98334c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-59413c4b-b3f9-4364-aa07-fad4b523b036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316889594-172.17.0.17-1597679751792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-430f47ad-a3cb-4039-891b-9736492281ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-6255edaf-ff16-4d6e-a894-345a6dca5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-5b002f71-0a6b-445b-acb8-871ed35314ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-1cb04920-bef4-4ee2-a8d2-5f1219f0e383,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-3f9b4341-8def-4a40-a696-38eb9a89cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-6d8ea994-b539-450b-a885-aef8b502c397,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ecb76e87-a6a5-4253-a6c5-b4de98334c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-59413c4b-b3f9-4364-aa07-fad4b523b036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757114389-172.17.0.17-1597680022881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-e6b37af7-d27f-4dda-85a0-244cac5eaeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-20a65d3b-4fb6-4968-8b27-ffde06b2ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a8eafbc2-144c-4fa1-ae26-6c877c95f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b0bf4eca-4a42-431b-84d2-fbcb6afda28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-2702befa-21d7-4bed-a802-32a97cdf3a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-9cea3726-701f-484c-97f1-b3bb3a89fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-226f1c05-f5b6-42c2-90e9-b32c3f80fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-1209853a-14d8-4c6b-9832-0fa98bef81c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757114389-172.17.0.17-1597680022881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-e6b37af7-d27f-4dda-85a0-244cac5eaeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-20a65d3b-4fb6-4968-8b27-ffde06b2ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a8eafbc2-144c-4fa1-ae26-6c877c95f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b0bf4eca-4a42-431b-84d2-fbcb6afda28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-2702befa-21d7-4bed-a802-32a97cdf3a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-9cea3726-701f-484c-97f1-b3bb3a89fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-226f1c05-f5b6-42c2-90e9-b32c3f80fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-1209853a-14d8-4c6b-9832-0fa98bef81c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206632322-172.17.0.17-1597680416315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-5f8924c1-2f24-4289-a5bc-04a4d7027933,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f6396c6e-6c14-4646-85cc-d9ec70206b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-a0393e7a-6ae9-463b-b7c7-6d129b0545b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-773f6bcf-e5fb-43a8-bb86-a0b67acc7591,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9cbe324c-0016-4695-94ed-a5f4c9827323,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-1bf70ab6-abdb-4409-9ac5-24fac2d03f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ac83ceb4-584a-462f-a7d8-479b2ad4dab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-96603b5e-9fa6-4ad4-8e5c-41368603a371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206632322-172.17.0.17-1597680416315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-5f8924c1-2f24-4289-a5bc-04a4d7027933,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f6396c6e-6c14-4646-85cc-d9ec70206b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-a0393e7a-6ae9-463b-b7c7-6d129b0545b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-773f6bcf-e5fb-43a8-bb86-a0b67acc7591,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9cbe324c-0016-4695-94ed-a5f4c9827323,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-1bf70ab6-abdb-4409-9ac5-24fac2d03f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ac83ceb4-584a-462f-a7d8-479b2ad4dab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-96603b5e-9fa6-4ad4-8e5c-41368603a371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571928830-172.17.0.17-1597680667999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-623e68ac-e0b4-495b-908b-3f6c0b415ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-17cbeeff-11ee-428d-95cf-964d1dd46a49,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-2574ed05-5d7d-47da-8442-bcd7b01e8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-310e85c0-e046-48ec-8909-ba26f6921d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-f268ab26-a65e-4233-8e1a-b39407b9691e,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-20c4bb30-c99c-4b98-9f60-62d69cd5dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-2a961d50-892e-4980-bafc-bacb0bb802c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-7dcd9f14-0966-4dae-b351-b217f4e0f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571928830-172.17.0.17-1597680667999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-623e68ac-e0b4-495b-908b-3f6c0b415ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-17cbeeff-11ee-428d-95cf-964d1dd46a49,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-2574ed05-5d7d-47da-8442-bcd7b01e8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-310e85c0-e046-48ec-8909-ba26f6921d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-f268ab26-a65e-4233-8e1a-b39407b9691e,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-20c4bb30-c99c-4b98-9f60-62d69cd5dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-2a961d50-892e-4980-bafc-bacb0bb802c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-7dcd9f14-0966-4dae-b351-b217f4e0f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232926396-172.17.0.17-1597680733735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-d8da303c-8a8a-4c26-8e3c-1194cc0d871d,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-268e4da2-bace-48bb-917b-8665aa76af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b5becb3e-34a2-4fb0-bdbd-d0eb5360ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-b81fcb8f-e82d-4009-94cd-b324499025b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-a0b2c05b-ee9f-4cbf-a5a0-4139e3cd2389,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-998732e3-bc0e-4002-b97e-bc07eaf9f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7fc843ac-a0f8-4c8c-bbed-1d2705daea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-247746ed-63f6-469e-a5ab-2c78eb665c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232926396-172.17.0.17-1597680733735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-d8da303c-8a8a-4c26-8e3c-1194cc0d871d,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-268e4da2-bace-48bb-917b-8665aa76af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b5becb3e-34a2-4fb0-bdbd-d0eb5360ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-b81fcb8f-e82d-4009-94cd-b324499025b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-a0b2c05b-ee9f-4cbf-a5a0-4139e3cd2389,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-998732e3-bc0e-4002-b97e-bc07eaf9f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7fc843ac-a0f8-4c8c-bbed-1d2705daea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-247746ed-63f6-469e-a5ab-2c78eb665c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946396609-172.17.0.17-1597681099443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-3599bc24-2a12-409b-946c-5668f58dc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-dff18e30-df36-4fa9-8a48-b5feda0f92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-9cb08606-3c82-4e2c-a2d8-7de82d720c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-b6eb18fa-f126-463c-a8c3-10cd3c99f924,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f0afdbd5-aafe-4665-8c83-2256e56cbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-b794b2c7-a9ac-47a0-9861-4f15b8f79a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-cdd8bb1f-217f-4df5-b8bc-bdbe2407d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-aa47b1a9-ded1-45d8-b113-83925c1dbf2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946396609-172.17.0.17-1597681099443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-3599bc24-2a12-409b-946c-5668f58dc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-dff18e30-df36-4fa9-8a48-b5feda0f92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-9cb08606-3c82-4e2c-a2d8-7de82d720c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-b6eb18fa-f126-463c-a8c3-10cd3c99f924,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f0afdbd5-aafe-4665-8c83-2256e56cbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-b794b2c7-a9ac-47a0-9861-4f15b8f79a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-cdd8bb1f-217f-4df5-b8bc-bdbe2407d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-aa47b1a9-ded1-45d8-b113-83925c1dbf2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436699203-172.17.0.17-1597681202669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-12683e4d-f1ee-465d-8149-fe250890f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-71d11123-293c-4cb0-a897-f4102c49c395,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-b774ed15-affc-4937-80f9-a8674b6cbc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1ca2866d-0e88-4504-89e2-519c213b1195,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-3208a6c9-8a4f-49ef-9a81-26732a10652a,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-5f514ba6-9d6e-4290-bab5-ef13aa3b4004,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a33af4ef-3405-4ef5-9eae-0cd0b2db094e,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-2265b0dd-823b-4d26-9da6-3de80a0ad3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436699203-172.17.0.17-1597681202669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-12683e4d-f1ee-465d-8149-fe250890f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-71d11123-293c-4cb0-a897-f4102c49c395,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-b774ed15-affc-4937-80f9-a8674b6cbc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1ca2866d-0e88-4504-89e2-519c213b1195,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-3208a6c9-8a4f-49ef-9a81-26732a10652a,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-5f514ba6-9d6e-4290-bab5-ef13aa3b4004,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a33af4ef-3405-4ef5-9eae-0cd0b2db094e,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-2265b0dd-823b-4d26-9da6-3de80a0ad3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003124126-172.17.0.17-1597681704444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-a762f805-46a8-46d9-a44a-1947b47d916f,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-fcd5a8eb-a08b-423d-a99b-01dded4384ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-c053e65a-0986-416f-9964-290adcc88959,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-827c78bc-7c24-47d4-b99a-01d673fb3965,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-25ded02f-882c-4f0b-a70f-df5997cb6054,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-9ae3eb1a-40e8-4c83-85ce-d7bc55047f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-15373a19-9a64-45bc-a005-6fa0c84082e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-4d24e4aa-c67b-4c24-9c94-f9243c798718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003124126-172.17.0.17-1597681704444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-a762f805-46a8-46d9-a44a-1947b47d916f,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-fcd5a8eb-a08b-423d-a99b-01dded4384ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-c053e65a-0986-416f-9964-290adcc88959,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-827c78bc-7c24-47d4-b99a-01d673fb3965,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-25ded02f-882c-4f0b-a70f-df5997cb6054,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-9ae3eb1a-40e8-4c83-85ce-d7bc55047f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-15373a19-9a64-45bc-a005-6fa0c84082e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-4d24e4aa-c67b-4c24-9c94-f9243c798718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203033083-172.17.0.17-1597681779165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-277aa4ec-c693-4065-9126-f63e3f43db45,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6b0618d2-d629-433c-b105-07bdcd9e2218,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-8256b50d-6b4e-4339-a149-6c52caff5938,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d7123e94-11f1-4f0d-8f3a-24c75dacc0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-4e53725f-10ac-4c53-99d9-6318251e6003,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-481b644d-bd1d-4d1e-8785-11a6c838438f,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-645e1000-fe34-4a93-b8a9-2bdd12237578,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-a0a7ca9d-2733-4d51-ab91-205fba11f0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203033083-172.17.0.17-1597681779165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-277aa4ec-c693-4065-9126-f63e3f43db45,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6b0618d2-d629-433c-b105-07bdcd9e2218,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-8256b50d-6b4e-4339-a149-6c52caff5938,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d7123e94-11f1-4f0d-8f3a-24c75dacc0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-4e53725f-10ac-4c53-99d9-6318251e6003,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-481b644d-bd1d-4d1e-8785-11a6c838438f,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-645e1000-fe34-4a93-b8a9-2bdd12237578,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-a0a7ca9d-2733-4d51-ab91-205fba11f0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918672691-172.17.0.17-1597682060197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-6efcf7c7-94dd-44f0-bed4-0ccc8c6e53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-b4fde7a0-b072-484a-83b2-db21a84ab792,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-ff533044-7ec1-43fd-9c2e-3a2c6e842a08,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-0d845567-f77c-423b-9910-2602d8e75974,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-25918c5b-79fc-4705-8dcc-fb8b07277d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-463890b9-8d01-4c85-9d37-723bbadda210,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-393cbb1e-8651-4aa6-9671-ad934728d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-672caa02-75bc-45ec-b918-bf2560714194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918672691-172.17.0.17-1597682060197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-6efcf7c7-94dd-44f0-bed4-0ccc8c6e53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-b4fde7a0-b072-484a-83b2-db21a84ab792,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-ff533044-7ec1-43fd-9c2e-3a2c6e842a08,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-0d845567-f77c-423b-9910-2602d8e75974,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-25918c5b-79fc-4705-8dcc-fb8b07277d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-463890b9-8d01-4c85-9d37-723bbadda210,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-393cbb1e-8651-4aa6-9671-ad934728d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-672caa02-75bc-45ec-b918-bf2560714194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387744658-172.17.0.17-1597682209935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-b22abe1f-6407-4221-804c-5fb8425ce48a,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-2904336d-ee9f-4226-aa27-acd0343d85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-a46fd206-93c3-4650-872d-27a22a80428f,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-58ed27c8-92c8-4d44-9436-03366a3ab4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-22639986-c088-447e-9b6f-1d05886e16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-8d820e93-3989-4525-90c2-333cd21444eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-45c7d11e-e20c-4e96-9a75-94c2fd6213da,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7e657023-99fe-470d-8b31-63d700806bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387744658-172.17.0.17-1597682209935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-b22abe1f-6407-4221-804c-5fb8425ce48a,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-2904336d-ee9f-4226-aa27-acd0343d85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-a46fd206-93c3-4650-872d-27a22a80428f,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-58ed27c8-92c8-4d44-9436-03366a3ab4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-22639986-c088-447e-9b6f-1d05886e16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-8d820e93-3989-4525-90c2-333cd21444eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-45c7d11e-e20c-4e96-9a75-94c2fd6213da,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7e657023-99fe-470d-8b31-63d700806bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546249007-172.17.0.17-1597682552323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41957,DS-24850df2-dbe2-4c43-abf6-561199b35682,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3b00719c-41fb-4c62-994e-4640ceb8de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-dd2272d3-6bfd-46de-9d26-ee2d37e40d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-b46c069d-8917-439c-84e9-e0ad01e54867,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-97099e66-44e4-4163-ad5f-954923c22ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-aaddee55-4e69-48b7-9667-fd6e7a7c3d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-2eda546c-5a6f-4a0d-9787-ba7a64621de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-1c14d8f0-66b4-4872-a0ad-48ff3fadfa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546249007-172.17.0.17-1597682552323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41957,DS-24850df2-dbe2-4c43-abf6-561199b35682,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3b00719c-41fb-4c62-994e-4640ceb8de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-dd2272d3-6bfd-46de-9d26-ee2d37e40d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-b46c069d-8917-439c-84e9-e0ad01e54867,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-97099e66-44e4-4163-ad5f-954923c22ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-aaddee55-4e69-48b7-9667-fd6e7a7c3d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-2eda546c-5a6f-4a0d-9787-ba7a64621de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-1c14d8f0-66b4-4872-a0ad-48ff3fadfa21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934832730-172.17.0.17-1597682587241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-16fdbda7-3745-448d-bcdb-29d8a7868a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-5cd15907-f243-4d2a-af6e-ed0d13adcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c99dc81c-e0a3-4427-9e5b-93554cb17ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-ee050d20-1837-4456-b24a-623aa0a2ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-e31e2095-efa5-4e28-8add-2833bbfe9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-43917f38-d5b5-4059-9adf-f7ed814718ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-75b3251f-3310-4bbf-8866-a7ca53e361f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-e26124c5-a754-4085-88a4-7ca9810b73b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934832730-172.17.0.17-1597682587241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-16fdbda7-3745-448d-bcdb-29d8a7868a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-5cd15907-f243-4d2a-af6e-ed0d13adcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c99dc81c-e0a3-4427-9e5b-93554cb17ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-ee050d20-1837-4456-b24a-623aa0a2ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-e31e2095-efa5-4e28-8add-2833bbfe9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-43917f38-d5b5-4059-9adf-f7ed814718ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-75b3251f-3310-4bbf-8866-a7ca53e361f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-e26124c5-a754-4085-88a4-7ca9810b73b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495716904-172.17.0.17-1597682930060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-865fa60a-7e5d-4144-bcba-ff385246de66,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-d30e11dd-9c38-4096-b063-71513c9ad1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-bfc685ee-609e-4a17-b032-dcadfb40223e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-f86af740-30a6-4881-80a7-decc081097e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-0442be4a-6767-4825-8bc1-33b4b0689ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-2710fff9-0e24-469c-9992-d883a2a88c98,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-67f455ef-0286-4589-b92b-3a662672e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0fb9527d-3bd8-49fe-b8ec-a34c393a7399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495716904-172.17.0.17-1597682930060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-865fa60a-7e5d-4144-bcba-ff385246de66,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-d30e11dd-9c38-4096-b063-71513c9ad1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-bfc685ee-609e-4a17-b032-dcadfb40223e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-f86af740-30a6-4881-80a7-decc081097e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-0442be4a-6767-4825-8bc1-33b4b0689ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-2710fff9-0e24-469c-9992-d883a2a88c98,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-67f455ef-0286-4589-b92b-3a662672e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0fb9527d-3bd8-49fe-b8ec-a34c393a7399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942214986-172.17.0.17-1597682963377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45811,DS-51605b52-23f2-4e78-90ed-774b43998ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-87a4fc55-f2aa-444b-ac7d-f16b7078810a,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-7824c716-f32f-4c11-a6f3-506e83d1b019,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-43784817-476e-483e-9243-97d880a594d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-807e96b9-e82d-4be1-be55-ecb8b46eee93,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7a3bc7a3-808d-4139-afcc-ca47f4c13852,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-346916be-031c-422a-be4b-63eb27605454,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-02622757-1f2f-421e-bc93-a88a9c606ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942214986-172.17.0.17-1597682963377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45811,DS-51605b52-23f2-4e78-90ed-774b43998ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-87a4fc55-f2aa-444b-ac7d-f16b7078810a,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-7824c716-f32f-4c11-a6f3-506e83d1b019,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-43784817-476e-483e-9243-97d880a594d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-807e96b9-e82d-4be1-be55-ecb8b46eee93,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7a3bc7a3-808d-4139-afcc-ca47f4c13852,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-346916be-031c-422a-be4b-63eb27605454,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-02622757-1f2f-421e-bc93-a88a9c606ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313887973-172.17.0.17-1597683268182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-d892c0dd-d7fd-407d-882a-a1e9314935c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-a73944e1-0f0e-4643-931e-cbdb07b9a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-7b1b8cd8-e5d7-42c1-b6ca-29a7f272f367,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-98363741-920b-42b6-b7a1-b1702e10ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-b20d8f26-656b-442b-ad36-bbbb5e9406e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-7cab2e82-6f53-4132-8d11-bb38dd8ff060,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-79006aca-f568-420b-af83-b0ab38b9b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-806452b2-9ffa-47b9-b297-05fbcf7acc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313887973-172.17.0.17-1597683268182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-d892c0dd-d7fd-407d-882a-a1e9314935c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-a73944e1-0f0e-4643-931e-cbdb07b9a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-7b1b8cd8-e5d7-42c1-b6ca-29a7f272f367,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-98363741-920b-42b6-b7a1-b1702e10ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-b20d8f26-656b-442b-ad36-bbbb5e9406e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-7cab2e82-6f53-4132-8d11-bb38dd8ff060,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-79006aca-f568-420b-af83-b0ab38b9b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-806452b2-9ffa-47b9-b297-05fbcf7acc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199826510-172.17.0.17-1597683450080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-d62421f1-7cb0-4ab2-99ad-faf5a3c8a389,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-1bd2a0d0-6bf4-426c-b0fc-c4951626b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-1efa0f25-8114-4f4a-a428-287ea2542f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-32db2691-98e3-49a4-8bc9-c5239a558c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-7f5364a8-f4d3-4ede-824d-27256d06d708,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c435b519-215e-4c55-a5c9-96929bebba31,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-78974e87-12c4-4f51-9393-ba5aebcc9b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-75f6435f-0ef7-4466-a01a-770a3b524380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199826510-172.17.0.17-1597683450080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-d62421f1-7cb0-4ab2-99ad-faf5a3c8a389,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-1bd2a0d0-6bf4-426c-b0fc-c4951626b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-1efa0f25-8114-4f4a-a428-287ea2542f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-32db2691-98e3-49a4-8bc9-c5239a558c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-7f5364a8-f4d3-4ede-824d-27256d06d708,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c435b519-215e-4c55-a5c9-96929bebba31,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-78974e87-12c4-4f51-9393-ba5aebcc9b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-75f6435f-0ef7-4466-a01a-770a3b524380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305402178-172.17.0.17-1597683675871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-fe4dc916-8f0a-4522-89a1-caa92b74ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-8e8cb14f-32e3-4c69-bb47-fa6812033436,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ef9ca80b-b794-4727-83a6-a15be8d622d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-69d54c96-2071-4747-a37f-a8235701aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-cf0e380a-83cd-423d-b425-720d863555a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-cab26fd8-aaa4-496b-8f2c-a9a66e369adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-4f45585a-826d-4cc0-9880-e156049cd5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-893a00af-00b0-4292-8fc0-e8b1ab92d384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305402178-172.17.0.17-1597683675871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-fe4dc916-8f0a-4522-89a1-caa92b74ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-8e8cb14f-32e3-4c69-bb47-fa6812033436,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-ef9ca80b-b794-4727-83a6-a15be8d622d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-69d54c96-2071-4747-a37f-a8235701aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-cf0e380a-83cd-423d-b425-720d863555a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-cab26fd8-aaa4-496b-8f2c-a9a66e369adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-4f45585a-826d-4cc0-9880-e156049cd5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-893a00af-00b0-4292-8fc0-e8b1ab92d384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149559151-172.17.0.17-1597683980003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-6fdc2830-cc3b-4b1d-847e-ea309c459cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-170d79f2-a708-4e36-9a48-522eab3a36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-7cfb6429-27ca-45aa-8d4b-429ad6500ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-f2d5a0bf-66aa-4617-a019-96b326d03f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-76a46700-27c8-4125-9c35-968d4271f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b027aea9-f518-4b96-937c-a658c06a29f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-ef4a3d99-3c15-4305-947e-b5520d08e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-03fd84e4-759e-4aaa-b8c4-a4ea201b5053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149559151-172.17.0.17-1597683980003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-6fdc2830-cc3b-4b1d-847e-ea309c459cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-170d79f2-a708-4e36-9a48-522eab3a36ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-7cfb6429-27ca-45aa-8d4b-429ad6500ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-f2d5a0bf-66aa-4617-a019-96b326d03f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-76a46700-27c8-4125-9c35-968d4271f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b027aea9-f518-4b96-937c-a658c06a29f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-ef4a3d99-3c15-4305-947e-b5520d08e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-03fd84e4-759e-4aaa-b8c4-a4ea201b5053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636630949-172.17.0.17-1597684274585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-763d57fd-858f-4a54-b2a3-3efaa116fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-b9e06071-ea85-4adc-9eb7-ac60f0bf3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-a073ca5f-fb03-4939-b6a4-de01ece38e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-d30d7390-013a-4ef8-94da-69c231fd3d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-47ad0067-de1f-4787-842d-48bdd42d2925,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-0d89fbc7-b450-4a93-a47f-12496c09a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-ac424b83-3c81-4080-9410-5b274682be49,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-cdffeceb-fedb-4db6-8a1d-62cfdaac69d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636630949-172.17.0.17-1597684274585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-763d57fd-858f-4a54-b2a3-3efaa116fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-b9e06071-ea85-4adc-9eb7-ac60f0bf3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-a073ca5f-fb03-4939-b6a4-de01ece38e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-d30d7390-013a-4ef8-94da-69c231fd3d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-47ad0067-de1f-4787-842d-48bdd42d2925,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-0d89fbc7-b450-4a93-a47f-12496c09a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-ac424b83-3c81-4080-9410-5b274682be49,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-cdffeceb-fedb-4db6-8a1d-62cfdaac69d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80637319-172.17.0.17-1597684414386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-6b536a76-4910-4c4e-9b11-6fffd9338c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-2a9d2ef1-e105-4570-8b6c-238373e9b423,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-09789de5-7752-4510-80d9-8658a852e3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-fac18aa4-133b-4813-9d95-497e72ae6328,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-3ab4631b-6a7d-4940-9e6b-7c37bbd90e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-24b165d6-4095-43c1-b727-58654d276834,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-a0ffb9d3-abdf-4b64-b1e2-45b040fbeb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-46152b91-42fb-4249-8a85-db56ebf27ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80637319-172.17.0.17-1597684414386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-6b536a76-4910-4c4e-9b11-6fffd9338c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-2a9d2ef1-e105-4570-8b6c-238373e9b423,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-09789de5-7752-4510-80d9-8658a852e3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-fac18aa4-133b-4813-9d95-497e72ae6328,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-3ab4631b-6a7d-4940-9e6b-7c37bbd90e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-24b165d6-4095-43c1-b727-58654d276834,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-a0ffb9d3-abdf-4b64-b1e2-45b040fbeb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-46152b91-42fb-4249-8a85-db56ebf27ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615279559-172.17.0.17-1597684663689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-be95f1cc-ab9d-44b5-ba46-c6ca26f5155e,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-3f16e3f5-b936-466a-9d33-b3007503f4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2ce1f8ac-b373-44cf-8399-c3f756713c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-537111b0-bbe9-40bd-a67c-5b0256eb4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-0fd56f73-42df-4367-8959-8da1c3f7f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-aebff5b2-8b03-444e-9ed9-494a8716df7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-bf45f276-6643-4691-914a-2cd55ebc31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-2e5636a6-2ff8-4c65-8885-bf3cbdbade1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615279559-172.17.0.17-1597684663689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-be95f1cc-ab9d-44b5-ba46-c6ca26f5155e,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-3f16e3f5-b936-466a-9d33-b3007503f4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2ce1f8ac-b373-44cf-8399-c3f756713c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-537111b0-bbe9-40bd-a67c-5b0256eb4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-0fd56f73-42df-4367-8959-8da1c3f7f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-aebff5b2-8b03-444e-9ed9-494a8716df7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-bf45f276-6643-4691-914a-2cd55ebc31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-2e5636a6-2ff8-4c65-8885-bf3cbdbade1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5485
