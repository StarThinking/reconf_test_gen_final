reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062040347-172.17.0.11-1597739221691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39127,DS-76724e2d-b72c-4201-bf37-8b35f77eb892,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-34a7028b-b19e-4f16-95d3-d8fca280ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-fe37c19e-d65b-499f-ac7b-ef5255ccf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-b9f642af-7926-44cb-9bba-970d79b6b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-377f0872-af9b-4141-9a84-b7bf1120da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-d8a31fc6-98a2-4bea-b5b5-e3ca32d6dcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-58431dc0-094f-4632-94a1-39e942b81ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a570081b-9ea8-4ee2-96eb-1fe7c57e8413,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062040347-172.17.0.11-1597739221691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39127,DS-76724e2d-b72c-4201-bf37-8b35f77eb892,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-34a7028b-b19e-4f16-95d3-d8fca280ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-fe37c19e-d65b-499f-ac7b-ef5255ccf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-b9f642af-7926-44cb-9bba-970d79b6b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-377f0872-af9b-4141-9a84-b7bf1120da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-d8a31fc6-98a2-4bea-b5b5-e3ca32d6dcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-58431dc0-094f-4632-94a1-39e942b81ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a570081b-9ea8-4ee2-96eb-1fe7c57e8413,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773597806-172.17.0.11-1597739609624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-660f379a-3f43-4359-a544-ce22e057dc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-48f66d71-c068-4151-bc7d-a06f418da80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-9606724c-e62f-441c-8d7c-46c1d9e05eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d3eaf360-811d-476e-b2bd-d43e1b879aab,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-3a0cc495-431e-4ae8-a726-01b94e438870,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-0b90ad90-00d8-46a1-88bd-f0f5d23c5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-ae18dd8f-f3e6-459e-a47c-b5affd29a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-7baa38fc-d442-49c4-b5dd-50b590c85b62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773597806-172.17.0.11-1597739609624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-660f379a-3f43-4359-a544-ce22e057dc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-48f66d71-c068-4151-bc7d-a06f418da80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-9606724c-e62f-441c-8d7c-46c1d9e05eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d3eaf360-811d-476e-b2bd-d43e1b879aab,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-3a0cc495-431e-4ae8-a726-01b94e438870,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-0b90ad90-00d8-46a1-88bd-f0f5d23c5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-ae18dd8f-f3e6-459e-a47c-b5affd29a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-7baa38fc-d442-49c4-b5dd-50b590c85b62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959424564-172.17.0.11-1597739735778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-66989de6-08ef-42c2-a871-6537f1ba9ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d7c68da9-da16-4b3b-ada0-9aee11154b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-29be3cca-6954-4891-acb9-d400b3fb4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-7f11d1b2-09d6-4dbb-b5ea-afd09fffdb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-dccfa415-de3c-4c75-abf3-7cf9fb06a897,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-e8dcf85f-136f-4df3-8c3d-5618fec01a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-ded8dfe4-6c8e-4b8b-8e15-45c13d96ab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3c071c45-a0ae-49c0-992c-9676329dc93a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959424564-172.17.0.11-1597739735778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-66989de6-08ef-42c2-a871-6537f1ba9ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d7c68da9-da16-4b3b-ada0-9aee11154b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-29be3cca-6954-4891-acb9-d400b3fb4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-7f11d1b2-09d6-4dbb-b5ea-afd09fffdb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-dccfa415-de3c-4c75-abf3-7cf9fb06a897,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-e8dcf85f-136f-4df3-8c3d-5618fec01a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-ded8dfe4-6c8e-4b8b-8e15-45c13d96ab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3c071c45-a0ae-49c0-992c-9676329dc93a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445639790-172.17.0.11-1597739805468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-29ce1a1a-d12d-46c6-ad2e-4a07d736ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-525a9652-fd63-47ed-bdb4-d90b43e67f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-87fc4eec-7525-46ed-bb32-76d5a6962293,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-9704cd73-f34c-40cd-b4cd-d09fd7bffc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-bb4ca5c6-f721-4af3-a9b1-9875c3e20cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-32e99c50-b1c3-4212-aaed-db26686b852f,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-6cb3c6a2-25e8-4c3a-8ce7-997579d528e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-cd1faa9c-0598-42d1-ae4f-9d17087c631e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445639790-172.17.0.11-1597739805468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-29ce1a1a-d12d-46c6-ad2e-4a07d736ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-525a9652-fd63-47ed-bdb4-d90b43e67f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-87fc4eec-7525-46ed-bb32-76d5a6962293,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-9704cd73-f34c-40cd-b4cd-d09fd7bffc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-bb4ca5c6-f721-4af3-a9b1-9875c3e20cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-32e99c50-b1c3-4212-aaed-db26686b852f,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-6cb3c6a2-25e8-4c3a-8ce7-997579d528e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-cd1faa9c-0598-42d1-ae4f-9d17087c631e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012082298-172.17.0.11-1597739965226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-88b7a5b6-4676-4b30-92a6-9da084c7cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-9b47176f-f1eb-4ea5-bc16-037b52fc8479,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-be913882-823a-4736-8e04-0d378fdd3496,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-27efa012-db5f-41e9-9f67-0ec38fb9d774,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d68bf720-9430-435e-9d35-871a87a0294b,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-4569f17b-ca8f-4f81-85c5-b0807b257175,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-3d7cdc14-5170-4621-8c39-f825c174cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-0fa8d5cc-0bc5-4483-a0e8-d3450fd7e5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012082298-172.17.0.11-1597739965226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-88b7a5b6-4676-4b30-92a6-9da084c7cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-9b47176f-f1eb-4ea5-bc16-037b52fc8479,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-be913882-823a-4736-8e04-0d378fdd3496,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-27efa012-db5f-41e9-9f67-0ec38fb9d774,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d68bf720-9430-435e-9d35-871a87a0294b,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-4569f17b-ca8f-4f81-85c5-b0807b257175,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-3d7cdc14-5170-4621-8c39-f825c174cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-0fa8d5cc-0bc5-4483-a0e8-d3450fd7e5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257091310-172.17.0.11-1597740044203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-654a58af-b17b-4a94-93aa-7c1c92c2f180,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-8ab10c59-660d-4cc8-afcd-2ce9912b9023,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-18e31e5f-c92a-4bca-88a6-2ba8a59873f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-bbf049a1-0d08-4180-9285-993f89935066,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-bdad815d-a195-4038-900f-c65781593b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-7a503ee0-05ab-4a65-8dbe-e990270ac079,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-4039e79a-acf9-4d67-91a0-bd549c8c68ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-b2478ee4-27aa-42d3-9ed2-fec70d2cd6cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257091310-172.17.0.11-1597740044203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-654a58af-b17b-4a94-93aa-7c1c92c2f180,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-8ab10c59-660d-4cc8-afcd-2ce9912b9023,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-18e31e5f-c92a-4bca-88a6-2ba8a59873f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-bbf049a1-0d08-4180-9285-993f89935066,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-bdad815d-a195-4038-900f-c65781593b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-7a503ee0-05ab-4a65-8dbe-e990270ac079,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-4039e79a-acf9-4d67-91a0-bd549c8c68ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-b2478ee4-27aa-42d3-9ed2-fec70d2cd6cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899826219-172.17.0.11-1597740088168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46495,DS-95bcb6c7-3a6a-41d0-8966-b15dd87622d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-354317ce-8082-45f7-a861-3d501aa5e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-c25adb49-60f7-477e-97a6-b2b4eec75563,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-c0eb940e-0c0c-49d2-a302-e49b120e5dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-d5040c0d-be47-494d-b439-0a1b6187068e,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-9709b2f5-cd01-480f-88d9-5f9229fb5505,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-fe947e5f-1a2d-462c-9dd1-716bd57393fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-a15130bb-d4c1-46e5-b1bf-1d18a5a01f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899826219-172.17.0.11-1597740088168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46495,DS-95bcb6c7-3a6a-41d0-8966-b15dd87622d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-354317ce-8082-45f7-a861-3d501aa5e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-c25adb49-60f7-477e-97a6-b2b4eec75563,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-c0eb940e-0c0c-49d2-a302-e49b120e5dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-d5040c0d-be47-494d-b439-0a1b6187068e,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-9709b2f5-cd01-480f-88d9-5f9229fb5505,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-fe947e5f-1a2d-462c-9dd1-716bd57393fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-a15130bb-d4c1-46e5-b1bf-1d18a5a01f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285093885-172.17.0.11-1597740408906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-155fa4b0-562c-453e-a504-7ba1c2005647,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-2eb3e986-34b4-408b-b62e-2fa178f57dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ff6c6a62-07ec-4acc-9e1d-b09ee4e3b002,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-660d0dbd-958b-4a16-99d7-1a3170cdb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-6b6bf71e-956b-483f-99b4-40528e61ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c563dccd-0b99-4e84-b163-13a6d85244d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-88687a06-26b8-45ee-920a-0b485a31fc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-e336ee27-67c2-460c-bdef-4caf2140493b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285093885-172.17.0.11-1597740408906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-155fa4b0-562c-453e-a504-7ba1c2005647,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-2eb3e986-34b4-408b-b62e-2fa178f57dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ff6c6a62-07ec-4acc-9e1d-b09ee4e3b002,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-660d0dbd-958b-4a16-99d7-1a3170cdb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-6b6bf71e-956b-483f-99b4-40528e61ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-c563dccd-0b99-4e84-b163-13a6d85244d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-88687a06-26b8-45ee-920a-0b485a31fc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-e336ee27-67c2-460c-bdef-4caf2140493b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143259173-172.17.0.11-1597740448587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-c6d15210-0371-4fcf-9071-910817a17e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d425b28a-75a4-46ff-82ca-b589b7865d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-a291a90a-6645-4ab7-8989-091fc0fbf691,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-fe79fd2f-79ef-46f2-80c7-93c59030c824,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-c1533078-a8a6-42f7-9fa8-e0c145aa744f,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-d03a0562-b8e4-4dfb-8d02-e6aae77454c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-53216d81-48d2-43f5-a620-c691ed0cc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-8850e88c-187f-401d-b40b-52ee99f113d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143259173-172.17.0.11-1597740448587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-c6d15210-0371-4fcf-9071-910817a17e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d425b28a-75a4-46ff-82ca-b589b7865d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-a291a90a-6645-4ab7-8989-091fc0fbf691,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-fe79fd2f-79ef-46f2-80c7-93c59030c824,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-c1533078-a8a6-42f7-9fa8-e0c145aa744f,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-d03a0562-b8e4-4dfb-8d02-e6aae77454c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-53216d81-48d2-43f5-a620-c691ed0cc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-8850e88c-187f-401d-b40b-52ee99f113d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134316894-172.17.0.11-1597740525401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40883,DS-9b1af4f7-8b8f-45fa-b08c-dceb0b5441df,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-2cc0151f-54af-4717-b40a-7d6e48dc56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-d5955ae0-f560-432a-b848-6d4c829cf460,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-875b141a-3618-4d4c-a76a-1274b075eade,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-f1df66da-e549-4c9d-aab2-8c62fbe73d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-a5d2ccb7-b0d2-4172-a45e-e116bf19b029,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f614e9f1-545d-46d9-bacb-37eec6d52cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-85d2ce11-2b02-4bc5-b68d-1327662d3bf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134316894-172.17.0.11-1597740525401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40883,DS-9b1af4f7-8b8f-45fa-b08c-dceb0b5441df,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-2cc0151f-54af-4717-b40a-7d6e48dc56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-d5955ae0-f560-432a-b848-6d4c829cf460,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-875b141a-3618-4d4c-a76a-1274b075eade,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-f1df66da-e549-4c9d-aab2-8c62fbe73d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-a5d2ccb7-b0d2-4172-a45e-e116bf19b029,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f614e9f1-545d-46d9-bacb-37eec6d52cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-85d2ce11-2b02-4bc5-b68d-1327662d3bf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999821235-172.17.0.11-1597741357755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-672e8370-ed7d-46da-a629-09c02739d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-d77b333a-10a9-450b-a2d7-7048e418a03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-e66b5797-c083-41a7-bbc2-aa9a2ac21e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-3139b98f-5cf9-4ea6-8e62-fa8e4aeeaf65,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0c61c1d7-5611-48bb-8e7c-3ff24888010d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-af84a5f4-3342-4b63-b496-62239209bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-85eebd2c-dc92-4df7-8272-afbc027818f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-ed0f89b8-b98d-4c6b-925a-79118c4fc89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999821235-172.17.0.11-1597741357755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-672e8370-ed7d-46da-a629-09c02739d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-d77b333a-10a9-450b-a2d7-7048e418a03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-e66b5797-c083-41a7-bbc2-aa9a2ac21e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-3139b98f-5cf9-4ea6-8e62-fa8e4aeeaf65,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0c61c1d7-5611-48bb-8e7c-3ff24888010d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-af84a5f4-3342-4b63-b496-62239209bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-85eebd2c-dc92-4df7-8272-afbc027818f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-ed0f89b8-b98d-4c6b-925a-79118c4fc89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606648758-172.17.0.11-1597741438706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-28e06856-6c77-49fa-8396-f2c74c2fe82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-bf2d99a1-c424-49ac-9cad-5a092f45b630,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-14a495d5-4a01-4dc2-b1db-2cbef135aae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-d70b4ce2-f26d-48fe-8a85-ef832a6c5632,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-43109274-8541-45c6-ab5e-0f13c618573f,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-c9244faa-8f77-44c7-8e51-43025ab50255,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-1ab1d8fb-d00c-4589-b111-18d83fb2095a,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-50676232-022f-4150-8e9e-929da5100ddf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606648758-172.17.0.11-1597741438706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-28e06856-6c77-49fa-8396-f2c74c2fe82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-bf2d99a1-c424-49ac-9cad-5a092f45b630,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-14a495d5-4a01-4dc2-b1db-2cbef135aae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-d70b4ce2-f26d-48fe-8a85-ef832a6c5632,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-43109274-8541-45c6-ab5e-0f13c618573f,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-c9244faa-8f77-44c7-8e51-43025ab50255,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-1ab1d8fb-d00c-4589-b111-18d83fb2095a,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-50676232-022f-4150-8e9e-929da5100ddf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529984550-172.17.0.11-1597741519740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-b9dd9e27-c55b-4613-ace5-fd998ee74e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-245cb418-3584-4bf3-b3c3-f4fd74c22124,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f8e2f702-cdd9-486a-8120-cf3601fc6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-443506f3-5a91-4feb-a33c-eb8d9d4a0d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-0ad8cce3-9e6f-45cc-82cc-d83770851ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-82eee890-b09f-49a7-8b24-e1a577b318ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-df9d34cb-9bbf-43e3-91e3-26f733627bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-6e167859-70bb-4abd-ad70-573afa61155d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529984550-172.17.0.11-1597741519740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-b9dd9e27-c55b-4613-ace5-fd998ee74e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-245cb418-3584-4bf3-b3c3-f4fd74c22124,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f8e2f702-cdd9-486a-8120-cf3601fc6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-443506f3-5a91-4feb-a33c-eb8d9d4a0d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-0ad8cce3-9e6f-45cc-82cc-d83770851ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-82eee890-b09f-49a7-8b24-e1a577b318ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-df9d34cb-9bbf-43e3-91e3-26f733627bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-6e167859-70bb-4abd-ad70-573afa61155d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263834641-172.17.0.11-1597741639121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-24ca670e-86bb-4359-a19e-32e3afa2ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-f4d1642b-2212-4a73-a56d-4b8e99e3102b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-12101210-4097-4ac4-aa67-f71986224d60,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-c7077141-23eb-4478-843a-c519a718eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-1e461202-0e3a-40d6-98c1-41a08a85b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-94e3002c-225a-4cbb-a9fc-da2f29aa77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-451faa06-0f53-4841-a9fc-0443ab14dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-6997da58-6e60-4ad2-bb4e-c23dffc65e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263834641-172.17.0.11-1597741639121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-24ca670e-86bb-4359-a19e-32e3afa2ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-f4d1642b-2212-4a73-a56d-4b8e99e3102b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-12101210-4097-4ac4-aa67-f71986224d60,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-c7077141-23eb-4478-843a-c519a718eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-1e461202-0e3a-40d6-98c1-41a08a85b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-94e3002c-225a-4cbb-a9fc-da2f29aa77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-451faa06-0f53-4841-a9fc-0443ab14dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-6997da58-6e60-4ad2-bb4e-c23dffc65e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464039390-172.17.0.11-1597741674596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-cd57498c-2565-4094-ad06-42228cfa618e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a2fca7fb-46bd-43d8-8f0c-9bea353568ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-6d63dc0d-13a2-4abd-b68d-7a29e50d9320,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-827acf7b-2b98-4742-9c8b-ebcfcff319f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-8fc0f80c-22cc-4ecc-addf-cf6dc2f4fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-5704be17-b013-4673-982b-c016d35b2028,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-95ebeb84-8200-4f2d-9a94-24982ea7848b,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2cdcddf7-1d16-418d-9726-d6cec98a23f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464039390-172.17.0.11-1597741674596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-cd57498c-2565-4094-ad06-42228cfa618e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a2fca7fb-46bd-43d8-8f0c-9bea353568ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-6d63dc0d-13a2-4abd-b68d-7a29e50d9320,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-827acf7b-2b98-4742-9c8b-ebcfcff319f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-8fc0f80c-22cc-4ecc-addf-cf6dc2f4fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-5704be17-b013-4673-982b-c016d35b2028,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-95ebeb84-8200-4f2d-9a94-24982ea7848b,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2cdcddf7-1d16-418d-9726-d6cec98a23f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50534631-172.17.0.11-1597741930669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-dd189307-02f8-4466-b49c-b2aa543eb2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-10a0053e-e139-4068-8a4f-51619750ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-e63975fa-066a-40f5-a970-961af1f8a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-0dbaa572-0b50-4997-a611-0087ccaf36f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-1556f380-a3b1-4e46-a40c-9450e6ef687e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-0f48dd2b-5cdd-4071-8c59-f953dd9a1e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-ae93cdbc-3f9d-4878-ace6-49fa72e2af54,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-e3373c48-46e4-4e2d-a56b-bbebdc4bc9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50534631-172.17.0.11-1597741930669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-dd189307-02f8-4466-b49c-b2aa543eb2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-10a0053e-e139-4068-8a4f-51619750ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-e63975fa-066a-40f5-a970-961af1f8a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-0dbaa572-0b50-4997-a611-0087ccaf36f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-1556f380-a3b1-4e46-a40c-9450e6ef687e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-0f48dd2b-5cdd-4071-8c59-f953dd9a1e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-ae93cdbc-3f9d-4878-ace6-49fa72e2af54,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-e3373c48-46e4-4e2d-a56b-bbebdc4bc9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002720465-172.17.0.11-1597742197126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-706445a0-0f9b-4a72-8e8b-b890ecebab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-72b85225-a8b0-42bf-9a65-4e41e8220e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-5adca34e-1863-4c47-97c7-c4d7227a3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-5ffcf83a-9dc3-4ea7-9a00-1ebe0ee0a089,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-edca669b-5dc4-49cd-9d2b-3d891276066a,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-28f6f425-393e-44ae-a7c8-3f2239acc5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-09fb8bdc-6b34-4556-bc56-322942628871,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-d7e6f528-b92a-4055-9aab-2d93fdd9c74d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002720465-172.17.0.11-1597742197126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-706445a0-0f9b-4a72-8e8b-b890ecebab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-72b85225-a8b0-42bf-9a65-4e41e8220e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-5adca34e-1863-4c47-97c7-c4d7227a3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-5ffcf83a-9dc3-4ea7-9a00-1ebe0ee0a089,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-edca669b-5dc4-49cd-9d2b-3d891276066a,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-28f6f425-393e-44ae-a7c8-3f2239acc5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-09fb8bdc-6b34-4556-bc56-322942628871,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-d7e6f528-b92a-4055-9aab-2d93fdd9c74d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182665295-172.17.0.11-1597742284204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-2dfd4220-08da-4dab-81e3-9f8f54cf6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-b078f4e8-ebfd-42d0-8beb-62bf7ddb7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-8d4c8884-c3d3-4db1-b100-6061838b25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a0214aa9-4b9d-423b-baa4-94a51e7e32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-21b80617-815a-47d1-97aa-60b21fd3213c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-e70dcaa8-4dd0-403b-8de7-f66fd4d26c54,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-5fb5e391-386d-4e70-8e72-58c6020577ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-b9cf1980-b16a-4343-b953-953970ddc44c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182665295-172.17.0.11-1597742284204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-2dfd4220-08da-4dab-81e3-9f8f54cf6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-b078f4e8-ebfd-42d0-8beb-62bf7ddb7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-8d4c8884-c3d3-4db1-b100-6061838b25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a0214aa9-4b9d-423b-baa4-94a51e7e32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-21b80617-815a-47d1-97aa-60b21fd3213c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-e70dcaa8-4dd0-403b-8de7-f66fd4d26c54,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-5fb5e391-386d-4e70-8e72-58c6020577ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-b9cf1980-b16a-4343-b953-953970ddc44c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160358450-172.17.0.11-1597742357676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-9e5e60ce-a1c7-4a7a-bf64-e21a4b2d9282,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-071d788d-3381-4be1-be9c-d3bf01903d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-0af18e2e-36bf-424a-87cb-3976e6b323e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e64cc316-a6d1-4212-a26a-f010fda6ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-f693207c-938c-4ce1-9862-73c6b5d3e312,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-68b504ab-84ba-41a7-bb42-02705e6ce55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-ed0c855e-4c1d-480c-a660-60bbcf719aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-a8915735-ff49-436f-ba7d-4042273e135d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160358450-172.17.0.11-1597742357676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-9e5e60ce-a1c7-4a7a-bf64-e21a4b2d9282,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-071d788d-3381-4be1-be9c-d3bf01903d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-0af18e2e-36bf-424a-87cb-3976e6b323e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e64cc316-a6d1-4212-a26a-f010fda6ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-f693207c-938c-4ce1-9862-73c6b5d3e312,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-68b504ab-84ba-41a7-bb42-02705e6ce55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-ed0c855e-4c1d-480c-a660-60bbcf719aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-a8915735-ff49-436f-ba7d-4042273e135d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294628039-172.17.0.11-1597742709832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-4b4e8950-3fb3-4e9a-a1f1-340aeefbb657,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-dc33b5af-f193-4622-bad6-7ee82e91fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-465e59c3-0739-4027-926f-2c1331efc100,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d3eadc79-de94-44d9-ba9e-f34e977c93e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-e88921a2-4fa9-48b0-ba2b-e10345c878ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-352b5605-2abb-41d6-8bc2-6bc6b0af630b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-29250cab-e1f9-46ed-9e45-090893a7370c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-2b0edc91-427d-40bd-87b0-2b10d71e13ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294628039-172.17.0.11-1597742709832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-4b4e8950-3fb3-4e9a-a1f1-340aeefbb657,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-dc33b5af-f193-4622-bad6-7ee82e91fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-465e59c3-0739-4027-926f-2c1331efc100,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d3eadc79-de94-44d9-ba9e-f34e977c93e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-e88921a2-4fa9-48b0-ba2b-e10345c878ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-352b5605-2abb-41d6-8bc2-6bc6b0af630b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-29250cab-e1f9-46ed-9e45-090893a7370c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-2b0edc91-427d-40bd-87b0-2b10d71e13ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530316520-172.17.0.11-1597742840297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-d2e0c5da-8698-4ce6-a2d9-33e10d9c5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-7d31b57c-99a9-4368-9cc4-4ecdc58a60d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-9f592912-7e89-41a3-a0e5-0b638a405a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ebb62073-de47-4eb4-b37a-aadf64045d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-93aaf0fa-7c3b-462b-94ed-b6e0549febdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e2ee376e-2b7c-4e4a-ab34-2e603ba9affe,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-dd2388fa-3e30-4a1c-a6aa-c6faaeb9c2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-591bbc11-1821-414d-ba5e-47a37d929df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530316520-172.17.0.11-1597742840297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-d2e0c5da-8698-4ce6-a2d9-33e10d9c5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-7d31b57c-99a9-4368-9cc4-4ecdc58a60d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-9f592912-7e89-41a3-a0e5-0b638a405a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ebb62073-de47-4eb4-b37a-aadf64045d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-93aaf0fa-7c3b-462b-94ed-b6e0549febdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e2ee376e-2b7c-4e4a-ab34-2e603ba9affe,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-dd2388fa-3e30-4a1c-a6aa-c6faaeb9c2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-591bbc11-1821-414d-ba5e-47a37d929df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766469017-172.17.0.11-1597742883441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-6c2ebe4a-b879-45ee-b0cf-bfd726480014,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-ac61329b-3bda-4f82-b594-b137226fbd33,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-e1a53040-a809-4990-95eb-4dc0bcd834ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-08c33aad-b920-4664-9d0f-bea861e0c515,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-b7556151-de86-4a94-9ac5-c46540289567,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-df58b3d5-ea10-40ad-ba18-6326b3fa880f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-d1aeb311-a845-41ed-8464-b35a32ecf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-11a72404-bda7-4c00-831f-a9f228545a0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766469017-172.17.0.11-1597742883441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-6c2ebe4a-b879-45ee-b0cf-bfd726480014,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-ac61329b-3bda-4f82-b594-b137226fbd33,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-e1a53040-a809-4990-95eb-4dc0bcd834ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-08c33aad-b920-4664-9d0f-bea861e0c515,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-b7556151-de86-4a94-9ac5-c46540289567,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-df58b3d5-ea10-40ad-ba18-6326b3fa880f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-d1aeb311-a845-41ed-8464-b35a32ecf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-11a72404-bda7-4c00-831f-a9f228545a0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235666830-172.17.0.11-1597743003780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-3fd4d521-31d2-44b9-9ee7-98c214a6b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-8dd19a94-1792-45b2-8f6d-496872e95790,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-bc17b3a3-9056-41f4-ba17-4d0ac17b7818,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-1dc3d655-8aed-4bc4-a930-e1bf70a553de,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-a5ac5d1e-6493-497c-bdce-2d6451897953,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-5b200aa9-bdab-4441-8e9a-62872237690e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-d5019fce-0653-4a71-934f-c36cb6474e87,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-2ffee5cb-0958-478a-958f-e77dcf8d592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235666830-172.17.0.11-1597743003780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-3fd4d521-31d2-44b9-9ee7-98c214a6b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-8dd19a94-1792-45b2-8f6d-496872e95790,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-bc17b3a3-9056-41f4-ba17-4d0ac17b7818,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-1dc3d655-8aed-4bc4-a930-e1bf70a553de,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-a5ac5d1e-6493-497c-bdce-2d6451897953,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-5b200aa9-bdab-4441-8e9a-62872237690e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-d5019fce-0653-4a71-934f-c36cb6474e87,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-2ffee5cb-0958-478a-958f-e77dcf8d592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618570897-172.17.0.11-1597743117748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38323,DS-78bcc6cb-b3bd-4710-8ee9-7d17c90ab097,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a62f4927-8faa-4234-bd88-ceed3ac94eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-bfce2b80-ba95-4d43-bab1-480f8e1e1679,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-e86b8a1a-dc6d-4936-a9ea-343a1ce91a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-1ee16c2b-ca87-4fa0-8cd5-d16b4d26dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-78c86542-a194-49d1-89d0-827c49fe4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-6f74774f-278a-4648-9c7c-9b84b23f2342,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-64c76142-2588-47f5-a7bf-aeb73ba36697,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618570897-172.17.0.11-1597743117748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38323,DS-78bcc6cb-b3bd-4710-8ee9-7d17c90ab097,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a62f4927-8faa-4234-bd88-ceed3ac94eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-bfce2b80-ba95-4d43-bab1-480f8e1e1679,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-e86b8a1a-dc6d-4936-a9ea-343a1ce91a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-1ee16c2b-ca87-4fa0-8cd5-d16b4d26dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-78c86542-a194-49d1-89d0-827c49fe4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-6f74774f-278a-4648-9c7c-9b84b23f2342,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-64c76142-2588-47f5-a7bf-aeb73ba36697,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034548440-172.17.0.11-1597743208561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-2a482196-f2b9-4446-8390-505c1b90a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-480e96d5-2af8-4582-a3cb-082365ed733c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-f8860d50-a42d-47ec-bb91-57db7ab24be8,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ae46b07c-36cc-4d3d-93c6-1d2d608263a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-fa26c3cb-d950-4505-ba15-833b92755346,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-191381b6-170e-4f06-9fe0-7b26f6f05cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-697a4510-31a8-428f-a5f2-cdee6c1a89b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-de59ebf0-8f45-4555-a88d-9d6ad89159a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034548440-172.17.0.11-1597743208561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-2a482196-f2b9-4446-8390-505c1b90a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-480e96d5-2af8-4582-a3cb-082365ed733c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-f8860d50-a42d-47ec-bb91-57db7ab24be8,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ae46b07c-36cc-4d3d-93c6-1d2d608263a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-fa26c3cb-d950-4505-ba15-833b92755346,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-191381b6-170e-4f06-9fe0-7b26f6f05cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-697a4510-31a8-428f-a5f2-cdee6c1a89b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-de59ebf0-8f45-4555-a88d-9d6ad89159a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192634190-172.17.0.11-1597743243127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42202,DS-22485357-2a83-4a61-981c-9a666006ceee,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-0a096324-4864-44b3-8a33-6c9bf8621d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-311d57db-8e91-4163-8b9d-9d766a705d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-5efd1d00-a40d-4f05-b708-2f79c75951af,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0c359b1f-ebde-4eb1-a25a-891f6b9f7127,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-ddd86c4c-a005-4b71-bb60-9c7cc3bb9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3753ec19-f70a-4932-bc47-610b9f4117bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-9e7d8d7e-7f9b-4a65-ab88-96326c463a81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192634190-172.17.0.11-1597743243127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42202,DS-22485357-2a83-4a61-981c-9a666006ceee,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-0a096324-4864-44b3-8a33-6c9bf8621d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-311d57db-8e91-4163-8b9d-9d766a705d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-5efd1d00-a40d-4f05-b708-2f79c75951af,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0c359b1f-ebde-4eb1-a25a-891f6b9f7127,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-ddd86c4c-a005-4b71-bb60-9c7cc3bb9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3753ec19-f70a-4932-bc47-610b9f4117bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-9e7d8d7e-7f9b-4a65-ab88-96326c463a81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18733717-172.17.0.11-1597743281448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-a3c67016-0546-414f-964f-9b445cd1fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-a35d6626-3e49-45ec-b9fd-ee628b1da9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-7e2c159a-6189-45d6-a15d-aa5308f557fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c736e235-2ed4-4847-9285-616ddaeb6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-48a5c50e-7046-44f7-9245-edda88b0bab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-c8a9d2e8-6833-4f4a-b20d-d3dd2583e796,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-cc9645df-68a4-46a4-907c-68605d3a6750,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-35d7c31c-a0fa-4203-aadf-3b48c3fa5a2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18733717-172.17.0.11-1597743281448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-a3c67016-0546-414f-964f-9b445cd1fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-a35d6626-3e49-45ec-b9fd-ee628b1da9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-7e2c159a-6189-45d6-a15d-aa5308f557fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c736e235-2ed4-4847-9285-616ddaeb6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-48a5c50e-7046-44f7-9245-edda88b0bab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-c8a9d2e8-6833-4f4a-b20d-d3dd2583e796,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-cc9645df-68a4-46a4-907c-68605d3a6750,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-35d7c31c-a0fa-4203-aadf-3b48c3fa5a2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135482754-172.17.0.11-1597743401780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-67e2b435-6c46-490e-afe8-a3607d2d3a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-36a9b7ed-467b-4506-8bde-bad77ed5ab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-4cda3817-1007-45f6-869a-0f407b4601d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-e9340bd1-8fa1-47db-bc04-356b47fa6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bc4a4839-fd95-4cb4-8040-a4fee0cce74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-694ca190-afab-4465-8821-25199e03530d,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-ee36a570-ca63-4918-a3bb-08c0e3a21f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5de95eae-c47d-41eb-99af-30437ab6eed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135482754-172.17.0.11-1597743401780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-67e2b435-6c46-490e-afe8-a3607d2d3a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-36a9b7ed-467b-4506-8bde-bad77ed5ab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-4cda3817-1007-45f6-869a-0f407b4601d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-e9340bd1-8fa1-47db-bc04-356b47fa6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bc4a4839-fd95-4cb4-8040-a4fee0cce74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-694ca190-afab-4465-8821-25199e03530d,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-ee36a570-ca63-4918-a3bb-08c0e3a21f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5de95eae-c47d-41eb-99af-30437ab6eed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833147075-172.17.0.11-1597743513057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-333e7602-23b2-4afb-a150-2e89dbe18086,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-961ba4ba-49c6-48cf-8bc3-981206cf39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e2458816-1f9c-42d9-9fca-657abce16c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-4c17776d-e91d-4968-aeb1-8901c3133192,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-7c826e0c-38fe-4e11-af48-6b490b3913fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-f628d509-7197-4929-aa5f-a6a33540d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-20b349fb-f464-4c45-a8b0-0a6ce9fdea74,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-0884999c-8049-4962-915f-fb8872fb5c81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833147075-172.17.0.11-1597743513057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-333e7602-23b2-4afb-a150-2e89dbe18086,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-961ba4ba-49c6-48cf-8bc3-981206cf39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e2458816-1f9c-42d9-9fca-657abce16c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-4c17776d-e91d-4968-aeb1-8901c3133192,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-7c826e0c-38fe-4e11-af48-6b490b3913fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-f628d509-7197-4929-aa5f-a6a33540d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-20b349fb-f464-4c45-a8b0-0a6ce9fdea74,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-0884999c-8049-4962-915f-fb8872fb5c81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102599724-172.17.0.11-1597743781943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-ace37fab-e7a1-477b-8b0a-e0d294e38362,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-011e5e96-d209-4910-ba03-c60531823c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-5bee808e-6435-4093-b7e9-ac2bb1c2bf13,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-d6befd5d-f9b1-4d9a-8b88-845d51d9552b,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-48a321c5-ac3d-4390-9863-959b45645f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-9509418b-371a-46dc-ab22-c4ab2512b974,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e362ee77-4698-4ace-8834-3e00eecd160e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f119b561-b2ac-4e0a-9efa-fe830de73674,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102599724-172.17.0.11-1597743781943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-ace37fab-e7a1-477b-8b0a-e0d294e38362,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-011e5e96-d209-4910-ba03-c60531823c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-5bee808e-6435-4093-b7e9-ac2bb1c2bf13,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-d6befd5d-f9b1-4d9a-8b88-845d51d9552b,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-48a321c5-ac3d-4390-9863-959b45645f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-9509418b-371a-46dc-ab22-c4ab2512b974,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e362ee77-4698-4ace-8834-3e00eecd160e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f119b561-b2ac-4e0a-9efa-fe830de73674,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078931921-172.17.0.11-1597744418471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-6e06d2f0-8977-458e-ada4-a9ce41970636,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-f2577107-45e8-485d-aed9-ed7fa96ad36a,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-e93b50e5-fb3e-4653-9ea4-dff820edf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-5d917994-44ed-4f88-8e9e-c7e8332cfce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-c6296a21-626d-4865-9b39-a88de6a9d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-522fb6ec-5152-4f39-b1c1-1bce51080bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-203d51a8-5b13-4128-8883-db225ad87546,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-3038969d-f92f-496d-9c63-37a63215171f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078931921-172.17.0.11-1597744418471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-6e06d2f0-8977-458e-ada4-a9ce41970636,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-f2577107-45e8-485d-aed9-ed7fa96ad36a,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-e93b50e5-fb3e-4653-9ea4-dff820edf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-5d917994-44ed-4f88-8e9e-c7e8332cfce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-c6296a21-626d-4865-9b39-a88de6a9d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-522fb6ec-5152-4f39-b1c1-1bce51080bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-203d51a8-5b13-4128-8883-db225ad87546,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-3038969d-f92f-496d-9c63-37a63215171f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532933313-172.17.0.11-1597744502187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42971,DS-971169ad-b41b-40de-8ffc-5aaa4529d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-78425c14-bba8-438d-bd46-5a28d7ad2b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-ef3c3052-5ec6-4090-a55a-b2c9c243c064,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-bc8ab203-2487-4963-a822-4dc82093cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-d67b3368-1cbf-4110-8823-5cbdc5b0307f,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-597ac7b1-96a0-460e-8687-f2b14b8df704,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-b6a23252-ee5b-434e-a28b-5451e70aba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-3b42edcf-b9d0-447b-8b49-0ecd839f8522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532933313-172.17.0.11-1597744502187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42971,DS-971169ad-b41b-40de-8ffc-5aaa4529d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-78425c14-bba8-438d-bd46-5a28d7ad2b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-ef3c3052-5ec6-4090-a55a-b2c9c243c064,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-bc8ab203-2487-4963-a822-4dc82093cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-d67b3368-1cbf-4110-8823-5cbdc5b0307f,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-597ac7b1-96a0-460e-8687-f2b14b8df704,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-b6a23252-ee5b-434e-a28b-5451e70aba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-3b42edcf-b9d0-447b-8b49-0ecd839f8522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989096579-172.17.0.11-1597744537744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-6da45e4a-e749-4f2b-bbf9-6b75ec47630f,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-1760857e-743e-4dd3-94be-88a92dac36d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-84a81e90-a369-43c7-baa4-72054ad6cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-63bf9080-b34a-456c-ad71-c3ab3c9cf637,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c6af6460-4d19-4b1f-b585-9e808545fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-a4529026-6efd-4bcb-bb0d-b1adb818b188,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6aa40273-7928-4e0c-a2a7-22070f951436,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-c37bd392-9182-4594-aae8-d198e769d23a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989096579-172.17.0.11-1597744537744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-6da45e4a-e749-4f2b-bbf9-6b75ec47630f,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-1760857e-743e-4dd3-94be-88a92dac36d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-84a81e90-a369-43c7-baa4-72054ad6cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-63bf9080-b34a-456c-ad71-c3ab3c9cf637,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c6af6460-4d19-4b1f-b585-9e808545fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-a4529026-6efd-4bcb-bb0d-b1adb818b188,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6aa40273-7928-4e0c-a2a7-22070f951436,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-c37bd392-9182-4594-aae8-d198e769d23a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811804036-172.17.0.11-1597744618002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-3aaab4b1-6a13-409e-9dc6-ea0a07537635,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-070e63cd-5f9d-4b51-83b9-8e48d552d378,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-3ec5a216-6c7f-43d6-b991-ba2a525bb362,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-24bcf86e-30d3-4bad-aa5f-cfc1e875dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-91b35d01-f9d5-4901-b392-939676f775cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6cf31ab8-76a7-432a-83d1-92512ca00292,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-550a6b05-b54b-4c29-94b9-8051a04c7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-e22e6cc2-cef4-4340-91de-44728ea80a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811804036-172.17.0.11-1597744618002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-3aaab4b1-6a13-409e-9dc6-ea0a07537635,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-070e63cd-5f9d-4b51-83b9-8e48d552d378,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-3ec5a216-6c7f-43d6-b991-ba2a525bb362,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-24bcf86e-30d3-4bad-aa5f-cfc1e875dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-91b35d01-f9d5-4901-b392-939676f775cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6cf31ab8-76a7-432a-83d1-92512ca00292,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-550a6b05-b54b-4c29-94b9-8051a04c7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-e22e6cc2-cef4-4340-91de-44728ea80a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440003817-172.17.0.11-1597744706709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-e2873346-2ac9-4283-accc-e56502d8270f,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-181bff3b-e119-469d-951c-ea5704e614f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2a00fdac-fa94-4689-9bde-a2f6de0a3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-0aa75e4e-17bd-4a87-9824-c5356a8f7f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-581a2a02-4c48-4944-982d-911cfe5adc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-859a8f55-6ed9-4a4e-b4f8-5fab0656ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f7a156a7-d661-4e5d-95b2-3b245eff9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-d4a3bf0f-39d4-4d1a-955b-320b4ff6352c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440003817-172.17.0.11-1597744706709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-e2873346-2ac9-4283-accc-e56502d8270f,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-181bff3b-e119-469d-951c-ea5704e614f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2a00fdac-fa94-4689-9bde-a2f6de0a3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-0aa75e4e-17bd-4a87-9824-c5356a8f7f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-581a2a02-4c48-4944-982d-911cfe5adc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-859a8f55-6ed9-4a4e-b4f8-5fab0656ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f7a156a7-d661-4e5d-95b2-3b245eff9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-d4a3bf0f-39d4-4d1a-955b-320b4ff6352c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459862482-172.17.0.11-1597744912593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-42617ac4-d940-4567-aa53-58f88b0e23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-484fe128-cd1c-47bf-a5dc-fa073ddc42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-7ec2685a-77d2-424e-8d8c-b49777fcf989,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-fda08a58-944d-4542-aced-350a0b9e1981,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-ef27a4a1-e2a2-49f8-992a-a2bae0ce61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-dcc0d878-7d9f-45e6-94dd-96eb5dcd80c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-3fb85956-e68a-4c8c-b275-bfada95a9be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-16f492ce-a781-4f46-bdc3-409028f79678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459862482-172.17.0.11-1597744912593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-42617ac4-d940-4567-aa53-58f88b0e23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-484fe128-cd1c-47bf-a5dc-fa073ddc42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-7ec2685a-77d2-424e-8d8c-b49777fcf989,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-fda08a58-944d-4542-aced-350a0b9e1981,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-ef27a4a1-e2a2-49f8-992a-a2bae0ce61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-dcc0d878-7d9f-45e6-94dd-96eb5dcd80c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-3fb85956-e68a-4c8c-b275-bfada95a9be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-16f492ce-a781-4f46-bdc3-409028f79678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326269789-172.17.0.11-1597745097606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-184b0354-9071-4153-a42f-db2674a1d982,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-5a4a8e7b-e945-48d8-affd-c86f24f58fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-e90435c5-3d3a-48fc-b2e5-96ebfeb213a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-4f30825d-6e68-44d9-aa2d-16967ed7e654,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-45f8e006-bed5-452d-8f65-7b1bdbf73714,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-20c05f5d-597f-4450-9253-676fc74d7496,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e870d9ed-9c6d-4b08-920b-d3d8841a13c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-ba83787f-f0a8-4cf5-8e0b-306894c8d754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326269789-172.17.0.11-1597745097606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-184b0354-9071-4153-a42f-db2674a1d982,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-5a4a8e7b-e945-48d8-affd-c86f24f58fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-e90435c5-3d3a-48fc-b2e5-96ebfeb213a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-4f30825d-6e68-44d9-aa2d-16967ed7e654,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-45f8e006-bed5-452d-8f65-7b1bdbf73714,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-20c05f5d-597f-4450-9253-676fc74d7496,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e870d9ed-9c6d-4b08-920b-d3d8841a13c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-ba83787f-f0a8-4cf5-8e0b-306894c8d754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5960
