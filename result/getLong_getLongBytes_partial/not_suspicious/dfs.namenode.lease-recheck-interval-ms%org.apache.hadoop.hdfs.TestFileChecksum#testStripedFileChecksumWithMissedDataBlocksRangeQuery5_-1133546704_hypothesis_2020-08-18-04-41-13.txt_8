reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806526269-172.17.0.4-1597726069574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-5292c5e4-8aee-416f-b8b3-05664fcc2f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-026c715b-aaf0-42b7-bedd-5166ff4c1228,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-232b91c4-db4d-4643-93b7-bef807acd0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-e3962b55-0666-4c21-81ec-f46e3e6c4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-8e0d9999-77e7-4a3a-ae9e-18d89908f345,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-120fb6e7-c617-45bb-a9d0-ac6cde1cc29b,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-4d4d9736-e6eb-4b94-bb64-18572987cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-aa7c1f63-944d-4eae-bc1a-0b2b6996da1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806526269-172.17.0.4-1597726069574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-5292c5e4-8aee-416f-b8b3-05664fcc2f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-026c715b-aaf0-42b7-bedd-5166ff4c1228,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-232b91c4-db4d-4643-93b7-bef807acd0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-e3962b55-0666-4c21-81ec-f46e3e6c4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-8e0d9999-77e7-4a3a-ae9e-18d89908f345,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-120fb6e7-c617-45bb-a9d0-ac6cde1cc29b,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-4d4d9736-e6eb-4b94-bb64-18572987cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-aa7c1f63-944d-4eae-bc1a-0b2b6996da1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128813328-172.17.0.4-1597726185792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-5f322c4b-0163-43cb-848c-8150144aaa25,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-5aa437ff-cc3d-442b-a8ee-927e222b4de1,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0f187db5-2e15-4a99-84e2-1f6949d3938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-50fd9935-0f10-432b-9406-28e00662ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-02aedf2e-6aca-42a1-bd14-de4f495b0e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-e5414932-7a4f-41f7-a8b1-22b3aa6c8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-f36293ac-ca99-49cb-8a0e-ca32ee3ec26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-6cce4a0d-616e-4579-9d15-d4ad6c7c3f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128813328-172.17.0.4-1597726185792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-5f322c4b-0163-43cb-848c-8150144aaa25,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-5aa437ff-cc3d-442b-a8ee-927e222b4de1,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0f187db5-2e15-4a99-84e2-1f6949d3938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-50fd9935-0f10-432b-9406-28e00662ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-02aedf2e-6aca-42a1-bd14-de4f495b0e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-e5414932-7a4f-41f7-a8b1-22b3aa6c8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-f36293ac-ca99-49cb-8a0e-ca32ee3ec26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-6cce4a0d-616e-4579-9d15-d4ad6c7c3f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051133799-172.17.0.4-1597726303378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-62a8340e-9dec-4f25-8534-a9791892eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-88851a2f-6ba8-45fb-a31c-2dcc86a87ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-ee88848d-293b-49c7-a101-63da8d5ed826,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-ffc308a5-7c4d-4bd6-9d46-4301a4c38153,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-24880001-edd7-4b23-bd5c-158ac6ad5912,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-594d1da6-197f-4116-8147-fb53d696fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-2ccdc6a2-5a8d-43a7-8b10-d43ca8398118,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-2618b85a-c6aa-4aff-88b6-8bd4f8f41a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051133799-172.17.0.4-1597726303378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-62a8340e-9dec-4f25-8534-a9791892eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-88851a2f-6ba8-45fb-a31c-2dcc86a87ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-ee88848d-293b-49c7-a101-63da8d5ed826,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-ffc308a5-7c4d-4bd6-9d46-4301a4c38153,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-24880001-edd7-4b23-bd5c-158ac6ad5912,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-594d1da6-197f-4116-8147-fb53d696fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-2ccdc6a2-5a8d-43a7-8b10-d43ca8398118,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-2618b85a-c6aa-4aff-88b6-8bd4f8f41a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16605129-172.17.0.4-1597726383285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-718bcf7a-12cd-4613-a648-6969f9b36f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-37cf0a73-c36a-4165-91f3-ce23778a6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-db42caa5-c4f2-47b4-8564-81f98abf814c,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-186cd757-dc0c-464f-883c-60e70d204d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-7c6ec512-5650-4f68-9985-086d41cdfdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-12c99d31-6d9b-4e38-902b-86ea0f6d4405,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-7d565137-b4a0-4498-b15f-d91308f5f773,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2a6408f7-d62c-4513-9338-d71c48b5b0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16605129-172.17.0.4-1597726383285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-718bcf7a-12cd-4613-a648-6969f9b36f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-37cf0a73-c36a-4165-91f3-ce23778a6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-db42caa5-c4f2-47b4-8564-81f98abf814c,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-186cd757-dc0c-464f-883c-60e70d204d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-7c6ec512-5650-4f68-9985-086d41cdfdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-12c99d31-6d9b-4e38-902b-86ea0f6d4405,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-7d565137-b4a0-4498-b15f-d91308f5f773,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2a6408f7-d62c-4513-9338-d71c48b5b0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103249016-172.17.0.4-1597726614948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45083,DS-6ffb0174-4e60-4e97-83ee-8ad304d736c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-d0e76244-675a-466c-a4e2-7365a3f29cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-8c7e40ce-ca39-4d60-89db-018b4ba111b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-2bca351b-a32c-43de-8a6b-20de229ff312,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-e974efa5-97bb-463d-b4d4-39d1bee1e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-5d675562-912f-4b36-b09e-d8a396bbece6,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-5f6369f1-62f5-435a-99c7-5c73d88085b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-68952776-9fac-4a4e-a936-9feceeb7eabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103249016-172.17.0.4-1597726614948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45083,DS-6ffb0174-4e60-4e97-83ee-8ad304d736c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-d0e76244-675a-466c-a4e2-7365a3f29cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-8c7e40ce-ca39-4d60-89db-018b4ba111b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-2bca351b-a32c-43de-8a6b-20de229ff312,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-e974efa5-97bb-463d-b4d4-39d1bee1e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-5d675562-912f-4b36-b09e-d8a396bbece6,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-5f6369f1-62f5-435a-99c7-5c73d88085b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-68952776-9fac-4a4e-a936-9feceeb7eabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302086381-172.17.0.4-1597727255506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-dc36e2b2-63e4-4b5f-a768-5223ad8571cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-a27a6e8a-6503-4b12-b8e5-1781ab602a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0736ffc7-00d7-4178-ab5d-58db13ab9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-983c73dc-56a9-4792-9a88-0bc79a053044,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-a452af31-f02c-4f2d-9c26-70cda3ff8fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-db9a77cd-c438-4b48-a17e-45db5edcf3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6ae47176-e3e4-480e-ae00-bc65a31512cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-4f9de630-6eee-4322-8a77-e10bb010fec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302086381-172.17.0.4-1597727255506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-dc36e2b2-63e4-4b5f-a768-5223ad8571cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-a27a6e8a-6503-4b12-b8e5-1781ab602a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0736ffc7-00d7-4178-ab5d-58db13ab9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-983c73dc-56a9-4792-9a88-0bc79a053044,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-a452af31-f02c-4f2d-9c26-70cda3ff8fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-db9a77cd-c438-4b48-a17e-45db5edcf3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6ae47176-e3e4-480e-ae00-bc65a31512cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-4f9de630-6eee-4322-8a77-e10bb010fec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258256582-172.17.0.4-1597727486117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-09d2373e-b35e-4e57-870f-f54573887146,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-4eb63538-27fa-4014-bb1d-f24e9ce1c5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-5924e91a-8b2f-4841-b04b-1ec44bdd0be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-3184c0e4-5883-489e-a879-349846ae206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-9b9e6527-30df-4879-8111-422f96290365,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-8d210280-3c02-48bf-a7a5-12efc3eeae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-701a7301-b8b0-40a8-b9fc-5eaf0fe15d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d9619285-0bbb-4078-a59f-2f93b3082a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258256582-172.17.0.4-1597727486117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-09d2373e-b35e-4e57-870f-f54573887146,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-4eb63538-27fa-4014-bb1d-f24e9ce1c5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-5924e91a-8b2f-4841-b04b-1ec44bdd0be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-3184c0e4-5883-489e-a879-349846ae206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-9b9e6527-30df-4879-8111-422f96290365,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-8d210280-3c02-48bf-a7a5-12efc3eeae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-701a7301-b8b0-40a8-b9fc-5eaf0fe15d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d9619285-0bbb-4078-a59f-2f93b3082a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319822431-172.17.0.4-1597728369151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-20abdd35-1129-4b1e-ba1f-ab8baf1a6cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-5d0445f1-5043-4466-aa50-e60528bca779,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-4c8eb469-27a3-4939-be1f-11bd5b14a3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-6493aaac-6642-4d9a-ac9e-fb2b857c3062,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9d086cef-9d8f-40a9-8d7c-a7de57952908,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-be1f85d5-e1ba-4c68-ab93-b0172305d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-0e347bdb-8580-4b02-8b6e-05b40862d891,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-26a7c42c-2954-49a6-8a53-fe7ca1227864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319822431-172.17.0.4-1597728369151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-20abdd35-1129-4b1e-ba1f-ab8baf1a6cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-5d0445f1-5043-4466-aa50-e60528bca779,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-4c8eb469-27a3-4939-be1f-11bd5b14a3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-6493aaac-6642-4d9a-ac9e-fb2b857c3062,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9d086cef-9d8f-40a9-8d7c-a7de57952908,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-be1f85d5-e1ba-4c68-ab93-b0172305d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-0e347bdb-8580-4b02-8b6e-05b40862d891,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-26a7c42c-2954-49a6-8a53-fe7ca1227864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70463830-172.17.0.4-1597728511376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46710,DS-c7a9fd3b-d535-47e3-b386-65b2dd902c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-92a72836-dc0c-42a0-b060-ff7614fd0ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0be976c3-eec5-4350-a125-e4c5d5e7ab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ac4718c6-2b00-43ae-85c6-c85c971557e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-deca1f23-520d-4835-9dc1-c43601046da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-83216dc6-81a4-46b9-a4b6-c21f7f47216a,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f3bba3a3-a44c-4112-8c97-15175230920c,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-f31f9519-5ba3-4240-a11b-36485e92179d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70463830-172.17.0.4-1597728511376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46710,DS-c7a9fd3b-d535-47e3-b386-65b2dd902c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-92a72836-dc0c-42a0-b060-ff7614fd0ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0be976c3-eec5-4350-a125-e4c5d5e7ab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ac4718c6-2b00-43ae-85c6-c85c971557e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-deca1f23-520d-4835-9dc1-c43601046da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-83216dc6-81a4-46b9-a4b6-c21f7f47216a,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f3bba3a3-a44c-4112-8c97-15175230920c,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-f31f9519-5ba3-4240-a11b-36485e92179d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078618966-172.17.0.4-1597728586571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-b6039a03-8214-497c-b394-73c779061340,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-daf8b75a-4c77-4504-8159-dd3f4a8fbaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-87442a8b-7206-40ae-a5a1-15addf355d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-72e4a137-11a4-4106-a479-c311abd010b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-7892a6f9-bdf7-4e00-8219-b65c868d5476,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-80f915cf-68f4-4c69-b533-cd154d1b24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-37c45e90-b939-46a9-87e6-80b2e15e1856,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-39049fcc-108a-413b-aa5c-cbe2602ab7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078618966-172.17.0.4-1597728586571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-b6039a03-8214-497c-b394-73c779061340,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-daf8b75a-4c77-4504-8159-dd3f4a8fbaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-87442a8b-7206-40ae-a5a1-15addf355d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-72e4a137-11a4-4106-a479-c311abd010b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-7892a6f9-bdf7-4e00-8219-b65c868d5476,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-80f915cf-68f4-4c69-b533-cd154d1b24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-37c45e90-b939-46a9-87e6-80b2e15e1856,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-39049fcc-108a-413b-aa5c-cbe2602ab7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753614090-172.17.0.4-1597730118723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-bd840dc4-bbb3-478a-af0a-3a31665cb706,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-d73271e9-c9bd-4882-9c94-a052b91004cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-8f5fd964-0a09-4888-8db7-a6c3c7895e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-2716f49d-7522-4df3-82f6-9e089f1289a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-0a2ce9d3-1a90-449b-a93e-7f3009e096f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-5523c82e-526a-4739-a79d-c17b2d2b19c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-a16724df-c12f-4264-9d55-11c136691471,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-214387fe-782a-4603-afbd-25b92aafd0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753614090-172.17.0.4-1597730118723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-bd840dc4-bbb3-478a-af0a-3a31665cb706,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-d73271e9-c9bd-4882-9c94-a052b91004cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-8f5fd964-0a09-4888-8db7-a6c3c7895e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-2716f49d-7522-4df3-82f6-9e089f1289a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-0a2ce9d3-1a90-449b-a93e-7f3009e096f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-5523c82e-526a-4739-a79d-c17b2d2b19c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-a16724df-c12f-4264-9d55-11c136691471,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-214387fe-782a-4603-afbd-25b92aafd0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431505819-172.17.0.4-1597730393563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-6e00fa94-9284-463e-af4c-b7c37c59edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f493f3e5-92d6-4782-a285-1be5c8d95be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-29183f54-d959-4356-8fc9-2133de047bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-712ed002-a51c-4b9d-8a43-d74c129d678a,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-4c36fa30-d413-4d2f-8bd1-5d24c158932e,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-31b01d38-820a-43d1-b4a3-c1a9fed37828,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-21e3711b-ed6b-4248-9b0e-990000897963,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-773a7e7d-9e4d-4929-b0c9-4f3422cd99d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431505819-172.17.0.4-1597730393563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-6e00fa94-9284-463e-af4c-b7c37c59edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f493f3e5-92d6-4782-a285-1be5c8d95be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-29183f54-d959-4356-8fc9-2133de047bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-712ed002-a51c-4b9d-8a43-d74c129d678a,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-4c36fa30-d413-4d2f-8bd1-5d24c158932e,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-31b01d38-820a-43d1-b4a3-c1a9fed37828,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-21e3711b-ed6b-4248-9b0e-990000897963,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-773a7e7d-9e4d-4929-b0c9-4f3422cd99d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256227385-172.17.0.4-1597730589982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-42656e0c-f7ae-4116-bfe9-156ae8f5d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-8c5b4982-e143-45a4-9752-8b60adf83d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-b6053bff-625d-4f0b-9bcf-d46899169d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-16f15ef6-5270-45c1-b25d-cd83dd06ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-30cfc999-abd9-46b6-983d-950de117e795,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ac9d0fe9-5f3b-4374-922b-3f30e888cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-8d539ad6-bdb1-4b5a-af57-e69df3550c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-e8b10684-3239-4ee2-8f29-d909e67f4a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256227385-172.17.0.4-1597730589982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-42656e0c-f7ae-4116-bfe9-156ae8f5d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-8c5b4982-e143-45a4-9752-8b60adf83d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-b6053bff-625d-4f0b-9bcf-d46899169d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-16f15ef6-5270-45c1-b25d-cd83dd06ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-30cfc999-abd9-46b6-983d-950de117e795,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ac9d0fe9-5f3b-4374-922b-3f30e888cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-8d539ad6-bdb1-4b5a-af57-e69df3550c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-e8b10684-3239-4ee2-8f29-d909e67f4a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613286930-172.17.0.4-1597730851125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39927,DS-0db2846c-4712-4bbb-80b3-f8d9bf0afb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-0e416f1f-8b71-4560-97de-3a4fd8c00fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-d5d1a8af-cd29-45bd-ab23-85ee1ccd3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-c4d1cd01-86d2-4d54-92b1-9fc55817ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-124cfc94-4768-4269-84b6-4cb42dc0384a,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-33021b21-f8f9-4aa9-872d-86bf569f4226,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8adeb2c2-deb2-4436-b56b-df087f068800,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-f32669de-57b6-4381-bb5c-e008e832bcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613286930-172.17.0.4-1597730851125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39927,DS-0db2846c-4712-4bbb-80b3-f8d9bf0afb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-0e416f1f-8b71-4560-97de-3a4fd8c00fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-d5d1a8af-cd29-45bd-ab23-85ee1ccd3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-c4d1cd01-86d2-4d54-92b1-9fc55817ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-124cfc94-4768-4269-84b6-4cb42dc0384a,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-33021b21-f8f9-4aa9-872d-86bf569f4226,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8adeb2c2-deb2-4436-b56b-df087f068800,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-f32669de-57b6-4381-bb5c-e008e832bcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54299199-172.17.0.4-1597731220334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36541,DS-469e0961-e360-4a4e-a806-f6df256d942d,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b9d2149a-843b-4c28-a3b6-240732fabad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-59fb6c62-5db9-4825-bd80-70e1fd8ae61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-0ff0cf28-2d74-40fb-8eee-403272958aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-4ea09bbd-794f-461a-9257-fb0e93106c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2c1497f5-cf92-4452-aec4-e40cc093b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-f7b865a6-918a-4f9b-bfdf-f8d577392949,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-b40a701d-de2e-4b0e-92cd-7f64c5c80ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54299199-172.17.0.4-1597731220334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36541,DS-469e0961-e360-4a4e-a806-f6df256d942d,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b9d2149a-843b-4c28-a3b6-240732fabad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-59fb6c62-5db9-4825-bd80-70e1fd8ae61d,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-0ff0cf28-2d74-40fb-8eee-403272958aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-4ea09bbd-794f-461a-9257-fb0e93106c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2c1497f5-cf92-4452-aec4-e40cc093b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-f7b865a6-918a-4f9b-bfdf-f8d577392949,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-b40a701d-de2e-4b0e-92cd-7f64c5c80ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002164315-172.17.0.4-1597731259680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-bfe336d0-6f70-4ef8-a2f1-11e97d759663,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-0503c637-1a85-4d59-84e5-ffa7ecd02f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-b8f813b7-d668-4a65-bd01-0d654bd15b30,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-816367a6-bab0-4809-880d-5c41d6605507,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-c8354e97-c51b-470a-b665-93811fba9c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ce6a35e9-f971-4fae-9300-039bc919a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-417fc241-6a9c-4491-b493-3a8fc783b065,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-89148b47-8e52-465e-9aa7-47675cf58f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002164315-172.17.0.4-1597731259680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-bfe336d0-6f70-4ef8-a2f1-11e97d759663,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-0503c637-1a85-4d59-84e5-ffa7ecd02f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-b8f813b7-d668-4a65-bd01-0d654bd15b30,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-816367a6-bab0-4809-880d-5c41d6605507,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-c8354e97-c51b-470a-b665-93811fba9c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ce6a35e9-f971-4fae-9300-039bc919a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-417fc241-6a9c-4491-b493-3a8fc783b065,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-89148b47-8e52-465e-9aa7-47675cf58f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5674
