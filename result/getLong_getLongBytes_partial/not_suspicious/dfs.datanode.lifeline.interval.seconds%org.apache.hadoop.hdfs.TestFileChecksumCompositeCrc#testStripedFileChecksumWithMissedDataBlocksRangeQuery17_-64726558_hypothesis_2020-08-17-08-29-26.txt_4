reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389206465-172.17.0.21-1597653166093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-7309bf5e-3f95-4d99-b736-d375038561ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-4af4337a-5655-4c99-87a2-5baf9e2c577f,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-8aa80fbc-5443-48d3-8f1d-852850a2e903,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-8330dae5-adff-4d93-9897-e83cca2f7968,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ce12beff-9b46-4f02-83c9-3129416ed981,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-ab197160-49f2-4dd7-b9b5-0535934099d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-26cc4655-570a-4457-a537-83554fc4bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-0483a65c-af61-4965-aed6-dff687b1a543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389206465-172.17.0.21-1597653166093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-7309bf5e-3f95-4d99-b736-d375038561ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-4af4337a-5655-4c99-87a2-5baf9e2c577f,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-8aa80fbc-5443-48d3-8f1d-852850a2e903,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-8330dae5-adff-4d93-9897-e83cca2f7968,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ce12beff-9b46-4f02-83c9-3129416ed981,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-ab197160-49f2-4dd7-b9b5-0535934099d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-26cc4655-570a-4457-a537-83554fc4bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-0483a65c-af61-4965-aed6-dff687b1a543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601526770-172.17.0.21-1597653454867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-15082dea-4216-4252-a3e8-0585e2d436f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-3199cfae-ff3a-4a7f-b4b2-2503c0849906,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-0c6cd30a-9836-46a3-923d-0d0ff45899e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f13b834f-aac6-42db-b42b-583b238ef146,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-2d9480d4-a97e-4ac2-bc6a-907d21650fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-0e7a17f0-f92c-4fa8-9b29-e9df441f222a,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-06063d5f-3d90-45c9-9dd4-5988e8440a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-67901036-189a-4eb2-8266-1afe428bcff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601526770-172.17.0.21-1597653454867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-15082dea-4216-4252-a3e8-0585e2d436f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-3199cfae-ff3a-4a7f-b4b2-2503c0849906,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-0c6cd30a-9836-46a3-923d-0d0ff45899e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f13b834f-aac6-42db-b42b-583b238ef146,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-2d9480d4-a97e-4ac2-bc6a-907d21650fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-0e7a17f0-f92c-4fa8-9b29-e9df441f222a,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-06063d5f-3d90-45c9-9dd4-5988e8440a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-67901036-189a-4eb2-8266-1afe428bcff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043862580-172.17.0.21-1597654182079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-4dab381a-4394-4e81-8e80-3978691beaca,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-08cc5408-da67-4bd9-a83c-e21e2029944c,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-8f5cced5-4ca4-43e3-bed0-4a24f2600c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-49820357-2f6c-4bb8-9ce3-faa35173c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c7b4203d-b57a-4621-b102-24a644e012d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-e5cf1637-c561-409b-b755-1ba63d4d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-e3b9c7e0-99ee-4b81-8e5d-4c75257ce7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-4d2b7c04-090e-4398-aea4-9d51d7eb4903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043862580-172.17.0.21-1597654182079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-4dab381a-4394-4e81-8e80-3978691beaca,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-08cc5408-da67-4bd9-a83c-e21e2029944c,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-8f5cced5-4ca4-43e3-bed0-4a24f2600c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-49820357-2f6c-4bb8-9ce3-faa35173c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c7b4203d-b57a-4621-b102-24a644e012d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-e5cf1637-c561-409b-b755-1ba63d4d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-e3b9c7e0-99ee-4b81-8e5d-4c75257ce7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-4d2b7c04-090e-4398-aea4-9d51d7eb4903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022965832-172.17.0.21-1597655215191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-dae997d1-602a-466d-b5a6-801c4d73c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-23cd0f1c-4d56-4184-8a60-a56d8f216e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-5524eee1-e974-41ab-beec-bbde98fe6a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b75d37b8-11c5-4503-8eaf-dbb536eb2193,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-66276502-32a7-41b4-b2d3-bb43a08b7242,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-5c63592b-9b80-4c39-9a01-6ec4635b714e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-32f9c9cd-e2b5-4c96-bb09-3d891be3662f,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-081fea79-844a-4c4f-a51f-4d90dc568192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022965832-172.17.0.21-1597655215191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-dae997d1-602a-466d-b5a6-801c4d73c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-23cd0f1c-4d56-4184-8a60-a56d8f216e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-5524eee1-e974-41ab-beec-bbde98fe6a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b75d37b8-11c5-4503-8eaf-dbb536eb2193,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-66276502-32a7-41b4-b2d3-bb43a08b7242,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-5c63592b-9b80-4c39-9a01-6ec4635b714e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-32f9c9cd-e2b5-4c96-bb09-3d891be3662f,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-081fea79-844a-4c4f-a51f-4d90dc568192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175179608-172.17.0.21-1597655487267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-e8d99db8-8193-4b84-a9c1-3399c6c9cbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-df1523fa-df3c-4dc9-ac69-c0856fe5ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-fd6e9966-0f49-4ed2-b68e-dd34cfc19ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a7c7b86f-e4c4-4600-9330-4b9f7370078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-97b715d1-16e0-4754-a3d4-ffe76f0d09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-71b0e65c-1a19-449a-8ec4-fcae13ea9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-30591fde-3c9a-49e1-a938-5c05d513cdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-8f9ecd10-63dd-4382-80e2-23101da4e644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175179608-172.17.0.21-1597655487267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-e8d99db8-8193-4b84-a9c1-3399c6c9cbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-df1523fa-df3c-4dc9-ac69-c0856fe5ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-fd6e9966-0f49-4ed2-b68e-dd34cfc19ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a7c7b86f-e4c4-4600-9330-4b9f7370078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-97b715d1-16e0-4754-a3d4-ffe76f0d09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-71b0e65c-1a19-449a-8ec4-fcae13ea9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-30591fde-3c9a-49e1-a938-5c05d513cdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-8f9ecd10-63dd-4382-80e2-23101da4e644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623616098-172.17.0.21-1597657277020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-86bfafd3-4647-4604-bf8f-525b1faea274,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-05bc4d2b-d49d-47b5-9100-996bdafb9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-cc2ebd79-3455-4ed7-b339-e63c2668d094,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-1608ae2f-869a-4dd8-986c-175bbcb76797,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-506bec05-be70-41de-86e4-a5aca6de784c,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-2cb84377-dde4-4dbc-90d9-678194fb2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-381dba10-c2b8-488f-8c29-f03488d1944b,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-b020a2fe-7080-4cdd-aea5-8ac9ed910ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623616098-172.17.0.21-1597657277020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-86bfafd3-4647-4604-bf8f-525b1faea274,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-05bc4d2b-d49d-47b5-9100-996bdafb9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-cc2ebd79-3455-4ed7-b339-e63c2668d094,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-1608ae2f-869a-4dd8-986c-175bbcb76797,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-506bec05-be70-41de-86e4-a5aca6de784c,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-2cb84377-dde4-4dbc-90d9-678194fb2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-381dba10-c2b8-488f-8c29-f03488d1944b,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-b020a2fe-7080-4cdd-aea5-8ac9ed910ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058288969-172.17.0.21-1597657818348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-77813617-b7ef-41d4-b92e-83d4475f4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-c26209a1-9560-4f99-8f87-a3da32b4a37a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-ca454751-8f62-4f93-8a2a-c167a2851a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-90eeddf7-f0ea-4b8c-8567-f02200e89077,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-28dcde5d-709f-4e23-a9b7-2d3a3a37ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-b5d1deba-2cc7-4c8c-911e-f7f26c999390,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-dca0c5b7-7b7e-4164-83b0-4fdf4291f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-b8401f8f-2c94-4c17-ba5a-2d21aee4b599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058288969-172.17.0.21-1597657818348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-77813617-b7ef-41d4-b92e-83d4475f4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-c26209a1-9560-4f99-8f87-a3da32b4a37a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-ca454751-8f62-4f93-8a2a-c167a2851a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-90eeddf7-f0ea-4b8c-8567-f02200e89077,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-28dcde5d-709f-4e23-a9b7-2d3a3a37ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-b5d1deba-2cc7-4c8c-911e-f7f26c999390,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-dca0c5b7-7b7e-4164-83b0-4fdf4291f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-b8401f8f-2c94-4c17-ba5a-2d21aee4b599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127687743-172.17.0.21-1597657948215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-8500d53f-50a7-4c3b-bb1b-9575b95d082b,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-6b6084ab-6db5-4fb2-87c4-47f52eda46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-7802606e-3107-45c2-ae67-fb1db619fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7d2cfb82-7a9d-4d69-bcb0-3cf0e43f75c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-3f9d26f3-7801-44c1-8741-eb794f8b373d,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-af95959c-0ccb-4697-9a6e-3e12f9082b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-7d265743-d4c5-4ac9-93fc-9de614d331ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-a94f61d0-a17c-442b-b2b0-b6a1754c05d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127687743-172.17.0.21-1597657948215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-8500d53f-50a7-4c3b-bb1b-9575b95d082b,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-6b6084ab-6db5-4fb2-87c4-47f52eda46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-7802606e-3107-45c2-ae67-fb1db619fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7d2cfb82-7a9d-4d69-bcb0-3cf0e43f75c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-3f9d26f3-7801-44c1-8741-eb794f8b373d,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-af95959c-0ccb-4697-9a6e-3e12f9082b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-7d265743-d4c5-4ac9-93fc-9de614d331ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-a94f61d0-a17c-442b-b2b0-b6a1754c05d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627123947-172.17.0.21-1597657996193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-d017c157-4248-4944-a2a1-132579626a12,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-53aa37ce-bfc6-4d35-855a-0b6bcedbb5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0c8d26da-405d-4bc6-8048-f9b450cc0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-15f1d8d2-f996-4079-ab15-0deb8edbb685,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-18c34f24-9daa-4581-b6a1-0ecc32b780a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-06829d6c-57cc-44e0-9a00-11f3e46d1976,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-c01ff236-ffe1-409c-aee6-2ba2169abae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-db74038d-0b99-4fe1-b6f8-c1d169544539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627123947-172.17.0.21-1597657996193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-d017c157-4248-4944-a2a1-132579626a12,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-53aa37ce-bfc6-4d35-855a-0b6bcedbb5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0c8d26da-405d-4bc6-8048-f9b450cc0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-15f1d8d2-f996-4079-ab15-0deb8edbb685,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-18c34f24-9daa-4581-b6a1-0ecc32b780a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-06829d6c-57cc-44e0-9a00-11f3e46d1976,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-c01ff236-ffe1-409c-aee6-2ba2169abae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-db74038d-0b99-4fe1-b6f8-c1d169544539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744535679-172.17.0.21-1597658588293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-5afb49c0-90e4-451f-8169-12dfa9414e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-45e8e9b1-4c1c-45a2-b01d-dc404af8fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e18bdbf3-a106-47f4-98f6-06eaddecfaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-907d6e03-2c47-42ec-b35a-746bb98c39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-77c35821-98e6-40f6-9f68-34c763a7e321,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-7e77f4c1-7668-43e4-ad4e-9449e747a851,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-b4df36ff-3261-4234-9313-c4f74be75fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-b4121049-d7a0-45ae-87d7-cd6a228e24f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744535679-172.17.0.21-1597658588293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-5afb49c0-90e4-451f-8169-12dfa9414e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-45e8e9b1-4c1c-45a2-b01d-dc404af8fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e18bdbf3-a106-47f4-98f6-06eaddecfaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-907d6e03-2c47-42ec-b35a-746bb98c39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-77c35821-98e6-40f6-9f68-34c763a7e321,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-7e77f4c1-7668-43e4-ad4e-9449e747a851,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-b4df36ff-3261-4234-9313-c4f74be75fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-b4121049-d7a0-45ae-87d7-cd6a228e24f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644461082-172.17.0.21-1597659329517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-6b35c6d0-9564-479a-a90b-e75159491f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-43c45517-3b50-42ab-b8db-31049e89d979,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-4446f968-fffe-4581-b444-f5908c264757,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-5255493b-6096-45e4-910d-d6023b0f39ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-ab8b0b21-8f0e-4cc7-a841-ddabadc0d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c5b5a1db-471d-46b8-a336-a5b96b0d1f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-480dbc46-4b9c-46b1-bd68-c201c3b1b856,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-3696c303-cf05-46c9-8b41-c7e43626d340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644461082-172.17.0.21-1597659329517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-6b35c6d0-9564-479a-a90b-e75159491f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-43c45517-3b50-42ab-b8db-31049e89d979,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-4446f968-fffe-4581-b444-f5908c264757,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-5255493b-6096-45e4-910d-d6023b0f39ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-ab8b0b21-8f0e-4cc7-a841-ddabadc0d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c5b5a1db-471d-46b8-a336-a5b96b0d1f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-480dbc46-4b9c-46b1-bd68-c201c3b1b856,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-3696c303-cf05-46c9-8b41-c7e43626d340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352398996-172.17.0.21-1597659428872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-b57ceab9-4248-445c-9408-cfd8f373cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-526faa2f-5a80-4c9d-b54d-2d36b2dbad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e5d02df5-6827-4cab-95e3-664a1b071058,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-125ddfe5-4257-4215-9a00-fca27bc50bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-7f2ce91b-0354-4ea0-b07b-b181611af918,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-79b91d5c-230d-404d-8f4f-b68ae38fc20a,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-34a78ad3-ab40-406c-9d77-5ca5d04088c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-286ff1ff-0033-4b3a-be5d-4fda027c1483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352398996-172.17.0.21-1597659428872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-b57ceab9-4248-445c-9408-cfd8f373cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-526faa2f-5a80-4c9d-b54d-2d36b2dbad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e5d02df5-6827-4cab-95e3-664a1b071058,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-125ddfe5-4257-4215-9a00-fca27bc50bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-7f2ce91b-0354-4ea0-b07b-b181611af918,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-79b91d5c-230d-404d-8f4f-b68ae38fc20a,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-34a78ad3-ab40-406c-9d77-5ca5d04088c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-286ff1ff-0033-4b3a-be5d-4fda027c1483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360096348-172.17.0.21-1597659614536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-d686f3fb-eed4-4482-b52f-45252e694a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-b9bd64b7-cad9-4a21-b357-c342ed42f007,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-e1e5665b-3330-4f2a-9fe2-d3c2f37532c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-d8f695cd-5d4f-410c-9d62-c849046198a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-e4159db0-a8b6-418d-acba-709d11a838f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-eba7691f-c3b9-4792-87ac-574e5462ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-17532546-18f2-436d-a107-7031184bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-e2ab7f8a-cefc-48c4-95ee-d8294df41944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360096348-172.17.0.21-1597659614536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-d686f3fb-eed4-4482-b52f-45252e694a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-b9bd64b7-cad9-4a21-b357-c342ed42f007,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-e1e5665b-3330-4f2a-9fe2-d3c2f37532c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-d8f695cd-5d4f-410c-9d62-c849046198a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-e4159db0-a8b6-418d-acba-709d11a838f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-eba7691f-c3b9-4792-87ac-574e5462ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-17532546-18f2-436d-a107-7031184bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-e2ab7f8a-cefc-48c4-95ee-d8294df41944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445368807-172.17.0.21-1597659712833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-8e2b95a6-0dfe-4e14-8a19-d96df9a78e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-b6c19c40-940c-46af-8c2f-d9141ab8004b,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-171f74e9-43c8-4983-93e7-116b54ec430b,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-3d3f10ae-8e2c-4375-ab1c-0aaccbd51848,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-2bba9acd-babd-4230-9d99-1260866af612,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-1c9874f4-0977-42fa-b59a-dcde0c86d615,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-96467ddb-034d-4c79-b989-5a1acd4d322b,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-379c0a7b-aa49-463e-9d11-a601de2d837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445368807-172.17.0.21-1597659712833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-8e2b95a6-0dfe-4e14-8a19-d96df9a78e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-b6c19c40-940c-46af-8c2f-d9141ab8004b,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-171f74e9-43c8-4983-93e7-116b54ec430b,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-3d3f10ae-8e2c-4375-ab1c-0aaccbd51848,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-2bba9acd-babd-4230-9d99-1260866af612,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-1c9874f4-0977-42fa-b59a-dcde0c86d615,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-96467ddb-034d-4c79-b989-5a1acd4d322b,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-379c0a7b-aa49-463e-9d11-a601de2d837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272086021-172.17.0.21-1597659801527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-3c0b1fc8-1af1-4f06-9b6f-6ffa4fd95767,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-9e02b0f0-210d-484e-9009-e004528421db,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-7ade666b-76b4-453f-a841-4092dc83aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-c9310a44-75b4-4f3c-b908-4af13e239cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-60033642-8d24-4b62-8f9e-a988d7d5e607,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-2f7c8b1b-fe30-489e-939e-61cd6138e0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-cf9b65af-0be7-48e1-acbe-a7beb2d12101,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-9a0b2be5-a909-4a41-9f07-f7912827b5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272086021-172.17.0.21-1597659801527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-3c0b1fc8-1af1-4f06-9b6f-6ffa4fd95767,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-9e02b0f0-210d-484e-9009-e004528421db,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-7ade666b-76b4-453f-a841-4092dc83aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-c9310a44-75b4-4f3c-b908-4af13e239cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-60033642-8d24-4b62-8f9e-a988d7d5e607,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-2f7c8b1b-fe30-489e-939e-61cd6138e0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-cf9b65af-0be7-48e1-acbe-a7beb2d12101,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-9a0b2be5-a909-4a41-9f07-f7912827b5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7008
