reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488526424-172.17.0.7-1597532068623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-e5d9bcc4-f5a0-473f-8340-a0b45d34dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-88d88454-847c-4516-a643-b7d600665cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-4328ae58-8cc1-4800-a393-57e04fc3acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-eefe42a0-28d9-4d71-a4f3-f600306b05d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-4baa9662-0f40-41db-8266-750d27799c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-cef9e57d-b997-410a-bc48-a89b7b911614,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-5d437e92-b0ba-431d-ac3f-7ad74e8f7299,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-463138a0-7cff-47d2-adc5-675e517867a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488526424-172.17.0.7-1597532068623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-e5d9bcc4-f5a0-473f-8340-a0b45d34dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-88d88454-847c-4516-a643-b7d600665cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-4328ae58-8cc1-4800-a393-57e04fc3acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-eefe42a0-28d9-4d71-a4f3-f600306b05d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-4baa9662-0f40-41db-8266-750d27799c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-cef9e57d-b997-410a-bc48-a89b7b911614,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-5d437e92-b0ba-431d-ac3f-7ad74e8f7299,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-463138a0-7cff-47d2-adc5-675e517867a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033569882-172.17.0.7-1597532174433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46046,DS-0706568f-461a-4640-9ae1-bb323cb7a3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-d94fe066-8c56-4576-b70e-b75defda16de,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-15e7dcf9-14a9-4477-bead-cdcbf327fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-42ab8fef-1050-4648-a41a-d94a0f723497,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-01a05367-7975-409f-a67d-b0dd58919c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-c0262cc9-be7f-4c11-89aa-6db48b0feca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e5a9982d-52eb-4df1-bb4a-7d951b8f11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-51b04aba-e06c-4957-b1a4-b8c882b1a8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033569882-172.17.0.7-1597532174433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46046,DS-0706568f-461a-4640-9ae1-bb323cb7a3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-d94fe066-8c56-4576-b70e-b75defda16de,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-15e7dcf9-14a9-4477-bead-cdcbf327fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-42ab8fef-1050-4648-a41a-d94a0f723497,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-01a05367-7975-409f-a67d-b0dd58919c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-c0262cc9-be7f-4c11-89aa-6db48b0feca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e5a9982d-52eb-4df1-bb4a-7d951b8f11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-51b04aba-e06c-4957-b1a4-b8c882b1a8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669559396-172.17.0.7-1597533332305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-001b14ad-62a6-4c87-a6fb-8d1bdbe533df,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e693a3b4-e6c5-4253-9311-2cb235cf0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-8d1ad5d9-1990-4a98-9751-2de80207a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-e20dd71f-9be6-4728-b2bf-9e09f8b397dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-3a71d503-68e0-463d-a333-b25ceec7d660,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-04898397-d1ee-465d-a6ae-1874696bf13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0db03beb-aee2-4a7b-b721-e3d02e59fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-38fdbae1-7083-487f-9311-d0cc4ff09778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669559396-172.17.0.7-1597533332305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-001b14ad-62a6-4c87-a6fb-8d1bdbe533df,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e693a3b4-e6c5-4253-9311-2cb235cf0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-8d1ad5d9-1990-4a98-9751-2de80207a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-e20dd71f-9be6-4728-b2bf-9e09f8b397dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-3a71d503-68e0-463d-a333-b25ceec7d660,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-04898397-d1ee-465d-a6ae-1874696bf13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0db03beb-aee2-4a7b-b721-e3d02e59fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-38fdbae1-7083-487f-9311-d0cc4ff09778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153973936-172.17.0.7-1597533370078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-a782dbb7-a54a-40dc-91bb-bf825f8f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ab051d99-6af4-48de-a482-8c05cc082c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-b2ebea3a-595c-49e3-8e19-19729e41e50e,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-6724c308-4a6f-4b53-92c9-6ec8c18edf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-64af418b-4aee-4c6d-8638-c68502230b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-b74ac6a4-35e5-4194-a954-71043e03c3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-af3bbf0f-971a-4e7b-85a1-9a74491cb01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-82cda24c-5c72-46b3-a169-af90d7ee9bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153973936-172.17.0.7-1597533370078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-a782dbb7-a54a-40dc-91bb-bf825f8f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ab051d99-6af4-48de-a482-8c05cc082c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-b2ebea3a-595c-49e3-8e19-19729e41e50e,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-6724c308-4a6f-4b53-92c9-6ec8c18edf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-64af418b-4aee-4c6d-8638-c68502230b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-b74ac6a4-35e5-4194-a954-71043e03c3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-af3bbf0f-971a-4e7b-85a1-9a74491cb01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-82cda24c-5c72-46b3-a169-af90d7ee9bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814634744-172.17.0.7-1597533957436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-71f7341f-57e8-488a-ac67-591d73b01744,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-3b48aa54-1cda-4784-a55e-28c61862acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-11e4c36d-7715-4689-b8ca-e57231b234ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-e6f3dec6-9757-4cae-86f8-b22cfad05607,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-0e967c18-941b-4eba-93aa-b2c37ebaaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-4a9242f6-7df2-4bc4-8d44-fbedaef0d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-c6f01eaf-96c9-47dd-9ae0-439f7d1cfc42,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-f3b728ef-f4b1-4c7f-b30f-6d1bd3bdc520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814634744-172.17.0.7-1597533957436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-71f7341f-57e8-488a-ac67-591d73b01744,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-3b48aa54-1cda-4784-a55e-28c61862acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-11e4c36d-7715-4689-b8ca-e57231b234ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-e6f3dec6-9757-4cae-86f8-b22cfad05607,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-0e967c18-941b-4eba-93aa-b2c37ebaaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-4a9242f6-7df2-4bc4-8d44-fbedaef0d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-c6f01eaf-96c9-47dd-9ae0-439f7d1cfc42,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-f3b728ef-f4b1-4c7f-b30f-6d1bd3bdc520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708353418-172.17.0.7-1597534022603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-dc3684ac-8d2c-43cd-a169-b64052be80a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-a213fb24-b217-4efb-bbda-3cec1f403bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-595f2836-8e00-4324-8292-b10462bdd2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-28636b45-61f9-4b0f-9232-dd0c26751393,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-0ff44ec7-4aba-4c26-86b3-c08dd34e4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-7faf2b1e-467e-4de0-97a4-f97538c608da,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-59413674-0502-4094-bc58-d5d23254b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-064d9fd2-ee01-4da5-b6ad-34a0291e3333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708353418-172.17.0.7-1597534022603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-dc3684ac-8d2c-43cd-a169-b64052be80a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-a213fb24-b217-4efb-bbda-3cec1f403bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-595f2836-8e00-4324-8292-b10462bdd2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-28636b45-61f9-4b0f-9232-dd0c26751393,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-0ff44ec7-4aba-4c26-86b3-c08dd34e4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-7faf2b1e-467e-4de0-97a4-f97538c608da,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-59413674-0502-4094-bc58-d5d23254b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-064d9fd2-ee01-4da5-b6ad-34a0291e3333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053503478-172.17.0.7-1597534272564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-6cbbdcb1-b2ab-4094-b7e1-ba504b392e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-bca5334d-d5d9-4849-9786-398b98e92a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-2446874b-fa2d-4da2-bc0f-32e4b0860b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-45524797-bb64-4d03-ab34-71a0feea0d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-66cb7135-1850-4abf-8faa-866ff53c3d94,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-5fe82d35-dcc6-41f5-9b37-d84e233cd111,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f57868b9-94fe-49b6-b9ee-21b928c9f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-3827b093-b8c2-4ad5-a986-41228f7bf05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053503478-172.17.0.7-1597534272564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-6cbbdcb1-b2ab-4094-b7e1-ba504b392e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-bca5334d-d5d9-4849-9786-398b98e92a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-2446874b-fa2d-4da2-bc0f-32e4b0860b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-45524797-bb64-4d03-ab34-71a0feea0d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-66cb7135-1850-4abf-8faa-866ff53c3d94,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-5fe82d35-dcc6-41f5-9b37-d84e233cd111,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f57868b9-94fe-49b6-b9ee-21b928c9f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-3827b093-b8c2-4ad5-a986-41228f7bf05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118339559-172.17.0.7-1597534732220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-19d8f934-8ba5-4cfc-a1f7-e12982391664,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-8fdf922b-7686-4891-a7a7-2aafd176ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-f476be75-a284-4bfb-a176-e4dd72b45380,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-7761981c-093a-4bb5-a3e2-afe02f42bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-d127542f-fb2a-4c00-ba15-735ec905f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-95aa5aba-ee20-4eda-910f-97dbf71c59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-a33af012-3d15-4670-85e8-89a325d88787,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-4dd3cc44-7e73-4834-8e44-9f6e45e6402e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118339559-172.17.0.7-1597534732220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-19d8f934-8ba5-4cfc-a1f7-e12982391664,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-8fdf922b-7686-4891-a7a7-2aafd176ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-f476be75-a284-4bfb-a176-e4dd72b45380,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-7761981c-093a-4bb5-a3e2-afe02f42bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-d127542f-fb2a-4c00-ba15-735ec905f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-95aa5aba-ee20-4eda-910f-97dbf71c59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-a33af012-3d15-4670-85e8-89a325d88787,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-4dd3cc44-7e73-4834-8e44-9f6e45e6402e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882525198-172.17.0.7-1597535108639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-3351651d-205a-4b93-979d-27aedb66f860,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1dcb236e-7f83-417f-8f61-e9af5896289a,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-308e14d6-6062-4699-b82d-5b98cf4896de,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-b5bf7874-a89f-499d-b26e-ee56a51c63e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-9f017192-a3a2-45fb-88a3-50bbda09d1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-6c190700-76f5-4e37-bfae-a28a0a8de613,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-547d16b4-3c94-48bb-a682-126224e202a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-43f8dfe5-1a41-493d-8e99-2e4445d68f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882525198-172.17.0.7-1597535108639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-3351651d-205a-4b93-979d-27aedb66f860,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1dcb236e-7f83-417f-8f61-e9af5896289a,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-308e14d6-6062-4699-b82d-5b98cf4896de,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-b5bf7874-a89f-499d-b26e-ee56a51c63e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-9f017192-a3a2-45fb-88a3-50bbda09d1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-6c190700-76f5-4e37-bfae-a28a0a8de613,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-547d16b4-3c94-48bb-a682-126224e202a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-43f8dfe5-1a41-493d-8e99-2e4445d68f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12284213-172.17.0.7-1597535206222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-0563572d-f94d-44f0-816c-024b64a7fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-634a880f-5463-4ec2-8107-5d994d6037f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-6964bfbb-55a1-457b-a36f-437a91afa226,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-bfe13141-c3aa-4946-af96-64d919c4d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-225537bb-0d19-4945-95ce-9a93ad310163,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-b515d774-31e8-4d86-8efb-c23f3cf94177,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-252f3c4d-3f36-4e1f-9181-6056cb1217ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-f3a1c05c-b139-4f83-8cff-7da3ad9f5340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12284213-172.17.0.7-1597535206222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-0563572d-f94d-44f0-816c-024b64a7fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-634a880f-5463-4ec2-8107-5d994d6037f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-6964bfbb-55a1-457b-a36f-437a91afa226,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-bfe13141-c3aa-4946-af96-64d919c4d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-225537bb-0d19-4945-95ce-9a93ad310163,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-b515d774-31e8-4d86-8efb-c23f3cf94177,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-252f3c4d-3f36-4e1f-9181-6056cb1217ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-f3a1c05c-b139-4f83-8cff-7da3ad9f5340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367912152-172.17.0.7-1597536009307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42024,DS-b1df2f07-0280-47ad-8971-3bf9ad61a475,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-65b72706-7bbc-4d24-a312-0a68bc443ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-480f5661-11e7-4810-a134-e958b41a5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-42fff451-650f-43b9-b1c5-72ca2cbd4716,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-04d3d9fb-edb3-4767-9211-46ca4a0bd9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-37857d48-a3a4-4423-86a6-4eb13ba5d98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-0740caeb-203d-4605-ae0e-eaf3d30ed4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-8ec9165f-907d-46e7-b828-72a3b6b393d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367912152-172.17.0.7-1597536009307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42024,DS-b1df2f07-0280-47ad-8971-3bf9ad61a475,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-65b72706-7bbc-4d24-a312-0a68bc443ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-480f5661-11e7-4810-a134-e958b41a5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-42fff451-650f-43b9-b1c5-72ca2cbd4716,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-04d3d9fb-edb3-4767-9211-46ca4a0bd9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-37857d48-a3a4-4423-86a6-4eb13ba5d98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-0740caeb-203d-4605-ae0e-eaf3d30ed4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-8ec9165f-907d-46e7-b828-72a3b6b393d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067203899-172.17.0.7-1597536046684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-9bd15555-2fcd-4866-9dd6-38fed0ad174b,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-bddfabcb-4bd3-485f-8a36-fef7d9ba6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2558bd7d-4593-4be2-9ecd-36918f311c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-b0d44ed3-c11f-4d5e-9d0f-c2a31089e330,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6ec70187-0839-4031-aa4b-c16d6c8a40d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-64e6e409-e6fd-434a-a4b4-3ea54bb18e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d103279c-2365-441d-be77-4eff78ea3c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-c74bca79-0bd6-49b9-9b4e-78e332d85e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067203899-172.17.0.7-1597536046684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-9bd15555-2fcd-4866-9dd6-38fed0ad174b,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-bddfabcb-4bd3-485f-8a36-fef7d9ba6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2558bd7d-4593-4be2-9ecd-36918f311c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-b0d44ed3-c11f-4d5e-9d0f-c2a31089e330,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6ec70187-0839-4031-aa4b-c16d6c8a40d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-64e6e409-e6fd-434a-a4b4-3ea54bb18e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d103279c-2365-441d-be77-4eff78ea3c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-c74bca79-0bd6-49b9-9b4e-78e332d85e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979324078-172.17.0.7-1597536162016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-72ad0d34-bb4c-46d2-8cf1-cac211c24186,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-09f3e41b-2f5a-44ca-93ec-d73129e22b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-685a291d-dacb-4e62-a815-91fb43acebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-c823f0a8-14b3-4844-a4f7-336f66db3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4d577c93-6875-4336-acda-706f41fb3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-6281fcb0-f10f-4a9e-93a1-e3ca78d87856,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a73c2df8-7aab-41d2-bd2f-9f765fadc144,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-172aa7a2-d793-40ae-bd39-c4571f997d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979324078-172.17.0.7-1597536162016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-72ad0d34-bb4c-46d2-8cf1-cac211c24186,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-09f3e41b-2f5a-44ca-93ec-d73129e22b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-685a291d-dacb-4e62-a815-91fb43acebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-c823f0a8-14b3-4844-a4f7-336f66db3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4d577c93-6875-4336-acda-706f41fb3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-6281fcb0-f10f-4a9e-93a1-e3ca78d87856,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a73c2df8-7aab-41d2-bd2f-9f765fadc144,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-172aa7a2-d793-40ae-bd39-c4571f997d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699234701-172.17.0.7-1597536393771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-e07ce8de-97e5-4020-832c-c40a2aed2571,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-2b31129a-b110-42c2-a421-cf0564aeda73,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-ca997f63-7342-43b4-83fa-57ba51811c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-e0316704-3800-4576-a880-4ae75b7771a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-14c6ca4a-0a9f-4ba5-8bbe-bb2f20afe4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fa37b26d-4db8-464e-b218-d8e9f9d109d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-ea143799-d891-48a5-94c5-e91d55032600,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-9c8251e3-c665-411e-85aa-41b01c9cb04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699234701-172.17.0.7-1597536393771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-e07ce8de-97e5-4020-832c-c40a2aed2571,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-2b31129a-b110-42c2-a421-cf0564aeda73,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-ca997f63-7342-43b4-83fa-57ba51811c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-e0316704-3800-4576-a880-4ae75b7771a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-14c6ca4a-0a9f-4ba5-8bbe-bb2f20afe4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fa37b26d-4db8-464e-b218-d8e9f9d109d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-ea143799-d891-48a5-94c5-e91d55032600,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-9c8251e3-c665-411e-85aa-41b01c9cb04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963273116-172.17.0.7-1597536466069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-3b018bbd-2091-446f-bbda-538a244a680b,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-e1116792-ccea-4a55-9c48-932f9db20184,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-8948164a-6ee3-4425-a1a7-f059e5d9a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-ec3cf05c-38aa-4753-9381-fd317856f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-cf1b23a0-88ec-4e00-a1a2-7e99c8e6d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-342154fc-b9fe-4d50-bdeb-fcbd2538df41,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-40b9d5d0-15e6-43df-a11d-74bafecebae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-475e0940-c50a-4dda-aeda-e923d394505e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963273116-172.17.0.7-1597536466069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-3b018bbd-2091-446f-bbda-538a244a680b,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-e1116792-ccea-4a55-9c48-932f9db20184,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-8948164a-6ee3-4425-a1a7-f059e5d9a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-ec3cf05c-38aa-4753-9381-fd317856f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-cf1b23a0-88ec-4e00-a1a2-7e99c8e6d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-342154fc-b9fe-4d50-bdeb-fcbd2538df41,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-40b9d5d0-15e6-43df-a11d-74bafecebae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-475e0940-c50a-4dda-aeda-e923d394505e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063676385-172.17.0.7-1597536612859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-d108996a-d664-4ef2-9c6c-e82869358044,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-10d476a0-ffb9-4f4a-b503-d17cf5aa9c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-91f2600d-c71d-4a4c-99e0-fc2b3fe76c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-78dca47b-9373-48a3-b3fd-1b2591cd92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-512737c6-ab5d-45aa-bdf6-faac4fc1f468,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-822b50f4-a2af-46dc-8285-da84753f6090,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-6a210e30-5b87-4f4a-91a6-3cee2b8707b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4d47e901-f225-41e9-a480-39610b659602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063676385-172.17.0.7-1597536612859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-d108996a-d664-4ef2-9c6c-e82869358044,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-10d476a0-ffb9-4f4a-b503-d17cf5aa9c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-91f2600d-c71d-4a4c-99e0-fc2b3fe76c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-78dca47b-9373-48a3-b3fd-1b2591cd92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-512737c6-ab5d-45aa-bdf6-faac4fc1f468,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-822b50f4-a2af-46dc-8285-da84753f6090,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-6a210e30-5b87-4f4a-91a6-3cee2b8707b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4d47e901-f225-41e9-a480-39610b659602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664350716-172.17.0.7-1597536751400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-c05db540-249b-47b5-a906-0fcbf298c858,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-eed72ff6-a1d8-4989-b835-dc15da36714f,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-af84a83d-d2f4-45a9-9df9-357ca6e16885,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-9c52fe78-67f0-4137-8824-d919300b9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-fa56ab8a-45bd-4f40-a697-f92e3e5702e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-b35e219e-bb7d-4f94-bff3-bb46648746be,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-8fd96776-97fe-4eb2-8415-0623ce4a7770,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-abb2b439-8eaa-4694-aa14-5aa3ec0a2355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664350716-172.17.0.7-1597536751400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-c05db540-249b-47b5-a906-0fcbf298c858,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-eed72ff6-a1d8-4989-b835-dc15da36714f,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-af84a83d-d2f4-45a9-9df9-357ca6e16885,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-9c52fe78-67f0-4137-8824-d919300b9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-fa56ab8a-45bd-4f40-a697-f92e3e5702e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-b35e219e-bb7d-4f94-bff3-bb46648746be,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-8fd96776-97fe-4eb2-8415-0623ce4a7770,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-abb2b439-8eaa-4694-aa14-5aa3ec0a2355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693105821-172.17.0.7-1597536975878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-41ffb5b0-2044-4e7b-ae72-76863a806d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-6ceff52d-08cd-49ce-8b04-75e51aea1375,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-1418e77b-21c4-40b6-89d6-b2e499f0c0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-67e2e22d-e7c5-4c3f-a147-e09a548b766d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-156e19b0-a544-4ed9-b7e9-a45607c08022,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-1bf0d44d-c409-4967-9082-ef6ed76f7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-873b2599-510e-442f-879d-5422ccaafdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a497af74-deab-42ab-b851-e2f2d13a9e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693105821-172.17.0.7-1597536975878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-41ffb5b0-2044-4e7b-ae72-76863a806d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-6ceff52d-08cd-49ce-8b04-75e51aea1375,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-1418e77b-21c4-40b6-89d6-b2e499f0c0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-67e2e22d-e7c5-4c3f-a147-e09a548b766d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-156e19b0-a544-4ed9-b7e9-a45607c08022,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-1bf0d44d-c409-4967-9082-ef6ed76f7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-873b2599-510e-442f-879d-5422ccaafdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a497af74-deab-42ab-b851-e2f2d13a9e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1276056110-172.17.0.7-1597537094800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38848,DS-8db0c937-71af-4abf-849d-4624fd8a8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-27e60376-9274-4e66-b523-24394fa5adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-eb9867fe-0f5e-481a-b79d-1748d0cf703f,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-e795aad1-e406-4136-8cc1-080eea218839,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ada32e61-9742-4702-a3c2-86ce1151a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-b9a10222-2799-4ae2-9fb6-c5953f877bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-13fcff6a-84bb-4f26-bf4c-f6fa6ac123fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-e3ded6d3-6b1a-4cd3-b35d-0d3174c89548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1276056110-172.17.0.7-1597537094800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38848,DS-8db0c937-71af-4abf-849d-4624fd8a8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-27e60376-9274-4e66-b523-24394fa5adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-eb9867fe-0f5e-481a-b79d-1748d0cf703f,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-e795aad1-e406-4136-8cc1-080eea218839,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ada32e61-9742-4702-a3c2-86ce1151a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-b9a10222-2799-4ae2-9fb6-c5953f877bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-13fcff6a-84bb-4f26-bf4c-f6fa6ac123fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-e3ded6d3-6b1a-4cd3-b35d-0d3174c89548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5377
