reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622452131-172.17.0.19-1597298565470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-bac84620-9d40-4915-b6ce-1fc07db24320,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-dd961057-40aa-44ac-921a-11f9418a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-a60a90a4-e550-49aa-9e98-453cb14680da,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-67acb221-d678-47f7-aaf4-3420f6b20a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-9664a997-32cd-47f6-9b59-c3f2e66c3735,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-69d889ef-b639-4962-be1b-e93bc7daf685,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-40869a27-0de2-4edf-93f7-10f541c98fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-a64df58c-c47a-4215-8d8d-02d5a736fdf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622452131-172.17.0.19-1597298565470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-bac84620-9d40-4915-b6ce-1fc07db24320,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-dd961057-40aa-44ac-921a-11f9418a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-a60a90a4-e550-49aa-9e98-453cb14680da,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-67acb221-d678-47f7-aaf4-3420f6b20a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-9664a997-32cd-47f6-9b59-c3f2e66c3735,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-69d889ef-b639-4962-be1b-e93bc7daf685,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-40869a27-0de2-4edf-93f7-10f541c98fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-a64df58c-c47a-4215-8d8d-02d5a736fdf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995741838-172.17.0.19-1597300067164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-fab7dc3d-8670-4ef2-b1bc-74cfdee18a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ed43f816-1603-44fe-b9c6-c1a7884091bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-e330a913-1e3a-467d-a579-79a961ab54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-5fb291d8-9266-47ed-a7d1-7880b5d20655,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-4dfa1037-d140-4684-923d-4b3f1b0503ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-1a312c45-6cad-4f66-a8e0-21207c79b112,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-7a6db5e2-7346-49f4-a38a-6acda2d0f06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-88a365e1-c67d-47e3-afd2-9981e1d31d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995741838-172.17.0.19-1597300067164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-fab7dc3d-8670-4ef2-b1bc-74cfdee18a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ed43f816-1603-44fe-b9c6-c1a7884091bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-e330a913-1e3a-467d-a579-79a961ab54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-5fb291d8-9266-47ed-a7d1-7880b5d20655,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-4dfa1037-d140-4684-923d-4b3f1b0503ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-1a312c45-6cad-4f66-a8e0-21207c79b112,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-7a6db5e2-7346-49f4-a38a-6acda2d0f06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-88a365e1-c67d-47e3-afd2-9981e1d31d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847909747-172.17.0.19-1597301172632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-47009774-8abb-45ec-9b10-59ad8d899a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-88738bcc-0e66-4e98-bee1-5cc2e2373f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-a0f2d312-1b80-44f2-8af1-357f5a767b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-3ba0b8d5-a63a-4444-b91b-5ece847a54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-6b0534ed-fda9-4f6c-bc27-2e1f1f6bad30,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-ebce385e-fe38-4fb2-9617-0317c31d8518,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-d367c2f3-5536-483f-a339-7e64e8e08d99,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-b8b85bf7-74f7-4879-b72c-9242efdc0e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847909747-172.17.0.19-1597301172632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-47009774-8abb-45ec-9b10-59ad8d899a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-88738bcc-0e66-4e98-bee1-5cc2e2373f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-a0f2d312-1b80-44f2-8af1-357f5a767b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-3ba0b8d5-a63a-4444-b91b-5ece847a54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-6b0534ed-fda9-4f6c-bc27-2e1f1f6bad30,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-ebce385e-fe38-4fb2-9617-0317c31d8518,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-d367c2f3-5536-483f-a339-7e64e8e08d99,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-b8b85bf7-74f7-4879-b72c-9242efdc0e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245937413-172.17.0.19-1597301562606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-bdbcf77d-128a-4be9-a16f-0d95645a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-a2e414c7-d145-4a01-8089-767803a6d896,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-d00d26c9-5f4a-4a09-afa1-c103fdff4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-3d640307-4692-4e9c-b950-801fee7f3d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9a83dffa-3d56-4bf9-805c-193599da61b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-699300dc-9fda-4da5-b369-46f982dc020f,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-6cc8fca9-9b37-451f-adb2-2b8794155bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-609b8f49-e30e-4f0b-94d3-308007135da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245937413-172.17.0.19-1597301562606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-bdbcf77d-128a-4be9-a16f-0d95645a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-a2e414c7-d145-4a01-8089-767803a6d896,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-d00d26c9-5f4a-4a09-afa1-c103fdff4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-3d640307-4692-4e9c-b950-801fee7f3d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9a83dffa-3d56-4bf9-805c-193599da61b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-699300dc-9fda-4da5-b369-46f982dc020f,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-6cc8fca9-9b37-451f-adb2-2b8794155bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-609b8f49-e30e-4f0b-94d3-308007135da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481285289-172.17.0.19-1597301923655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-2b83a8d7-2470-4669-8cab-9a0a5fbb2e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-b5c2d84b-d90c-48ba-8ce9-768a23f56774,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e8dce6dc-63d7-43ef-9966-0a78f3ace2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-fb5deeaa-47e0-4c71-b645-f601f5edf28c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-13d2d6d2-ad54-4d03-aabc-24e45d831fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-94553b44-d0cf-43b1-9764-8688074bdc60,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-3914c303-0e94-4fb7-8877-62e8e3b01fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-705d10c6-75a3-4cb6-bec4-9adc82d5a505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481285289-172.17.0.19-1597301923655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-2b83a8d7-2470-4669-8cab-9a0a5fbb2e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-b5c2d84b-d90c-48ba-8ce9-768a23f56774,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e8dce6dc-63d7-43ef-9966-0a78f3ace2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-fb5deeaa-47e0-4c71-b645-f601f5edf28c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-13d2d6d2-ad54-4d03-aabc-24e45d831fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-94553b44-d0cf-43b1-9764-8688074bdc60,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-3914c303-0e94-4fb7-8877-62e8e3b01fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-705d10c6-75a3-4cb6-bec4-9adc82d5a505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81049563-172.17.0.19-1597302403159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-58b84424-787d-494b-8ef7-ab4eb022c106,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-2ed32913-9735-4f63-98b2-640ae93f63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-6affc93c-d0c8-406b-b052-f00eeb520451,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-b448ce3d-d916-4922-8156-eb07af9bed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-f526b070-2b72-47d7-9322-d760e11517e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-639a4dd3-1427-4b40-87c2-01512caa8cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-5a356cc6-51e0-4bd2-8b41-b61975246fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-1551f318-fa8c-40e6-a05b-5cfd4a74e625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81049563-172.17.0.19-1597302403159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-58b84424-787d-494b-8ef7-ab4eb022c106,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-2ed32913-9735-4f63-98b2-640ae93f63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-6affc93c-d0c8-406b-b052-f00eeb520451,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-b448ce3d-d916-4922-8156-eb07af9bed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-f526b070-2b72-47d7-9322-d760e11517e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-639a4dd3-1427-4b40-87c2-01512caa8cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-5a356cc6-51e0-4bd2-8b41-b61975246fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-1551f318-fa8c-40e6-a05b-5cfd4a74e625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439231946-172.17.0.19-1597302957766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-ced68b80-68d6-4469-b423-6633a5987646,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-42116c4a-857a-4e61-9cc3-4f8050f98664,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-b184ea50-c5c9-4691-9f6b-b0b96c394a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-66c507a5-e19d-4013-9859-8e6dffc59bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-c4345bfd-3d81-4174-977e-f2b63c36f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e9a42eac-efd5-4485-9364-7ef94896f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-c5d9b3ad-91f0-4ec1-a469-0131dfe33f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-465856c4-e75d-4d57-9bf7-3118f23da8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439231946-172.17.0.19-1597302957766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-ced68b80-68d6-4469-b423-6633a5987646,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-42116c4a-857a-4e61-9cc3-4f8050f98664,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-b184ea50-c5c9-4691-9f6b-b0b96c394a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-66c507a5-e19d-4013-9859-8e6dffc59bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-c4345bfd-3d81-4174-977e-f2b63c36f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e9a42eac-efd5-4485-9364-7ef94896f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-c5d9b3ad-91f0-4ec1-a469-0131dfe33f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-465856c4-e75d-4d57-9bf7-3118f23da8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822042046-172.17.0.19-1597303039436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-40b1d8fc-48a7-4c13-ba70-844a2d8d3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-afe5c98c-7631-4c4d-943e-0ebb89f2e4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-ef841914-a987-45de-af1b-60183e6204e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-6ae018bf-1748-406e-b69b-335b648c8717,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-f2f2462e-908c-4b8a-b5b8-4b6b24f63342,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-4c1bb4d0-5924-4665-a99f-28e8ec7640c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-142b1de8-9cf6-4dce-b9f4-d10a6a89a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-aa4cc420-0289-4a75-9c81-534ecea5f89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822042046-172.17.0.19-1597303039436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-40b1d8fc-48a7-4c13-ba70-844a2d8d3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-afe5c98c-7631-4c4d-943e-0ebb89f2e4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-ef841914-a987-45de-af1b-60183e6204e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-6ae018bf-1748-406e-b69b-335b648c8717,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-f2f2462e-908c-4b8a-b5b8-4b6b24f63342,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-4c1bb4d0-5924-4665-a99f-28e8ec7640c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-142b1de8-9cf6-4dce-b9f4-d10a6a89a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-aa4cc420-0289-4a75-9c81-534ecea5f89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249938212-172.17.0.19-1597303267091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-a517fa1b-e5ea-4a44-a27f-2fc08eb4a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-8eb56559-5c41-4eaf-97a2-f0b488f13549,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-dd97426b-7aa5-4c59-ada2-08027da47151,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9f284331-8e49-4ed8-beb9-7797da0de36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-0ec48345-f731-4e5b-ab1d-deffe8c1fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-86eec9a1-be88-4172-87db-e71260fc2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-5d55a385-63d8-4156-9059-b9541456043a,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-c363815f-80cb-443f-a9e9-37bb363016ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249938212-172.17.0.19-1597303267091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-a517fa1b-e5ea-4a44-a27f-2fc08eb4a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-8eb56559-5c41-4eaf-97a2-f0b488f13549,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-dd97426b-7aa5-4c59-ada2-08027da47151,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9f284331-8e49-4ed8-beb9-7797da0de36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-0ec48345-f731-4e5b-ab1d-deffe8c1fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-86eec9a1-be88-4172-87db-e71260fc2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-5d55a385-63d8-4156-9059-b9541456043a,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-c363815f-80cb-443f-a9e9-37bb363016ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70438091-172.17.0.19-1597303305937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-5f85ed1e-16fc-46a5-83b3-d27e9d2e1369,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-3feb6da8-918a-44f2-b7fb-d6aa8d71db3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-a0472d4e-103e-49e5-8de4-fb041efa8bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-06bae849-526a-4e93-a9c4-760816c4f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-c4579f91-ecad-4c6f-b194-3187cae706f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-922cf4f1-e07c-466a-ab45-5b8c2f187ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-cf834ff8-917c-4801-bad7-a363b370b441,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-07ff23c2-9855-44e0-8792-9ca4860bf08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70438091-172.17.0.19-1597303305937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-5f85ed1e-16fc-46a5-83b3-d27e9d2e1369,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-3feb6da8-918a-44f2-b7fb-d6aa8d71db3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-a0472d4e-103e-49e5-8de4-fb041efa8bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-06bae849-526a-4e93-a9c4-760816c4f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-c4579f91-ecad-4c6f-b194-3187cae706f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-922cf4f1-e07c-466a-ab45-5b8c2f187ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-cf834ff8-917c-4801-bad7-a363b370b441,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-07ff23c2-9855-44e0-8792-9ca4860bf08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722150349-172.17.0.19-1597303600450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-15a2619e-146f-4d06-bac9-b96f03a50afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-25ab5740-452d-44fa-898f-fba90b5e8eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f759005c-c14f-41bd-8aba-df6146e3f499,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-8455e5fd-ad07-47e2-a807-ba254eaada77,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-97cd805b-0e45-46f2-b407-9c64d549b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-dc54e662-5c45-40c3-bed1-6f32a1e00397,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-02e6592d-90a6-4838-9606-5c2699fa099c,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-f4ecc107-3055-4b35-8b0d-15bea2f57d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722150349-172.17.0.19-1597303600450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-15a2619e-146f-4d06-bac9-b96f03a50afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-25ab5740-452d-44fa-898f-fba90b5e8eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f759005c-c14f-41bd-8aba-df6146e3f499,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-8455e5fd-ad07-47e2-a807-ba254eaada77,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-97cd805b-0e45-46f2-b407-9c64d549b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-dc54e662-5c45-40c3-bed1-6f32a1e00397,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-02e6592d-90a6-4838-9606-5c2699fa099c,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-f4ecc107-3055-4b35-8b0d-15bea2f57d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830324755-172.17.0.19-1597303876306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-0e0c223f-7802-4bdc-89d6-1d2fa0fcf5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-a1c13f64-0b3d-4251-aa3f-62d6ccfa98cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-eef29833-6248-4c5b-90f7-51cba54de1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-2889c14a-9a75-46b3-a7ff-a55f552ee59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-bc242498-ae53-43a1-b110-d3f66aa2ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-db96bf98-f6fb-429e-99a5-8647ccab53a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-8a33407f-e387-41c2-b790-778509effeae,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-a39d22d8-1a1c-4c22-810d-4fbeb796388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830324755-172.17.0.19-1597303876306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-0e0c223f-7802-4bdc-89d6-1d2fa0fcf5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-a1c13f64-0b3d-4251-aa3f-62d6ccfa98cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-eef29833-6248-4c5b-90f7-51cba54de1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-2889c14a-9a75-46b3-a7ff-a55f552ee59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-bc242498-ae53-43a1-b110-d3f66aa2ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-db96bf98-f6fb-429e-99a5-8647ccab53a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-8a33407f-e387-41c2-b790-778509effeae,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-a39d22d8-1a1c-4c22-810d-4fbeb796388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630147098-172.17.0.19-1597304188065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-a5fdeb33-3db7-40ad-9bd0-ab454c25efed,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-0e07da40-1869-4ebf-8dde-b1d5c2a230fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-8cacff15-17e9-4ad3-ae65-16125704abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-c23f94f4-d9fe-410c-9267-97717305ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-f94c740e-a528-4d15-b007-681fbd4d3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-efdc1d51-aec5-46d4-bde7-ee85a2339acf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-59345c90-079b-4f84-99e5-1973d31691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-cd37facd-23e5-4ec3-bdca-4ebdb6e601a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630147098-172.17.0.19-1597304188065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-a5fdeb33-3db7-40ad-9bd0-ab454c25efed,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-0e07da40-1869-4ebf-8dde-b1d5c2a230fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-8cacff15-17e9-4ad3-ae65-16125704abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-c23f94f4-d9fe-410c-9267-97717305ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-f94c740e-a528-4d15-b007-681fbd4d3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-efdc1d51-aec5-46d4-bde7-ee85a2339acf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-59345c90-079b-4f84-99e5-1973d31691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-cd37facd-23e5-4ec3-bdca-4ebdb6e601a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15655798-172.17.0.19-1597304360498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-209e6a3c-fe85-4a6b-9b86-b1615241364c,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-35bed3bd-f443-4221-a731-f76abac02b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-6647f708-8755-466d-98ad-23bbfb32156f,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-6bf17c9a-d74f-4299-92ba-05d5d17ec01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-a3b72fe9-608b-48a6-8ea9-d6db5dca98db,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-a63b7aaf-0050-4745-bf28-4456b6814076,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-54a3dfb0-21b9-4b55-a20e-20a06af91a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-8947936d-8532-49ff-992c-4b95fbf15577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15655798-172.17.0.19-1597304360498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-209e6a3c-fe85-4a6b-9b86-b1615241364c,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-35bed3bd-f443-4221-a731-f76abac02b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-6647f708-8755-466d-98ad-23bbfb32156f,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-6bf17c9a-d74f-4299-92ba-05d5d17ec01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-a3b72fe9-608b-48a6-8ea9-d6db5dca98db,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-a63b7aaf-0050-4745-bf28-4456b6814076,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-54a3dfb0-21b9-4b55-a20e-20a06af91a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-8947936d-8532-49ff-992c-4b95fbf15577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166238103-172.17.0.19-1597304529422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-2cffc19e-4812-4161-8d27-b902ac381d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-d83afb7f-534d-479c-8cde-0adc5ed969ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-e388ebb7-d2ea-4ce1-90cc-8ba2332f3fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-02291123-ee67-4363-b36b-52384c544ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-3534dc4c-ec10-4c49-a7f3-02007429a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-0e957ead-cee9-408e-afa2-1bda281f44db,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-00dbfbc4-bc54-4a1b-abfb-55a6489eb1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-7d6d8d23-7272-4941-a9f7-b59804889667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166238103-172.17.0.19-1597304529422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-2cffc19e-4812-4161-8d27-b902ac381d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-d83afb7f-534d-479c-8cde-0adc5ed969ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-e388ebb7-d2ea-4ce1-90cc-8ba2332f3fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-02291123-ee67-4363-b36b-52384c544ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-3534dc4c-ec10-4c49-a7f3-02007429a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-0e957ead-cee9-408e-afa2-1bda281f44db,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-00dbfbc4-bc54-4a1b-abfb-55a6489eb1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-7d6d8d23-7272-4941-a9f7-b59804889667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414279214-172.17.0.19-1597304756745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-3e71db50-6b26-43b1-aec3-b997d3a26954,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-82aa1657-17b0-4fc5-ad3b-9b13ee83762a,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-8e41eefb-75b2-4625-be51-dc6dc77acb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-d6ec128d-04ba-49e5-98f3-a0665a66f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-e5910481-0252-4a6b-bc92-1055b6bc7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-8beb458b-0da8-401c-bf3e-2fd51f198ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-4236b0dd-e557-4aa2-9310-62958ca32b57,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-32114440-6f97-4a12-8e83-9b05b52e7216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414279214-172.17.0.19-1597304756745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-3e71db50-6b26-43b1-aec3-b997d3a26954,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-82aa1657-17b0-4fc5-ad3b-9b13ee83762a,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-8e41eefb-75b2-4625-be51-dc6dc77acb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-d6ec128d-04ba-49e5-98f3-a0665a66f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-e5910481-0252-4a6b-bc92-1055b6bc7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-8beb458b-0da8-401c-bf3e-2fd51f198ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-4236b0dd-e557-4aa2-9310-62958ca32b57,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-32114440-6f97-4a12-8e83-9b05b52e7216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6652
