reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585976961-172.17.0.15-1597696436811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-437aef51-577d-4a05-a08b-8ef3ea60c829,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-0b66edfa-13c5-4935-95cd-ba7187801016,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-d845e851-c7d6-4962-84dd-18fb4ac6f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d87f2e6b-a3e4-4589-ae41-26901c2918c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8686db2b-e2d1-46b6-ad53-ab552bb9a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-437b897a-8a70-4faa-b59a-be1612b54f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-9de4bcbb-bf25-4140-9a94-1bc9cce5770a,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-8d49254a-a76c-4e9b-9467-8178bd97bc82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585976961-172.17.0.15-1597696436811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-437aef51-577d-4a05-a08b-8ef3ea60c829,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-0b66edfa-13c5-4935-95cd-ba7187801016,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-d845e851-c7d6-4962-84dd-18fb4ac6f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d87f2e6b-a3e4-4589-ae41-26901c2918c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-8686db2b-e2d1-46b6-ad53-ab552bb9a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-437b897a-8a70-4faa-b59a-be1612b54f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-9de4bcbb-bf25-4140-9a94-1bc9cce5770a,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-8d49254a-a76c-4e9b-9467-8178bd97bc82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535516304-172.17.0.15-1597697005251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-5a90d9ef-432c-4f2c-a16d-29d54d8047d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-b5ca324f-82ad-4b5b-84dd-a96c0a3bb95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-27ffb99d-df87-475d-a6b8-d20058ade485,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-5b70ec0d-648b-48d8-865e-15e9aa9e8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-d113574b-3250-43eb-ae5e-cb0135f95e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-98debba4-f1a9-4aea-9f29-9becda7d376f,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-90f37305-d1d3-4517-964c-372bba8211ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-295a2274-574a-4512-9038-dc0dfeb5b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535516304-172.17.0.15-1597697005251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-5a90d9ef-432c-4f2c-a16d-29d54d8047d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-b5ca324f-82ad-4b5b-84dd-a96c0a3bb95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-27ffb99d-df87-475d-a6b8-d20058ade485,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-5b70ec0d-648b-48d8-865e-15e9aa9e8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-d113574b-3250-43eb-ae5e-cb0135f95e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-98debba4-f1a9-4aea-9f29-9becda7d376f,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-90f37305-d1d3-4517-964c-372bba8211ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-295a2274-574a-4512-9038-dc0dfeb5b0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361843185-172.17.0.15-1597697084905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-23a41106-f62a-46fd-84eb-6bbf5d4e72af,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c1ece188-3ae1-4b8c-a00d-94dcdf212088,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-38698ffb-a39c-4f1e-8641-4ebf86da02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-341d3681-a080-4e6b-ae5c-078df4d2bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b6baf8ac-3e3e-45cf-8b05-6da9f0321dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-a35d5b92-7758-4996-bf19-6549058e1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-53b00cc0-a742-45b8-ad49-a9c3c8818797,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-ed326872-83cf-4325-810b-318e8f0a99b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361843185-172.17.0.15-1597697084905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-23a41106-f62a-46fd-84eb-6bbf5d4e72af,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c1ece188-3ae1-4b8c-a00d-94dcdf212088,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-38698ffb-a39c-4f1e-8641-4ebf86da02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-341d3681-a080-4e6b-ae5c-078df4d2bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b6baf8ac-3e3e-45cf-8b05-6da9f0321dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-a35d5b92-7758-4996-bf19-6549058e1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-53b00cc0-a742-45b8-ad49-a9c3c8818797,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-ed326872-83cf-4325-810b-318e8f0a99b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577511035-172.17.0.15-1597697339498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-4ce68bae-2ea4-4000-bce6-aecd360d2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-a089c55d-a38c-4bb7-8d6c-9ff151983b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-96607b24-836d-4fa1-abda-8553629b7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-070befd7-ef0d-4055-b723-b7ebcba7c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-9365cb74-095f-4686-ba39-b281bee915e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-4322f45f-e524-4350-abcd-6db3c4b2d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-9c33b091-5409-4986-9284-4072fc2551a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-110fe3b8-1778-4c8c-99e1-e1ba92b350f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577511035-172.17.0.15-1597697339498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-4ce68bae-2ea4-4000-bce6-aecd360d2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-a089c55d-a38c-4bb7-8d6c-9ff151983b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-96607b24-836d-4fa1-abda-8553629b7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-070befd7-ef0d-4055-b723-b7ebcba7c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-9365cb74-095f-4686-ba39-b281bee915e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-4322f45f-e524-4350-abcd-6db3c4b2d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-9c33b091-5409-4986-9284-4072fc2551a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-110fe3b8-1778-4c8c-99e1-e1ba92b350f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901059111-172.17.0.15-1597697449678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-cc38a55a-f861-4a42-91fa-02c456cb5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-2a0f22cd-c9aa-4877-8d23-f09d76eb5079,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-bce1938c-67d5-4d57-9546-a708e0e421e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-4268d766-99ef-40c1-b853-535795a51051,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-1241deca-3374-4191-90af-b96565f7dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-ae6d2645-3eab-49c3-9cd0-4dd568101d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-2f9cc768-bcd4-4f9f-80f2-0bea04cc01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-07b68a3e-2461-440f-b3fa-5abab13afb27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901059111-172.17.0.15-1597697449678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-cc38a55a-f861-4a42-91fa-02c456cb5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-2a0f22cd-c9aa-4877-8d23-f09d76eb5079,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-bce1938c-67d5-4d57-9546-a708e0e421e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-4268d766-99ef-40c1-b853-535795a51051,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-1241deca-3374-4191-90af-b96565f7dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-ae6d2645-3eab-49c3-9cd0-4dd568101d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-2f9cc768-bcd4-4f9f-80f2-0bea04cc01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-07b68a3e-2461-440f-b3fa-5abab13afb27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367030335-172.17.0.15-1597698032282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-b41f6936-9f9a-40c3-9ef7-ef956b7c59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-b5888a51-0d4f-4c88-80ac-d51a3a8c23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-b5d01e22-8835-4628-b638-5eed0ab1d695,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-ddcc969e-820c-4606-9cef-5a8cf2a3c967,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-2c3bec4d-678e-442e-8329-5eda1dedd8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-421de7b9-0c74-43f9-9076-d716edd227ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6953a268-6de9-4571-b5bf-9a42136ea66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-f194d5eb-cf3a-4352-aa29-92a778363b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367030335-172.17.0.15-1597698032282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-b41f6936-9f9a-40c3-9ef7-ef956b7c59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-b5888a51-0d4f-4c88-80ac-d51a3a8c23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-b5d01e22-8835-4628-b638-5eed0ab1d695,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-ddcc969e-820c-4606-9cef-5a8cf2a3c967,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-2c3bec4d-678e-442e-8329-5eda1dedd8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-421de7b9-0c74-43f9-9076-d716edd227ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6953a268-6de9-4571-b5bf-9a42136ea66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-f194d5eb-cf3a-4352-aa29-92a778363b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114950803-172.17.0.15-1597698070000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-245ef477-0f1a-42bb-99a0-8ef95fd3610c,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-b41400b4-86ac-4057-8c5b-d52f9ffd70a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8111f776-2dc0-4be8-9a35-d8a65eaedaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-42f6755e-d02f-4088-9d0c-828f3950def6,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-329c06f8-1d0d-406d-8e62-c4934b9f58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-df664f1b-ca99-477a-80be-872ab0e3a0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-fadea10e-5b21-413b-a081-f0ab0b883333,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-79b65270-8997-42bc-b9b9-83a7ae3c27f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114950803-172.17.0.15-1597698070000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-245ef477-0f1a-42bb-99a0-8ef95fd3610c,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-b41400b4-86ac-4057-8c5b-d52f9ffd70a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8111f776-2dc0-4be8-9a35-d8a65eaedaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-42f6755e-d02f-4088-9d0c-828f3950def6,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-329c06f8-1d0d-406d-8e62-c4934b9f58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-df664f1b-ca99-477a-80be-872ab0e3a0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-fadea10e-5b21-413b-a081-f0ab0b883333,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-79b65270-8997-42bc-b9b9-83a7ae3c27f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307259233-172.17.0.15-1597698342946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-1c032011-83dc-4cc9-a4df-ac5a1455b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-a5cbc089-b05d-47a2-9d93-93126e92cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-2bb854e2-a85e-4237-87c5-98b903c14a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-2bce6da9-731c-4314-9aa6-4d733c4ecb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-b7787b69-3a8e-49f4-9c81-d4c0621a417f,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7f6dfd91-7890-4b3c-aee5-03dddcd7b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-31f55cfe-e303-4a2a-82e1-fe1a8f74137a,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2715f426-04d1-42ea-9dda-e3e8a511186e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307259233-172.17.0.15-1597698342946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-1c032011-83dc-4cc9-a4df-ac5a1455b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-a5cbc089-b05d-47a2-9d93-93126e92cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-2bb854e2-a85e-4237-87c5-98b903c14a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-2bce6da9-731c-4314-9aa6-4d733c4ecb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-b7787b69-3a8e-49f4-9c81-d4c0621a417f,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7f6dfd91-7890-4b3c-aee5-03dddcd7b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-31f55cfe-e303-4a2a-82e1-fe1a8f74137a,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2715f426-04d1-42ea-9dda-e3e8a511186e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734233972-172.17.0.15-1597698543691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-f50165f1-7c00-418e-904a-efa204ef5ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-147f47b1-7b52-47f0-a250-5051630b82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-146cd0c0-ee16-4ee9-bc16-d7f12b9c0477,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f9a78da6-c2a3-47d0-ae54-eaea1b6bb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-303dc77a-10bf-4aa1-8973-6035c7caebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-df51f6f3-ee7f-41de-9fe7-a9e901c4e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-a17b9c47-ebb2-4601-a686-e192cc2f5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-7a30a9f5-2bca-47c0-aaa1-f315abd5b6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734233972-172.17.0.15-1597698543691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-f50165f1-7c00-418e-904a-efa204ef5ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-147f47b1-7b52-47f0-a250-5051630b82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-146cd0c0-ee16-4ee9-bc16-d7f12b9c0477,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f9a78da6-c2a3-47d0-ae54-eaea1b6bb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-303dc77a-10bf-4aa1-8973-6035c7caebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-df51f6f3-ee7f-41de-9fe7-a9e901c4e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-a17b9c47-ebb2-4601-a686-e192cc2f5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-7a30a9f5-2bca-47c0-aaa1-f315abd5b6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496220495-172.17.0.15-1597698614715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-ed59e714-0b6d-4c53-8521-7b52f50f5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-9c8bd733-ab75-4744-9081-f6e12f42ed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-bfe69b28-a414-40b3-ac70-c901f29ba53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-bd2a00ac-708c-4c70-a042-c5eec96df7db,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-43aa106b-d80d-467b-9c52-0b3426cc208b,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-68f5df08-632e-4cbd-83af-a881606bf2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-500b8bed-471e-453a-852f-932de1e7ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-32f71838-e0df-46cd-b60b-1e46263a907a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496220495-172.17.0.15-1597698614715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-ed59e714-0b6d-4c53-8521-7b52f50f5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-9c8bd733-ab75-4744-9081-f6e12f42ed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-bfe69b28-a414-40b3-ac70-c901f29ba53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-bd2a00ac-708c-4c70-a042-c5eec96df7db,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-43aa106b-d80d-467b-9c52-0b3426cc208b,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-68f5df08-632e-4cbd-83af-a881606bf2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-500b8bed-471e-453a-852f-932de1e7ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-32f71838-e0df-46cd-b60b-1e46263a907a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907558248-172.17.0.15-1597698660112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-b4e7505c-f7a1-4144-862a-ae008f8dbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c4ef9358-6f68-4759-8c5e-1b857e83b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-4adcf390-58b5-44cc-9531-7b186944ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-66986f9e-3a3f-4bcd-b790-45cfc6c1673b,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-2b34833c-62da-45d7-8ef7-b823831aa980,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0dd46dd1-78a7-427e-989f-22ffe55462f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-0bca55e0-39db-4f82-873e-0cf0223b2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4e614ebe-c4c2-4309-a637-729772ab5cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907558248-172.17.0.15-1597698660112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-b4e7505c-f7a1-4144-862a-ae008f8dbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c4ef9358-6f68-4759-8c5e-1b857e83b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-4adcf390-58b5-44cc-9531-7b186944ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-66986f9e-3a3f-4bcd-b790-45cfc6c1673b,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-2b34833c-62da-45d7-8ef7-b823831aa980,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0dd46dd1-78a7-427e-989f-22ffe55462f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-0bca55e0-39db-4f82-873e-0cf0223b2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4e614ebe-c4c2-4309-a637-729772ab5cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687579207-172.17.0.15-1597698701170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-a7d700c6-e965-4009-8de6-28c38c2ff1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-b7dd93ed-657a-4a06-af3a-57c68facb115,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a2119acf-4f56-4f62-a5fa-7b00a17bb150,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-d0ceb072-3d65-40ba-8eb6-13d7733cdf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-0a60fb2a-4c5d-43e6-92eb-cec8ed22f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-29efc007-d256-4757-88b2-b63fab2b2f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-8cfd5061-60dc-46c4-92e0-2ffcf540e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b9cd8847-5993-41d0-a8e0-375d2e4972be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687579207-172.17.0.15-1597698701170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-a7d700c6-e965-4009-8de6-28c38c2ff1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-b7dd93ed-657a-4a06-af3a-57c68facb115,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a2119acf-4f56-4f62-a5fa-7b00a17bb150,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-d0ceb072-3d65-40ba-8eb6-13d7733cdf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-0a60fb2a-4c5d-43e6-92eb-cec8ed22f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-29efc007-d256-4757-88b2-b63fab2b2f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-8cfd5061-60dc-46c4-92e0-2ffcf540e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b9cd8847-5993-41d0-a8e0-375d2e4972be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984543739-172.17.0.15-1597698944270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-6b0079ab-fdcd-421c-9b3f-39d172b55035,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-308eb50f-8979-4eea-ade5-eded250ddfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-13bf61bd-4cf7-421e-a5e1-e872c2f75ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-f70e8068-1850-43c0-a9f5-9facd45249fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4206e722-dbda-4a97-9a42-6d8dd03c9eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-e149d1d6-a05d-49f6-b43e-558b11614c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-b0677cdd-89b1-4a7e-8019-cbc8e039e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-50dbb0e7-8042-4136-8854-67402ac9e2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984543739-172.17.0.15-1597698944270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-6b0079ab-fdcd-421c-9b3f-39d172b55035,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-308eb50f-8979-4eea-ade5-eded250ddfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-13bf61bd-4cf7-421e-a5e1-e872c2f75ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-f70e8068-1850-43c0-a9f5-9facd45249fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4206e722-dbda-4a97-9a42-6d8dd03c9eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-e149d1d6-a05d-49f6-b43e-558b11614c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-b0677cdd-89b1-4a7e-8019-cbc8e039e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-50dbb0e7-8042-4136-8854-67402ac9e2b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546898868-172.17.0.15-1597699341136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-4e7ae67a-5ffe-4dd4-9942-677873889cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-7c669ec7-77dc-4adb-99ba-0245b3f6a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-652bc6c7-f5bd-433b-9e62-14b33c2cb213,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-90ccc28d-2a79-494e-b763-b0d284337ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-958708a3-a87a-4845-9965-7f4975231781,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-5da323a8-7d82-4c4a-8fb6-6773f9e551e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ac6f0846-55ca-4324-9ba0-41f9c14589b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1175bcd9-f909-4e52-be2d-d72cec10d6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546898868-172.17.0.15-1597699341136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-4e7ae67a-5ffe-4dd4-9942-677873889cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-7c669ec7-77dc-4adb-99ba-0245b3f6a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-652bc6c7-f5bd-433b-9e62-14b33c2cb213,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-90ccc28d-2a79-494e-b763-b0d284337ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-958708a3-a87a-4845-9965-7f4975231781,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-5da323a8-7d82-4c4a-8fb6-6773f9e551e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ac6f0846-55ca-4324-9ba0-41f9c14589b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1175bcd9-f909-4e52-be2d-d72cec10d6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619259792-172.17.0.15-1597699487354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-0b3a2f1a-2ec0-455b-b79e-8bee5a3460a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3dde287f-27fa-4860-a87c-8e5787d20173,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-57569795-9147-46d7-9484-d328e920abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-cedd5dac-92be-4d25-8139-a0c04f0eb0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-f7e2396c-5bf9-4d9d-b20b-c18a45ec104d,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-51268b70-f71f-4bac-a90a-63da14a5a498,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-3bbb0f8a-ae3d-4a18-bd17-f29d2a97b8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-13e1ae4d-9975-4a7d-b4af-e6061e3dd3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619259792-172.17.0.15-1597699487354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-0b3a2f1a-2ec0-455b-b79e-8bee5a3460a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3dde287f-27fa-4860-a87c-8e5787d20173,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-57569795-9147-46d7-9484-d328e920abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-cedd5dac-92be-4d25-8139-a0c04f0eb0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-f7e2396c-5bf9-4d9d-b20b-c18a45ec104d,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-51268b70-f71f-4bac-a90a-63da14a5a498,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-3bbb0f8a-ae3d-4a18-bd17-f29d2a97b8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-13e1ae4d-9975-4a7d-b4af-e6061e3dd3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533241129-172.17.0.15-1597699805475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-723fbd99-c37f-4e3b-9d31-9c48181c5fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-f7e12907-a88c-4621-b916-be3cab6aa1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-cf8e0cf7-ec8f-4247-984f-d8dda40438bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-7fc86e3b-b211-4948-8565-b2ca1b1556de,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a220a523-96ae-4f95-a926-20de6d394d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-867f1828-43f6-48fb-b1a2-61b5b02533d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-0e32acb5-2516-4955-8c7b-3433ba16762a,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-4fc781fb-25ee-4287-bb58-e9f4e6f9fc3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533241129-172.17.0.15-1597699805475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-723fbd99-c37f-4e3b-9d31-9c48181c5fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-f7e12907-a88c-4621-b916-be3cab6aa1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-cf8e0cf7-ec8f-4247-984f-d8dda40438bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-7fc86e3b-b211-4948-8565-b2ca1b1556de,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a220a523-96ae-4f95-a926-20de6d394d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-867f1828-43f6-48fb-b1a2-61b5b02533d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-0e32acb5-2516-4955-8c7b-3433ba16762a,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-4fc781fb-25ee-4287-bb58-e9f4e6f9fc3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521100827-172.17.0.15-1597700111328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-9120e1c2-296c-44a1-a200-8c6a32aabd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-57280ba7-fcc3-49e7-879d-1f59c4f8dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-32ce7233-e01a-4dae-aff0-92d93422fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-5c7edc70-e16c-4a07-a81a-8877054030fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-39a1cf3e-2033-4699-9e4a-a2c58b3009bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-6b698b10-ad94-402e-9399-791f014e4395,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-79848517-a376-4548-a0c8-304b08a547a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-63d3072d-9611-4263-a478-13040943c2c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521100827-172.17.0.15-1597700111328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-9120e1c2-296c-44a1-a200-8c6a32aabd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-57280ba7-fcc3-49e7-879d-1f59c4f8dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-32ce7233-e01a-4dae-aff0-92d93422fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-5c7edc70-e16c-4a07-a81a-8877054030fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-39a1cf3e-2033-4699-9e4a-a2c58b3009bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-6b698b10-ad94-402e-9399-791f014e4395,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-79848517-a376-4548-a0c8-304b08a547a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-63d3072d-9611-4263-a478-13040943c2c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015260288-172.17.0.15-1597700146315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-29ab111c-30eb-4255-b82a-5c3fd70b0343,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-7bea48a6-6135-4f08-9855-5c60f7509f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-32276949-f0b8-4db6-8949-8cc87de1f7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-4b1c0a6a-de56-4b35-9b23-f12e03af279d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-7ab695fe-f7fd-4589-9047-5fc544e04148,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-d67759ae-f1ee-4e09-b95d-ccc24aed6486,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-155c72c8-5c47-4436-b3a5-997c316266b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-1ecd25e5-3ee1-417c-aa2e-cf27143e8dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015260288-172.17.0.15-1597700146315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-29ab111c-30eb-4255-b82a-5c3fd70b0343,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-7bea48a6-6135-4f08-9855-5c60f7509f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-32276949-f0b8-4db6-8949-8cc87de1f7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-4b1c0a6a-de56-4b35-9b23-f12e03af279d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-7ab695fe-f7fd-4589-9047-5fc544e04148,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-d67759ae-f1ee-4e09-b95d-ccc24aed6486,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-155c72c8-5c47-4436-b3a5-997c316266b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-1ecd25e5-3ee1-417c-aa2e-cf27143e8dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914457320-172.17.0.15-1597700268874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-9527bd65-8409-4882-ba2d-c1510c20b2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-01b319f5-fa97-4d66-a422-9f0d8d792510,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-bc1823de-6ba9-47be-8be7-5039b2595f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b2b1e95e-a44f-4d54-bee9-92e4b3a0ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-cf8e4543-d948-429a-b501-ee71e3654d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-35898b41-07d9-40f0-bab1-4a5fbae870d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-fe3493f2-5159-4b96-a54e-7bcaffe81b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-81e92099-a9bd-4578-9c08-1b683a9ad952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914457320-172.17.0.15-1597700268874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-9527bd65-8409-4882-ba2d-c1510c20b2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-01b319f5-fa97-4d66-a422-9f0d8d792510,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-bc1823de-6ba9-47be-8be7-5039b2595f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b2b1e95e-a44f-4d54-bee9-92e4b3a0ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-cf8e4543-d948-429a-b501-ee71e3654d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-35898b41-07d9-40f0-bab1-4a5fbae870d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-fe3493f2-5159-4b96-a54e-7bcaffe81b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-81e92099-a9bd-4578-9c08-1b683a9ad952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109562641-172.17.0.15-1597700342202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-f68969e4-0c06-484c-9cb0-af0600ec2b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-be93e304-b357-4fed-a72b-316d08ab2d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-0f238632-58df-4db7-8b8c-baa08b4120ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-51994620-1a94-4bec-b2f9-42e8925abcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-99b26e20-4a8a-4a44-b0e6-db503799bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-c141dd8b-e45d-4f72-b23d-a75060a17edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1b4a7201-6c0e-46a4-b08a-e5954663c138,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-c8051a0c-26e3-4a07-b9fe-d593c6176dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109562641-172.17.0.15-1597700342202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-f68969e4-0c06-484c-9cb0-af0600ec2b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-be93e304-b357-4fed-a72b-316d08ab2d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-0f238632-58df-4db7-8b8c-baa08b4120ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-51994620-1a94-4bec-b2f9-42e8925abcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-99b26e20-4a8a-4a44-b0e6-db503799bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-c141dd8b-e45d-4f72-b23d-a75060a17edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1b4a7201-6c0e-46a4-b08a-e5954663c138,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-c8051a0c-26e3-4a07-b9fe-d593c6176dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057112793-172.17.0.15-1597700766473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34583,DS-c48fad6e-cd50-4fb4-b08c-5c1b76f37a50,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8c026de6-8d63-4f6d-96af-8b1d67349719,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-652b8a02-4ade-44a9-a5a1-097d2dd92bae,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-c8a0511e-be4b-4a8e-a628-70bc8f2ce8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-27736dfe-0969-4bb1-8816-e25688535705,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-d994360d-4eb7-45fa-92a1-b71825bdf59a,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-0591ba9e-b3cb-45ad-8959-5d1e131e7a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-e6dce049-dbc6-408a-a614-c16e99062348,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057112793-172.17.0.15-1597700766473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34583,DS-c48fad6e-cd50-4fb4-b08c-5c1b76f37a50,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8c026de6-8d63-4f6d-96af-8b1d67349719,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-652b8a02-4ade-44a9-a5a1-097d2dd92bae,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-c8a0511e-be4b-4a8e-a628-70bc8f2ce8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-27736dfe-0969-4bb1-8816-e25688535705,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-d994360d-4eb7-45fa-92a1-b71825bdf59a,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-0591ba9e-b3cb-45ad-8959-5d1e131e7a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-e6dce049-dbc6-408a-a614-c16e99062348,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339080135-172.17.0.15-1597700804147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-fe71ec3a-fe74-47e6-8a8d-d9c9e5e3f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-3aa1f305-747a-4932-a5b6-e6c2d076628c,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-3237b6a3-d69c-43f2-9ff9-8ad616bbc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-593805de-32a4-4427-8a80-7365b784f6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-69b92e9e-5b67-4fc1-95aa-fc2ec6af34c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-f7c13076-16c0-4af9-ba4d-9dc08ecb0dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-5710c8f7-a640-4923-81f9-af21a46aeacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e556e531-1a8d-45b1-81ad-82640e22ff0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339080135-172.17.0.15-1597700804147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-fe71ec3a-fe74-47e6-8a8d-d9c9e5e3f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-3aa1f305-747a-4932-a5b6-e6c2d076628c,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-3237b6a3-d69c-43f2-9ff9-8ad616bbc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-593805de-32a4-4427-8a80-7365b784f6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-69b92e9e-5b67-4fc1-95aa-fc2ec6af34c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-f7c13076-16c0-4af9-ba4d-9dc08ecb0dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-5710c8f7-a640-4923-81f9-af21a46aeacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e556e531-1a8d-45b1-81ad-82640e22ff0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543050106-172.17.0.15-1597701142047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34180,DS-ea5d4f88-f2b5-490c-956e-6a4d2ca528c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-f545762b-7dc5-4852-98f2-b000f11fc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-d69e6a87-ba3d-46bb-92b4-e02f02de188b,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-b33e585c-3b9e-45d0-98f4-37cb636be629,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-317b3227-43c0-4070-96b1-9e9a44d0636e,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f6b56e9d-578f-4006-a937-74e28e1d62bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-2587a351-9b4c-4a26-84ee-73e2cdf120b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-140db430-efe4-47e4-a70c-0d2a2517c90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543050106-172.17.0.15-1597701142047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34180,DS-ea5d4f88-f2b5-490c-956e-6a4d2ca528c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-f545762b-7dc5-4852-98f2-b000f11fc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-d69e6a87-ba3d-46bb-92b4-e02f02de188b,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-b33e585c-3b9e-45d0-98f4-37cb636be629,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-317b3227-43c0-4070-96b1-9e9a44d0636e,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f6b56e9d-578f-4006-a937-74e28e1d62bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-2587a351-9b4c-4a26-84ee-73e2cdf120b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-140db430-efe4-47e4-a70c-0d2a2517c90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115408938-172.17.0.15-1597701282732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-6e8a8b49-372b-4631-85a6-c6114447f852,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-95213780-7982-4974-b4b4-5571a047dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ab7aee6c-dbfa-46d6-a66f-a5a1ebeb59ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-bcd883f3-a9d5-4c7f-b8f7-53341ece3234,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-b10f127f-b7ad-4c5b-904c-de125c021e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-935738ce-8b44-4b1d-92f5-4cc68dd85886,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-077b4784-aaf5-47c9-8831-bb44401cddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-5eca9883-bb1e-4604-b661-68147de3d799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115408938-172.17.0.15-1597701282732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-6e8a8b49-372b-4631-85a6-c6114447f852,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-95213780-7982-4974-b4b4-5571a047dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ab7aee6c-dbfa-46d6-a66f-a5a1ebeb59ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-bcd883f3-a9d5-4c7f-b8f7-53341ece3234,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-b10f127f-b7ad-4c5b-904c-de125c021e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-935738ce-8b44-4b1d-92f5-4cc68dd85886,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-077b4784-aaf5-47c9-8831-bb44401cddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-5eca9883-bb1e-4604-b661-68147de3d799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015350785-172.17.0.15-1597701352706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-594df6d4-1814-46b1-a496-f53dd7d517c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6b432a6-eea6-4aa8-a97e-8576d32b653d,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-3a34d905-ab38-46e2-88a3-53b4f1de4ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-35642770-9532-4221-9f68-f469bec45614,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-f837fc93-93b3-40d0-9f40-99299f308780,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-766f3d24-85d1-4616-bb6c-fa02fd86b3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-9fbab9b6-e211-487e-9920-1f89ee4a13f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-6f16c2de-6674-4af3-b4b4-76de20ab4de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015350785-172.17.0.15-1597701352706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-594df6d4-1814-46b1-a496-f53dd7d517c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6b432a6-eea6-4aa8-a97e-8576d32b653d,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-3a34d905-ab38-46e2-88a3-53b4f1de4ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-35642770-9532-4221-9f68-f469bec45614,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-f837fc93-93b3-40d0-9f40-99299f308780,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-766f3d24-85d1-4616-bb6c-fa02fd86b3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-9fbab9b6-e211-487e-9920-1f89ee4a13f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-6f16c2de-6674-4af3-b4b4-76de20ab4de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221332711-172.17.0.15-1597701602815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-5bb60c65-0ae0-4f1e-9399-ee8c237f8536,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-7af64f5d-694e-4dd1-b4c6-3cb1e1655adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-7e57104d-42d9-4825-8d38-64692c05a093,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-6d86824e-8c83-4aa6-93de-9d878473192d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-83196f82-bf44-48bb-bf9c-e1bc969fb03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-d15a47d9-a8fe-4d70-a240-d138c8608754,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-53eb1234-b17d-40d6-a2a9-d5ea304b15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-3760bc49-9dc1-4e2b-aea8-a64f8e10258e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221332711-172.17.0.15-1597701602815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-5bb60c65-0ae0-4f1e-9399-ee8c237f8536,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-7af64f5d-694e-4dd1-b4c6-3cb1e1655adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-7e57104d-42d9-4825-8d38-64692c05a093,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-6d86824e-8c83-4aa6-93de-9d878473192d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-83196f82-bf44-48bb-bf9c-e1bc969fb03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-d15a47d9-a8fe-4d70-a240-d138c8608754,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-53eb1234-b17d-40d6-a2a9-d5ea304b15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-3760bc49-9dc1-4e2b-aea8-a64f8e10258e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324935179-172.17.0.15-1597701934203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-771b8ad7-1784-4e5a-926b-028e9d76454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-1c72b73a-9a67-47aa-9e6e-caa7a370e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-bab33d4d-df28-42f4-bc32-37473102c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-a2e81eff-207c-4b87-8bfa-05ea9405f79e,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-8e8f52c5-75a7-400d-a007-832977ba7dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-187f3fc4-ee17-4564-856f-2644bb5ea97a,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-8be334c5-577e-44c1-8764-8a22019484ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-422812da-6be9-41a4-b729-6b7fba622a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324935179-172.17.0.15-1597701934203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-771b8ad7-1784-4e5a-926b-028e9d76454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-1c72b73a-9a67-47aa-9e6e-caa7a370e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-bab33d4d-df28-42f4-bc32-37473102c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-a2e81eff-207c-4b87-8bfa-05ea9405f79e,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-8e8f52c5-75a7-400d-a007-832977ba7dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-187f3fc4-ee17-4564-856f-2644bb5ea97a,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-8be334c5-577e-44c1-8764-8a22019484ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-422812da-6be9-41a4-b729-6b7fba622a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259674857-172.17.0.15-1597701975654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-e6adf554-b399-4efd-b9d8-de89564ae269,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-17572b9c-45ea-49e9-80a7-95b5a01d673a,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-7fd648d5-d60c-461a-8c30-5a1de94070a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-fdd3cbf7-e589-477b-8a83-f4e9f54330ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-5f45dc41-70c4-4a87-92d3-5790971cf37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-9a347b5c-75aa-4735-beb6-5cbbb13396f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-1a8efa4e-b678-454c-90bf-c93e4606f700,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-673074b3-3ca7-4047-8810-403f54343d70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259674857-172.17.0.15-1597701975654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-e6adf554-b399-4efd-b9d8-de89564ae269,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-17572b9c-45ea-49e9-80a7-95b5a01d673a,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-7fd648d5-d60c-461a-8c30-5a1de94070a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-fdd3cbf7-e589-477b-8a83-f4e9f54330ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-5f45dc41-70c4-4a87-92d3-5790971cf37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-9a347b5c-75aa-4735-beb6-5cbbb13396f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-1a8efa4e-b678-454c-90bf-c93e4606f700,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-673074b3-3ca7-4047-8810-403f54343d70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443365387-172.17.0.15-1597702017967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-a1f2c9e8-da88-4e81-a1c8-3abbedc46a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-b33614e6-7d00-415c-a7a9-f5d5dc995a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-5aae190a-237d-48a9-bc1d-6c9458400403,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-fc06aa26-6e1e-4aca-9840-147fb63c766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-162941ec-3340-48e3-915a-f15850076994,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-2a11849c-5a31-4024-8e32-01d9d562b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-348e34a0-4f1d-4111-a7e3-371f5c765ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-c58e6298-c703-458d-96a4-ee396eb18e43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443365387-172.17.0.15-1597702017967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-a1f2c9e8-da88-4e81-a1c8-3abbedc46a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-b33614e6-7d00-415c-a7a9-f5d5dc995a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-5aae190a-237d-48a9-bc1d-6c9458400403,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-fc06aa26-6e1e-4aca-9840-147fb63c766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-162941ec-3340-48e3-915a-f15850076994,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-2a11849c-5a31-4024-8e32-01d9d562b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-348e34a0-4f1d-4111-a7e3-371f5c765ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-c58e6298-c703-458d-96a4-ee396eb18e43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737218235-172.17.0.15-1597702054827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-63d049b7-25ba-4290-8d09-6a639080d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-2874310d-e6af-4a2e-bff8-791c58acef07,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-a79bc165-2d45-4f86-9e54-323f7e656190,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-071344a5-3151-4da2-942d-0baffe399e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7ae39b1a-10f5-4dc9-8c82-17aafb576240,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-baf55693-c859-4b9d-9455-4cb4754419f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-2f9c2725-72e9-46fc-972a-df8715d4a437,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-1c23382c-2b62-4d47-abb9-19bf660e5370,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737218235-172.17.0.15-1597702054827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-63d049b7-25ba-4290-8d09-6a639080d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-2874310d-e6af-4a2e-bff8-791c58acef07,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-a79bc165-2d45-4f86-9e54-323f7e656190,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-071344a5-3151-4da2-942d-0baffe399e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7ae39b1a-10f5-4dc9-8c82-17aafb576240,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-baf55693-c859-4b9d-9455-4cb4754419f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-2f9c2725-72e9-46fc-972a-df8715d4a437,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-1c23382c-2b62-4d47-abb9-19bf660e5370,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5814
