reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846074172-172.17.0.15-1597679687140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32895,DS-4fd2c105-614e-4aed-a706-2ee487f53f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-6a2d2406-b7ad-43fc-a61b-5a2463f63af8,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-0faddf93-f24c-4fa2-a841-e83a7ee8f425,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-e3453dac-86b8-47f1-87e8-2ee2567ec556,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-74548cca-9c86-4711-9cc8-8cda426e8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-0592b90e-ba99-4173-99d6-e8976c6f072c,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-eb2beb30-89db-4cef-90d1-5b40386cd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d643d69d-8556-48bf-a3c4-2d0385a5b7d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846074172-172.17.0.15-1597679687140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32895,DS-4fd2c105-614e-4aed-a706-2ee487f53f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-6a2d2406-b7ad-43fc-a61b-5a2463f63af8,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-0faddf93-f24c-4fa2-a841-e83a7ee8f425,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-e3453dac-86b8-47f1-87e8-2ee2567ec556,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-74548cca-9c86-4711-9cc8-8cda426e8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-0592b90e-ba99-4173-99d6-e8976c6f072c,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-eb2beb30-89db-4cef-90d1-5b40386cd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d643d69d-8556-48bf-a3c4-2d0385a5b7d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422968082-172.17.0.15-1597679729682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-76104c58-c72e-46ed-bb7b-aead4106775b,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-96081361-f06c-4187-952a-761fde92936f,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a8b0b37f-2b7d-4df9-945f-124978e130ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-92790a73-f3e6-4916-9790-beee59ce4463,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-85c6e7d2-25fd-40c2-bf02-54ad519b339e,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-62457798-b60b-4917-8708-2202de122a45,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-bc8a0b07-e1bf-4ca1-bc1c-0fa98bf78c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-06eca84f-acd8-4f23-b85e-da53fd8b23b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422968082-172.17.0.15-1597679729682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-76104c58-c72e-46ed-bb7b-aead4106775b,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-96081361-f06c-4187-952a-761fde92936f,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a8b0b37f-2b7d-4df9-945f-124978e130ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-92790a73-f3e6-4916-9790-beee59ce4463,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-85c6e7d2-25fd-40c2-bf02-54ad519b339e,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-62457798-b60b-4917-8708-2202de122a45,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-bc8a0b07-e1bf-4ca1-bc1c-0fa98bf78c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-06eca84f-acd8-4f23-b85e-da53fd8b23b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596894668-172.17.0.15-1597679929922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-68b1619a-f636-4c0e-b107-8a09482a4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-27ef12af-9249-48eb-b8a6-ef9b59da1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-58bc3aa7-833d-41aa-bf5d-11ef1e2e79db,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-acf4a1bb-fcbb-4ffa-b7e6-254f2d4c684c,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-439a323d-1ba8-4961-93cc-518d742422b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-85f15138-f447-4022-a41b-26681969aca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-46b201fc-901f-4516-997f-829dac0cbb78,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-161954cf-2200-4a95-80fd-e0c342cc0916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596894668-172.17.0.15-1597679929922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-68b1619a-f636-4c0e-b107-8a09482a4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-27ef12af-9249-48eb-b8a6-ef9b59da1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-58bc3aa7-833d-41aa-bf5d-11ef1e2e79db,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-acf4a1bb-fcbb-4ffa-b7e6-254f2d4c684c,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-439a323d-1ba8-4961-93cc-518d742422b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-85f15138-f447-4022-a41b-26681969aca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-46b201fc-901f-4516-997f-829dac0cbb78,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-161954cf-2200-4a95-80fd-e0c342cc0916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673951087-172.17.0.15-1597680135196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-7f57a633-bebf-48e7-9758-8f453facf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-ff47518b-51cb-4f2b-8ee3-334843035094,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-bd793689-2085-424c-b7d3-0f4b7f3dc4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-b5afaca1-9c14-44ca-b557-09ba3273a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-51c03b10-6fb4-4768-9e79-729f90d0479e,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-677fbf03-3322-4e41-b828-26737a874785,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d3b44f8d-976d-4942-983a-cba96d2e086e,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-885df4c5-740c-48b6-b2d4-1847c8f71c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673951087-172.17.0.15-1597680135196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-7f57a633-bebf-48e7-9758-8f453facf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-ff47518b-51cb-4f2b-8ee3-334843035094,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-bd793689-2085-424c-b7d3-0f4b7f3dc4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-b5afaca1-9c14-44ca-b557-09ba3273a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-51c03b10-6fb4-4768-9e79-729f90d0479e,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-677fbf03-3322-4e41-b828-26737a874785,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d3b44f8d-976d-4942-983a-cba96d2e086e,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-885df4c5-740c-48b6-b2d4-1847c8f71c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231038107-172.17.0.15-1597680294203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33326,DS-2fa8f54e-4ba7-4681-a3d1-fed8e7c94a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-8a80e717-0b4f-4ead-b814-c18d17943415,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-2c3157d1-4c90-4b1d-8a23-394ef4b11d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-93b71aba-64a4-4202-9dd8-f6cf23ca57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-707ad395-94ff-4ff7-954d-573b1872fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-f3fc57af-56b0-4dda-874c-a257ab98ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-987031de-3809-4e2f-ab4b-7d009ff29af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-f36439e9-f5a8-43f4-99cc-e3325b1dce7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231038107-172.17.0.15-1597680294203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33326,DS-2fa8f54e-4ba7-4681-a3d1-fed8e7c94a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-8a80e717-0b4f-4ead-b814-c18d17943415,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-2c3157d1-4c90-4b1d-8a23-394ef4b11d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-93b71aba-64a4-4202-9dd8-f6cf23ca57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-707ad395-94ff-4ff7-954d-573b1872fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-f3fc57af-56b0-4dda-874c-a257ab98ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-987031de-3809-4e2f-ab4b-7d009ff29af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-f36439e9-f5a8-43f4-99cc-e3325b1dce7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645246602-172.17.0.15-1597680673322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-75982ee2-c4cf-4f6b-857e-758f02985221,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-43ce8c6f-bfc1-40c9-8f35-6a147064c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-7adc8159-3dee-4853-bb5e-e9a546a372e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-f9b8cc57-c019-4b9b-8585-9107e1105e84,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-592ec84a-3e9d-4c04-b2f6-ea4f1a183b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-9daf1e49-50d3-4837-9ff8-be7e9960b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-a5ae52a4-85b5-4832-96b0-0d089bf7438a,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f7343ebb-60a7-4dbf-99d5-8d172b052bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645246602-172.17.0.15-1597680673322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-75982ee2-c4cf-4f6b-857e-758f02985221,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-43ce8c6f-bfc1-40c9-8f35-6a147064c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-7adc8159-3dee-4853-bb5e-e9a546a372e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-f9b8cc57-c019-4b9b-8585-9107e1105e84,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-592ec84a-3e9d-4c04-b2f6-ea4f1a183b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-9daf1e49-50d3-4837-9ff8-be7e9960b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-a5ae52a4-85b5-4832-96b0-0d089bf7438a,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f7343ebb-60a7-4dbf-99d5-8d172b052bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835977049-172.17.0.15-1597680791958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46436,DS-64000841-de2c-45ed-95a3-0fa64a5bf2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-d0d1dd46-80ad-4ca4-a525-6ac5400cd143,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-513a3e93-d55b-4071-baa6-fe9a9591bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f60f55bc-8fe1-4e8f-b2c8-2d13a43648c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-75192bdc-c603-48d1-847a-b7a6d52ff482,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-3d3b9fe3-a272-4ab3-9a3d-fe15e20a3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-91726b04-041e-4b30-8d41-25246b7bb6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-926aaef8-f0e8-4dff-95b7-cf55e131683a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835977049-172.17.0.15-1597680791958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46436,DS-64000841-de2c-45ed-95a3-0fa64a5bf2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-d0d1dd46-80ad-4ca4-a525-6ac5400cd143,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-513a3e93-d55b-4071-baa6-fe9a9591bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f60f55bc-8fe1-4e8f-b2c8-2d13a43648c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-75192bdc-c603-48d1-847a-b7a6d52ff482,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-3d3b9fe3-a272-4ab3-9a3d-fe15e20a3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-91726b04-041e-4b30-8d41-25246b7bb6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-926aaef8-f0e8-4dff-95b7-cf55e131683a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131304285-172.17.0.15-1597681810063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-309efca9-7f31-47d4-9c07-fd9510f29b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-dd4325ff-196a-499a-8614-afe6f82909c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-4720331a-516b-451b-a986-e1e5cfa47425,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-d523ed31-272c-49e1-97d1-026648f31b39,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7873885d-c570-4e80-ab89-df5aab20e3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-497d85c4-2cef-45be-be99-398f41986e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-5b4800cb-678a-4e79-ba83-3e4c1b1e9925,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-6d4e230f-17bd-491b-95d4-19fef34e77b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131304285-172.17.0.15-1597681810063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-309efca9-7f31-47d4-9c07-fd9510f29b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-dd4325ff-196a-499a-8614-afe6f82909c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-4720331a-516b-451b-a986-e1e5cfa47425,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-d523ed31-272c-49e1-97d1-026648f31b39,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7873885d-c570-4e80-ab89-df5aab20e3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-497d85c4-2cef-45be-be99-398f41986e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-5b4800cb-678a-4e79-ba83-3e4c1b1e9925,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-6d4e230f-17bd-491b-95d4-19fef34e77b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234881379-172.17.0.15-1597682265252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-53ec8798-cbe2-4f5f-a03c-b5620759d9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-cdfa528f-8615-42c1-9159-11b3b9973bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-26bcb1a5-6001-42d2-9baa-57e45ad88ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-b6e16d78-ffd1-4231-82a4-56ced93893d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-fdfb8bb4-5b78-4090-954c-eb471cd33495,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-67d4aff6-ee2e-463d-a176-5524985f6606,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d7dc89e5-94d8-4b73-862e-1a507a61f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-d335202d-fdef-46d7-9d0e-65b75e3cd780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234881379-172.17.0.15-1597682265252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-53ec8798-cbe2-4f5f-a03c-b5620759d9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-cdfa528f-8615-42c1-9159-11b3b9973bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-26bcb1a5-6001-42d2-9baa-57e45ad88ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-b6e16d78-ffd1-4231-82a4-56ced93893d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-fdfb8bb4-5b78-4090-954c-eb471cd33495,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-67d4aff6-ee2e-463d-a176-5524985f6606,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d7dc89e5-94d8-4b73-862e-1a507a61f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-d335202d-fdef-46d7-9d0e-65b75e3cd780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556545112-172.17.0.15-1597682307163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-5513641f-26cb-4602-b1d7-3aaa4eb36bad,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-58345017-f39c-4c95-8fa1-f43fb64a48fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-51a7b6a8-1666-4bab-989a-966cf00d41ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-36ff124c-df72-4834-82f7-69441ad368a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-c8648d5a-d3df-4de7-a113-1164c60b8593,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-2e04280b-425c-4774-98b7-a74d74fbf043,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-830a815a-1954-4b35-aa6f-eec9b7b44d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-0ac96dd0-73cc-44e7-bb39-47eff1903e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556545112-172.17.0.15-1597682307163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-5513641f-26cb-4602-b1d7-3aaa4eb36bad,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-58345017-f39c-4c95-8fa1-f43fb64a48fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-51a7b6a8-1666-4bab-989a-966cf00d41ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-36ff124c-df72-4834-82f7-69441ad368a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-c8648d5a-d3df-4de7-a113-1164c60b8593,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-2e04280b-425c-4774-98b7-a74d74fbf043,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-830a815a-1954-4b35-aa6f-eec9b7b44d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-0ac96dd0-73cc-44e7-bb39-47eff1903e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928089830-172.17.0.15-1597682475758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-35284a0d-75a9-4d7e-b3bd-00e5b2fb8db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c5f9bf4c-7c9a-48ee-9d0b-7aa74636bd05,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-75d7b753-393b-4173-95ee-3d11ce05e693,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-45b53480-a524-4477-ab6f-97114352739a,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-5b6071f7-dd52-4b80-9eb4-930c0e8e5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-5e18e2b4-1166-41d7-8ea8-ff7f0e01fc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-a365aa75-58c7-4375-bbec-d50c5eea62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-4f30d105-c5fd-485c-b559-d58a27375a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928089830-172.17.0.15-1597682475758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-35284a0d-75a9-4d7e-b3bd-00e5b2fb8db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c5f9bf4c-7c9a-48ee-9d0b-7aa74636bd05,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-75d7b753-393b-4173-95ee-3d11ce05e693,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-45b53480-a524-4477-ab6f-97114352739a,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-5b6071f7-dd52-4b80-9eb4-930c0e8e5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-5e18e2b4-1166-41d7-8ea8-ff7f0e01fc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-a365aa75-58c7-4375-bbec-d50c5eea62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-4f30d105-c5fd-485c-b559-d58a27375a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620818132-172.17.0.15-1597682633906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35917,DS-d29f0906-8feb-429b-9aef-67229e1b2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-69cb3f09-42b8-4452-8b69-5d833df6a388,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-05f62b8c-1702-424f-a027-d8b97c127821,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-baa36941-389d-4f0a-91d0-1f05ae8bd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-69232787-2826-404d-8dec-5785b1566d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-06ed7a25-e8f8-496f-acd7-d80c16f00a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-80b87797-9d47-4ed6-a374-d12882e74891,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f30d2e28-7b88-49f6-a2ce-96709c8d4ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620818132-172.17.0.15-1597682633906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35917,DS-d29f0906-8feb-429b-9aef-67229e1b2fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-69cb3f09-42b8-4452-8b69-5d833df6a388,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-05f62b8c-1702-424f-a027-d8b97c127821,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-baa36941-389d-4f0a-91d0-1f05ae8bd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-69232787-2826-404d-8dec-5785b1566d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-06ed7a25-e8f8-496f-acd7-d80c16f00a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-80b87797-9d47-4ed6-a374-d12882e74891,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f30d2e28-7b88-49f6-a2ce-96709c8d4ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645692305-172.17.0.15-1597682679505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-4e9508cd-3e5f-4d91-b55b-990efbf6ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-44b4c853-37d6-45e5-9594-15bab35ef3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-e1a0f5a0-1f2e-4b93-8860-b551b76a12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-7762d029-0b56-4590-a890-6fb8d395ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-f1a3e39a-f44e-456c-9b95-db6504b7892e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-50e26343-b4c7-4740-8bd2-02f3dcc79436,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-5ab7d441-c8e7-47a7-965d-4323b0cbf87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-9c880ae6-3db1-4ca5-b5d2-95ffc5eb4ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645692305-172.17.0.15-1597682679505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-4e9508cd-3e5f-4d91-b55b-990efbf6ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-44b4c853-37d6-45e5-9594-15bab35ef3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-e1a0f5a0-1f2e-4b93-8860-b551b76a12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-7762d029-0b56-4590-a890-6fb8d395ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-f1a3e39a-f44e-456c-9b95-db6504b7892e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-50e26343-b4c7-4740-8bd2-02f3dcc79436,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-5ab7d441-c8e7-47a7-965d-4323b0cbf87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-9c880ae6-3db1-4ca5-b5d2-95ffc5eb4ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332599462-172.17.0.15-1597683741251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-54ab3508-693b-45ba-b3b9-b4451bf8a894,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-847c4a89-44c3-4212-91ef-2b0ea1fbeb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-3c8e13b7-8fb0-43d9-9bd2-2c9920052c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-86b9df34-4f6c-4b3d-adc1-e883d33a6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-ce85c919-23c9-47fb-9841-c410c71bc546,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-87cf90c9-5e15-4810-9d32-f889aa10e0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-4c205727-6d1e-4ef9-9d9c-15f5ac2c2c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5a0d275b-fbe3-4d0b-8a24-d660a5bbfcc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332599462-172.17.0.15-1597683741251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-54ab3508-693b-45ba-b3b9-b4451bf8a894,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-847c4a89-44c3-4212-91ef-2b0ea1fbeb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-3c8e13b7-8fb0-43d9-9bd2-2c9920052c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-86b9df34-4f6c-4b3d-adc1-e883d33a6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-ce85c919-23c9-47fb-9841-c410c71bc546,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-87cf90c9-5e15-4810-9d32-f889aa10e0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-4c205727-6d1e-4ef9-9d9c-15f5ac2c2c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5a0d275b-fbe3-4d0b-8a24-d660a5bbfcc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211923989-172.17.0.15-1597683817625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-9a6363fa-21ae-4bbd-97da-24fa67bd9124,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-9d89c433-767a-4928-a6f4-618669e9051d,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8c7cd020-8717-46eb-826e-7fcd8b83bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-9503ba2b-cb7d-4d45-a03b-dcb1c8ac0bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-053a6b34-5c4f-48cb-97df-8e55cee9dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-330282d8-dc4a-4c5e-b49f-1b5b286d4700,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-6359d559-492e-42df-b76a-d10ef18cf723,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-15bcb992-7a4a-43af-9eaa-69104536822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211923989-172.17.0.15-1597683817625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-9a6363fa-21ae-4bbd-97da-24fa67bd9124,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-9d89c433-767a-4928-a6f4-618669e9051d,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8c7cd020-8717-46eb-826e-7fcd8b83bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-9503ba2b-cb7d-4d45-a03b-dcb1c8ac0bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-053a6b34-5c4f-48cb-97df-8e55cee9dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-330282d8-dc4a-4c5e-b49f-1b5b286d4700,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-6359d559-492e-42df-b76a-d10ef18cf723,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-15bcb992-7a4a-43af-9eaa-69104536822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088067348-172.17.0.15-1597684054759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-839e698f-d8b8-4f93-b81c-669854fd3d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-66322149-db24-43df-85bf-b20cf059602e,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-9e9e730f-ae8b-4069-8555-035d64e6d145,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-1137ec18-26d6-472c-8665-f5782c0d77c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2487fa7e-53b1-499b-89dd-ff29d2f7688f,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-b93e1d94-36b8-409a-a854-42b2b7393fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-0b7fa605-154e-42b7-9c44-82449fcde55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-3b84b509-3d5d-48b8-a93e-bc55efe9fef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088067348-172.17.0.15-1597684054759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-839e698f-d8b8-4f93-b81c-669854fd3d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-66322149-db24-43df-85bf-b20cf059602e,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-9e9e730f-ae8b-4069-8555-035d64e6d145,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-1137ec18-26d6-472c-8665-f5782c0d77c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2487fa7e-53b1-499b-89dd-ff29d2f7688f,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-b93e1d94-36b8-409a-a854-42b2b7393fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-0b7fa605-154e-42b7-9c44-82449fcde55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-3b84b509-3d5d-48b8-a93e-bc55efe9fef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437269360-172.17.0.15-1597684252787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-a20d0792-0755-41ea-858b-18536a9f7e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-9aab5f15-e565-46b0-a1be-52382ff671b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-4e86e1e7-5c34-490e-a632-ed9f20a970ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-5d1849a2-e01c-4b8d-b738-af1d9ea9d596,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-753ce899-f324-4190-93f4-18d6d1e8853c,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-2c6da76e-9403-49f8-9fb3-98f25940ca02,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-190a6168-a7c4-4d42-be3a-29a9b0a3d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-32d68ecd-55a0-4bbd-a83f-9dcd7ac5b90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437269360-172.17.0.15-1597684252787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-a20d0792-0755-41ea-858b-18536a9f7e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-9aab5f15-e565-46b0-a1be-52382ff671b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-4e86e1e7-5c34-490e-a632-ed9f20a970ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-5d1849a2-e01c-4b8d-b738-af1d9ea9d596,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-753ce899-f324-4190-93f4-18d6d1e8853c,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-2c6da76e-9403-49f8-9fb3-98f25940ca02,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-190a6168-a7c4-4d42-be3a-29a9b0a3d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-32d68ecd-55a0-4bbd-a83f-9dcd7ac5b90a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47692013-172.17.0.15-1597684565984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-ce897ac0-ba36-45ca-b1d6-f46a95bd067c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-5a490197-4ee4-424e-ae74-79ca5f051d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-5354c6ef-4b4a-48e3-9e11-5647b4b54d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-47f1687a-9217-42cf-b03b-b1f12cbcb9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-33d0eb47-5d36-4eab-a73f-5ff32667d592,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-071c0190-bae5-4918-a4ab-075613545fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-b9c1e656-baab-484f-b6aa-62945853680d,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-579224a9-67b9-47d0-9444-5a166f46806c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47692013-172.17.0.15-1597684565984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-ce897ac0-ba36-45ca-b1d6-f46a95bd067c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-5a490197-4ee4-424e-ae74-79ca5f051d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-5354c6ef-4b4a-48e3-9e11-5647b4b54d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-47f1687a-9217-42cf-b03b-b1f12cbcb9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-33d0eb47-5d36-4eab-a73f-5ff32667d592,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-071c0190-bae5-4918-a4ab-075613545fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-b9c1e656-baab-484f-b6aa-62945853680d,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-579224a9-67b9-47d0-9444-5a166f46806c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836813562-172.17.0.15-1597684782094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-e39f789d-30ef-40eb-afac-d3a60b5d9a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-584f5e6d-7ffd-492c-838e-1141e57c53be,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-f7c101a3-a3ad-4812-b150-35be6149487e,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-271a8515-34bc-4437-a115-ff8998724f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-ad89e433-20c3-4cf5-ba9a-43006a89dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-bf016690-8daf-4d4b-bca6-97d72f547563,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4e5c9ab1-c7d1-44f7-b41b-2a9c2fec1808,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-33b972ba-e4b2-4e67-866f-aa60003bc813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836813562-172.17.0.15-1597684782094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-e39f789d-30ef-40eb-afac-d3a60b5d9a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-584f5e6d-7ffd-492c-838e-1141e57c53be,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-f7c101a3-a3ad-4812-b150-35be6149487e,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-271a8515-34bc-4437-a115-ff8998724f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-ad89e433-20c3-4cf5-ba9a-43006a89dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-bf016690-8daf-4d4b-bca6-97d72f547563,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4e5c9ab1-c7d1-44f7-b41b-2a9c2fec1808,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-33b972ba-e4b2-4e67-866f-aa60003bc813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047747610-172.17.0.15-1597685211373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41662,DS-6df9f52a-197d-447b-b383-166ce5a399c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-94f2bd46-8612-4c54-9c0c-fe9dfae2c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-0b0361ed-5721-400f-8844-3429284e07be,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-f4701515-fb70-4b0d-bc52-250329680a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-9a1983e6-593e-45cb-8f39-c6f487760699,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-3ab95111-220d-4205-b0a0-5f9e75035aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-ad98c52c-764d-4494-8257-b6da92cc70ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-042402c9-d101-48aa-9249-199f5f5c670f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047747610-172.17.0.15-1597685211373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41662,DS-6df9f52a-197d-447b-b383-166ce5a399c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-94f2bd46-8612-4c54-9c0c-fe9dfae2c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-0b0361ed-5721-400f-8844-3429284e07be,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-f4701515-fb70-4b0d-bc52-250329680a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-9a1983e6-593e-45cb-8f39-c6f487760699,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-3ab95111-220d-4205-b0a0-5f9e75035aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-ad98c52c-764d-4494-8257-b6da92cc70ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-042402c9-d101-48aa-9249-199f5f5c670f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214361994-172.17.0.15-1597685375772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-69d01fb2-5fb5-41eb-94d5-70fae7b7220e,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-505f2ccf-5c48-46af-8e0f-5fbfd398fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-f45128ac-8e3b-4e96-8ce2-29082b271a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-3da72bc3-7ca0-42aa-a990-01bb197ae66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-47aea5e7-7d62-40e6-85cd-85e91c3c9ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-fc7dbc77-864c-4149-893f-1e50a7d8ed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-ada272e2-ec6a-4574-bc81-a2c26926f225,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-fc4c5901-a335-48a0-b1db-81080d8b2c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214361994-172.17.0.15-1597685375772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-69d01fb2-5fb5-41eb-94d5-70fae7b7220e,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-505f2ccf-5c48-46af-8e0f-5fbfd398fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-f45128ac-8e3b-4e96-8ce2-29082b271a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-3da72bc3-7ca0-42aa-a990-01bb197ae66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-47aea5e7-7d62-40e6-85cd-85e91c3c9ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-fc7dbc77-864c-4149-893f-1e50a7d8ed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-ada272e2-ec6a-4574-bc81-a2c26926f225,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-fc4c5901-a335-48a0-b1db-81080d8b2c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5848
