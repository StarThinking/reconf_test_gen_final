reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196994304-172.17.0.11-1597535088494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-8f53cc85-4794-4701-a16a-156c4070891d,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-58b394a2-f3ae-4e3e-b49c-f6a5721315c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-57a5553e-a788-432c-97c8-335a7851a284,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-414bfc37-ecd1-44ca-8847-dce847e8435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-f634aa99-83d2-4a92-aa67-20404e503e02,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-81b52981-71ca-47b4-b925-a094cc95313a,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-720bb070-a4a4-4e45-8739-adec2b83780d,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-364e3924-89fd-4acc-a0b7-d0560d91b3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196994304-172.17.0.11-1597535088494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-8f53cc85-4794-4701-a16a-156c4070891d,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-58b394a2-f3ae-4e3e-b49c-f6a5721315c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-57a5553e-a788-432c-97c8-335a7851a284,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-414bfc37-ecd1-44ca-8847-dce847e8435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-f634aa99-83d2-4a92-aa67-20404e503e02,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-81b52981-71ca-47b4-b925-a094cc95313a,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-720bb070-a4a4-4e45-8739-adec2b83780d,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-364e3924-89fd-4acc-a0b7-d0560d91b3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545860410-172.17.0.11-1597535523069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-b113829f-b4a6-4f75-8f7a-359f026e4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-6db9ee7d-e643-4542-b5bf-e7cd366262d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-187e5d59-d491-49be-91fd-4fbc6608a418,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0e93f3d3-4261-423b-96bc-476465a9da21,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-f1702711-67d4-45ff-8f47-80bb66480741,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-39be2e0b-0bde-47c0-a761-5532a93e0bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-3371673f-16cd-4cd6-833d-006465026cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-94a8546e-8c46-41bf-bd15-b261c55394c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545860410-172.17.0.11-1597535523069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-b113829f-b4a6-4f75-8f7a-359f026e4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-6db9ee7d-e643-4542-b5bf-e7cd366262d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-187e5d59-d491-49be-91fd-4fbc6608a418,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0e93f3d3-4261-423b-96bc-476465a9da21,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-f1702711-67d4-45ff-8f47-80bb66480741,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-39be2e0b-0bde-47c0-a761-5532a93e0bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-3371673f-16cd-4cd6-833d-006465026cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-94a8546e-8c46-41bf-bd15-b261c55394c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625319581-172.17.0.11-1597535724281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-0e42cd5d-8f43-49ed-b69d-4387cdbe0a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-aa0a9c10-f839-41da-b2dc-ab76d2739ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-9840c42a-fde6-49a0-ba93-2320c0be32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-16ace1f9-5902-4d57-850c-8f0d91670afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-08cfe361-7de2-4d17-98a8-cd6ba2c8bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c941d92a-8c36-4ad6-9c6c-c0842d2480bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-c6776ece-1dfa-4954-9d79-21149ee3d913,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-7b7b1828-9cb9-4afd-a04b-7363137a081e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625319581-172.17.0.11-1597535724281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-0e42cd5d-8f43-49ed-b69d-4387cdbe0a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-aa0a9c10-f839-41da-b2dc-ab76d2739ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-9840c42a-fde6-49a0-ba93-2320c0be32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-16ace1f9-5902-4d57-850c-8f0d91670afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-08cfe361-7de2-4d17-98a8-cd6ba2c8bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-c941d92a-8c36-4ad6-9c6c-c0842d2480bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-c6776ece-1dfa-4954-9d79-21149ee3d913,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-7b7b1828-9cb9-4afd-a04b-7363137a081e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022114993-172.17.0.11-1597536140122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-68b895cf-6893-4895-b4f0-394eff375585,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-02417fbb-b705-4f51-a131-8ecc401b57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-69bb473e-cced-4f3f-8b83-7e217b6df0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-a6c36152-2c97-458c-9db0-954e8be87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-90632589-613a-4f19-9423-b8a573163b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-8085863f-4484-4de9-a24b-a83116350eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-3a4ac351-862b-484c-a745-b0b3a262971a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-18fb6849-daf0-4dd6-ab7e-9265ad6d9d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022114993-172.17.0.11-1597536140122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-68b895cf-6893-4895-b4f0-394eff375585,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-02417fbb-b705-4f51-a131-8ecc401b57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-69bb473e-cced-4f3f-8b83-7e217b6df0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-a6c36152-2c97-458c-9db0-954e8be87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-90632589-613a-4f19-9423-b8a573163b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-8085863f-4484-4de9-a24b-a83116350eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-3a4ac351-862b-484c-a745-b0b3a262971a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-18fb6849-daf0-4dd6-ab7e-9265ad6d9d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262131716-172.17.0.11-1597536212725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-61461790-a5c9-4911-bdb8-86803d8ba5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-58cb3d14-6914-4873-b810-6994de25ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-b9fc42fe-ce46-469f-9405-4869709e72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-487c258e-68b0-41ac-bbbf-2897a0ea0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-bad6938b-e05e-4f67-9e24-f7a482e7b479,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-fcd33b8a-1609-4c9e-bddc-ae9a84e2f66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6f58afda-99ac-4487-91e4-3df0d5a9ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c9ee9247-a86b-4bd9-a9a2-a1fea2fc4ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262131716-172.17.0.11-1597536212725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-61461790-a5c9-4911-bdb8-86803d8ba5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-58cb3d14-6914-4873-b810-6994de25ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-b9fc42fe-ce46-469f-9405-4869709e72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-487c258e-68b0-41ac-bbbf-2897a0ea0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-bad6938b-e05e-4f67-9e24-f7a482e7b479,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-fcd33b8a-1609-4c9e-bddc-ae9a84e2f66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6f58afda-99ac-4487-91e4-3df0d5a9ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c9ee9247-a86b-4bd9-a9a2-a1fea2fc4ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978799308-172.17.0.11-1597536286446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-aac1e807-fe02-498f-a425-8bd863e2e706,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ed469d23-9f3e-465d-aa2a-1602eb8962a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-48ba103a-4501-4568-a2a4-da793054efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fb4bb6bb-e3e8-4aa0-92aa-a7ae86d49e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-ebe5d142-9010-4254-b990-4c8f462bbcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-7269824d-5392-4bd8-b4ca-726a086072d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-955db4d9-fb13-4023-add4-7b6791f9cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-4cd10a54-328d-4dab-888b-2d1c8e7a346c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978799308-172.17.0.11-1597536286446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-aac1e807-fe02-498f-a425-8bd863e2e706,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ed469d23-9f3e-465d-aa2a-1602eb8962a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-48ba103a-4501-4568-a2a4-da793054efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fb4bb6bb-e3e8-4aa0-92aa-a7ae86d49e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-ebe5d142-9010-4254-b990-4c8f462bbcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-7269824d-5392-4bd8-b4ca-726a086072d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-955db4d9-fb13-4023-add4-7b6791f9cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-4cd10a54-328d-4dab-888b-2d1c8e7a346c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718195018-172.17.0.11-1597536550171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-5147632a-e5c6-41a2-a919-baa4d9a5bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-82bee181-828e-4d11-bc87-8cd23610eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d1ca91b7-911a-4ada-97d9-fc5cff6675bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-5996cff5-27fa-4b22-8f53-9d46b83cbc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-29a5c531-c172-494a-8487-bf1c29d699f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-efa5f0c6-adab-4283-bb56-e6ff1b4f6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f87470b7-2a8b-4d7b-afed-7ac02bb552a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-4c9553aa-f8ea-4b50-9f1a-efd6a32c685f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718195018-172.17.0.11-1597536550171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-5147632a-e5c6-41a2-a919-baa4d9a5bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-82bee181-828e-4d11-bc87-8cd23610eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d1ca91b7-911a-4ada-97d9-fc5cff6675bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-5996cff5-27fa-4b22-8f53-9d46b83cbc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-29a5c531-c172-494a-8487-bf1c29d699f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-efa5f0c6-adab-4283-bb56-e6ff1b4f6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f87470b7-2a8b-4d7b-afed-7ac02bb552a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-4c9553aa-f8ea-4b50-9f1a-efd6a32c685f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995148971-172.17.0.11-1597536670906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-d87ae97a-95fe-4289-9b9f-c4f8290085f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-4e4c482a-9375-4bbf-998d-48b378e0d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-abdb7379-9a50-4e0f-a1ee-5399e644a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-5190a2cd-fc63-43a3-8624-fc1a786da33d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-78bc73ae-90d1-4be6-8af8-06650d10d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-adf892bd-d7fd-4114-be6a-2b433cb423f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-8d8bf9bf-176f-4f3b-a453-b8a276f91802,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-64396fde-f3b8-4fe2-b36c-38c03311c0d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995148971-172.17.0.11-1597536670906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-d87ae97a-95fe-4289-9b9f-c4f8290085f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-4e4c482a-9375-4bbf-998d-48b378e0d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-abdb7379-9a50-4e0f-a1ee-5399e644a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-5190a2cd-fc63-43a3-8624-fc1a786da33d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-78bc73ae-90d1-4be6-8af8-06650d10d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-adf892bd-d7fd-4114-be6a-2b433cb423f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-8d8bf9bf-176f-4f3b-a453-b8a276f91802,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-64396fde-f3b8-4fe2-b36c-38c03311c0d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654888703-172.17.0.11-1597536945015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-46bbef83-0c3b-4003-b57f-db6d2eb29095,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-adeb0eda-cf61-4f6f-aff8-3ac05a50b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-9bb8ddbd-046f-44fd-92fc-a7b2a36bb236,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-edb9338b-cb7f-4459-a6ea-d1d27c2f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ad077dbc-b731-47cf-8a76-4564eee0be89,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-38ba3800-437a-46d4-a4fa-96333e158c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-f3450272-9deb-4952-8f54-27844f10bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-165eadfe-7235-4c0f-823f-29b5f0040fb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654888703-172.17.0.11-1597536945015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-46bbef83-0c3b-4003-b57f-db6d2eb29095,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-adeb0eda-cf61-4f6f-aff8-3ac05a50b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-9bb8ddbd-046f-44fd-92fc-a7b2a36bb236,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-edb9338b-cb7f-4459-a6ea-d1d27c2f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ad077dbc-b731-47cf-8a76-4564eee0be89,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-38ba3800-437a-46d4-a4fa-96333e158c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-f3450272-9deb-4952-8f54-27844f10bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-165eadfe-7235-4c0f-823f-29b5f0040fb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122943731-172.17.0.11-1597537019569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38029,DS-42225331-4a3e-4724-82e4-bcabfc3f609f,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-10a8d34b-abf1-444b-9bee-e9967a4c19c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-5281d1bf-8ee6-4c6d-bc95-824a7b13b943,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-e439f365-679e-4d23-881c-9af3f225e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-8925926c-9eb4-4617-b3a5-9cd87c4b475c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-42100eaa-ac1b-49c2-bfd2-20f4af31ea31,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-91dbfe0a-4d0b-463c-9be0-c220e444f0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-2fd79e15-31a7-4c6f-8dc9-78adf3da1500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122943731-172.17.0.11-1597537019569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38029,DS-42225331-4a3e-4724-82e4-bcabfc3f609f,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-10a8d34b-abf1-444b-9bee-e9967a4c19c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-5281d1bf-8ee6-4c6d-bc95-824a7b13b943,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-e439f365-679e-4d23-881c-9af3f225e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-8925926c-9eb4-4617-b3a5-9cd87c4b475c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-42100eaa-ac1b-49c2-bfd2-20f4af31ea31,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-91dbfe0a-4d0b-463c-9be0-c220e444f0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-2fd79e15-31a7-4c6f-8dc9-78adf3da1500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089502058-172.17.0.11-1597537206597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-c410421e-2720-4e24-a749-721ae6db9526,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-38a02140-786d-4910-bc63-e4d049abc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-20398107-33b2-40b5-a5e0-2450ad516c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-cff64007-bf9d-46de-b7a2-ff716ce30bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-f16f74aa-3832-4c1d-b390-eaec7aeda878,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-de48c1de-cada-4cda-80e5-8c1e3874b436,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-8b97a693-9163-4d47-80ab-d815308c4596,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-00794637-e018-4b07-875e-eaf6841aef7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089502058-172.17.0.11-1597537206597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-c410421e-2720-4e24-a749-721ae6db9526,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-38a02140-786d-4910-bc63-e4d049abc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-20398107-33b2-40b5-a5e0-2450ad516c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-cff64007-bf9d-46de-b7a2-ff716ce30bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-f16f74aa-3832-4c1d-b390-eaec7aeda878,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-de48c1de-cada-4cda-80e5-8c1e3874b436,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-8b97a693-9163-4d47-80ab-d815308c4596,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-00794637-e018-4b07-875e-eaf6841aef7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924710-172.17.0.11-1597537696852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-71a22159-eff6-49d1-a96b-978b0d438ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-107a27e4-8778-42b4-992c-430d77938389,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-677bed51-d725-4cc4-ae3c-97a811710f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-3303995c-fd40-40ae-b81d-24613640492a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-eb5499c0-b8e9-48b7-908d-452d073a014c,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-796c09a1-a283-4cfa-afa7-607793207368,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-adbfc90a-86f7-4dd4-b569-51d00af95730,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-51feb563-697c-4319-8fab-9bf543e324c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924710-172.17.0.11-1597537696852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-71a22159-eff6-49d1-a96b-978b0d438ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-107a27e4-8778-42b4-992c-430d77938389,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-677bed51-d725-4cc4-ae3c-97a811710f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-3303995c-fd40-40ae-b81d-24613640492a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-eb5499c0-b8e9-48b7-908d-452d073a014c,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-796c09a1-a283-4cfa-afa7-607793207368,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-adbfc90a-86f7-4dd4-b569-51d00af95730,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-51feb563-697c-4319-8fab-9bf543e324c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553207980-172.17.0.11-1597537942842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33063,DS-b9286703-48d7-4902-9351-32b583661040,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-56f6b3ea-5c83-4a14-a473-d904794e4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a5beddca-4eaa-4abb-9c16-3ea09de26817,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-7a75adca-b905-4e5b-8ed5-32c99dcb823a,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-8e174dd8-fdc5-4f98-84e1-2092dfaea8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-803742a6-abd0-478e-8105-3a1cb41818ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-3481f3f2-5106-4287-88d4-7e85fbdb784b,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-760776ba-c899-423c-acf1-d6267675ceda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553207980-172.17.0.11-1597537942842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33063,DS-b9286703-48d7-4902-9351-32b583661040,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-56f6b3ea-5c83-4a14-a473-d904794e4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a5beddca-4eaa-4abb-9c16-3ea09de26817,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-7a75adca-b905-4e5b-8ed5-32c99dcb823a,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-8e174dd8-fdc5-4f98-84e1-2092dfaea8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-803742a6-abd0-478e-8105-3a1cb41818ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-3481f3f2-5106-4287-88d4-7e85fbdb784b,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-760776ba-c899-423c-acf1-d6267675ceda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960220240-172.17.0.11-1597538089106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-860ac1a1-7130-4da0-b74c-fc51fdaf5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-be5caafd-0711-41c4-bcb6-16cc03e80553,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-0184fa42-b731-4e03-b68f-a58caae4aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-66cf7e2d-8ec7-4c8a-ba2f-798403ec320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-cf7eb714-45a4-45db-a9f2-376146081424,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-1814b59d-aeaf-4945-a9d4-c0a511eccdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-c9900b47-1952-4bf6-9e2d-41af1d776438,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-9a146055-7d57-4e4d-85b4-989afcb188ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960220240-172.17.0.11-1597538089106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-860ac1a1-7130-4da0-b74c-fc51fdaf5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-be5caafd-0711-41c4-bcb6-16cc03e80553,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-0184fa42-b731-4e03-b68f-a58caae4aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-66cf7e2d-8ec7-4c8a-ba2f-798403ec320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-cf7eb714-45a4-45db-a9f2-376146081424,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-1814b59d-aeaf-4945-a9d4-c0a511eccdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-c9900b47-1952-4bf6-9e2d-41af1d776438,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-9a146055-7d57-4e4d-85b4-989afcb188ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976369322-172.17.0.11-1597538395505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46799,DS-d0672706-708f-435f-b86c-92610c610a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-a0464187-5307-4f87-b20e-100fdf4ab373,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-6d5fa054-b827-4744-bdd6-2c821d22d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-484c349b-4d56-4852-8922-434ef0f29b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-588d5fd4-2e78-49ab-a9d2-99d15c30e70a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-38bfc34c-802a-49e9-974a-8d6d582848b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-a21e4158-3ce1-426e-baf3-cc4cc93e3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-421a4ded-ec79-41e4-87c7-b2e8fd4f5d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976369322-172.17.0.11-1597538395505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46799,DS-d0672706-708f-435f-b86c-92610c610a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-a0464187-5307-4f87-b20e-100fdf4ab373,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-6d5fa054-b827-4744-bdd6-2c821d22d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-484c349b-4d56-4852-8922-434ef0f29b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-588d5fd4-2e78-49ab-a9d2-99d15c30e70a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-38bfc34c-802a-49e9-974a-8d6d582848b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-a21e4158-3ce1-426e-baf3-cc4cc93e3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-421a4ded-ec79-41e4-87c7-b2e8fd4f5d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030917234-172.17.0.11-1597538500915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-90872cfd-56e8-4370-b9cf-5f6fc46a99ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-77b054c8-44f7-460d-8f80-4b6d1a7d375f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a2a4fa42-0d72-4151-8aa3-336b296435f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-13c0a122-fea0-42ee-b1ad-00bc0fa6d641,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-8fdc1765-7bfc-4bd0-9451-18d0c3faf550,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-fdf81d92-3dbf-4a4d-9566-2da25ce4bfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-97e7ae8a-8d58-4ecd-9e68-f607760f03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-82cd6679-6544-41a3-8e32-476c8a5307f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030917234-172.17.0.11-1597538500915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-90872cfd-56e8-4370-b9cf-5f6fc46a99ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-77b054c8-44f7-460d-8f80-4b6d1a7d375f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a2a4fa42-0d72-4151-8aa3-336b296435f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-13c0a122-fea0-42ee-b1ad-00bc0fa6d641,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-8fdc1765-7bfc-4bd0-9451-18d0c3faf550,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-fdf81d92-3dbf-4a4d-9566-2da25ce4bfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-97e7ae8a-8d58-4ecd-9e68-f607760f03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-82cd6679-6544-41a3-8e32-476c8a5307f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73601254-172.17.0.11-1597538541371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-5577476d-5971-4a23-9987-8a0d4ebb4629,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1d126e0e-8f45-49c3-9072-428269c3bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-33a2bce9-e5b5-4e4b-af1d-3f8b65609209,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-c7411dd9-862b-4e82-b074-c5d76a61718a,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-67a9bd78-b8ef-4af4-b486-fdc55ca127f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-ce220166-0e18-42c3-bace-90ee1959c217,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-2e368f57-7494-4a13-909c-7d14bff8aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-f327684d-6b98-45b2-9317-decddbfcf8ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73601254-172.17.0.11-1597538541371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-5577476d-5971-4a23-9987-8a0d4ebb4629,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1d126e0e-8f45-49c3-9072-428269c3bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-33a2bce9-e5b5-4e4b-af1d-3f8b65609209,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-c7411dd9-862b-4e82-b074-c5d76a61718a,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-67a9bd78-b8ef-4af4-b486-fdc55ca127f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-ce220166-0e18-42c3-bace-90ee1959c217,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-2e368f57-7494-4a13-909c-7d14bff8aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-f327684d-6b98-45b2-9317-decddbfcf8ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404762593-172.17.0.11-1597538996585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-1d1d8198-2d64-4fa5-953d-00fb3b99143d,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1088b87b-040d-4bac-aa5c-3475e303b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-57d5feeb-3e3d-4fe5-b512-441a485580a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-9ee1ba2f-359e-4562-825e-1e0c5f3afb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-9ec799fc-f509-4bc7-ae07-8da8aeefaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e56167ff-8a77-4363-b03c-1dcae05d4820,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-11672794-f325-4b20-9276-4c399450c41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-fcbff09c-fe3b-4a13-8055-4cdc02208f94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404762593-172.17.0.11-1597538996585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-1d1d8198-2d64-4fa5-953d-00fb3b99143d,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1088b87b-040d-4bac-aa5c-3475e303b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-57d5feeb-3e3d-4fe5-b512-441a485580a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-9ee1ba2f-359e-4562-825e-1e0c5f3afb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-9ec799fc-f509-4bc7-ae07-8da8aeefaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e56167ff-8a77-4363-b03c-1dcae05d4820,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-11672794-f325-4b20-9276-4c399450c41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-fcbff09c-fe3b-4a13-8055-4cdc02208f94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98498551-172.17.0.11-1597539025428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33119,DS-7c0d6cfd-2777-479d-bff4-a6993da0020a,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8e809115-cb6d-4948-a9ff-0370e9ffdd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-e49e8f1c-fde4-4c7a-b386-730bc4169a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-e42b28d4-c10f-4526-aff4-0d5c0b0d5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-c588b7af-7bba-49cd-8486-8cc9e1891e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-ae8ba118-877e-4b0d-abf6-20015e4b4344,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-758eee65-83d5-44d3-a8b7-9dbc3883ed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-7322a158-26c8-467d-a54b-e7cdc53f4878,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98498551-172.17.0.11-1597539025428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33119,DS-7c0d6cfd-2777-479d-bff4-a6993da0020a,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8e809115-cb6d-4948-a9ff-0370e9ffdd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-e49e8f1c-fde4-4c7a-b386-730bc4169a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-e42b28d4-c10f-4526-aff4-0d5c0b0d5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-c588b7af-7bba-49cd-8486-8cc9e1891e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-ae8ba118-877e-4b0d-abf6-20015e4b4344,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-758eee65-83d5-44d3-a8b7-9dbc3883ed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-7322a158-26c8-467d-a54b-e7cdc53f4878,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413571372-172.17.0.11-1597539160933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-53156070-e900-43aa-a76f-0a5689f76d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-ad74a838-e85c-4ee1-b8d3-fda38c9c8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-633161b1-e35a-4b73-ad3f-53880ab14c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-41797fe0-d6b1-42a6-9146-02d9a2efb4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-06b87be5-508b-403c-8585-4a86e06eaf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-51f184f1-6b79-4a62-bd34-427033045ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-3788322f-ed28-4e88-a2c8-a82045aa8321,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f6bf2544-0fba-4ebf-925a-bd6f8f3e2191,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413571372-172.17.0.11-1597539160933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-53156070-e900-43aa-a76f-0a5689f76d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-ad74a838-e85c-4ee1-b8d3-fda38c9c8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-633161b1-e35a-4b73-ad3f-53880ab14c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-41797fe0-d6b1-42a6-9146-02d9a2efb4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-06b87be5-508b-403c-8585-4a86e06eaf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-51f184f1-6b79-4a62-bd34-427033045ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-3788322f-ed28-4e88-a2c8-a82045aa8321,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f6bf2544-0fba-4ebf-925a-bd6f8f3e2191,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045994666-172.17.0.11-1597539241431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-312d7247-9d62-4a69-ab32-3c2fb48c9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-1adde5e8-f82b-4276-b7e8-e10fc4715ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-2c71f85c-6cbc-4e20-8927-8833a5fb0879,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-cad90a11-b111-4b37-a18c-f03bd40c599a,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-1c86d384-6294-4416-8832-560ae8d488df,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-a2be7de6-2cca-416f-a917-8fc6f699cb42,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-8d1b431d-eb3e-451e-ad25-a264d319d888,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-a2100d47-129d-4c94-8152-54cfd19f48e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045994666-172.17.0.11-1597539241431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-312d7247-9d62-4a69-ab32-3c2fb48c9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-1adde5e8-f82b-4276-b7e8-e10fc4715ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-2c71f85c-6cbc-4e20-8927-8833a5fb0879,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-cad90a11-b111-4b37-a18c-f03bd40c599a,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-1c86d384-6294-4416-8832-560ae8d488df,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-a2be7de6-2cca-416f-a917-8fc6f699cb42,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-8d1b431d-eb3e-451e-ad25-a264d319d888,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-a2100d47-129d-4c94-8152-54cfd19f48e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135948113-172.17.0.11-1597539311630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-f2eb1537-34b8-49b7-bf6c-a6bd51854579,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-3822b667-3a9b-4fc6-aea9-1ad84e9f0335,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-d3993947-d25f-46d0-af3e-2a8a4a5da196,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-c9786570-e852-4d21-b67d-827851f479f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-4bd025c2-305b-4b14-b448-47c068a82650,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-a8b9a1fd-74f2-4920-b030-64a1824771c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-e763a1f5-509c-4e46-8eb4-f7042ea627aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-7cf0f214-ab70-4859-b99c-c21185ce5ca4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135948113-172.17.0.11-1597539311630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-f2eb1537-34b8-49b7-bf6c-a6bd51854579,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-3822b667-3a9b-4fc6-aea9-1ad84e9f0335,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-d3993947-d25f-46d0-af3e-2a8a4a5da196,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-c9786570-e852-4d21-b67d-827851f479f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-4bd025c2-305b-4b14-b448-47c068a82650,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-a8b9a1fd-74f2-4920-b030-64a1824771c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-e763a1f5-509c-4e46-8eb4-f7042ea627aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-7cf0f214-ab70-4859-b99c-c21185ce5ca4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395117272-172.17.0.11-1597539490132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-04a4c096-79b0-4ddf-824d-17afb1eb5366,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-c8e74d08-86e1-443f-a139-914bce42cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-39bea50c-ceaa-4879-900c-9dda07bd365b,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3256a83d-a173-46db-b093-0a9f65645a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-139eb549-c841-466d-adda-87551e1f31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-a205e40d-b986-4864-a754-937485c36d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-1413a2aa-6473-4ba5-bbe0-650223f9de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-4a117698-99d2-4f8e-ad92-b3cd5bd756fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395117272-172.17.0.11-1597539490132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-04a4c096-79b0-4ddf-824d-17afb1eb5366,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-c8e74d08-86e1-443f-a139-914bce42cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-39bea50c-ceaa-4879-900c-9dda07bd365b,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3256a83d-a173-46db-b093-0a9f65645a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-139eb549-c841-466d-adda-87551e1f31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-a205e40d-b986-4864-a754-937485c36d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-1413a2aa-6473-4ba5-bbe0-650223f9de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-4a117698-99d2-4f8e-ad92-b3cd5bd756fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589694993-172.17.0.11-1597539534450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43909,DS-e0fd1c94-9c23-4d8a-a0cf-b36f4b9f30af,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-267d74b1-0dcf-4ca1-8c8e-b00cd41cc578,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-460415ec-0879-4897-a548-13145a89120f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-f14bfdb1-bbc8-40a8-941a-d8d8e04d170c,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6017671a-ccf6-4920-a0af-3aacc7ac9725,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-52327603-fe6e-4ad6-a3c4-8414dfc68c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c36dbbfd-705e-423f-86b8-a166180ccf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-a0325654-f411-46da-aabd-e0d3fa2fe17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589694993-172.17.0.11-1597539534450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43909,DS-e0fd1c94-9c23-4d8a-a0cf-b36f4b9f30af,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-267d74b1-0dcf-4ca1-8c8e-b00cd41cc578,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-460415ec-0879-4897-a548-13145a89120f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-f14bfdb1-bbc8-40a8-941a-d8d8e04d170c,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6017671a-ccf6-4920-a0af-3aacc7ac9725,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-52327603-fe6e-4ad6-a3c4-8414dfc68c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c36dbbfd-705e-423f-86b8-a166180ccf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-a0325654-f411-46da-aabd-e0d3fa2fe17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269925906-172.17.0.11-1597539865495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-f930bf04-c5f8-4b1e-9b96-04d380ce3637,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-d011f765-e032-44b0-b5d0-7433cdfb10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-c3c375a1-4b50-40d9-9fbf-d2e819648b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-08be266f-b25d-460c-ae94-6fa0c72f5a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-42a071b5-65ef-4131-b03a-5276bef029d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-845b2a48-da07-4b2e-83f9-f720157643e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-3949c296-7ec4-46c8-8b1d-cb365f9b7864,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-d7999f10-9724-4bc9-8c2a-eeedd08c1095,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269925906-172.17.0.11-1597539865495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-f930bf04-c5f8-4b1e-9b96-04d380ce3637,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-d011f765-e032-44b0-b5d0-7433cdfb10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-c3c375a1-4b50-40d9-9fbf-d2e819648b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-08be266f-b25d-460c-ae94-6fa0c72f5a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-42a071b5-65ef-4131-b03a-5276bef029d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-845b2a48-da07-4b2e-83f9-f720157643e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-3949c296-7ec4-46c8-8b1d-cb365f9b7864,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-d7999f10-9724-4bc9-8c2a-eeedd08c1095,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166518432-172.17.0.11-1597539972120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-b022a4e6-9e82-4a7c-8705-a1915dc6f268,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-98a9dd9d-1b1f-4ba7-8f2f-70586441e437,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-64062ca9-dd7a-4b80-952d-6871a2ededa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-f9d730b6-ec70-46da-88ab-59c6f5aceaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-e437e080-ba93-462e-a81e-66eba88e820c,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-ee075161-73e4-407f-97f2-60a0cf687c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-3412c69d-3586-4442-a186-ad2935606faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-60e4f5fd-213a-4a4d-a843-bfaa48e81e25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166518432-172.17.0.11-1597539972120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-b022a4e6-9e82-4a7c-8705-a1915dc6f268,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-98a9dd9d-1b1f-4ba7-8f2f-70586441e437,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-64062ca9-dd7a-4b80-952d-6871a2ededa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-f9d730b6-ec70-46da-88ab-59c6f5aceaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-e437e080-ba93-462e-a81e-66eba88e820c,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-ee075161-73e4-407f-97f2-60a0cf687c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-3412c69d-3586-4442-a186-ad2935606faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-60e4f5fd-213a-4a4d-a843-bfaa48e81e25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889382443-172.17.0.11-1597540004243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-6cebcbf5-728a-4dd8-943c-147f31ca6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e056a9d2-4b22-4095-bd93-5285d972b9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-333f77a9-5c88-4079-a2a6-104b7fd1076a,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-014c934e-3e83-4143-a2d2-8f64c32fbf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-de7314e7-a9cf-48cf-8c4e-ede49a804c81,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-763adc48-1ffe-400c-b80a-113d93fda75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-83ba82f6-7f9f-42e2-99c8-abfc46c34c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-986e31ae-f714-40c8-b615-f6dc5713ee32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889382443-172.17.0.11-1597540004243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-6cebcbf5-728a-4dd8-943c-147f31ca6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e056a9d2-4b22-4095-bd93-5285d972b9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-333f77a9-5c88-4079-a2a6-104b7fd1076a,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-014c934e-3e83-4143-a2d2-8f64c32fbf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-de7314e7-a9cf-48cf-8c4e-ede49a804c81,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-763adc48-1ffe-400c-b80a-113d93fda75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-83ba82f6-7f9f-42e2-99c8-abfc46c34c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-986e31ae-f714-40c8-b615-f6dc5713ee32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469875806-172.17.0.11-1597540398537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-946faa42-7767-432e-a46d-c5b1b268eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-890b6b3f-0bd8-47e2-ab00-62cbab5de604,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-9f7f0f83-7af4-4300-b534-8d5404041dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-435aec2d-2011-4dab-b1d4-9ada8688e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-4700325b-b309-440a-8c25-d4a38b7946fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-213831da-6ef6-460c-890f-ffb7b3846b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-2ce7cda6-ebe5-40f5-98b6-78586631af74,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-6cc139c6-28ec-4996-b1a9-222ac3802974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469875806-172.17.0.11-1597540398537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-946faa42-7767-432e-a46d-c5b1b268eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-890b6b3f-0bd8-47e2-ab00-62cbab5de604,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-9f7f0f83-7af4-4300-b534-8d5404041dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-435aec2d-2011-4dab-b1d4-9ada8688e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-4700325b-b309-440a-8c25-d4a38b7946fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-213831da-6ef6-460c-890f-ffb7b3846b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-2ce7cda6-ebe5-40f5-98b6-78586631af74,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-6cc139c6-28ec-4996-b1a9-222ac3802974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512109241-172.17.0.11-1597540514050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-7c30047d-3302-45b7-a769-cee0fb037415,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-512e9e1d-f411-4180-b4c7-d7c60ced9e83,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-175f1425-a04c-45cf-987e-7f1c5f178c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2d65a6f8-7ccb-4c27-9f6a-f494bf76fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-8332b8d1-d169-4837-9e3a-5a92678ab2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ae2e455c-8942-40ed-9407-47b3da939430,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-18d80f65-19af-42ae-bb82-cf23040c25cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-ed97f5ef-261c-45bf-bcf3-d106ca7dcf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512109241-172.17.0.11-1597540514050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-7c30047d-3302-45b7-a769-cee0fb037415,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-512e9e1d-f411-4180-b4c7-d7c60ced9e83,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-175f1425-a04c-45cf-987e-7f1c5f178c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2d65a6f8-7ccb-4c27-9f6a-f494bf76fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-8332b8d1-d169-4837-9e3a-5a92678ab2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ae2e455c-8942-40ed-9407-47b3da939430,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-18d80f65-19af-42ae-bb82-cf23040c25cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-ed97f5ef-261c-45bf-bcf3-d106ca7dcf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5595
