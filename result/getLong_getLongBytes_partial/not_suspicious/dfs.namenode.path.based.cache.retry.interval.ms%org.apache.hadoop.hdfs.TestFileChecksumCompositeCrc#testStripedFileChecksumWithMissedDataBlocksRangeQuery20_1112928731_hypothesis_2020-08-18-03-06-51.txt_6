reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460920605-172.17.0.17-1597720693967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41054,DS-9176bd2c-eb5e-44fe-96fc-bcd76f6d9492,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-7777b86f-a749-49b4-8731-0a891e6aece3,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a013788a-da99-47c7-babf-5886ab280b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-9eb3c490-4a98-406e-88b9-48ff4b2923b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-2aa3c2da-8f29-469f-9904-da1d4d024be2,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-107277bf-94b1-402d-ba8f-b196ecea6796,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-1cb128d4-6f47-407b-862d-733491dcbb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-157d85ba-556d-4aaa-aad7-eb98613f3ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460920605-172.17.0.17-1597720693967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41054,DS-9176bd2c-eb5e-44fe-96fc-bcd76f6d9492,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-7777b86f-a749-49b4-8731-0a891e6aece3,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a013788a-da99-47c7-babf-5886ab280b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-9eb3c490-4a98-406e-88b9-48ff4b2923b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-2aa3c2da-8f29-469f-9904-da1d4d024be2,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-107277bf-94b1-402d-ba8f-b196ecea6796,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-1cb128d4-6f47-407b-862d-733491dcbb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-157d85ba-556d-4aaa-aad7-eb98613f3ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708571035-172.17.0.17-1597720941797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-e284d468-80b2-4136-8651-163e80917bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-6d84e029-d6d7-46ec-8e72-a262349b70cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-753ea2de-1c0f-49d9-8eb3-16623e04b796,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-6e1fd55c-6901-4107-9563-eaee1f1bdc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-65afeb18-5bb2-4b3d-a49f-cc45d5f45431,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-64537826-d4f5-4989-9c26-b21283032e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-c0c1cc05-b817-43a1-b281-9f04ee202e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-98c609bf-99df-4093-8dd7-4f2d6540bc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708571035-172.17.0.17-1597720941797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-e284d468-80b2-4136-8651-163e80917bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-6d84e029-d6d7-46ec-8e72-a262349b70cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-753ea2de-1c0f-49d9-8eb3-16623e04b796,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-6e1fd55c-6901-4107-9563-eaee1f1bdc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-65afeb18-5bb2-4b3d-a49f-cc45d5f45431,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-64537826-d4f5-4989-9c26-b21283032e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-c0c1cc05-b817-43a1-b281-9f04ee202e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-98c609bf-99df-4093-8dd7-4f2d6540bc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018319915-172.17.0.17-1597721509279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-c3afecff-84ac-4443-8f39-0a03be6dfd26,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-590fd16c-ce05-46b6-9d2b-8155fc176bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-30d30984-5a98-42a5-9548-9f283b111ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-93b1c19a-d3ba-44c6-9c35-5dfbe70e6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-00e4477a-94a0-47b3-99e0-351a9d939616,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-e56ec7a7-eae6-40fe-a9ec-7c98c88d2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-d122251a-1e39-41ae-ab41-ab8e0569f3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-2fb397b5-494a-433c-be47-308498fe470e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018319915-172.17.0.17-1597721509279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-c3afecff-84ac-4443-8f39-0a03be6dfd26,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-590fd16c-ce05-46b6-9d2b-8155fc176bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-30d30984-5a98-42a5-9548-9f283b111ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-93b1c19a-d3ba-44c6-9c35-5dfbe70e6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-00e4477a-94a0-47b3-99e0-351a9d939616,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-e56ec7a7-eae6-40fe-a9ec-7c98c88d2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-d122251a-1e39-41ae-ab41-ab8e0569f3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-2fb397b5-494a-433c-be47-308498fe470e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917579932-172.17.0.17-1597721724161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-1ba7a1aa-9d93-42bd-b94a-2b024cba8978,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f82f3018-38cf-4952-9161-ed7403721913,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-52b22174-f276-45f1-90af-3b966c4404ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-59c96516-4d40-4d2d-9ea7-079ad00d8b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-bf94caf6-8443-42c1-879d-eeb6302fd269,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-485860c1-d54e-4556-9149-47c01ec2a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-939f31e6-fe47-44b8-946a-490adf0babe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-960e43d4-2dd7-4a52-81f0-39a6dfbf1a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917579932-172.17.0.17-1597721724161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-1ba7a1aa-9d93-42bd-b94a-2b024cba8978,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f82f3018-38cf-4952-9161-ed7403721913,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-52b22174-f276-45f1-90af-3b966c4404ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-59c96516-4d40-4d2d-9ea7-079ad00d8b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-bf94caf6-8443-42c1-879d-eeb6302fd269,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-485860c1-d54e-4556-9149-47c01ec2a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-939f31e6-fe47-44b8-946a-490adf0babe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-960e43d4-2dd7-4a52-81f0-39a6dfbf1a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606506070-172.17.0.17-1597721865366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34525,DS-b4f9284f-e7d8-41ad-aba1-76174b4492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-948f192f-9511-49ee-bcc7-c491790c0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-1db8e94b-7b70-4c2b-bfb4-03d2de4e7674,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e9617ce7-d0e9-4c79-9314-cc5c1041f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-c3c4fb59-b8e6-45e1-8d55-1f187e783810,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-72ceaa4e-f7a4-4c27-8540-0ec7b5ae8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-5e71e2cb-65b6-4b90-8cac-41df7ffa8081,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-03ced8ce-7454-4176-95c7-321b3efea80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606506070-172.17.0.17-1597721865366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34525,DS-b4f9284f-e7d8-41ad-aba1-76174b4492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-948f192f-9511-49ee-bcc7-c491790c0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-1db8e94b-7b70-4c2b-bfb4-03d2de4e7674,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e9617ce7-d0e9-4c79-9314-cc5c1041f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-c3c4fb59-b8e6-45e1-8d55-1f187e783810,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-72ceaa4e-f7a4-4c27-8540-0ec7b5ae8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-5e71e2cb-65b6-4b90-8cac-41df7ffa8081,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-03ced8ce-7454-4176-95c7-321b3efea80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220436672-172.17.0.17-1597722361894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45980,DS-dee59436-f609-4d81-8d32-06da3a4e66c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-c266df66-b640-44cd-a808-cd5bca2d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-0886e0dd-cdc8-47ae-b62a-12fe9731eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-ca8bf8f7-afd1-42cc-b0bc-42a80ac0d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-56bf9458-d82b-4918-a494-e3338a854b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4c2c2b11-c2c4-4d15-8ae8-602ac88eb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-231fd926-197d-4052-b25c-df0ec3a6735c,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-f1ab2f53-c469-4e0d-9fff-45fd1e3a0578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220436672-172.17.0.17-1597722361894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45980,DS-dee59436-f609-4d81-8d32-06da3a4e66c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-c266df66-b640-44cd-a808-cd5bca2d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-0886e0dd-cdc8-47ae-b62a-12fe9731eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-ca8bf8f7-afd1-42cc-b0bc-42a80ac0d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-56bf9458-d82b-4918-a494-e3338a854b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4c2c2b11-c2c4-4d15-8ae8-602ac88eb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-231fd926-197d-4052-b25c-df0ec3a6735c,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-f1ab2f53-c469-4e0d-9fff-45fd1e3a0578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174566501-172.17.0.17-1597722476697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-1581cf35-2b8c-439e-af0f-229da9698157,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-fa49516b-4348-43ef-9a6d-98ae8dda9279,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-07156a12-f63e-4d66-9ec2-209b1d5e8eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-34c7e374-da3e-40cb-a389-2f4a0501df12,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2f7a66d2-3161-4356-93e9-ef4d275d1321,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-d7dd1b90-0755-4b39-82a7-ceba2dfe0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-d1c38ff2-80ea-4d23-99df-af34893dcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-0a266a19-3e3f-42c8-a2af-8c7c26cb1d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174566501-172.17.0.17-1597722476697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-1581cf35-2b8c-439e-af0f-229da9698157,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-fa49516b-4348-43ef-9a6d-98ae8dda9279,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-07156a12-f63e-4d66-9ec2-209b1d5e8eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-34c7e374-da3e-40cb-a389-2f4a0501df12,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2f7a66d2-3161-4356-93e9-ef4d275d1321,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-d7dd1b90-0755-4b39-82a7-ceba2dfe0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-d1c38ff2-80ea-4d23-99df-af34893dcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-0a266a19-3e3f-42c8-a2af-8c7c26cb1d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436609171-172.17.0.17-1597722697545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-5879eb79-bc5a-4509-8d33-dd55976044e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-8d5fec26-4d3d-46f0-bb01-ea2cf6e90e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-56c02fcf-8765-4497-8150-8c6de74f3c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-ad517597-48f0-4d1e-a25e-edaf3648ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-5fc0fb2d-982e-4284-b915-36cd27e8a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-1f94a0db-aa37-4b96-8ee9-da02c00331e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-936f5833-ee2a-4745-9eb4-85b34e904fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6f9d7f70-2756-410d-97a1-9899e361b340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436609171-172.17.0.17-1597722697545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-5879eb79-bc5a-4509-8d33-dd55976044e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-8d5fec26-4d3d-46f0-bb01-ea2cf6e90e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-56c02fcf-8765-4497-8150-8c6de74f3c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-ad517597-48f0-4d1e-a25e-edaf3648ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-5fc0fb2d-982e-4284-b915-36cd27e8a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-1f94a0db-aa37-4b96-8ee9-da02c00331e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-936f5833-ee2a-4745-9eb4-85b34e904fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6f9d7f70-2756-410d-97a1-9899e361b340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041201513-172.17.0.17-1597722757632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-39f57459-de21-486d-8f7b-f05c2752ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-7fcf43da-c21e-4e05-8800-9eee44be2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-6058c21a-5b6c-4951-a50b-3e6af8717ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8ed0802a-c5eb-4fa2-aa7f-4c324383ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-f96af745-4c47-41f2-aeb8-31777174d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-3bc7f18a-d586-429b-ad5b-16b3410980c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-5f423e7f-356f-4781-a3ee-e7086a7d8489,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-ce464eb3-0f09-4c8c-981f-8f3d4e776fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041201513-172.17.0.17-1597722757632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-39f57459-de21-486d-8f7b-f05c2752ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-7fcf43da-c21e-4e05-8800-9eee44be2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-6058c21a-5b6c-4951-a50b-3e6af8717ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8ed0802a-c5eb-4fa2-aa7f-4c324383ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-f96af745-4c47-41f2-aeb8-31777174d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-3bc7f18a-d586-429b-ad5b-16b3410980c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-5f423e7f-356f-4781-a3ee-e7086a7d8489,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-ce464eb3-0f09-4c8c-981f-8f3d4e776fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174531458-172.17.0.17-1597723125130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-f849e053-a118-4d3f-8a22-7be056c29d56,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-0258e7a3-26f5-40db-9585-cde9393473ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-ef4b7944-1366-4452-b711-c0a2a841b237,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-b045f254-d60d-41b8-94b7-7dfbfe80a620,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-823478f9-86cf-4804-ade5-1e2840a8d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9f66f723-35ee-46f8-8342-f81f0bd0bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-01f97fe9-573c-4beb-bd12-8b6bcfc3741d,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-de55eab3-6843-43ad-b3b5-bd8263a3b28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174531458-172.17.0.17-1597723125130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-f849e053-a118-4d3f-8a22-7be056c29d56,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-0258e7a3-26f5-40db-9585-cde9393473ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-ef4b7944-1366-4452-b711-c0a2a841b237,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-b045f254-d60d-41b8-94b7-7dfbfe80a620,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-823478f9-86cf-4804-ade5-1e2840a8d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9f66f723-35ee-46f8-8342-f81f0bd0bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-01f97fe9-573c-4beb-bd12-8b6bcfc3741d,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-de55eab3-6843-43ad-b3b5-bd8263a3b28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760090565-172.17.0.17-1597723445999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-0aa418ba-a6a1-4f58-af62-cf4bf2285cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9a668130-26f6-4239-ad7e-c6b396c36f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-0172908b-3913-436c-abf1-99de00ddc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-c263d455-0da3-463e-be57-ca37191040f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-1d2a5b0d-b8c1-4e42-a8fd-1548e0be87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-64f69472-ac2c-4246-9ab8-16f4c70c1d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-d7d88bb8-fef7-441e-a84d-2960c33b3396,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b9f3f2e5-3b28-468a-a7e0-8ccf13de6b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760090565-172.17.0.17-1597723445999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-0aa418ba-a6a1-4f58-af62-cf4bf2285cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-9a668130-26f6-4239-ad7e-c6b396c36f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-0172908b-3913-436c-abf1-99de00ddc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-c263d455-0da3-463e-be57-ca37191040f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-1d2a5b0d-b8c1-4e42-a8fd-1548e0be87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-64f69472-ac2c-4246-9ab8-16f4c70c1d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-d7d88bb8-fef7-441e-a84d-2960c33b3396,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b9f3f2e5-3b28-468a-a7e0-8ccf13de6b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249810721-172.17.0.17-1597723547369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-6f252db4-2112-4a32-8f85-bb7039fa874e,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-e074c752-e179-4ffe-979c-d58b59db67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-98a42df7-a2b4-48c5-8ca8-03b90cf2d778,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-c75b2e00-546a-4eda-b3f3-f1b291c91706,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9291ec0f-855c-4cb8-9dcb-a67ad6ff7387,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-5f787a2e-ea18-42c1-9a80-1df7d3930428,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-805fc3ba-7d34-4603-a67b-7970b6ed211c,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-fde159fc-27fc-4a83-9685-bf465a6aa46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249810721-172.17.0.17-1597723547369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-6f252db4-2112-4a32-8f85-bb7039fa874e,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-e074c752-e179-4ffe-979c-d58b59db67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-98a42df7-a2b4-48c5-8ca8-03b90cf2d778,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-c75b2e00-546a-4eda-b3f3-f1b291c91706,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9291ec0f-855c-4cb8-9dcb-a67ad6ff7387,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-5f787a2e-ea18-42c1-9a80-1df7d3930428,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-805fc3ba-7d34-4603-a67b-7970b6ed211c,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-fde159fc-27fc-4a83-9685-bf465a6aa46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338221122-172.17.0.17-1597723622152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-9ac61f28-818a-4d92-9d2b-802af1b465e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-b6f7a0c6-f47b-49f0-902b-c624f1cc1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-a9d4f338-77b1-4fdd-bc37-e7adbec17e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-1c56e190-e476-42c2-831d-4382c9ab39ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-9b1d3948-c4fe-4a3c-a605-68c674e0fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-9a1ac69d-10f0-4829-8061-c0537c739a47,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-821e6fa3-489b-482b-b87c-a9b0b9bf6760,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d4e02b37-d7fe-469c-9a84-1442021103d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338221122-172.17.0.17-1597723622152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-9ac61f28-818a-4d92-9d2b-802af1b465e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-b6f7a0c6-f47b-49f0-902b-c624f1cc1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-a9d4f338-77b1-4fdd-bc37-e7adbec17e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-1c56e190-e476-42c2-831d-4382c9ab39ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-9b1d3948-c4fe-4a3c-a605-68c674e0fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-9a1ac69d-10f0-4829-8061-c0537c739a47,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-821e6fa3-489b-482b-b87c-a9b0b9bf6760,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d4e02b37-d7fe-469c-9a84-1442021103d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541010862-172.17.0.17-1597723698231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-2c90ac22-90f6-4351-8fd9-470ec5430bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-052c32aa-b1a1-489e-b312-886007e378c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-f7cda061-fa50-4407-9cde-6555568c5725,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-20c9bcea-9582-4315-8b9e-c8f24299cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ec9f2e22-e7e0-4d64-bb50-7aa7a8135ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3046e0ce-02fd-468c-ad40-d89005294b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c12f2c88-f43d-4366-992f-90ce96031a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-aa6aee3f-2ee1-4d6f-8b02-1c62f71c479a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541010862-172.17.0.17-1597723698231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-2c90ac22-90f6-4351-8fd9-470ec5430bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-052c32aa-b1a1-489e-b312-886007e378c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-f7cda061-fa50-4407-9cde-6555568c5725,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-20c9bcea-9582-4315-8b9e-c8f24299cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ec9f2e22-e7e0-4d64-bb50-7aa7a8135ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3046e0ce-02fd-468c-ad40-d89005294b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c12f2c88-f43d-4366-992f-90ce96031a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-aa6aee3f-2ee1-4d6f-8b02-1c62f71c479a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588719693-172.17.0.17-1597724211569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-cde1079f-7a24-4349-ac30-a68e31d7b5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-4a91eeb6-70df-4ef8-8c50-6fe5f04b3d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-63e696d7-a481-4222-9401-f1a825f3705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e4ca331c-346f-41b0-a2d6-292333a5097f,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-3a5eda11-9509-4109-80bd-7c7223f64d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c4d9ed45-3760-4490-8fd8-c74e7ebc2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-a891f5a5-1369-425b-a066-cc32954c1231,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-4085c666-83fb-43c7-8eae-13aaf3a8e303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588719693-172.17.0.17-1597724211569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-cde1079f-7a24-4349-ac30-a68e31d7b5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-4a91eeb6-70df-4ef8-8c50-6fe5f04b3d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-63e696d7-a481-4222-9401-f1a825f3705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e4ca331c-346f-41b0-a2d6-292333a5097f,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-3a5eda11-9509-4109-80bd-7c7223f64d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c4d9ed45-3760-4490-8fd8-c74e7ebc2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-a891f5a5-1369-425b-a066-cc32954c1231,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-4085c666-83fb-43c7-8eae-13aaf3a8e303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108743759-172.17.0.17-1597724319595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-1d64ae5a-fcfa-4abb-a3c1-10c2adaf7871,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c2ab3621-3cdb-4c47-ae84-78855f503482,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-3428314f-7183-449d-9fa5-fc9597af73e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-4e13478d-738f-4f08-98da-78d626616c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-f1b478f5-d37f-4a2e-a66e-af929102a881,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-5bf15d7a-81ee-465a-8545-7162fb266ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-01518eaf-a35a-4ea7-a649-4140158f39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-b4b71825-b987-445c-8bba-3bf8fa3b971e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108743759-172.17.0.17-1597724319595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-1d64ae5a-fcfa-4abb-a3c1-10c2adaf7871,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c2ab3621-3cdb-4c47-ae84-78855f503482,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-3428314f-7183-449d-9fa5-fc9597af73e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-4e13478d-738f-4f08-98da-78d626616c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-f1b478f5-d37f-4a2e-a66e-af929102a881,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-5bf15d7a-81ee-465a-8545-7162fb266ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-01518eaf-a35a-4ea7-a649-4140158f39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-b4b71825-b987-445c-8bba-3bf8fa3b971e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58753054-172.17.0.17-1597724748283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38746,DS-acaa3950-5cd2-45b4-b72b-39a8f074f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-5b11b39e-7877-4ba9-8859-941f3e826045,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-929d5c75-6cfd-4d31-9f9a-e9288a41e920,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-db120207-4cee-4442-8b79-523efcf5deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-52b8f016-825b-438a-a504-27b3c50c1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-f926745a-d9ac-489d-a0bd-b70e51802691,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-1f72fd9a-f152-452b-8dba-37dfa01650e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1d789319-3150-40b9-9ea1-690fa51f87bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58753054-172.17.0.17-1597724748283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38746,DS-acaa3950-5cd2-45b4-b72b-39a8f074f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-5b11b39e-7877-4ba9-8859-941f3e826045,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-929d5c75-6cfd-4d31-9f9a-e9288a41e920,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-db120207-4cee-4442-8b79-523efcf5deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-52b8f016-825b-438a-a504-27b3c50c1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-f926745a-d9ac-489d-a0bd-b70e51802691,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-1f72fd9a-f152-452b-8dba-37dfa01650e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1d789319-3150-40b9-9ea1-690fa51f87bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692803541-172.17.0.17-1597724892490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-f5948ae4-86a3-48c4-9341-d89d53d9ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-00c0e90d-abed-409b-97ff-bcb638ae586a,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-d7eaa891-b1b3-4b1d-b711-a53d02a28a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-10ee060a-2d18-4538-b479-3e7b3e28a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-08f23a91-9ae3-47e0-8711-9b5c83be6929,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-77463692-97a8-429f-a335-bc462d1e3227,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-df1ed636-cdbd-4ccc-a75b-76bcb578214c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-e2ff6a7c-3193-4e87-aa0d-4652c57644d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692803541-172.17.0.17-1597724892490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-f5948ae4-86a3-48c4-9341-d89d53d9ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-00c0e90d-abed-409b-97ff-bcb638ae586a,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-d7eaa891-b1b3-4b1d-b711-a53d02a28a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-10ee060a-2d18-4538-b479-3e7b3e28a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-08f23a91-9ae3-47e0-8711-9b5c83be6929,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-77463692-97a8-429f-a335-bc462d1e3227,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-df1ed636-cdbd-4ccc-a75b-76bcb578214c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-e2ff6a7c-3193-4e87-aa0d-4652c57644d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726188143-172.17.0.17-1597725028526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-a25578bb-7be0-42cd-8d70-39e29d64cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-a7fb4d58-6c4b-4b03-9206-74b6d86e0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-29ba0ca8-eaaf-472e-bc7d-75b3df63c674,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-45d9b406-9a3f-4679-b3f0-4ed70fa7338e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-2872b5c1-c9c8-4b40-a1fc-b65b094e6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-2077625d-b310-4ce4-aa36-5a62964110ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-d39dc5df-9c88-424d-9174-de2d32f3b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-a26aaed0-837f-4a77-b0f0-c641c54ed847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726188143-172.17.0.17-1597725028526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-a25578bb-7be0-42cd-8d70-39e29d64cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-a7fb4d58-6c4b-4b03-9206-74b6d86e0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-29ba0ca8-eaaf-472e-bc7d-75b3df63c674,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-45d9b406-9a3f-4679-b3f0-4ed70fa7338e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-2872b5c1-c9c8-4b40-a1fc-b65b094e6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-2077625d-b310-4ce4-aa36-5a62964110ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-d39dc5df-9c88-424d-9174-de2d32f3b40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-a26aaed0-837f-4a77-b0f0-c641c54ed847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051315126-172.17.0.17-1597725216714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-b927782b-c5e4-4b4f-ab40-abf898411ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-2ff75e43-2e17-4e36-bda3-6df0cd680ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-bee21d7f-1909-4804-a863-a71bfd377c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-7feb241a-878a-4001-8466-6b03fcba3d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-450bfb94-738e-404d-a2f8-e1d0a3285974,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-5c192558-baae-44a9-9a34-43f7dcdb50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-08d8d645-84fa-4504-b99a-b7376e3b6029,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4ada06fb-8f3e-4ee4-98c3-031e9ce098db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051315126-172.17.0.17-1597725216714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-b927782b-c5e4-4b4f-ab40-abf898411ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-2ff75e43-2e17-4e36-bda3-6df0cd680ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-bee21d7f-1909-4804-a863-a71bfd377c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-7feb241a-878a-4001-8466-6b03fcba3d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-450bfb94-738e-404d-a2f8-e1d0a3285974,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-5c192558-baae-44a9-9a34-43f7dcdb50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-08d8d645-84fa-4504-b99a-b7376e3b6029,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4ada06fb-8f3e-4ee4-98c3-031e9ce098db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5372
