reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120874455-172.17.0.18-1597533524540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-c4d9e17d-a4ab-4d99-8dbc-848381dd6604,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-d53d4f63-df03-4bc2-9b8c-0eb5fe20e3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-14b57302-4f37-45ff-8d5f-74784a83af86,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-57f023a3-dbf1-435c-99d2-4a966543cbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-568fa887-ac4e-4fe0-b0b6-995865734520,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-772a851f-d257-4611-860a-d1ec16ac09a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-a6b5dfe5-ca78-4002-be80-825b0d080228,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1f832731-6e61-4749-92dc-4216bede0a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120874455-172.17.0.18-1597533524540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-c4d9e17d-a4ab-4d99-8dbc-848381dd6604,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-d53d4f63-df03-4bc2-9b8c-0eb5fe20e3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-14b57302-4f37-45ff-8d5f-74784a83af86,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-57f023a3-dbf1-435c-99d2-4a966543cbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-568fa887-ac4e-4fe0-b0b6-995865734520,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-772a851f-d257-4611-860a-d1ec16ac09a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-a6b5dfe5-ca78-4002-be80-825b0d080228,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1f832731-6e61-4749-92dc-4216bede0a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509217956-172.17.0.18-1597533572151:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-f28176fc-4654-4be0-8bc3-1921369f783d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-214ae117-643b-4b25-869d-05aec0c11870,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-d7e9a809-4836-42d8-ab4e-7117f76ecb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-f57414db-8d10-4b4e-bebd-6ed2bcc051e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-337d3eef-d200-4f8c-bfa1-55071310fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-7c5f32ac-9967-473a-98d2-936b2880d273,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-430492a3-25d2-4afb-b449-0cb1eddd7422,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-c96bded1-b655-4af0-9ecb-8fc6b65489d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509217956-172.17.0.18-1597533572151:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-f28176fc-4654-4be0-8bc3-1921369f783d,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-214ae117-643b-4b25-869d-05aec0c11870,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-d7e9a809-4836-42d8-ab4e-7117f76ecb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-f57414db-8d10-4b4e-bebd-6ed2bcc051e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-337d3eef-d200-4f8c-bfa1-55071310fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-7c5f32ac-9967-473a-98d2-936b2880d273,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-430492a3-25d2-4afb-b449-0cb1eddd7422,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-c96bded1-b655-4af0-9ecb-8fc6b65489d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340586961-172.17.0.18-1597534099093:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-5670dcdf-d8af-455b-a1eb-eb4753b29d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-3694f12c-d309-4320-891e-6a4eb1433d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-a20a51cd-0537-4352-adf2-dbb1a454849c,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-5282d4a8-a12e-4fb2-a9d8-f08df1751e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-db133bed-dbe8-485c-b064-be7d4116c002,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-a20068fc-ff37-4569-8188-a1078af13ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-13aafa62-b0f4-44b1-b0c7-bb1a41a615c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-4db71a41-49e3-4082-93ed-049bb5e0242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340586961-172.17.0.18-1597534099093:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-5670dcdf-d8af-455b-a1eb-eb4753b29d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-3694f12c-d309-4320-891e-6a4eb1433d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-a20a51cd-0537-4352-adf2-dbb1a454849c,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-5282d4a8-a12e-4fb2-a9d8-f08df1751e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-db133bed-dbe8-485c-b064-be7d4116c002,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-a20068fc-ff37-4569-8188-a1078af13ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-13aafa62-b0f4-44b1-b0c7-bb1a41a615c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-4db71a41-49e3-4082-93ed-049bb5e0242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271026050-172.17.0.18-1597534536485:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-b7aa899a-31ad-4a9c-9b31-6342fce1fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-18a2dbb5-4a9d-42b6-97cd-5ab2e757e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-9af71d7c-0e6e-4867-acda-363a76b46ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-405796b7-09f9-4c3b-bca4-f0d7c25cadd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-959e64a9-ad4c-4f9c-9906-23b58caf104e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-90ed3772-1c73-4da5-a0ef-809d6949e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-1d15386a-87ef-4f06-aa61-58e1b622f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-7c7187d6-dd40-4fb8-ae34-888a63a87010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271026050-172.17.0.18-1597534536485:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-b7aa899a-31ad-4a9c-9b31-6342fce1fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-18a2dbb5-4a9d-42b6-97cd-5ab2e757e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-9af71d7c-0e6e-4867-acda-363a76b46ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-405796b7-09f9-4c3b-bca4-f0d7c25cadd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-959e64a9-ad4c-4f9c-9906-23b58caf104e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-90ed3772-1c73-4da5-a0ef-809d6949e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-1d15386a-87ef-4f06-aa61-58e1b622f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-7c7187d6-dd40-4fb8-ae34-888a63a87010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986595616-172.17.0.18-1597534575798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-b3a69a87-2b1b-496b-88ea-db9bbbe14030,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f854aa92-0059-4b0a-a1ea-f2d01a3416d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-f768d596-d9e1-4ebd-8a76-8f88e02220aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-97667e70-34e8-43d8-9a70-556ff86279a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-72c18678-7030-4f28-b7bd-90335c9cf7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1e0b1c1f-0f53-49f4-99ed-cdf6bde130f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-4494e98c-3182-4857-9c45-c0bce6a467c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-f63c914e-74c7-48d3-81b1-6231a749be48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986595616-172.17.0.18-1597534575798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-b3a69a87-2b1b-496b-88ea-db9bbbe14030,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f854aa92-0059-4b0a-a1ea-f2d01a3416d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-f768d596-d9e1-4ebd-8a76-8f88e02220aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-97667e70-34e8-43d8-9a70-556ff86279a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-72c18678-7030-4f28-b7bd-90335c9cf7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1e0b1c1f-0f53-49f4-99ed-cdf6bde130f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-4494e98c-3182-4857-9c45-c0bce6a467c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-f63c914e-74c7-48d3-81b1-6231a749be48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897613740-172.17.0.18-1597534764260:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-29462764-a091-4e51-8b05-f2902a1dcf98,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-a0a333b3-134e-4486-909c-73768c32381a,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-1fa4c3a5-67ef-4feb-a429-7864fde8bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-d738900c-c320-4bcb-b5ee-b7a50473c753,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-dd0b6d2e-a233-4199-9e43-31d9579708b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-9652b993-81ab-408a-b501-1a52593c6768,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-78bd0004-e6f2-444a-8fae-04586827d806,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6bd61363-8ec1-4bc7-b80f-f1c337607d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897613740-172.17.0.18-1597534764260:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-29462764-a091-4e51-8b05-f2902a1dcf98,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-a0a333b3-134e-4486-909c-73768c32381a,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-1fa4c3a5-67ef-4feb-a429-7864fde8bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-d738900c-c320-4bcb-b5ee-b7a50473c753,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-dd0b6d2e-a233-4199-9e43-31d9579708b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-9652b993-81ab-408a-b501-1a52593c6768,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-78bd0004-e6f2-444a-8fae-04586827d806,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6bd61363-8ec1-4bc7-b80f-f1c337607d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601620751-172.17.0.18-1597535610202:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-d3148103-3bf1-4fe6-bba9-0ab6cd19bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-8add100c-46b3-4582-a1a4-8c7c0b40b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-9731c183-df47-4955-b391-d708d544c887,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-7782f3f2-c333-4d44-81af-50f7c9513d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-a76fd52c-9f13-4a59-98ad-0a9427b4db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-81a40617-0c69-4da6-9714-f5401d734708,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-bed512d3-f69c-4b98-8fdd-58235fb65011,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a1154c08-2540-416b-9710-ac05bd10a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601620751-172.17.0.18-1597535610202:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-d3148103-3bf1-4fe6-bba9-0ab6cd19bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-8add100c-46b3-4582-a1a4-8c7c0b40b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-9731c183-df47-4955-b391-d708d544c887,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-7782f3f2-c333-4d44-81af-50f7c9513d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-a76fd52c-9f13-4a59-98ad-0a9427b4db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-81a40617-0c69-4da6-9714-f5401d734708,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-bed512d3-f69c-4b98-8fdd-58235fb65011,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a1154c08-2540-416b-9710-ac05bd10a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365553394-172.17.0.18-1597536325141:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-19300047-6d59-4ba2-9c78-06962350fefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-397dbf35-fdff-446b-bb8e-1002a5d4ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-5618145f-30c8-4c3e-94e1-b9dc107abee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-51075566-b70f-48c6-8b3f-55cc3ae5a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-0b499f30-f032-483b-9159-b1fe9414489f,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-670c77ec-ee0e-4ded-a331-0be171095c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-1fe40fec-7d4e-485f-8ea7-25b55aafa3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-1e9b05d5-c364-4bc7-b27e-2089e005e04d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365553394-172.17.0.18-1597536325141:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-19300047-6d59-4ba2-9c78-06962350fefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-397dbf35-fdff-446b-bb8e-1002a5d4ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-5618145f-30c8-4c3e-94e1-b9dc107abee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-51075566-b70f-48c6-8b3f-55cc3ae5a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-0b499f30-f032-483b-9159-b1fe9414489f,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-670c77ec-ee0e-4ded-a331-0be171095c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-1fe40fec-7d4e-485f-8ea7-25b55aafa3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-1e9b05d5-c364-4bc7-b27e-2089e005e04d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459291835-172.17.0.18-1597537182839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-ba3fc8a3-f0a0-412f-9ec4-7c112eb70237,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-a48dd85c-599b-4233-836f-0fea6bba559a,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-72115030-d6c6-4022-b799-49c694cf23f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-d43db4bd-4275-4cd0-9f52-262dc1d7eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-54f9f4ba-050a-48b6-be06-a819ec4f2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-eb08f384-1cc9-4107-9d94-c449252b2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-24292de2-2e82-4bf9-9fc5-3e0b95e78d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-20362f14-9d70-40e8-a000-ea5e3b5a31e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459291835-172.17.0.18-1597537182839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-ba3fc8a3-f0a0-412f-9ec4-7c112eb70237,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-a48dd85c-599b-4233-836f-0fea6bba559a,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-72115030-d6c6-4022-b799-49c694cf23f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-d43db4bd-4275-4cd0-9f52-262dc1d7eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-54f9f4ba-050a-48b6-be06-a819ec4f2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-eb08f384-1cc9-4107-9d94-c449252b2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-24292de2-2e82-4bf9-9fc5-3e0b95e78d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-20362f14-9d70-40e8-a000-ea5e3b5a31e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137836625-172.17.0.18-1597537417597:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-a295199f-7389-4bc9-b98f-42920f10aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-9d75f64e-29d1-4686-b5ee-1a32cbeab80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-fca597fe-0905-477e-a74f-c07b4e662f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-2c0de3f0-71f7-41eb-b905-c51d7d512617,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-b3aabb3e-e0d8-48ff-907c-cbf1551ae29a,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-ac1620de-652e-48fb-9fd9-11c5718bee52,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-b7a1ea5f-bf21-4931-910d-29291ed2c524,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-ab33b588-1b08-45be-be9c-1804a878ebf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137836625-172.17.0.18-1597537417597:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-a295199f-7389-4bc9-b98f-42920f10aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-9d75f64e-29d1-4686-b5ee-1a32cbeab80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-fca597fe-0905-477e-a74f-c07b4e662f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-2c0de3f0-71f7-41eb-b905-c51d7d512617,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-b3aabb3e-e0d8-48ff-907c-cbf1551ae29a,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-ac1620de-652e-48fb-9fd9-11c5718bee52,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-b7a1ea5f-bf21-4931-910d-29291ed2c524,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-ab33b588-1b08-45be-be9c-1804a878ebf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957607011-172.17.0.18-1597537742564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-e309db7f-63d3-4450-803d-37d2cf7691cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1a413b5b-c81a-4b34-a127-14af516a70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-251f12ff-afed-4244-bb39-33aac102f977,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-77b5a8ab-1b77-46b0-981e-17430e76ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-a9c08cac-db61-4256-81ce-f0d8fd560f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8b743a85-07e0-4e6c-9019-9394aaa91ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-dace5062-3040-4eb8-9d61-fdd1432e381b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-141ce4c6-ec79-43fc-81a1-c15176ccd810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957607011-172.17.0.18-1597537742564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-e309db7f-63d3-4450-803d-37d2cf7691cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1a413b5b-c81a-4b34-a127-14af516a70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-251f12ff-afed-4244-bb39-33aac102f977,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-77b5a8ab-1b77-46b0-981e-17430e76ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-a9c08cac-db61-4256-81ce-f0d8fd560f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8b743a85-07e0-4e6c-9019-9394aaa91ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-dace5062-3040-4eb8-9d61-fdd1432e381b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-141ce4c6-ec79-43fc-81a1-c15176ccd810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246621152-172.17.0.18-1597538543216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39897,DS-7851579e-08c2-469d-8efb-dd87561debbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1cccb6ca-5c45-4e19-ab7d-78dc10f8f452,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-1d485495-486e-4215-ba25-405c096ebcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-908def60-827b-4177-b512-9710c274be64,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-305e7b7e-d84f-4927-9276-bcbd9d6b36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-e8c17895-3e04-4740-bf42-51064020f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-abf35c2a-c2c7-4a98-ae36-2fba1e3ba69d,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-feb86b9a-d79b-43e1-a99b-29b7a0f8814b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246621152-172.17.0.18-1597538543216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39897,DS-7851579e-08c2-469d-8efb-dd87561debbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1cccb6ca-5c45-4e19-ab7d-78dc10f8f452,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-1d485495-486e-4215-ba25-405c096ebcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-908def60-827b-4177-b512-9710c274be64,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-305e7b7e-d84f-4927-9276-bcbd9d6b36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-e8c17895-3e04-4740-bf42-51064020f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-abf35c2a-c2c7-4a98-ae36-2fba1e3ba69d,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-feb86b9a-d79b-43e1-a99b-29b7a0f8814b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849771494-172.17.0.18-1597539248021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-825a0d2a-afac-4e96-85da-fe5d1855952b,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-df43316b-109c-4f21-a0ce-a6fe85912af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-98c127b7-9cc2-4532-9dca-e95d44c7a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-04885540-dcb5-4211-91b1-7e73801487fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-36e08f69-b693-439f-8c88-cf873f82e983,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-e002688b-273c-4b8d-b3e1-c8203fa24517,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-93eb6217-e2fd-4863-83ae-5a13506bc939,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-b589bc89-3736-4996-a620-806d45b5ac0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849771494-172.17.0.18-1597539248021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-825a0d2a-afac-4e96-85da-fe5d1855952b,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-df43316b-109c-4f21-a0ce-a6fe85912af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-98c127b7-9cc2-4532-9dca-e95d44c7a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-04885540-dcb5-4211-91b1-7e73801487fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-36e08f69-b693-439f-8c88-cf873f82e983,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-e002688b-273c-4b8d-b3e1-c8203fa24517,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-93eb6217-e2fd-4863-83ae-5a13506bc939,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-b589bc89-3736-4996-a620-806d45b5ac0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461533010-172.17.0.18-1597539341057:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-bd5ddef3-6270-4ba7-9755-26e4f455d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-dc2640f4-9011-4b21-a681-0302b2235715,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b185d40c-eeb0-497f-a6b4-5cf3254a031e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-ba22b7d3-30e8-469e-885d-c824d98c534c,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-5eb96859-0bc7-419d-a368-b6484ec01f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-8b55fc37-e015-4a34-b34e-68c23afdd6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-38ac204f-861a-412f-961d-a1db45e5fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-58bbb353-d2f8-4fe5-b0d5-f664ebd55936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461533010-172.17.0.18-1597539341057:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-bd5ddef3-6270-4ba7-9755-26e4f455d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-dc2640f4-9011-4b21-a681-0302b2235715,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b185d40c-eeb0-497f-a6b4-5cf3254a031e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-ba22b7d3-30e8-469e-885d-c824d98c534c,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-5eb96859-0bc7-419d-a368-b6484ec01f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-8b55fc37-e015-4a34-b34e-68c23afdd6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-38ac204f-861a-412f-961d-a1db45e5fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-58bbb353-d2f8-4fe5-b0d5-f664ebd55936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198818476-172.17.0.18-1597539443204:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-e213d68a-63e3-403a-88c3-8ca4fb7f3054,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-add2f02a-e3b8-4d34-8ba4-b45416fdd3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-822160c5-e7d9-4fda-873a-ed777acfe7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-f3f4309f-0dd6-4dc0-b681-ac3e1f9fb374,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-da873e07-1941-457e-ade3-59ed6a2dc302,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-e837e8d0-f04d-4495-80b8-ace2f63aa35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-6da44a46-2b81-4c7c-a42d-9d8f90e115a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-94e59d6a-6f28-435e-8d6c-82beb8e48f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198818476-172.17.0.18-1597539443204:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-e213d68a-63e3-403a-88c3-8ca4fb7f3054,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-add2f02a-e3b8-4d34-8ba4-b45416fdd3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-822160c5-e7d9-4fda-873a-ed777acfe7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-f3f4309f-0dd6-4dc0-b681-ac3e1f9fb374,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-da873e07-1941-457e-ade3-59ed6a2dc302,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-e837e8d0-f04d-4495-80b8-ace2f63aa35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-6da44a46-2b81-4c7c-a42d-9d8f90e115a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-94e59d6a-6f28-435e-8d6c-82beb8e48f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542204664-172.17.0.18-1597539527917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-a0e046c7-bf6c-4db9-93c2-c29673cbb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-e0235150-2919-449f-88d2-b0b6fa28413e,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-151fc531-e1e3-4790-9a16-aba66771af14,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-709688c9-593c-4383-9186-2c08f569f852,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-95c86e79-639a-4d19-9313-79753bc0fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-c1129ac0-2694-41a3-b260-a4ce452d9790,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-600ca35a-ff15-4688-ae2c-ecfacc01e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-958ff5b3-d8ed-48dd-a760-a1459739a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542204664-172.17.0.18-1597539527917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-a0e046c7-bf6c-4db9-93c2-c29673cbb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-e0235150-2919-449f-88d2-b0b6fa28413e,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-151fc531-e1e3-4790-9a16-aba66771af14,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-709688c9-593c-4383-9186-2c08f569f852,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-95c86e79-639a-4d19-9313-79753bc0fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-c1129ac0-2694-41a3-b260-a4ce452d9790,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-600ca35a-ff15-4688-ae2c-ecfacc01e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-958ff5b3-d8ed-48dd-a760-a1459739a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223962254-172.17.0.18-1597539759477:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-b2d106b7-0178-4101-b88b-b546b51ae7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-77214e25-cd4f-487e-9a17-ecf62d56ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-227b6c72-573a-4b84-8eb0-4303b0b3796a,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-489fe476-2176-4440-9ef4-fdda3489b327,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-e661a28f-73a7-4cda-a570-fe8fa9c77c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-30ca2b27-72d3-4bc2-991e-c3c8a394fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-0ff31c29-1d0a-4ace-a324-85b465c4cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-cd108f67-611c-498d-8c51-93c71ae34b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223962254-172.17.0.18-1597539759477:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-b2d106b7-0178-4101-b88b-b546b51ae7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-77214e25-cd4f-487e-9a17-ecf62d56ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-227b6c72-573a-4b84-8eb0-4303b0b3796a,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-489fe476-2176-4440-9ef4-fdda3489b327,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-e661a28f-73a7-4cda-a570-fe8fa9c77c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-30ca2b27-72d3-4bc2-991e-c3c8a394fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-0ff31c29-1d0a-4ace-a324-85b465c4cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-cd108f67-611c-498d-8c51-93c71ae34b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914516477-172.17.0.18-1597539902291:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-0bd52e5d-5857-4f03-b4c8-5cfa2022f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-3d1e7f6d-fc00-4cfd-9b7c-f3d033eac146,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-82871dd7-3b3f-42bd-ad04-7b4b5946e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-bb7e34ae-07a6-4556-891b-8a065009b589,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-a991e003-939e-4787-ac24-6936866fa93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5f1d9d84-fadd-4a41-9148-bffb930f72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-4842b729-c533-49ed-b0a6-a0e6d8f5c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-b586de9d-f534-46ce-a768-fc53951f4154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914516477-172.17.0.18-1597539902291:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-0bd52e5d-5857-4f03-b4c8-5cfa2022f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-3d1e7f6d-fc00-4cfd-9b7c-f3d033eac146,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-82871dd7-3b3f-42bd-ad04-7b4b5946e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-bb7e34ae-07a6-4556-891b-8a065009b589,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-a991e003-939e-4787-ac24-6936866fa93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5f1d9d84-fadd-4a41-9148-bffb930f72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-4842b729-c533-49ed-b0a6-a0e6d8f5c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-b586de9d-f534-46ce-a768-fc53951f4154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6845
