reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902912370-172.17.0.5-1597489568215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-0b502649-cb0e-4108-b104-01a5b3c50c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-0395ec29-49ec-4333-b664-ab7276ac3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-249f89e5-d632-4a15-bccf-4f22b075685b,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-c6504f9e-07a7-4211-b133-d37486b62ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-cd865679-1549-4d31-890b-6ee4923bb5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-2969e9c1-1251-496b-a2cc-ab0d7d508ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-3d53d11b-d813-4527-bd17-85d37b052796,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-4226714d-e998-435c-81e5-52357b1316d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902912370-172.17.0.5-1597489568215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-0b502649-cb0e-4108-b104-01a5b3c50c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-0395ec29-49ec-4333-b664-ab7276ac3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-249f89e5-d632-4a15-bccf-4f22b075685b,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-c6504f9e-07a7-4211-b133-d37486b62ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-cd865679-1549-4d31-890b-6ee4923bb5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-2969e9c1-1251-496b-a2cc-ab0d7d508ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-3d53d11b-d813-4527-bd17-85d37b052796,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-4226714d-e998-435c-81e5-52357b1316d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910368478-172.17.0.5-1597489599665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-5cfaf000-3dc5-4d0a-a048-7e95a8f6c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-559ad1cc-4881-483f-a082-78bfd9d67106,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-f350b449-e044-49ab-8a41-06bfadf28f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-bd9ffcd4-11dc-4699-aa16-cbd1d0f07e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-4b293920-4950-4b58-9df3-ad80b97bca18,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f088a4b7-d5f6-4a0f-a940-b48d49a9e937,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-63946f18-1b91-452e-aa5f-506ea6fa0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-c3657ac1-aba3-41c2-9cf5-62131718bc84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910368478-172.17.0.5-1597489599665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-5cfaf000-3dc5-4d0a-a048-7e95a8f6c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-559ad1cc-4881-483f-a082-78bfd9d67106,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-f350b449-e044-49ab-8a41-06bfadf28f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-bd9ffcd4-11dc-4699-aa16-cbd1d0f07e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-4b293920-4950-4b58-9df3-ad80b97bca18,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f088a4b7-d5f6-4a0f-a940-b48d49a9e937,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-63946f18-1b91-452e-aa5f-506ea6fa0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-c3657ac1-aba3-41c2-9cf5-62131718bc84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103090762-172.17.0.5-1597490021946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-ba8fd5ee-e107-4812-a9a5-e7cb61331935,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-7336c04c-7f3a-4264-9b62-4a3b60e0fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-e3d53f78-950b-439f-b4f3-f2480d02d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0b08b5c4-d50e-469f-be62-db380530ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-2be8d1b4-db16-420b-aff6-9e9be2413fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-76a932f7-5082-4b86-8ac2-b400a9933b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-3a950c61-c264-44dd-87a3-4a6178fc197b,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-521c3c47-f5ec-4516-885f-e4fb8b863a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103090762-172.17.0.5-1597490021946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-ba8fd5ee-e107-4812-a9a5-e7cb61331935,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-7336c04c-7f3a-4264-9b62-4a3b60e0fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-e3d53f78-950b-439f-b4f3-f2480d02d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0b08b5c4-d50e-469f-be62-db380530ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-2be8d1b4-db16-420b-aff6-9e9be2413fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-76a932f7-5082-4b86-8ac2-b400a9933b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-3a950c61-c264-44dd-87a3-4a6178fc197b,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-521c3c47-f5ec-4516-885f-e4fb8b863a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763686848-172.17.0.5-1597490134425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-a82ec84b-dbd8-445e-aa42-27f4c8c34729,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-fe616e79-eb68-4973-9b06-39623df6f562,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-86c96724-c832-4b6b-8d5d-bd560acfb471,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-32a6ce04-00ce-4742-b1bd-5fa2c1c9aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f943ead2-3004-4724-9db3-37732ffaeddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-fc0bc7d1-b989-4b6c-90b6-81ba8f8cbf65,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-f3e847c7-d482-41cf-921c-ed6480711fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-4c7c2e9c-7319-4be1-98d1-09c9d73135e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763686848-172.17.0.5-1597490134425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-a82ec84b-dbd8-445e-aa42-27f4c8c34729,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-fe616e79-eb68-4973-9b06-39623df6f562,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-86c96724-c832-4b6b-8d5d-bd560acfb471,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-32a6ce04-00ce-4742-b1bd-5fa2c1c9aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f943ead2-3004-4724-9db3-37732ffaeddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-fc0bc7d1-b989-4b6c-90b6-81ba8f8cbf65,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-f3e847c7-d482-41cf-921c-ed6480711fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-4c7c2e9c-7319-4be1-98d1-09c9d73135e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920520831-172.17.0.5-1597490796299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45341,DS-5bf32414-7a5a-444b-a08a-1f646fd3fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-fad19d26-de82-4bf6-9739-69724915beec,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9869d435-aac8-481e-8e88-51837fef35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-10ef3e15-c0f0-4bd9-95ad-07dae3cad2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-4275a5a9-2395-443e-85b8-a587ad9ede34,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-71f73525-61b9-4c60-b072-a9516f08b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-97dc5e38-e3f6-42a2-944b-dacc3b274102,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-33759bf8-1309-4878-977c-87eeed57f47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920520831-172.17.0.5-1597490796299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45341,DS-5bf32414-7a5a-444b-a08a-1f646fd3fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-fad19d26-de82-4bf6-9739-69724915beec,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9869d435-aac8-481e-8e88-51837fef35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-10ef3e15-c0f0-4bd9-95ad-07dae3cad2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-4275a5a9-2395-443e-85b8-a587ad9ede34,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-71f73525-61b9-4c60-b072-a9516f08b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-97dc5e38-e3f6-42a2-944b-dacc3b274102,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-33759bf8-1309-4878-977c-87eeed57f47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361198684-172.17.0.5-1597491398626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-b1bd432b-0204-4a6b-810b-89b76497c779,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-a1d15c6c-4a6f-4395-bdd2-7d6ccd0e5385,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-bf53a447-4f9a-4af9-a389-c00f8d8ab554,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-3dedac23-4474-4d29-9463-b6b68e4dd6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-a7a6f6e7-997d-4624-95ba-c1b0c20aa411,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ca381a69-120f-4b01-b88c-8d15ddcd75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-0944ca86-3a09-486e-a4ac-7f1021baf95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-aa2fdf09-7e8b-422b-9150-26e0a2d9eb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361198684-172.17.0.5-1597491398626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-b1bd432b-0204-4a6b-810b-89b76497c779,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-a1d15c6c-4a6f-4395-bdd2-7d6ccd0e5385,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-bf53a447-4f9a-4af9-a389-c00f8d8ab554,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-3dedac23-4474-4d29-9463-b6b68e4dd6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-a7a6f6e7-997d-4624-95ba-c1b0c20aa411,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ca381a69-120f-4b01-b88c-8d15ddcd75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-0944ca86-3a09-486e-a4ac-7f1021baf95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-aa2fdf09-7e8b-422b-9150-26e0a2d9eb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823209971-172.17.0.5-1597491703251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37062,DS-1858b222-d380-43ff-ad64-3af12f85e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-3cb35b43-d033-4cfa-b942-35831200cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-4cf101a9-6f32-4ee4-a9bc-5d3637dab60e,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-049ace10-c45e-4ed0-a1c1-3a4e3b851440,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c641a493-ecc9-4eb9-a916-add6d98994e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-2264783d-c668-4e82-823c-c104dc1c81ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-eda9fda0-6786-4ab8-bb7b-d8e0d503adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-9f5795b2-9d18-4c57-9659-d6674de1206f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823209971-172.17.0.5-1597491703251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37062,DS-1858b222-d380-43ff-ad64-3af12f85e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-3cb35b43-d033-4cfa-b942-35831200cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-4cf101a9-6f32-4ee4-a9bc-5d3637dab60e,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-049ace10-c45e-4ed0-a1c1-3a4e3b851440,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c641a493-ecc9-4eb9-a916-add6d98994e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-2264783d-c668-4e82-823c-c104dc1c81ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-eda9fda0-6786-4ab8-bb7b-d8e0d503adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-9f5795b2-9d18-4c57-9659-d6674de1206f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4825429-172.17.0.5-1597492067896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45330,DS-24259c98-cdde-44e9-ac2a-08e5391b57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c22d8dd3-29ff-4519-a57d-0a4a753e8589,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-bfd05d4e-3708-448f-949a-1076c70e4767,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-6f569cc5-967e-4ede-a1c8-560027c6720f,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-d5e221f2-c84d-4a54-a7f5-bb7e5334d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-2fb67b31-95e3-411a-a8f9-30ff82e14cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-9b06b188-700f-4cb4-aebf-d7017af53916,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-55996391-7840-4851-9da5-175ba2b689ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4825429-172.17.0.5-1597492067896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45330,DS-24259c98-cdde-44e9-ac2a-08e5391b57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c22d8dd3-29ff-4519-a57d-0a4a753e8589,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-bfd05d4e-3708-448f-949a-1076c70e4767,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-6f569cc5-967e-4ede-a1c8-560027c6720f,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-d5e221f2-c84d-4a54-a7f5-bb7e5334d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-2fb67b31-95e3-411a-a8f9-30ff82e14cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-9b06b188-700f-4cb4-aebf-d7017af53916,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-55996391-7840-4851-9da5-175ba2b689ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840093482-172.17.0.5-1597492228755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-e4a2b6ed-18de-4ea6-85ce-fda477d158f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-532237ab-1a01-48a4-8969-d3c117a20b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-87be8bbe-c72f-4d8c-82c6-cdefa1e7bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-01807e06-e3e7-4405-b078-a605eb07f196,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-71faf096-c94c-40eb-9e82-9f739c56f5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-b1e9b125-245b-4006-9f7c-c4b1f7398f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-97ddeaee-c7a6-465e-91cb-451646eaa03c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-0860d8d4-3460-46bb-b6d3-60dc63ba4cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840093482-172.17.0.5-1597492228755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-e4a2b6ed-18de-4ea6-85ce-fda477d158f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-532237ab-1a01-48a4-8969-d3c117a20b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-87be8bbe-c72f-4d8c-82c6-cdefa1e7bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-01807e06-e3e7-4405-b078-a605eb07f196,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-71faf096-c94c-40eb-9e82-9f739c56f5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-b1e9b125-245b-4006-9f7c-c4b1f7398f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-97ddeaee-c7a6-465e-91cb-451646eaa03c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-0860d8d4-3460-46bb-b6d3-60dc63ba4cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11904862-172.17.0.5-1597492503688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-8b88578d-4acf-41ba-8b80-81355fd6fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-59a039fc-f01c-44bf-9869-2afe69e92387,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-93bc0084-bf5c-497e-b685-0a6f4e96ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-a22b4697-d68c-46d9-a1cb-1ee88deca861,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-4eed2e10-932f-43df-9e72-13c181df362b,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-6ad400c6-fdf8-4ff7-871c-695a977f3e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-04caed7a-72bc-4508-a306-2a3dafbe5347,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-ea200a37-8df3-4f6b-8699-a3810ed476c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11904862-172.17.0.5-1597492503688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-8b88578d-4acf-41ba-8b80-81355fd6fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-59a039fc-f01c-44bf-9869-2afe69e92387,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-93bc0084-bf5c-497e-b685-0a6f4e96ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-a22b4697-d68c-46d9-a1cb-1ee88deca861,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-4eed2e10-932f-43df-9e72-13c181df362b,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-6ad400c6-fdf8-4ff7-871c-695a977f3e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-04caed7a-72bc-4508-a306-2a3dafbe5347,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-ea200a37-8df3-4f6b-8699-a3810ed476c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770538226-172.17.0.5-1597492654820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-46b1a21c-b65c-4f26-bb7c-2294cc87c527,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-1b227d9e-e180-4b6e-bbc2-75f5ce7cbe43,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-9bc2ad64-be33-4890-afb3-4f55d5f5d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-eb2666bb-40a8-4111-bb88-d211c7de1b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-34a14918-e290-4f5f-b546-55b355bacd63,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7b6aecea-6d2a-4110-918f-209b14d7c221,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-04fccd4b-ef8f-46e7-94cc-727100f82b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-ceba1337-f41b-4f51-a6dd-009f67b1ed45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770538226-172.17.0.5-1597492654820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-46b1a21c-b65c-4f26-bb7c-2294cc87c527,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-1b227d9e-e180-4b6e-bbc2-75f5ce7cbe43,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-9bc2ad64-be33-4890-afb3-4f55d5f5d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-eb2666bb-40a8-4111-bb88-d211c7de1b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-34a14918-e290-4f5f-b546-55b355bacd63,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7b6aecea-6d2a-4110-918f-209b14d7c221,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-04fccd4b-ef8f-46e7-94cc-727100f82b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-ceba1337-f41b-4f51-a6dd-009f67b1ed45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384757832-172.17.0.5-1597492957369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-db32d4fe-c33b-4ec2-b165-fffb7b83fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-3f61960b-674f-4d5c-a548-62ece001fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-470298e3-7243-416d-a669-76d4aa9cb25c,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-d72cd45d-76e0-43cf-ae0a-8b0a1781c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-5f90c121-e606-43ee-b91c-93efd007f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-a440b3f2-e971-4862-a34a-e0ed08f99c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-01d5bfd3-7215-4a5f-999c-905ba2deca29,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-24e6a3bf-b7b4-42cf-8ad9-d1cfef27a653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384757832-172.17.0.5-1597492957369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-db32d4fe-c33b-4ec2-b165-fffb7b83fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-3f61960b-674f-4d5c-a548-62ece001fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-470298e3-7243-416d-a669-76d4aa9cb25c,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-d72cd45d-76e0-43cf-ae0a-8b0a1781c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-5f90c121-e606-43ee-b91c-93efd007f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-a440b3f2-e971-4862-a34a-e0ed08f99c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-01d5bfd3-7215-4a5f-999c-905ba2deca29,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-24e6a3bf-b7b4-42cf-8ad9-d1cfef27a653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452390259-172.17.0.5-1597493081606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-969df3c8-fddd-4866-93d9-9f0e14146e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-192e8af0-f9f6-47e3-8686-df632fd64c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-93486a0f-e4a3-4d24-a247-1bca2d865d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-52a0cae2-30ed-49b0-a156-7f4accd158aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-59257cd5-6b3d-4407-8bd6-beb0f761b624,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-b96ccc9a-419c-4dd9-b8b1-c79570d0af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-8b8cb874-a0cd-46df-824b-db0981e0fe22,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-43a106d0-01ee-471b-bef8-458b3d08417a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452390259-172.17.0.5-1597493081606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-969df3c8-fddd-4866-93d9-9f0e14146e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-192e8af0-f9f6-47e3-8686-df632fd64c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-93486a0f-e4a3-4d24-a247-1bca2d865d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-52a0cae2-30ed-49b0-a156-7f4accd158aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-59257cd5-6b3d-4407-8bd6-beb0f761b624,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-b96ccc9a-419c-4dd9-b8b1-c79570d0af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-8b8cb874-a0cd-46df-824b-db0981e0fe22,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-43a106d0-01ee-471b-bef8-458b3d08417a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9882023-172.17.0.5-1597493190922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-50370572-ecfa-4545-a54a-f26a7934aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-d2d79388-82ff-4517-9a83-31c11efd1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-b14c156d-3fd6-48ee-bb52-1ac678c7eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-52f34d4c-9e92-473f-a31a-ae997c6a7315,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9ab4f43e-5dad-44b1-8a29-fbc2545b0e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c6e5a1bd-60fc-4a3b-a8f0-54c87738dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-a62700aa-0570-495b-981d-453a367ad045,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-afba531a-da98-43ae-892f-48f6b410ec2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9882023-172.17.0.5-1597493190922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-50370572-ecfa-4545-a54a-f26a7934aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-d2d79388-82ff-4517-9a83-31c11efd1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-b14c156d-3fd6-48ee-bb52-1ac678c7eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-52f34d4c-9e92-473f-a31a-ae997c6a7315,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9ab4f43e-5dad-44b1-8a29-fbc2545b0e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c6e5a1bd-60fc-4a3b-a8f0-54c87738dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-a62700aa-0570-495b-981d-453a367ad045,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-afba531a-da98-43ae-892f-48f6b410ec2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213020513-172.17.0.5-1597494085209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-763b3ecb-91ee-41ae-97c2-76d150a11ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-1bd29797-c55e-487c-93d3-d75bb3a70630,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-c4b0c96d-47e2-4f1c-9dda-eafa64be1afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-c532d26c-2509-4279-ab68-1798fbc05d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-751d3d9f-1e21-4d14-93b2-e44a722631f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-03edb24a-c948-4aad-a941-aff1e64f8834,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-c0df40ac-8b0d-4ded-8a6f-ac8df32b751b,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-eab3d1d3-7578-4b36-83b9-502011985c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213020513-172.17.0.5-1597494085209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-763b3ecb-91ee-41ae-97c2-76d150a11ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-1bd29797-c55e-487c-93d3-d75bb3a70630,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-c4b0c96d-47e2-4f1c-9dda-eafa64be1afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-c532d26c-2509-4279-ab68-1798fbc05d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-751d3d9f-1e21-4d14-93b2-e44a722631f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-03edb24a-c948-4aad-a941-aff1e64f8834,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-c0df40ac-8b0d-4ded-8a6f-ac8df32b751b,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-eab3d1d3-7578-4b36-83b9-502011985c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815690031-172.17.0.5-1597494126410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-7d26e03a-2e23-482c-877b-5046b1dfb300,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-b861201e-9ad7-4d72-a3d4-e6f8261c08b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-7ef8afa6-1d1c-40a9-9392-7988ba1398b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-d6c4ff2a-9658-4310-a3f8-11f8686acaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-e861960f-6546-478e-89d0-157743189bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-73786252-3407-4317-b543-06a6c1ddedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-dea1d441-0fcb-4892-8458-f7843826bf12,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-002df4d1-3acb-41c1-b0d8-f28cc70db508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815690031-172.17.0.5-1597494126410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-7d26e03a-2e23-482c-877b-5046b1dfb300,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-b861201e-9ad7-4d72-a3d4-e6f8261c08b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-7ef8afa6-1d1c-40a9-9392-7988ba1398b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-d6c4ff2a-9658-4310-a3f8-11f8686acaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-e861960f-6546-478e-89d0-157743189bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-73786252-3407-4317-b543-06a6c1ddedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-dea1d441-0fcb-4892-8458-f7843826bf12,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-002df4d1-3acb-41c1-b0d8-f28cc70db508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619192470-172.17.0.5-1597494312092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-da8f4e06-3143-4671-8525-7e22e348e484,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-5b243589-3985-4d3d-ae07-5abced805f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-89793432-85bf-47a2-95db-91d40edfe141,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-cd75bf12-7192-4021-90fa-3d97619a34e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-2c7eb270-a491-441d-a994-b079eff1791b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-a15882bd-187e-4418-bde1-78cdae3e9bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-fe282d49-264e-4c0a-8a58-adcca2c03f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-651b44e8-020b-4e58-8fb2-a234a4496e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619192470-172.17.0.5-1597494312092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-da8f4e06-3143-4671-8525-7e22e348e484,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-5b243589-3985-4d3d-ae07-5abced805f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-89793432-85bf-47a2-95db-91d40edfe141,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-cd75bf12-7192-4021-90fa-3d97619a34e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-2c7eb270-a491-441d-a994-b079eff1791b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-a15882bd-187e-4418-bde1-78cdae3e9bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-fe282d49-264e-4c0a-8a58-adcca2c03f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-651b44e8-020b-4e58-8fb2-a234a4496e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282370862-172.17.0.5-1597494576472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-1f1597ee-99bc-47a3-babf-87a3adb0ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-fb1cd638-9577-4382-b941-ef216acc7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-7abfd450-6e06-4eac-bb7a-f2725239e535,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e228b3b2-5d61-4863-b66e-641b4cf4453b,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1ed60360-c3a7-46e2-a323-5abcc0d2826d,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-08a61763-bd11-415e-a1dc-83b904fbb5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-734fbed1-7130-45ab-a5db-6ae7371e5b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-054455bb-6b9a-46ef-8a00-9b6ca0359eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282370862-172.17.0.5-1597494576472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-1f1597ee-99bc-47a3-babf-87a3adb0ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-fb1cd638-9577-4382-b941-ef216acc7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-7abfd450-6e06-4eac-bb7a-f2725239e535,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e228b3b2-5d61-4863-b66e-641b4cf4453b,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1ed60360-c3a7-46e2-a323-5abcc0d2826d,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-08a61763-bd11-415e-a1dc-83b904fbb5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-734fbed1-7130-45ab-a5db-6ae7371e5b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-054455bb-6b9a-46ef-8a00-9b6ca0359eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662947356-172.17.0.5-1597494646363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-90b25894-8470-4633-ba1a-3d7d931ca228,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9965517d-76d5-4965-8a9b-aea61ef85bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-b4993c78-0984-4baf-a3b7-13798b1853d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-ad70bfcc-c442-403b-851a-1526ba2d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-990ad1ce-0174-4118-a32c-0d72ba3a6639,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1e2d9f42-0230-493c-9b2e-b67b00441c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-bc0474a0-1b4d-4bfd-9de6-951125870e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-e001f284-156a-49b1-8a4a-9627094e6450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662947356-172.17.0.5-1597494646363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-90b25894-8470-4633-ba1a-3d7d931ca228,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9965517d-76d5-4965-8a9b-aea61ef85bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-b4993c78-0984-4baf-a3b7-13798b1853d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-ad70bfcc-c442-403b-851a-1526ba2d05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-990ad1ce-0174-4118-a32c-0d72ba3a6639,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1e2d9f42-0230-493c-9b2e-b67b00441c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-bc0474a0-1b4d-4bfd-9de6-951125870e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-e001f284-156a-49b1-8a4a-9627094e6450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5684
