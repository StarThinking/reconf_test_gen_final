reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951720186-172.17.0.12-1597535150669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-9eba9324-8b55-4f06-9b16-b3b47efacd89,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-dbb9b66c-1c2d-4ded-b558-41d87995c28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b474960d-7745-4ced-a64d-2efc58945e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-349aa4bd-a70d-4f2b-94fe-7c8dc6437ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-687a127f-ea7d-41dc-b9ee-e88e59f82c62,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-2710a0b5-8e07-492a-941a-b8bcdb2443d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-8f04604f-0f5f-4843-8f64-c7fa5efd58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-4466bc42-2e38-4ca4-9728-8870be4bb70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951720186-172.17.0.12-1597535150669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-9eba9324-8b55-4f06-9b16-b3b47efacd89,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-dbb9b66c-1c2d-4ded-b558-41d87995c28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b474960d-7745-4ced-a64d-2efc58945e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-349aa4bd-a70d-4f2b-94fe-7c8dc6437ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-687a127f-ea7d-41dc-b9ee-e88e59f82c62,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-2710a0b5-8e07-492a-941a-b8bcdb2443d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-8f04604f-0f5f-4843-8f64-c7fa5efd58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-4466bc42-2e38-4ca4-9728-8870be4bb70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493611351-172.17.0.12-1597535263465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36038,DS-eb49b380-6a28-4e26-bbf2-c6ebb947df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-0b5d6b09-3a76-4406-8345-a8f6602ecd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-1b8c036b-354c-4c0a-9767-0f964d7c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-003d6a93-7926-4be6-ae1c-4705346e5a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d2282a2e-a30a-446c-9dfb-b350a176c348,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-7f349a46-aec2-4d8c-ae48-b2b3ef6141b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-0fe112d7-6de0-45ab-b656-c1c7e572a295,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-a470e83e-51c2-4c4f-8b8a-e1ca2b401579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493611351-172.17.0.12-1597535263465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36038,DS-eb49b380-6a28-4e26-bbf2-c6ebb947df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-0b5d6b09-3a76-4406-8345-a8f6602ecd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-1b8c036b-354c-4c0a-9767-0f964d7c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-003d6a93-7926-4be6-ae1c-4705346e5a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d2282a2e-a30a-446c-9dfb-b350a176c348,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-7f349a46-aec2-4d8c-ae48-b2b3ef6141b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-0fe112d7-6de0-45ab-b656-c1c7e572a295,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-a470e83e-51c2-4c4f-8b8a-e1ca2b401579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754958414-172.17.0.12-1597535303051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-8a5e7687-1dd1-4f73-b10b-185a26e454eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-90c2a4df-9a28-4c52-98bb-003e2e7d8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-c5c7b848-14b2-4bb8-a5f3-db8ed663c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-230b4953-1a0e-4355-99c0-b2182190cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-a9eb3c1e-42a1-49b6-9fe1-a01308d6951e,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-61105373-a3d5-4f8e-8387-17785758a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-d84cf210-2071-4e78-b349-dc3e93dfbe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f453c607-cbb3-4f43-a8c4-48477b90c645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754958414-172.17.0.12-1597535303051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-8a5e7687-1dd1-4f73-b10b-185a26e454eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-90c2a4df-9a28-4c52-98bb-003e2e7d8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-c5c7b848-14b2-4bb8-a5f3-db8ed663c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-230b4953-1a0e-4355-99c0-b2182190cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-a9eb3c1e-42a1-49b6-9fe1-a01308d6951e,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-61105373-a3d5-4f8e-8387-17785758a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-d84cf210-2071-4e78-b349-dc3e93dfbe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f453c607-cbb3-4f43-a8c4-48477b90c645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168878489-172.17.0.12-1597535345793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-8382a432-3e48-40a0-93a8-d162e02d0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-d07df0fe-a48a-46ba-a240-0484a8759e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-d946117b-8c60-4f34-9f35-32e3a8587d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d19ed184-0263-451a-8ecf-9ba97d801fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-49302c33-7c3a-4e40-a8e5-e0edf03ddd27,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-b4c0285f-49a7-4d52-bd7d-7b1b876075a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-9186978c-9156-4684-8e7e-f86c2d5dd364,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-c87a899a-845b-4600-9118-765bff6f0617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168878489-172.17.0.12-1597535345793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-8382a432-3e48-40a0-93a8-d162e02d0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-d07df0fe-a48a-46ba-a240-0484a8759e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-d946117b-8c60-4f34-9f35-32e3a8587d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d19ed184-0263-451a-8ecf-9ba97d801fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-49302c33-7c3a-4e40-a8e5-e0edf03ddd27,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-b4c0285f-49a7-4d52-bd7d-7b1b876075a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-9186978c-9156-4684-8e7e-f86c2d5dd364,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-c87a899a-845b-4600-9118-765bff6f0617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976261010-172.17.0.12-1597535379760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-e3cd2389-1cea-4aec-9c57-21e238aff225,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-09c0c35e-5106-4fa4-83e0-fdbf83b2c552,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c0dae09a-fb9f-4043-8d63-14b697c10f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-ba1c5b6b-5cb0-473a-9d19-9ab0f1ad9726,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-a27a6a68-b335-4054-aeff-620b4e7495b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-f5f50d56-5f56-4838-bfc3-2d297769f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-f4ac252d-d870-49d7-b9bf-d6994021bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-98a43aed-ae9c-440e-aced-849c80db9c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976261010-172.17.0.12-1597535379760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-e3cd2389-1cea-4aec-9c57-21e238aff225,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-09c0c35e-5106-4fa4-83e0-fdbf83b2c552,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c0dae09a-fb9f-4043-8d63-14b697c10f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-ba1c5b6b-5cb0-473a-9d19-9ab0f1ad9726,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-a27a6a68-b335-4054-aeff-620b4e7495b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-f5f50d56-5f56-4838-bfc3-2d297769f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-f4ac252d-d870-49d7-b9bf-d6994021bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-98a43aed-ae9c-440e-aced-849c80db9c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952525241-172.17.0.12-1597535789191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0766bd6f-7f7f-4b87-be64-81caec354a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-a6209d2d-1bc1-4661-a3a9-0b9cd1605905,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-7727f356-4bd1-4ee5-ae0a-6cf84e164819,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-717c9377-e892-4bc1-be13-2634b1942d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1261f744-d121-44e4-a2c8-77970ad3d289,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-cd103d29-a26c-4e11-8ff7-ae78dd069efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-bb07890a-03cd-4235-aed2-161c28641146,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-89fe9725-750d-4c2b-9a18-6bfd7ba57d31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952525241-172.17.0.12-1597535789191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0766bd6f-7f7f-4b87-be64-81caec354a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-a6209d2d-1bc1-4661-a3a9-0b9cd1605905,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-7727f356-4bd1-4ee5-ae0a-6cf84e164819,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-717c9377-e892-4bc1-be13-2634b1942d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1261f744-d121-44e4-a2c8-77970ad3d289,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-cd103d29-a26c-4e11-8ff7-ae78dd069efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-bb07890a-03cd-4235-aed2-161c28641146,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-89fe9725-750d-4c2b-9a18-6bfd7ba57d31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277941739-172.17.0.12-1597535827406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-4edb1751-aa44-460e-978b-7e8391894d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-32ee0bdf-e8e9-48b9-ac48-2f7e3d605960,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-c7caec06-68c2-419b-9367-a1c198e38c03,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8ff4b415-b135-45a9-a305-99959f1811c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-c5e07028-fdf6-42ca-b93e-841f16bf442d,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-1f164fcb-9a35-45fa-ace7-5052fa5231e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-b600d8e9-d7be-4c4a-b0d0-55e8adc75e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-30ccc894-dc31-43fe-8178-515e355c5a2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277941739-172.17.0.12-1597535827406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-4edb1751-aa44-460e-978b-7e8391894d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-32ee0bdf-e8e9-48b9-ac48-2f7e3d605960,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-c7caec06-68c2-419b-9367-a1c198e38c03,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8ff4b415-b135-45a9-a305-99959f1811c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-c5e07028-fdf6-42ca-b93e-841f16bf442d,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-1f164fcb-9a35-45fa-ace7-5052fa5231e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-b600d8e9-d7be-4c4a-b0d0-55e8adc75e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-30ccc894-dc31-43fe-8178-515e355c5a2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987513844-172.17.0.12-1597535862177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-ddc1234c-bd9a-4b2d-9642-189b41bd4663,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-fa04066a-92be-4176-83ee-e9675833541d,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-57ba8c9c-1a7f-4474-b385-4032ab9569a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-35ef4f23-5f1f-45ac-b644-b1b8a657aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e6548f22-478f-4f5e-ac14-4df4e82da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c8af8899-0041-4e70-9fd5-4c39a181c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b298917a-7fb4-4867-a211-68f9d02f353f,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-63d264d1-33ac-4471-91cd-076696105388,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987513844-172.17.0.12-1597535862177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-ddc1234c-bd9a-4b2d-9642-189b41bd4663,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-fa04066a-92be-4176-83ee-e9675833541d,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-57ba8c9c-1a7f-4474-b385-4032ab9569a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-35ef4f23-5f1f-45ac-b644-b1b8a657aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e6548f22-478f-4f5e-ac14-4df4e82da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c8af8899-0041-4e70-9fd5-4c39a181c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b298917a-7fb4-4867-a211-68f9d02f353f,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-63d264d1-33ac-4471-91cd-076696105388,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961391991-172.17.0.12-1597535895196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-46ad273a-64ea-4a84-b7cf-3f31d48338f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-00c96ebf-f490-407b-b982-a5df2769a03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7fb91ba9-a85b-49dd-a0e8-02ce5220e07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-e3438abf-707b-45f4-b8e6-848be536ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-3b6ec6a2-abd9-40de-a8c9-de2422ca7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-d5b5738b-db89-4057-a35f-9ec7053ca308,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-9e7057ba-2ed8-423d-a657-71c1ca2e45e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-e4161ff8-9a83-4a1a-a487-c266c307b6bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961391991-172.17.0.12-1597535895196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-46ad273a-64ea-4a84-b7cf-3f31d48338f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-00c96ebf-f490-407b-b982-a5df2769a03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7fb91ba9-a85b-49dd-a0e8-02ce5220e07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-e3438abf-707b-45f4-b8e6-848be536ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-3b6ec6a2-abd9-40de-a8c9-de2422ca7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-d5b5738b-db89-4057-a35f-9ec7053ca308,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-9e7057ba-2ed8-423d-a657-71c1ca2e45e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-e4161ff8-9a83-4a1a-a487-c266c307b6bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739502135-172.17.0.12-1597535962570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44224,DS-f313d85b-8e14-4390-a360-a4eb68df4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-832450f2-6129-4201-81c3-9dd83cb008de,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-8ff8af49-76f2-4174-a6f0-3e23902a3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-87c621a6-6c6b-47ac-bc5b-65446b33c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-98d2bb31-135d-45fb-96dc-f05d66629d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-0a4669c4-3275-4e50-a082-a13f55165cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-929c1bf8-f121-4de2-81a8-6afbf067a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-45ee4c22-adeb-456b-8fc6-0171db5ce9c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739502135-172.17.0.12-1597535962570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44224,DS-f313d85b-8e14-4390-a360-a4eb68df4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-832450f2-6129-4201-81c3-9dd83cb008de,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-8ff8af49-76f2-4174-a6f0-3e23902a3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-87c621a6-6c6b-47ac-bc5b-65446b33c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-98d2bb31-135d-45fb-96dc-f05d66629d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-0a4669c4-3275-4e50-a082-a13f55165cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-929c1bf8-f121-4de2-81a8-6afbf067a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-45ee4c22-adeb-456b-8fc6-0171db5ce9c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506217142-172.17.0.12-1597536268524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-89bd147f-ea7b-474d-b6af-d0b442e5cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-04919bef-eaa7-40f0-b6d7-4dcf111310da,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-6d3aa55d-6d26-49b0-a61b-527526883503,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-f57a7303-57df-4725-b577-fad4540a9bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-b211df77-f9d2-421e-977e-85d7cb0c7acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-55858478-2b02-412f-a4c0-a9456f34cfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-ce660556-7854-4ac9-b4c4-10cbaee67e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-06e54693-523f-46d1-850a-d9b485c4af06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506217142-172.17.0.12-1597536268524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-89bd147f-ea7b-474d-b6af-d0b442e5cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-04919bef-eaa7-40f0-b6d7-4dcf111310da,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-6d3aa55d-6d26-49b0-a61b-527526883503,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-f57a7303-57df-4725-b577-fad4540a9bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-b211df77-f9d2-421e-977e-85d7cb0c7acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-55858478-2b02-412f-a4c0-a9456f34cfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-ce660556-7854-4ac9-b4c4-10cbaee67e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-06e54693-523f-46d1-850a-d9b485c4af06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556758506-172.17.0.12-1597536420413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-b4a9d8a4-79f6-4862-9143-f58e914fa51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-333899cf-67ff-4205-bcb3-b6a943bb8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-66ad2140-6b8d-43e6-85d3-51adb88bad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-646d6f90-6962-4aff-b679-d562b8848765,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-d82466c7-c400-41e8-9d99-8cad31db0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-32d46933-516d-4043-a03a-1fb13cc053d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-4ec0ec29-fc11-416c-af0d-426fd6c52b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-421437b1-af0b-4b99-9f1c-08bc414d3f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556758506-172.17.0.12-1597536420413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-b4a9d8a4-79f6-4862-9143-f58e914fa51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-333899cf-67ff-4205-bcb3-b6a943bb8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-66ad2140-6b8d-43e6-85d3-51adb88bad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-646d6f90-6962-4aff-b679-d562b8848765,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-d82466c7-c400-41e8-9d99-8cad31db0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-32d46933-516d-4043-a03a-1fb13cc053d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-4ec0ec29-fc11-416c-af0d-426fd6c52b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-421437b1-af0b-4b99-9f1c-08bc414d3f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046048408-172.17.0.12-1597536459195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-4f261e66-3e45-4fe6-8c05-b98d2a46034b,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bd2c8412-467e-4db4-9be2-ff311a1a1b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-694d3ba6-0eea-4df4-a41a-6421202453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-5833008f-f202-407c-b666-104fe43bd250,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-4a4c449f-d8fc-4146-8829-6fbb88a6e457,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3071ef7f-ef3b-465d-b277-a97e710659fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-c14120d0-2f7a-4480-b81f-eb7a813c6653,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-44f75eb1-4048-4faf-af9e-51740a9b5ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046048408-172.17.0.12-1597536459195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-4f261e66-3e45-4fe6-8c05-b98d2a46034b,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bd2c8412-467e-4db4-9be2-ff311a1a1b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-694d3ba6-0eea-4df4-a41a-6421202453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-5833008f-f202-407c-b666-104fe43bd250,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-4a4c449f-d8fc-4146-8829-6fbb88a6e457,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3071ef7f-ef3b-465d-b277-a97e710659fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-c14120d0-2f7a-4480-b81f-eb7a813c6653,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-44f75eb1-4048-4faf-af9e-51740a9b5ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181284131-172.17.0.12-1597536919476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-125c6a87-c280-45d9-a176-ba06822ea711,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-7547850d-33a1-4388-928e-2aa11d6c4886,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-0baf6d6f-21b3-4737-9f47-47df1397e902,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-bdb4a324-cd81-479e-aa37-26e8dd69dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-fa4e1c70-b40f-45ec-bea3-a1354f3f2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-f83af4c3-1a33-4a19-9436-777a925f6732,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-591dfb86-4966-4380-9178-6bd43594fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-a240bb2b-736c-46ec-b191-f0d51942b34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181284131-172.17.0.12-1597536919476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-125c6a87-c280-45d9-a176-ba06822ea711,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-7547850d-33a1-4388-928e-2aa11d6c4886,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-0baf6d6f-21b3-4737-9f47-47df1397e902,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-bdb4a324-cd81-479e-aa37-26e8dd69dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-fa4e1c70-b40f-45ec-bea3-a1354f3f2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-f83af4c3-1a33-4a19-9436-777a925f6732,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-591dfb86-4966-4380-9178-6bd43594fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-a240bb2b-736c-46ec-b191-f0d51942b34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709154088-172.17.0.12-1597536959278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-b7f92c9d-dc7f-401d-9f69-669d9b203ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-bde4366c-7945-466d-b7e8-918ed2084d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-76fb9bf1-3a3e-4423-aab2-797d2f72f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-74617796-200b-4969-bb80-b9363b3006d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-f27d123e-66f2-4852-9212-d01886e73707,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-035c0880-6675-4971-baa9-3ae4d244f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-6afe0151-088b-4f8f-b3eb-3fed9d6ee9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-da53e779-1742-4642-aa2e-0184287ea534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709154088-172.17.0.12-1597536959278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-b7f92c9d-dc7f-401d-9f69-669d9b203ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-bde4366c-7945-466d-b7e8-918ed2084d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-76fb9bf1-3a3e-4423-aab2-797d2f72f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-74617796-200b-4969-bb80-b9363b3006d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-f27d123e-66f2-4852-9212-d01886e73707,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-035c0880-6675-4971-baa9-3ae4d244f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-6afe0151-088b-4f8f-b3eb-3fed9d6ee9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-da53e779-1742-4642-aa2e-0184287ea534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210243640-172.17.0.12-1597537073068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-aef97e86-d7fa-4e9d-b272-39375338aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-0c47f364-4edb-420f-a0ab-9b09cd91f010,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-ee1a0740-d4f5-45d8-a806-428cdd78fce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-3acb0314-6e9e-4e1e-b356-3583f360a800,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-835a27e9-fba6-4855-a25c-09cbc584283e,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-8bb565a1-a415-49bc-a31a-76c14f6eefb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-22722975-ad99-48be-ad19-165f382b3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-fbb8bcc4-941e-451b-86ed-52b43871c1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210243640-172.17.0.12-1597537073068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-aef97e86-d7fa-4e9d-b272-39375338aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-0c47f364-4edb-420f-a0ab-9b09cd91f010,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-ee1a0740-d4f5-45d8-a806-428cdd78fce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-3acb0314-6e9e-4e1e-b356-3583f360a800,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-835a27e9-fba6-4855-a25c-09cbc584283e,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-8bb565a1-a415-49bc-a31a-76c14f6eefb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-22722975-ad99-48be-ad19-165f382b3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-fbb8bcc4-941e-451b-86ed-52b43871c1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477044773-172.17.0.12-1597537372882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-c913cb75-f997-4c8c-a390-239bfe8aa864,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-f3151f0f-cdeb-41ab-90d8-ed4b968be85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-e2eb0eac-baa4-44ba-aa95-bfe4bc179881,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-5adb5b94-a068-4e9a-8c3a-ef8f4731efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-c10a7d99-5949-4add-b6bb-35c1535097e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0ba4ca42-83d5-405e-aa8e-59b31f8abde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-e165e1cb-f615-4b68-887e-ad7a37b114ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-56d2f695-9220-4498-8a67-2270fcad1c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477044773-172.17.0.12-1597537372882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-c913cb75-f997-4c8c-a390-239bfe8aa864,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-f3151f0f-cdeb-41ab-90d8-ed4b968be85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-e2eb0eac-baa4-44ba-aa95-bfe4bc179881,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-5adb5b94-a068-4e9a-8c3a-ef8f4731efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-c10a7d99-5949-4add-b6bb-35c1535097e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0ba4ca42-83d5-405e-aa8e-59b31f8abde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-e165e1cb-f615-4b68-887e-ad7a37b114ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-56d2f695-9220-4498-8a67-2270fcad1c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249970845-172.17.0.12-1597537458107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-dcce83fb-6618-4999-888b-5b71a12abeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-23c2f036-a79f-4cea-8cfe-800f3629ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-853f0613-8e33-44a4-b494-b2fe81cb58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-013398ad-f827-4cf5-8008-b7526bb668e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-af4d7147-0d43-4675-8dd3-a5aea13a7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-4ad220a7-19f6-47de-9883-db7b2ce028bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-5040f655-8942-4564-8d06-4642f4866480,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-4f01f658-8feb-4d8f-84a4-dcac8b110eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249970845-172.17.0.12-1597537458107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-dcce83fb-6618-4999-888b-5b71a12abeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-23c2f036-a79f-4cea-8cfe-800f3629ddd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-853f0613-8e33-44a4-b494-b2fe81cb58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-013398ad-f827-4cf5-8008-b7526bb668e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-af4d7147-0d43-4675-8dd3-a5aea13a7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-4ad220a7-19f6-47de-9883-db7b2ce028bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-5040f655-8942-4564-8d06-4642f4866480,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-4f01f658-8feb-4d8f-84a4-dcac8b110eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008901547-172.17.0.12-1597537542141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-64ba4769-a904-4998-9533-1f9c6a66e431,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-171550f4-e37f-4f7c-abfb-d5e3c18cee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-becdfb84-7195-4949-a4bf-2a725a50c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-780d5b9b-64ec-454c-89b6-f65536e77d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e97bd770-c90c-49a5-a70f-7bb9c30ff73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-c05ff427-d2b3-4e81-9d82-ea871fe8bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-648a4e87-4c66-47bb-aff0-55b155220149,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-0f01977d-de16-491d-8f85-b49cb57b82b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008901547-172.17.0.12-1597537542141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-64ba4769-a904-4998-9533-1f9c6a66e431,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-171550f4-e37f-4f7c-abfb-d5e3c18cee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-becdfb84-7195-4949-a4bf-2a725a50c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-780d5b9b-64ec-454c-89b6-f65536e77d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e97bd770-c90c-49a5-a70f-7bb9c30ff73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-c05ff427-d2b3-4e81-9d82-ea871fe8bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-648a4e87-4c66-47bb-aff0-55b155220149,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-0f01977d-de16-491d-8f85-b49cb57b82b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313787714-172.17.0.12-1597537949180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40926,DS-79e0275f-679a-4f7d-929d-aed9ca5f251a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-b684cf22-3bc3-4801-be0d-c73ff0335e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-403364df-a891-4538-8b0f-0ca4dbc5f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-025b6475-9b03-4965-ab8a-9f7a48111b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ebebc9a6-be90-4778-983e-284e670d7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-63fc21d9-2eaf-4fef-b23c-c0053eccc275,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-b64b8bfa-09fc-43a5-b7f5-4a33b8d2835d,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-c6d695b5-1b8a-465c-b770-1f1bde21b84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313787714-172.17.0.12-1597537949180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40926,DS-79e0275f-679a-4f7d-929d-aed9ca5f251a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-b684cf22-3bc3-4801-be0d-c73ff0335e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-403364df-a891-4538-8b0f-0ca4dbc5f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-025b6475-9b03-4965-ab8a-9f7a48111b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ebebc9a6-be90-4778-983e-284e670d7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-63fc21d9-2eaf-4fef-b23c-c0053eccc275,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-b64b8bfa-09fc-43a5-b7f5-4a33b8d2835d,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-c6d695b5-1b8a-465c-b770-1f1bde21b84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746752920-172.17.0.12-1597538105421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-1c6cc519-9a92-4a01-9ef8-4cf4806244d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-fc1deb6b-5d78-4f48-8009-a147bb075ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1a5bdf40-c479-4b24-a9c6-fd709ee0b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-69835b00-84ad-4160-90ae-3b28d1ee7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-ad98f936-5506-4416-8799-3be5145f0792,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-8862e9ea-73c8-4ac0-85fb-56e2a1e01c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-5e3c9ead-a461-426f-b0a2-23febe8368bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-da44a283-30c7-4f3a-9344-dd940a60e534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746752920-172.17.0.12-1597538105421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-1c6cc519-9a92-4a01-9ef8-4cf4806244d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-fc1deb6b-5d78-4f48-8009-a147bb075ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1a5bdf40-c479-4b24-a9c6-fd709ee0b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-69835b00-84ad-4160-90ae-3b28d1ee7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-ad98f936-5506-4416-8799-3be5145f0792,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-8862e9ea-73c8-4ac0-85fb-56e2a1e01c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-5e3c9ead-a461-426f-b0a2-23febe8368bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-da44a283-30c7-4f3a-9344-dd940a60e534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431889562-172.17.0.12-1597538398605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-e2a48ff4-d4ba-424f-8b8e-34208c415d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-882bc23c-3c56-4136-a88a-533e1f8ffa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-32a233bc-836e-4305-9abb-b5fdf5f55ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-b53c0eb1-f0fb-4d90-a797-f07357f8e302,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-baec5819-64fb-4cef-ba86-7a716d70cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-37e76ede-7c76-495d-b104-47bab6eac0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-9ce99e63-2eff-4639-96b4-2cfd6ff9f0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5b271b90-a1b7-4e60-aa6f-894e490398b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431889562-172.17.0.12-1597538398605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-e2a48ff4-d4ba-424f-8b8e-34208c415d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-882bc23c-3c56-4136-a88a-533e1f8ffa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-32a233bc-836e-4305-9abb-b5fdf5f55ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-b53c0eb1-f0fb-4d90-a797-f07357f8e302,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-baec5819-64fb-4cef-ba86-7a716d70cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-37e76ede-7c76-495d-b104-47bab6eac0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-9ce99e63-2eff-4639-96b4-2cfd6ff9f0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5b271b90-a1b7-4e60-aa6f-894e490398b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631997392-172.17.0.12-1597538477100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46431,DS-fac6db65-f8f8-4080-835a-db06b5062f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-dcd52fc4-35e5-4fce-b840-49b0d24bc2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-9b9a85bf-1910-4e69-a85e-3c28984c01d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-efd3f2bd-0a23-4f1e-af78-dadcd0725ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-2f53ae19-99a1-4065-b3e8-cef18df5334a,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-0563bd49-36b9-40b1-bf7b-7c057e68372b,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-1a8d4925-6135-4201-acc8-3898e9897211,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d5d76753-81be-4e6e-b65a-f0f1e4b0a587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631997392-172.17.0.12-1597538477100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46431,DS-fac6db65-f8f8-4080-835a-db06b5062f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-dcd52fc4-35e5-4fce-b840-49b0d24bc2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-9b9a85bf-1910-4e69-a85e-3c28984c01d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-efd3f2bd-0a23-4f1e-af78-dadcd0725ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-2f53ae19-99a1-4065-b3e8-cef18df5334a,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-0563bd49-36b9-40b1-bf7b-7c057e68372b,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-1a8d4925-6135-4201-acc8-3898e9897211,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-d5d76753-81be-4e6e-b65a-f0f1e4b0a587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152710777-172.17.0.12-1597538740747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-60bdad66-23bd-482d-85bc-27a65ca5dc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c9423931-002e-4436-9ac1-8f6c9385aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-773bf46d-4993-42aa-a25e-cb6e47830dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6c8b107f-a75e-45a3-90f7-1630f18657b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-58c69591-666c-42bc-a6a3-ae64143b680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-e2ee8cad-25e5-48a5-b7e9-ee54fbcf2842,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-c286dfab-4484-4313-bdf1-ce58d3ef1019,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-bff065fe-e598-4808-903a-d19a78478e9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152710777-172.17.0.12-1597538740747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-60bdad66-23bd-482d-85bc-27a65ca5dc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c9423931-002e-4436-9ac1-8f6c9385aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-773bf46d-4993-42aa-a25e-cb6e47830dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6c8b107f-a75e-45a3-90f7-1630f18657b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-58c69591-666c-42bc-a6a3-ae64143b680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-e2ee8cad-25e5-48a5-b7e9-ee54fbcf2842,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-c286dfab-4484-4313-bdf1-ce58d3ef1019,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-bff065fe-e598-4808-903a-d19a78478e9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005021101-172.17.0.12-1597538815560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-5f8f267e-2e59-4b42-b779-24ce9f8f4016,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-0ef84d97-b6d9-4b65-803e-4d25b7abb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-8e992505-fcd6-4196-95c9-d1c07616c395,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-adf380b2-98a8-44dd-8d85-e0912d7e02bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-7ee22f20-855a-49f3-a3b2-45afa79a0710,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-a5b662f3-2b5d-42c9-b78f-b1d6168ad1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-d6289354-cb91-4267-9d63-c1bb3781d85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-3270da59-f867-404a-a12c-59a1b44eac31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005021101-172.17.0.12-1597538815560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-5f8f267e-2e59-4b42-b779-24ce9f8f4016,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-0ef84d97-b6d9-4b65-803e-4d25b7abb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-8e992505-fcd6-4196-95c9-d1c07616c395,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-adf380b2-98a8-44dd-8d85-e0912d7e02bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-7ee22f20-855a-49f3-a3b2-45afa79a0710,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-a5b662f3-2b5d-42c9-b78f-b1d6168ad1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-d6289354-cb91-4267-9d63-c1bb3781d85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-3270da59-f867-404a-a12c-59a1b44eac31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921269679-172.17.0.12-1597538899683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-d4bdabde-c5a1-47c9-bae5-b5c8feda4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-5c6ce426-372b-4569-b3b7-0f3a239fe8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ef6332bc-6070-40ad-a550-2a45bd02bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-3d788ec5-d0e4-4796-91be-319b214a8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-2841bf70-45e6-4bb5-8cb2-ded1333e6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-4346c1c2-417f-491a-a185-0e99f824015f,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-c85faa22-784b-44ec-95d1-2037387fa5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-36645180-f455-4917-8719-280de8a2e0c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921269679-172.17.0.12-1597538899683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-d4bdabde-c5a1-47c9-bae5-b5c8feda4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-5c6ce426-372b-4569-b3b7-0f3a239fe8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ef6332bc-6070-40ad-a550-2a45bd02bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-3d788ec5-d0e4-4796-91be-319b214a8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-2841bf70-45e6-4bb5-8cb2-ded1333e6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-4346c1c2-417f-491a-a185-0e99f824015f,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-c85faa22-784b-44ec-95d1-2037387fa5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-36645180-f455-4917-8719-280de8a2e0c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454740428-172.17.0.12-1597539206967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-1cedaca2-e05d-4e50-ab79-6df6c7184b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-52f5d761-86e1-4cfa-b0ff-ee4beb1bb220,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3df6abdc-5cbc-4dd9-9233-73800e913213,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-e9b7cda4-7a7f-450e-9152-a737aafce124,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-acc51e0c-4e31-499f-b29f-6a4b4fb0d538,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-0390c779-790f-45e9-8656-b208f266677a,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-5b2044ae-35c4-4f3d-bb32-708395e1087b,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-92d8119e-e5a2-4ab8-906f-b339864a7621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454740428-172.17.0.12-1597539206967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-1cedaca2-e05d-4e50-ab79-6df6c7184b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-52f5d761-86e1-4cfa-b0ff-ee4beb1bb220,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3df6abdc-5cbc-4dd9-9233-73800e913213,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-e9b7cda4-7a7f-450e-9152-a737aafce124,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-acc51e0c-4e31-499f-b29f-6a4b4fb0d538,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-0390c779-790f-45e9-8656-b208f266677a,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-5b2044ae-35c4-4f3d-bb32-708395e1087b,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-92d8119e-e5a2-4ab8-906f-b339864a7621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504739140-172.17.0.12-1597539476561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-a4b05cc7-29e5-41d6-aefa-f78bc143fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-36dbb935-3585-4664-ab84-0ae0ad4d849b,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-a8503a36-31d2-4a6b-a4ac-4e7185b7cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-2ea45ed7-fc6f-423f-9dbd-bee9206552d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-7527a259-055a-4a0a-8b05-e6acbd0c780b,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-87207cdd-d002-4e3b-bb2c-b1bd9fa0f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-266b2388-a057-4ebd-8fcb-ce514b998257,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-15cae9db-a54c-4130-b292-8e1086a1fe04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504739140-172.17.0.12-1597539476561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-a4b05cc7-29e5-41d6-aefa-f78bc143fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-36dbb935-3585-4664-ab84-0ae0ad4d849b,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-a8503a36-31d2-4a6b-a4ac-4e7185b7cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-2ea45ed7-fc6f-423f-9dbd-bee9206552d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-7527a259-055a-4a0a-8b05-e6acbd0c780b,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-87207cdd-d002-4e3b-bb2c-b1bd9fa0f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-266b2388-a057-4ebd-8fcb-ce514b998257,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-15cae9db-a54c-4130-b292-8e1086a1fe04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939099661-172.17.0.12-1597539594721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-6e8128a1-ba5c-4027-b0e7-e16e5376ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-82d00443-1fa6-4f51-b0e8-a06d28d28327,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-cc905818-3295-4c11-81bd-51065e96bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4fa632e5-704e-4515-b798-205016d4fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-61e9b815-4de1-4ed7-98e6-931408523470,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-1d46de25-995a-46d6-8dbd-78c8766fe494,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-64a4347f-2181-494d-848c-92b402a474dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-1e2cf5a5-2112-4568-8b85-005ad5d1e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939099661-172.17.0.12-1597539594721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-6e8128a1-ba5c-4027-b0e7-e16e5376ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-82d00443-1fa6-4f51-b0e8-a06d28d28327,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-cc905818-3295-4c11-81bd-51065e96bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4fa632e5-704e-4515-b798-205016d4fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-61e9b815-4de1-4ed7-98e6-931408523470,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-1d46de25-995a-46d6-8dbd-78c8766fe494,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-64a4347f-2181-494d-848c-92b402a474dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-1e2cf5a5-2112-4568-8b85-005ad5d1e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107324244-172.17.0.12-1597539744592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-87f80c6a-2482-445e-937a-da9721ea9b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-a08f02cd-4354-4454-b652-1b658e5c54be,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-1cd661ed-af8d-4561-bdda-9082cf582937,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-d63e9f4a-2938-4c38-8873-ef7acd8b1967,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-035fe55a-8869-465e-a47a-5d0ea2e8a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-1f3a0a25-81b0-4dcc-b329-0d6d2aa9a50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-884283ca-6c50-4d44-a1d9-9e7b69a53b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ef8c27cb-72ee-4398-b62f-371a2a2e0898,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107324244-172.17.0.12-1597539744592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-87f80c6a-2482-445e-937a-da9721ea9b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-a08f02cd-4354-4454-b652-1b658e5c54be,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-1cd661ed-af8d-4561-bdda-9082cf582937,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-d63e9f4a-2938-4c38-8873-ef7acd8b1967,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-035fe55a-8869-465e-a47a-5d0ea2e8a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-1f3a0a25-81b0-4dcc-b329-0d6d2aa9a50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-884283ca-6c50-4d44-a1d9-9e7b69a53b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ef8c27cb-72ee-4398-b62f-371a2a2e0898,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842018058-172.17.0.12-1597539780222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-6fa15212-6b33-47cc-8841-45932e1c9579,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-6eadba13-2e13-4c8e-a283-4a1cfd75cf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-363aa918-d057-4bc0-af6a-4cd8b75a80cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-f2f4b921-daba-418c-a608-9e984208b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-191435ca-379d-4b75-9f61-9273daff3314,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-32c1b642-840c-4ee3-a7f0-81796cd8e11a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-e15d1db1-d85f-4e49-9173-22db2783c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ec8b0da9-0735-4788-afc2-97da4d9febac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842018058-172.17.0.12-1597539780222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-6fa15212-6b33-47cc-8841-45932e1c9579,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-6eadba13-2e13-4c8e-a283-4a1cfd75cf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-363aa918-d057-4bc0-af6a-4cd8b75a80cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-f2f4b921-daba-418c-a608-9e984208b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-191435ca-379d-4b75-9f61-9273daff3314,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-32c1b642-840c-4ee3-a7f0-81796cd8e11a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-e15d1db1-d85f-4e49-9173-22db2783c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ec8b0da9-0735-4788-afc2-97da4d9febac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310223464-172.17.0.12-1597540171997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-b028e4b9-7536-428b-87f2-9cbcc24847c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-140d646e-044f-44e2-ae33-2d38ad55c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-866bd2ce-eb12-4b3f-b03e-5bcefe31c270,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-7bfafedb-50f6-4a35-abd5-d577a579488b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-6c7d1dc6-9f39-48e0-8eae-123963445823,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-82021e17-f663-471a-827a-8fe1c9f2686d,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-27976e59-b899-4308-ba9f-6272b7a8788d,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-d3631b01-3865-4b27-be35-ee06e3203323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310223464-172.17.0.12-1597540171997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-b028e4b9-7536-428b-87f2-9cbcc24847c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-140d646e-044f-44e2-ae33-2d38ad55c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-866bd2ce-eb12-4b3f-b03e-5bcefe31c270,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-7bfafedb-50f6-4a35-abd5-d577a579488b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-6c7d1dc6-9f39-48e0-8eae-123963445823,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-82021e17-f663-471a-827a-8fe1c9f2686d,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-27976e59-b899-4308-ba9f-6272b7a8788d,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-d3631b01-3865-4b27-be35-ee06e3203323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344357963-172.17.0.12-1597540324672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-afaf0fc2-ecde-4e50-875d-a2afb1194909,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-847d40d1-66fc-4a8f-805f-e598748da9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-06163cd2-8711-4f53-86ae-8d9412a4a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d6df8e44-97dc-4edb-8fb0-94909d9a6957,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-70de21f2-a874-4e25-a366-f231bbaab9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-17e60e31-f627-4a2b-9aa3-4efa454df667,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-44ae0646-b5c8-41b2-8d52-0b333c2dc719,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-f5b73de4-9d31-4c5e-97ed-bb4b0f26e0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344357963-172.17.0.12-1597540324672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42849,DS-afaf0fc2-ecde-4e50-875d-a2afb1194909,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-847d40d1-66fc-4a8f-805f-e598748da9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-06163cd2-8711-4f53-86ae-8d9412a4a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d6df8e44-97dc-4edb-8fb0-94909d9a6957,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-70de21f2-a874-4e25-a366-f231bbaab9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-17e60e31-f627-4a2b-9aa3-4efa454df667,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-44ae0646-b5c8-41b2-8d52-0b333c2dc719,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-f5b73de4-9d31-4c5e-97ed-bb4b0f26e0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947629317-172.17.0.12-1597540480075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-975d0627-3830-4b6c-b352-31cacd05afee,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-4d5b49c8-0924-4a61-a561-f436c57cf6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-be6f4b0b-3940-42d5-b820-7cf74ffa7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-54ca01c3-4869-42d1-aa90-67fc198ad461,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-f3647cb2-5c62-430c-bc32-582b2290e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f58b5938-cd65-4b64-8ee2-e25b46dcca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-6d057ff2-201b-44f9-b7da-98ea4f65b254,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-d59ece7f-4a00-4eec-99cc-4abba1b44f87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947629317-172.17.0.12-1597540480075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-975d0627-3830-4b6c-b352-31cacd05afee,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-4d5b49c8-0924-4a61-a561-f436c57cf6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-be6f4b0b-3940-42d5-b820-7cf74ffa7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-54ca01c3-4869-42d1-aa90-67fc198ad461,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-f3647cb2-5c62-430c-bc32-582b2290e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f58b5938-cd65-4b64-8ee2-e25b46dcca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-6d057ff2-201b-44f9-b7da-98ea4f65b254,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-d59ece7f-4a00-4eec-99cc-4abba1b44f87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744684395-172.17.0.12-1597540553293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43443,DS-f5f40a5a-2a6a-4271-9b0b-1ff314db7550,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f5e4cf20-a1d5-42fb-a33a-b3785b242aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-612a6254-2120-4c98-9f80-0b4a7f83d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-a8d9d122-3cd4-4324-9507-fb8a6d7cc358,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-eacd5993-cb16-4522-a55f-7562b566eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-b4be3444-0ccf-4fb8-a2f5-af064a44ebca,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-06644579-2622-499d-9078-5c1ff1d39ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-f4a66858-51ce-4581-8194-8a29269b9dd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744684395-172.17.0.12-1597540553293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43443,DS-f5f40a5a-2a6a-4271-9b0b-1ff314db7550,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f5e4cf20-a1d5-42fb-a33a-b3785b242aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-612a6254-2120-4c98-9f80-0b4a7f83d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-a8d9d122-3cd4-4324-9507-fb8a6d7cc358,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-eacd5993-cb16-4522-a55f-7562b566eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-b4be3444-0ccf-4fb8-a2f5-af064a44ebca,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-06644579-2622-499d-9078-5c1ff1d39ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-f4a66858-51ce-4581-8194-8a29269b9dd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514124974-172.17.0.12-1597540731360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-4d11d76e-627e-4c6a-84b9-517f6fbacf69,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-d5766a7a-6681-4267-b984-be0dad831492,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-8999361e-5419-4005-8a19-1a93bd917a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-0ea5b3ab-e561-4d86-b633-cf7020b12695,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-820a813b-ed53-4229-a8ec-4964d41d627e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-421242e3-b18a-4991-a8cb-296496b4ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-4f3ced2d-e2d9-43ee-b729-b2e53133455f,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-f59bf90e-3845-4a6e-be0c-3a0193166cee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514124974-172.17.0.12-1597540731360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-4d11d76e-627e-4c6a-84b9-517f6fbacf69,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-d5766a7a-6681-4267-b984-be0dad831492,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-8999361e-5419-4005-8a19-1a93bd917a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-0ea5b3ab-e561-4d86-b633-cf7020b12695,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-820a813b-ed53-4229-a8ec-4964d41d627e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-421242e3-b18a-4991-a8cb-296496b4ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-4f3ced2d-e2d9-43ee-b729-b2e53133455f,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-f59bf90e-3845-4a6e-be0c-3a0193166cee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5650
