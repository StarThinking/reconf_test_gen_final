reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084044465-172.17.0.4-1597289464299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-72df47ec-c526-478b-a840-eb560408cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-db4a0f07-fd4e-4e78-9d4c-58e105038862,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0da6f499-ccea-4245-ac76-626cdc021184,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-4fb4fc17-1b50-48b9-9c8a-00f9054016ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-eac68d9c-5108-4cd6-9666-4138b39ed76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-bba098c4-858d-44e7-acbb-3f0e788daeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-d3bd4de2-3069-4e18-8162-317c7c8dfaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-fd9b01b0-bdde-4472-b0fb-dbd7d9367a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084044465-172.17.0.4-1597289464299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-72df47ec-c526-478b-a840-eb560408cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-db4a0f07-fd4e-4e78-9d4c-58e105038862,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0da6f499-ccea-4245-ac76-626cdc021184,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-4fb4fc17-1b50-48b9-9c8a-00f9054016ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-eac68d9c-5108-4cd6-9666-4138b39ed76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-bba098c4-858d-44e7-acbb-3f0e788daeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-d3bd4de2-3069-4e18-8162-317c7c8dfaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-fd9b01b0-bdde-4472-b0fb-dbd7d9367a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253944221-172.17.0.4-1597290313444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-a81c4651-481b-44a9-81da-8cd4228231f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-a861bf56-7f57-49fc-9de0-921ac61ee2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-9cba820c-fcbe-4ea1-9ee0-b8e6bb98c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-fc6bad7d-e7e1-4bbd-8fc0-92e134aae429,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-b1a4d61c-3290-4acb-b2d3-65a2d989b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c890ba23-1dc0-4a80-b413-bb0df52ba16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-e5e823a1-68bd-465f-a075-2edd314a459e,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-e5d24aa8-3a2f-4605-9216-0893f4c2d3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253944221-172.17.0.4-1597290313444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-a81c4651-481b-44a9-81da-8cd4228231f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-a861bf56-7f57-49fc-9de0-921ac61ee2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-9cba820c-fcbe-4ea1-9ee0-b8e6bb98c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-fc6bad7d-e7e1-4bbd-8fc0-92e134aae429,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-b1a4d61c-3290-4acb-b2d3-65a2d989b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c890ba23-1dc0-4a80-b413-bb0df52ba16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-e5e823a1-68bd-465f-a075-2edd314a459e,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-e5d24aa8-3a2f-4605-9216-0893f4c2d3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842612155-172.17.0.4-1597290662681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37515,DS-bf4585b7-5c5c-45bf-ac47-4ecf90650ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-5813c7c7-cb6c-45ef-87a4-f2c3674a5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-93e5b020-02f1-4879-b992-7ab88ebf351a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1f7124c4-3dbc-4ecf-81c0-c6f55267b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-70b925a3-02d5-4df0-b648-3652bbb07f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-3ec2a9f7-f206-48ed-b901-f1af02cc400e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e521808b-991a-45c8-83c5-3f0375b2b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5b334e3a-c40e-4ebd-ac7b-24aa534525fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842612155-172.17.0.4-1597290662681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37515,DS-bf4585b7-5c5c-45bf-ac47-4ecf90650ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-5813c7c7-cb6c-45ef-87a4-f2c3674a5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-93e5b020-02f1-4879-b992-7ab88ebf351a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1f7124c4-3dbc-4ecf-81c0-c6f55267b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-70b925a3-02d5-4df0-b648-3652bbb07f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-3ec2a9f7-f206-48ed-b901-f1af02cc400e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e521808b-991a-45c8-83c5-3f0375b2b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5b334e3a-c40e-4ebd-ac7b-24aa534525fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140027647-172.17.0.4-1597291158634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36175,DS-678e9743-2013-44e6-9a97-f652ee39e621,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-983a9707-3ea1-46c9-a868-bcd6a24caee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-101dca07-ac58-4675-bff6-b3ddb6818bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-441a6ba6-3da2-4ceb-bce6-0b8001db2bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-7b995fc6-2828-4e64-9f3b-d3eb5b865038,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-02801c06-1227-402f-a59a-7cb04e80de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-b6baba53-a109-466e-b789-6176095e8674,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-a129f6fc-a133-492d-bcc2-3a418a7d1e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140027647-172.17.0.4-1597291158634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36175,DS-678e9743-2013-44e6-9a97-f652ee39e621,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-983a9707-3ea1-46c9-a868-bcd6a24caee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-101dca07-ac58-4675-bff6-b3ddb6818bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-441a6ba6-3da2-4ceb-bce6-0b8001db2bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-7b995fc6-2828-4e64-9f3b-d3eb5b865038,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-02801c06-1227-402f-a59a-7cb04e80de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-b6baba53-a109-466e-b789-6176095e8674,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-a129f6fc-a133-492d-bcc2-3a418a7d1e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044431165-172.17.0.4-1597291426790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-02115b7e-c960-498c-97c8-02b568afc752,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-58142048-0e0e-4b01-94a3-e87f5947c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-32bd80a0-3f10-49bb-9dab-ace47709712f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-408dd25f-f6b6-4cfb-96c0-07a15192fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-6300a5f4-f5c9-4d2a-a6df-c9cfbab5adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-34fbcba0-8f22-4143-8b04-63a489255726,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-b8b445e2-17b4-400b-bc67-263ae562eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-42e4eeb3-f1dc-46b1-84e2-0cfac10e6ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044431165-172.17.0.4-1597291426790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-02115b7e-c960-498c-97c8-02b568afc752,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-58142048-0e0e-4b01-94a3-e87f5947c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-32bd80a0-3f10-49bb-9dab-ace47709712f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-408dd25f-f6b6-4cfb-96c0-07a15192fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-6300a5f4-f5c9-4d2a-a6df-c9cfbab5adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-34fbcba0-8f22-4143-8b04-63a489255726,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-b8b445e2-17b4-400b-bc67-263ae562eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-42e4eeb3-f1dc-46b1-84e2-0cfac10e6ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632371607-172.17.0.4-1597291469080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-0c63f8fc-86d2-40ea-95c8-79d45e165882,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-fcc0395d-52c7-4e14-8027-4b352e84aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-24445048-36ac-4bde-a145-20139b51a767,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-04411b69-8c10-4a5d-920b-954d797a6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6ae8a21c-bc25-4620-af68-3fdce7163377,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-4539641c-37e0-433f-935c-3c7bac3a06cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-d77affd0-a10e-4d9e-9224-aba55f5643f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-ef3842a1-e1dd-4d8c-8fce-f83a5bc880b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632371607-172.17.0.4-1597291469080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-0c63f8fc-86d2-40ea-95c8-79d45e165882,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-fcc0395d-52c7-4e14-8027-4b352e84aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-24445048-36ac-4bde-a145-20139b51a767,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-04411b69-8c10-4a5d-920b-954d797a6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6ae8a21c-bc25-4620-af68-3fdce7163377,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-4539641c-37e0-433f-935c-3c7bac3a06cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-d77affd0-a10e-4d9e-9224-aba55f5643f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-ef3842a1-e1dd-4d8c-8fce-f83a5bc880b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773235794-172.17.0.4-1597291591579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-429304e9-d0a9-43cd-a71f-182b7b0785d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-a8f5eabd-37d6-4df3-89ba-b4c3d37c1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0c08078a-0716-476b-bb9f-6036fcc9f06b,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-994e7099-a612-43a0-9e54-ae5409d38e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-c1ca4e4f-3bc6-44c6-a607-b89ababdf8df,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-26d383d7-1e38-40bc-bcd2-483118d047f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-af0838f0-b08e-4f23-b805-22ab5b411a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-9504c48c-804c-475f-b3b7-ce4cf45c9510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773235794-172.17.0.4-1597291591579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-429304e9-d0a9-43cd-a71f-182b7b0785d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-a8f5eabd-37d6-4df3-89ba-b4c3d37c1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0c08078a-0716-476b-bb9f-6036fcc9f06b,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-994e7099-a612-43a0-9e54-ae5409d38e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-c1ca4e4f-3bc6-44c6-a607-b89ababdf8df,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-26d383d7-1e38-40bc-bcd2-483118d047f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-af0838f0-b08e-4f23-b805-22ab5b411a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-9504c48c-804c-475f-b3b7-ce4cf45c9510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858868117-172.17.0.4-1597292154050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-514d8b53-5388-415f-a9d3-6968f051a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-942fd88e-c6ec-450c-8c7f-4157932303b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-377655d2-2b7b-4cc6-838e-0a847a789740,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-6979ed0e-3044-45c6-b276-985ab4a1015c,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-940228bf-4bb1-4c1a-b26b-05cd38448dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-904d60ff-5ac9-4bda-a64e-5d8bcabf2b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-22acdd7d-336c-4043-8173-edf14b124d43,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-60741bd8-0b86-4c04-a640-69579f449183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858868117-172.17.0.4-1597292154050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-514d8b53-5388-415f-a9d3-6968f051a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-942fd88e-c6ec-450c-8c7f-4157932303b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-377655d2-2b7b-4cc6-838e-0a847a789740,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-6979ed0e-3044-45c6-b276-985ab4a1015c,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-940228bf-4bb1-4c1a-b26b-05cd38448dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-904d60ff-5ac9-4bda-a64e-5d8bcabf2b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-22acdd7d-336c-4043-8173-edf14b124d43,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-60741bd8-0b86-4c04-a640-69579f449183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903705604-172.17.0.4-1597292189729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-f639a9ca-a6e7-4c90-928d-f14f4c6f5526,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-51e85902-0807-4d11-98e1-71fc10eaa635,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-4927e3b9-df1e-443a-99c3-6b5bf6ef0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-2547cbb0-86ed-401a-a0de-7a7f208e76a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-27141770-bb9c-46d9-8315-a745dd445e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-50e96879-8ffc-4e9a-b721-4921fab0f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-eab3636d-bdc1-49cd-a998-efbd465c66de,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-eb28f3cf-5f65-4b5b-8ce1-949bc2f7cac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903705604-172.17.0.4-1597292189729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-f639a9ca-a6e7-4c90-928d-f14f4c6f5526,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-51e85902-0807-4d11-98e1-71fc10eaa635,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-4927e3b9-df1e-443a-99c3-6b5bf6ef0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-2547cbb0-86ed-401a-a0de-7a7f208e76a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-27141770-bb9c-46d9-8315-a745dd445e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-50e96879-8ffc-4e9a-b721-4921fab0f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-eab3636d-bdc1-49cd-a998-efbd465c66de,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-eb28f3cf-5f65-4b5b-8ce1-949bc2f7cac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268767366-172.17.0.4-1597292226582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-cf55a59c-c8ea-4051-babd-bc1b77729120,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f35e6ea0-f71c-4233-b0a5-a57ff43e3460,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-bb9e3bfd-1edc-45ec-9c49-0edcbf5b5be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-39fb83d3-e3bc-43ae-b0b7-39a4bf4824e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-96e6b00c-5510-4cee-879f-4edfeaf20e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-376c558f-3511-4104-a6e2-d1a866c295e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-aef99662-90b6-4dbe-8019-6622eda3d816,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-23cd08de-f1b1-42e3-95c4-dbd903978d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268767366-172.17.0.4-1597292226582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-cf55a59c-c8ea-4051-babd-bc1b77729120,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f35e6ea0-f71c-4233-b0a5-a57ff43e3460,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-bb9e3bfd-1edc-45ec-9c49-0edcbf5b5be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-39fb83d3-e3bc-43ae-b0b7-39a4bf4824e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-96e6b00c-5510-4cee-879f-4edfeaf20e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-376c558f-3511-4104-a6e2-d1a866c295e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-aef99662-90b6-4dbe-8019-6622eda3d816,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-23cd08de-f1b1-42e3-95c4-dbd903978d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921333719-172.17.0.4-1597292689726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-deb17b0a-3d99-4c10-8fa0-bd98c4adeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-cd249ddc-e455-43b7-bb75-75930f7d32da,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-8930e961-44d2-439d-ad6e-83a79f36eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-9f137fa5-3cc4-4e7e-a460-9de5d059740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-c89e8e8b-b4e9-4313-9765-af59311aca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-0d281df1-4b5f-4fbe-ba2b-c58a768b4580,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-268fb3b1-6638-4387-ba43-2c2eb87e44d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-d18b916c-30af-4dde-8d36-b349ebfa6c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921333719-172.17.0.4-1597292689726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-deb17b0a-3d99-4c10-8fa0-bd98c4adeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-cd249ddc-e455-43b7-bb75-75930f7d32da,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-8930e961-44d2-439d-ad6e-83a79f36eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-9f137fa5-3cc4-4e7e-a460-9de5d059740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-c89e8e8b-b4e9-4313-9765-af59311aca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-0d281df1-4b5f-4fbe-ba2b-c58a768b4580,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-268fb3b1-6638-4387-ba43-2c2eb87e44d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-d18b916c-30af-4dde-8d36-b349ebfa6c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448050759-172.17.0.4-1597292805511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-bae8c830-8268-4d1a-9291-137a5795c868,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-71968438-b981-44d2-88a6-724105434b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-6b2e9ccf-f015-4102-9b4a-4821a24d7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-8980a3da-bac3-409a-9b82-0a7f0f2e548f,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-a65beef8-3c5e-4395-9f9b-54c9bdfee628,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-936bf60c-a450-45cc-906e-85e46143d712,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-ff092887-5c40-4196-9819-a810677cf722,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-17fcc69d-2cf5-45e6-81c3-fa8f6e68aacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448050759-172.17.0.4-1597292805511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-bae8c830-8268-4d1a-9291-137a5795c868,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-71968438-b981-44d2-88a6-724105434b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-6b2e9ccf-f015-4102-9b4a-4821a24d7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-8980a3da-bac3-409a-9b82-0a7f0f2e548f,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-a65beef8-3c5e-4395-9f9b-54c9bdfee628,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-936bf60c-a450-45cc-906e-85e46143d712,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-ff092887-5c40-4196-9819-a810677cf722,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-17fcc69d-2cf5-45e6-81c3-fa8f6e68aacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408282534-172.17.0.4-1597293236694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-98b53026-d15b-4e5f-b9db-53e8aebf7230,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-591f7ef6-467c-42f4-9d21-3d2c84be02e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-9ecb5bb9-f3a3-4e1a-832a-eb9ba4f34645,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-1923c037-c3cb-4649-b676-fd48a3fb873b,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-f6fa6996-c616-48c8-890a-57604abd24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1f0361d2-4ce1-4e10-ac0f-e8f562be46ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-420164b3-4d8a-4b11-bb16-510e2fdf91af,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-9f12c7c4-5b58-435c-bc34-f92365c58e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408282534-172.17.0.4-1597293236694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-98b53026-d15b-4e5f-b9db-53e8aebf7230,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-591f7ef6-467c-42f4-9d21-3d2c84be02e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-9ecb5bb9-f3a3-4e1a-832a-eb9ba4f34645,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-1923c037-c3cb-4649-b676-fd48a3fb873b,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-f6fa6996-c616-48c8-890a-57604abd24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1f0361d2-4ce1-4e10-ac0f-e8f562be46ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-420164b3-4d8a-4b11-bb16-510e2fdf91af,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-9f12c7c4-5b58-435c-bc34-f92365c58e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335833851-172.17.0.4-1597293270976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36246,DS-8fe004bf-fbf3-4a54-9d1f-b5ff1f8b07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-fa5979c7-24e0-4656-b4af-615e5eb830c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-77887625-3697-420d-9262-c6bbfabe3e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-df30ac64-93cc-413f-9932-f3a73d724365,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-1f05e0a3-2d05-4640-b4f8-eebcf0c7061d,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-1279db2c-0a58-429f-8b7f-8468fc4318cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-33390736-dfcc-41d0-9327-b9f09e696704,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-006c6a76-0a07-47f0-b9d5-e7f756b08b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335833851-172.17.0.4-1597293270976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36246,DS-8fe004bf-fbf3-4a54-9d1f-b5ff1f8b07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-fa5979c7-24e0-4656-b4af-615e5eb830c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-77887625-3697-420d-9262-c6bbfabe3e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-df30ac64-93cc-413f-9932-f3a73d724365,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-1f05e0a3-2d05-4640-b4f8-eebcf0c7061d,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-1279db2c-0a58-429f-8b7f-8468fc4318cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-33390736-dfcc-41d0-9327-b9f09e696704,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-006c6a76-0a07-47f0-b9d5-e7f756b08b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043885414-172.17.0.4-1597293934941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42106,DS-8382341d-4cc9-49bc-b6d1-0494127e0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-8bef9254-c94d-4d5a-a049-1576f3a4ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-a3d47e44-92cd-4419-ab46-55b4d7178869,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-0dde4942-ccf3-4348-8252-1dd1c5c2b019,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a43311ab-c759-4370-8e22-45ecbbacb382,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-d9741b58-2c99-4337-9c6b-c810c90a1020,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-4b41c05d-feb6-486d-b1a2-e3f3d33718b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-93147238-5256-4d6e-a4b8-ed8d1697f255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043885414-172.17.0.4-1597293934941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42106,DS-8382341d-4cc9-49bc-b6d1-0494127e0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-8bef9254-c94d-4d5a-a049-1576f3a4ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-a3d47e44-92cd-4419-ab46-55b4d7178869,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-0dde4942-ccf3-4348-8252-1dd1c5c2b019,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a43311ab-c759-4370-8e22-45ecbbacb382,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-d9741b58-2c99-4337-9c6b-c810c90a1020,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-4b41c05d-feb6-486d-b1a2-e3f3d33718b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-93147238-5256-4d6e-a4b8-ed8d1697f255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811701166-172.17.0.4-1597294173471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-f3ee4d21-2668-4424-8f7f-4e6e95e11343,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-48ab3b55-2fde-4137-b526-92f33c8bcc45,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-9e9602fb-3536-45fc-81f1-4238dce7b984,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-c6f73167-f8e8-4fab-aebc-5a607913b266,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-597a9540-4f59-4579-8d53-c5e46daac432,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-d8ce4bbd-e5fd-461d-928b-8c70dd10ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-ef610d29-870f-42e0-b17b-252005b9b819,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-a9b11af5-2d1b-4eff-a249-caa36309e117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811701166-172.17.0.4-1597294173471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-f3ee4d21-2668-4424-8f7f-4e6e95e11343,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-48ab3b55-2fde-4137-b526-92f33c8bcc45,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-9e9602fb-3536-45fc-81f1-4238dce7b984,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-c6f73167-f8e8-4fab-aebc-5a607913b266,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-597a9540-4f59-4579-8d53-c5e46daac432,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-d8ce4bbd-e5fd-461d-928b-8c70dd10ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-ef610d29-870f-42e0-b17b-252005b9b819,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-a9b11af5-2d1b-4eff-a249-caa36309e117,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088867063-172.17.0.4-1597294558548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34770,DS-d68a2da0-5cc6-4e84-a31a-8627158f86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-256d910a-8ff4-4ef8-b0ad-d4847eab30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-11073206-81af-4bcc-a788-ee7d933c2fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-1ffda490-d97e-4ddf-b980-9f5e4b93276d,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-9081b580-ac0b-41d8-af9b-4394f2e66a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-5f0c66b6-93cd-4566-a34a-8628762fa9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-27e6d290-e11c-4793-ad82-b7647c9faaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-49a0462a-4693-43cf-8d26-c9be3cd4b6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088867063-172.17.0.4-1597294558548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34770,DS-d68a2da0-5cc6-4e84-a31a-8627158f86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-256d910a-8ff4-4ef8-b0ad-d4847eab30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-11073206-81af-4bcc-a788-ee7d933c2fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-1ffda490-d97e-4ddf-b980-9f5e4b93276d,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-9081b580-ac0b-41d8-af9b-4394f2e66a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-5f0c66b6-93cd-4566-a34a-8628762fa9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-27e6d290-e11c-4793-ad82-b7647c9faaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-49a0462a-4693-43cf-8d26-c9be3cd4b6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141345864-172.17.0.4-1597294782404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-4a2b6095-f804-49ac-8eaa-cead73a07009,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-8ca901b9-b010-4a13-bec7-3f694589e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-173b61bd-ee8e-44c1-9d0c-0d3fefb14302,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-82cd024b-649c-424c-84d0-71d4bd14f017,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-c944b4a2-3523-4df2-aa68-5bdc3bc53a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f33716a7-8350-49f5-b524-f1794d9b67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-731744a3-0443-4fb0-804c-5a0bae72e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-3d697b29-039e-4afc-a885-5407afa9353f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141345864-172.17.0.4-1597294782404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-4a2b6095-f804-49ac-8eaa-cead73a07009,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-8ca901b9-b010-4a13-bec7-3f694589e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-173b61bd-ee8e-44c1-9d0c-0d3fefb14302,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-82cd024b-649c-424c-84d0-71d4bd14f017,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-c944b4a2-3523-4df2-aa68-5bdc3bc53a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f33716a7-8350-49f5-b524-f1794d9b67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-731744a3-0443-4fb0-804c-5a0bae72e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-3d697b29-039e-4afc-a885-5407afa9353f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5820
