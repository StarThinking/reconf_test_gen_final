reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532394354-172.17.0.13-1597649326248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37373,DS-bac513a6-a67b-4590-b512-0c5113136a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-46f1c623-44b3-4757-9ff1-614d8592e922,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-588a7bbc-be1e-4d33-8a24-49419c6d801f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-376eb0b4-c76e-4b9e-aefc-11f75be3a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f5f0dc2d-59b5-4a1e-b51f-e5fda3bbc1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-682b30be-77d8-4349-9ddb-4edb339e2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-9a40f38f-6881-4fe4-82ea-c709f0b6c957,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-3b235a89-2380-471c-8daf-67443e16696e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532394354-172.17.0.13-1597649326248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37373,DS-bac513a6-a67b-4590-b512-0c5113136a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-46f1c623-44b3-4757-9ff1-614d8592e922,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-588a7bbc-be1e-4d33-8a24-49419c6d801f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-376eb0b4-c76e-4b9e-aefc-11f75be3a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f5f0dc2d-59b5-4a1e-b51f-e5fda3bbc1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-682b30be-77d8-4349-9ddb-4edb339e2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-9a40f38f-6881-4fe4-82ea-c709f0b6c957,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-3b235a89-2380-471c-8daf-67443e16696e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256230485-172.17.0.13-1597649581112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-e60aac92-8fd4-4be1-93e1-d7099f3bacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2822bae6-7ccf-46e8-9e2e-24130e7732f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-e53102aa-fbc4-4177-892b-a6163d9ec462,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-0dc7aa50-bcf7-4546-8bae-196b620c30f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-aa89e0ad-1fd4-4fbd-952a-be099aec7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-7fb7966c-54b5-42a9-af79-f16593d6f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-349aad42-a715-493f-ac7e-88f3386f52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-5cd531dd-d35d-4104-a27f-db5ccef55238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256230485-172.17.0.13-1597649581112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-e60aac92-8fd4-4be1-93e1-d7099f3bacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2822bae6-7ccf-46e8-9e2e-24130e7732f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-e53102aa-fbc4-4177-892b-a6163d9ec462,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-0dc7aa50-bcf7-4546-8bae-196b620c30f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-aa89e0ad-1fd4-4fbd-952a-be099aec7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-7fb7966c-54b5-42a9-af79-f16593d6f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-349aad42-a715-493f-ac7e-88f3386f52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-5cd531dd-d35d-4104-a27f-db5ccef55238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480315830-172.17.0.13-1597649950211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-ecea1585-a744-4c3b-a8ce-bfad75066d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-9cf5df2e-0271-4875-990d-2d0cd186203b,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-8e87fe28-e241-40e6-876f-7a2cc2970352,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-83bb9111-a525-4437-ac79-9d71dd7681a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e576ceb3-738d-4fba-8b6c-9a63b3e930e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-1b9f66c3-f74e-4ecb-b89a-976d85634f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-9eaf1555-6360-42a4-849e-2d5a87f1ed43,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-fd02af79-dcbe-47e4-9168-b6fa4c0a6490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480315830-172.17.0.13-1597649950211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-ecea1585-a744-4c3b-a8ce-bfad75066d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-9cf5df2e-0271-4875-990d-2d0cd186203b,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-8e87fe28-e241-40e6-876f-7a2cc2970352,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-83bb9111-a525-4437-ac79-9d71dd7681a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e576ceb3-738d-4fba-8b6c-9a63b3e930e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-1b9f66c3-f74e-4ecb-b89a-976d85634f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-9eaf1555-6360-42a4-849e-2d5a87f1ed43,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-fd02af79-dcbe-47e4-9168-b6fa4c0a6490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281587753-172.17.0.13-1597650177597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-5574dfdb-d76c-4c34-847a-2983438c9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-68c9a8d2-3dc5-4219-ab06-bdddbc0df46a,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-5a36a4eb-8074-4a22-b022-c462a3728823,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-b44ab46e-74a2-4cc9-880d-0aa68999572a,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-2f0d4c97-2e79-4490-9edf-528e89b8dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-465affff-1a2e-4019-a596-da1cdd3ef09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-ca1a553f-9f6a-471d-a38e-d77187a2b02a,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a7d13f5a-c9db-40c3-809d-1d82591933fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281587753-172.17.0.13-1597650177597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-5574dfdb-d76c-4c34-847a-2983438c9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-68c9a8d2-3dc5-4219-ab06-bdddbc0df46a,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-5a36a4eb-8074-4a22-b022-c462a3728823,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-b44ab46e-74a2-4cc9-880d-0aa68999572a,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-2f0d4c97-2e79-4490-9edf-528e89b8dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-465affff-1a2e-4019-a596-da1cdd3ef09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-ca1a553f-9f6a-471d-a38e-d77187a2b02a,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a7d13f5a-c9db-40c3-809d-1d82591933fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664062717-172.17.0.13-1597650344262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-621f020c-ff94-4835-b833-bb17b8fa9a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-56ebf779-520f-4db5-8802-e15d6d7280e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-6f304cc2-7383-4f0b-a81b-0cc15a1bfeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-5ce55cdb-e625-43bf-8916-4fb332330052,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-852f1d87-5dfc-4d53-a0d4-5dafe5ea8864,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-f0e2bd8a-3119-4fd4-86cf-b3aa68d2478e,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-7bae51d8-6bc4-41dc-a6ad-85663db056d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-0f2cdca1-8d69-4cd9-aeae-f7187f54c8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664062717-172.17.0.13-1597650344262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-621f020c-ff94-4835-b833-bb17b8fa9a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-56ebf779-520f-4db5-8802-e15d6d7280e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-6f304cc2-7383-4f0b-a81b-0cc15a1bfeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-5ce55cdb-e625-43bf-8916-4fb332330052,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-852f1d87-5dfc-4d53-a0d4-5dafe5ea8864,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-f0e2bd8a-3119-4fd4-86cf-b3aa68d2478e,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-7bae51d8-6bc4-41dc-a6ad-85663db056d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-0f2cdca1-8d69-4cd9-aeae-f7187f54c8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245754085-172.17.0.13-1597651202637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-4f85709b-19b6-4086-9412-72c8d885338b,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-a9760a3f-ad2e-4804-98e8-43e10e8b421b,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-6712d34f-ac19-4f06-80e5-cd4c5bec68e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-064fc4ec-e13d-40de-9d3c-3ebc06790685,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-560c3e8e-312c-4496-814b-245e934d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-89fa1d73-7232-4030-9e21-d34a45b642f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-9fd44daf-cb50-482b-9890-6a4f1cb86808,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-4b02e71a-05f3-4cf1-8e01-1e11ac734378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245754085-172.17.0.13-1597651202637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-4f85709b-19b6-4086-9412-72c8d885338b,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-a9760a3f-ad2e-4804-98e8-43e10e8b421b,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-6712d34f-ac19-4f06-80e5-cd4c5bec68e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-064fc4ec-e13d-40de-9d3c-3ebc06790685,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-560c3e8e-312c-4496-814b-245e934d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-89fa1d73-7232-4030-9e21-d34a45b642f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-9fd44daf-cb50-482b-9890-6a4f1cb86808,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-4b02e71a-05f3-4cf1-8e01-1e11ac734378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019505600-172.17.0.13-1597651315362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-3b8e8505-f5f8-4c83-9327-784be1ecf0db,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-5ca40845-be8e-4a6a-a514-47c4a979394a,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-0a77609a-f5d5-443a-bf78-284dc37b2f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-9cffcb18-d759-40c1-a9f3-87bfe4db8ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-9e7e6687-199b-4618-86c2-76b65af22076,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-300f686e-cc15-42cc-81d5-3c48199babcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-ee3dbe7d-32c4-49ae-ab0b-83253ddbb343,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b67b284f-7a86-4391-b0f4-164b15e92ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019505600-172.17.0.13-1597651315362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-3b8e8505-f5f8-4c83-9327-784be1ecf0db,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-5ca40845-be8e-4a6a-a514-47c4a979394a,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-0a77609a-f5d5-443a-bf78-284dc37b2f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-9cffcb18-d759-40c1-a9f3-87bfe4db8ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-9e7e6687-199b-4618-86c2-76b65af22076,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-300f686e-cc15-42cc-81d5-3c48199babcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-ee3dbe7d-32c4-49ae-ab0b-83253ddbb343,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b67b284f-7a86-4391-b0f4-164b15e92ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338276735-172.17.0.13-1597651800719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-dba2a8bd-57af-4157-8c15-c2e975dde9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-dfc11d7f-4e7f-4ce4-aa30-bb8157280ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-ecac7225-fb54-444f-bf8c-e08e3429d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-7a32a845-387e-4b7e-a58b-079649b0317b,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-0e8edaa6-b4a3-4ae5-a749-ba98d4f867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-fd4c885c-9ce5-4f6e-b6b0-e0a79b2ed986,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-74acb9ae-dae8-4818-a122-5b482ac26736,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-46e86a98-789c-4ac0-9033-4513768c3c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338276735-172.17.0.13-1597651800719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-dba2a8bd-57af-4157-8c15-c2e975dde9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-dfc11d7f-4e7f-4ce4-aa30-bb8157280ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-ecac7225-fb54-444f-bf8c-e08e3429d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-7a32a845-387e-4b7e-a58b-079649b0317b,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-0e8edaa6-b4a3-4ae5-a749-ba98d4f867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-fd4c885c-9ce5-4f6e-b6b0-e0a79b2ed986,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-74acb9ae-dae8-4818-a122-5b482ac26736,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-46e86a98-789c-4ac0-9033-4513768c3c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602364658-172.17.0.13-1597652719638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-38e1349a-1e7e-41c8-bd95-fe1ddcd26de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-a1e48788-15d3-4fd3-9812-0658b7a1c394,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-aa9f7cb7-ca19-4962-a667-7fc050f9de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-3d7f0473-34dd-4343-b868-ac92705c90f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-df804fdc-a3e8-4e35-8f22-fcb5fe583129,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-c5b3c409-8e1c-4aa4-9083-494c158bcbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-1194e52e-39b2-40b8-a9ec-fa75bf994317,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-1462fe25-a1fd-43f1-80bc-93a52a978414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602364658-172.17.0.13-1597652719638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-38e1349a-1e7e-41c8-bd95-fe1ddcd26de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-a1e48788-15d3-4fd3-9812-0658b7a1c394,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-aa9f7cb7-ca19-4962-a667-7fc050f9de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-3d7f0473-34dd-4343-b868-ac92705c90f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-df804fdc-a3e8-4e35-8f22-fcb5fe583129,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-c5b3c409-8e1c-4aa4-9083-494c158bcbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-1194e52e-39b2-40b8-a9ec-fa75bf994317,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-1462fe25-a1fd-43f1-80bc-93a52a978414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052383073-172.17.0.13-1597652941737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-7f128edc-0f31-4796-a478-62b2c036c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-6741d49a-4609-49d7-a0eb-e1e990db0d58,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2eb728f6-292e-4e6d-bd58-5d4c76c80e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-3cf593ff-6783-4425-8685-07be1c220b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-98b67c90-ef91-42b8-b4e5-0c37488edc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-f6ba7961-01be-4b3f-acdc-525b6151138b,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-1f22f9b0-d23a-4b98-ba5a-30b3abe60641,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-37c7e88a-93e9-408e-8fe2-d3d7942a7c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052383073-172.17.0.13-1597652941737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37992,DS-7f128edc-0f31-4796-a478-62b2c036c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-6741d49a-4609-49d7-a0eb-e1e990db0d58,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2eb728f6-292e-4e6d-bd58-5d4c76c80e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-3cf593ff-6783-4425-8685-07be1c220b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-98b67c90-ef91-42b8-b4e5-0c37488edc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-f6ba7961-01be-4b3f-acdc-525b6151138b,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-1f22f9b0-d23a-4b98-ba5a-30b3abe60641,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-37c7e88a-93e9-408e-8fe2-d3d7942a7c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978561191-172.17.0.13-1597653243566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-727072fc-8ca4-48c7-ac63-f4ffab19f885,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-7dfc9229-f831-455b-b49c-0170e15196b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-1f72b290-b0fa-4e90-b8bb-5d59df38534a,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-ced9dc79-6bbc-4313-b129-1fef23796c93,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-e866111d-c901-4e0a-9405-5eda557090cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-e448350b-c425-4ab7-b712-74ca62a026fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-58212664-d58e-47d6-b689-e9f1dcb6ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-7e93b656-5b4c-4e14-8506-a60dfea5bad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978561191-172.17.0.13-1597653243566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-727072fc-8ca4-48c7-ac63-f4ffab19f885,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-7dfc9229-f831-455b-b49c-0170e15196b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-1f72b290-b0fa-4e90-b8bb-5d59df38534a,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-ced9dc79-6bbc-4313-b129-1fef23796c93,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-e866111d-c901-4e0a-9405-5eda557090cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-e448350b-c425-4ab7-b712-74ca62a026fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-58212664-d58e-47d6-b689-e9f1dcb6ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-7e93b656-5b4c-4e14-8506-a60dfea5bad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765508124-172.17.0.13-1597653400624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-056c5a72-7957-4bf5-8fea-798d88a1e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-a6bc9868-61db-4642-abdd-eefe50dded1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b1dac7e6-8f23-44a0-bb42-bc0644a0dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-f1611a2e-cf7e-484d-91b6-465faa5662cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-c919021a-56ff-48d8-b097-bdfc901b05e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-3ee91392-1683-4cd2-99f2-7e7070f1c030,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d833901f-47db-4472-abe0-ddaac051b264,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-f43fd4f0-e1ba-4a9c-ba94-62f555b33315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765508124-172.17.0.13-1597653400624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-056c5a72-7957-4bf5-8fea-798d88a1e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-a6bc9868-61db-4642-abdd-eefe50dded1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b1dac7e6-8f23-44a0-bb42-bc0644a0dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-f1611a2e-cf7e-484d-91b6-465faa5662cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-c919021a-56ff-48d8-b097-bdfc901b05e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-3ee91392-1683-4cd2-99f2-7e7070f1c030,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d833901f-47db-4472-abe0-ddaac051b264,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-f43fd4f0-e1ba-4a9c-ba94-62f555b33315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46861885-172.17.0.13-1597653716113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33623,DS-779dc2bc-d503-4718-9af9-c78472775c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cc2d598d-3baa-4d61-a61a-1bca9b37892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-43df7651-e26e-4165-a90d-bcd552831c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-71da0eaf-eae1-466c-a1e2-5f3dac092c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d6f2cf06-64d1-4b84-b31b-dc30c9ea522d,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-5e3f234e-a216-4449-ad57-e06c4d5b822d,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-7c011b11-5e95-4cf0-b34e-652a76ff38ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-69538718-e0cb-480f-9a7d-b7b159522c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46861885-172.17.0.13-1597653716113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33623,DS-779dc2bc-d503-4718-9af9-c78472775c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cc2d598d-3baa-4d61-a61a-1bca9b37892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-43df7651-e26e-4165-a90d-bcd552831c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-71da0eaf-eae1-466c-a1e2-5f3dac092c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d6f2cf06-64d1-4b84-b31b-dc30c9ea522d,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-5e3f234e-a216-4449-ad57-e06c4d5b822d,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-7c011b11-5e95-4cf0-b34e-652a76ff38ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-69538718-e0cb-480f-9a7d-b7b159522c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244225295-172.17.0.13-1597653989515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37064,DS-ce1f4ee3-99a5-4430-992d-fed375db12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-734ecbae-6ebb-427f-ac04-d2252cfd3ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-880688ad-63ae-4e06-946d-95fa9f03e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-d84bf242-c763-47ac-bd0f-877dba02afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-ad88409f-6d46-42c6-a187-0ff26e43fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-07754cc2-c136-4f5d-8286-f31a8449f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-503632e9-06c5-4852-abd7-9a6a6098d385,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-ef278538-f4a5-40ab-b5f6-b68695387576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244225295-172.17.0.13-1597653989515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37064,DS-ce1f4ee3-99a5-4430-992d-fed375db12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-734ecbae-6ebb-427f-ac04-d2252cfd3ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-880688ad-63ae-4e06-946d-95fa9f03e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-d84bf242-c763-47ac-bd0f-877dba02afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-ad88409f-6d46-42c6-a187-0ff26e43fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-07754cc2-c136-4f5d-8286-f31a8449f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-503632e9-06c5-4852-abd7-9a6a6098d385,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-ef278538-f4a5-40ab-b5f6-b68695387576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5521
