reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45334639-172.17.0.17-1597272400271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-156df18c-6382-4141-bdf0-42c05f2ecc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1bf4dbb-71ba-4e69-aa22-81dce467f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-cc2f7bb9-d333-4e4a-af30-febf1fb67cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-be88dc65-2bfc-40c7-bca7-453a923e65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-d0108263-0025-4283-b357-af725c01a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-24953c0a-3815-43ff-9fc4-938ed43d5189,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-29427d2a-0a56-4f6f-8bde-04111d03400b,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-40fd65ad-dc30-4caa-94d1-29f1ec59b2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45334639-172.17.0.17-1597272400271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-156df18c-6382-4141-bdf0-42c05f2ecc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1bf4dbb-71ba-4e69-aa22-81dce467f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-cc2f7bb9-d333-4e4a-af30-febf1fb67cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-be88dc65-2bfc-40c7-bca7-453a923e65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-d0108263-0025-4283-b357-af725c01a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-24953c0a-3815-43ff-9fc4-938ed43d5189,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-29427d2a-0a56-4f6f-8bde-04111d03400b,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-40fd65ad-dc30-4caa-94d1-29f1ec59b2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086454321-172.17.0.17-1597272514556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-e72556a0-3844-4fb7-8607-1ac94b18fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e13cfc9f-70a8-4e32-b51f-bdd8c919bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-ae0ba2ba-6242-456b-a36c-ad406928d245,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-65122259-7d4a-4740-a491-c7f4ddec0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-8a600c52-b2b2-46f8-8845-6eae782f4cef,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a622a3f3-2b40-4f16-b1b6-7573efe98e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c5c5c6a1-0b12-4c82-bd19-fc1692e77e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-73d9871f-8db1-4089-b695-d7bf19ce64ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086454321-172.17.0.17-1597272514556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-e72556a0-3844-4fb7-8607-1ac94b18fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e13cfc9f-70a8-4e32-b51f-bdd8c919bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-ae0ba2ba-6242-456b-a36c-ad406928d245,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-65122259-7d4a-4740-a491-c7f4ddec0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-8a600c52-b2b2-46f8-8845-6eae782f4cef,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a622a3f3-2b40-4f16-b1b6-7573efe98e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c5c5c6a1-0b12-4c82-bd19-fc1692e77e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-73d9871f-8db1-4089-b695-d7bf19ce64ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581714135-172.17.0.17-1597272895431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-410b38c3-558e-41c8-9c79-8a871d6e6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-6ad55bc0-4896-40ec-b145-beda125b9e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-61612cd3-310d-4e2b-aaef-d3f62f8d90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-f2c12cf3-bf2f-483a-bd88-fda5e5e5a681,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-e7d6d974-3d5d-400c-bc26-4a3a159d0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-2f2ce077-5d25-403b-9bc5-55ca3e4e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-7807e712-b004-42df-b58d-8ea1df596c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-09e5c015-a473-4cdb-beb0-b1fbbfe428aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581714135-172.17.0.17-1597272895431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-410b38c3-558e-41c8-9c79-8a871d6e6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-6ad55bc0-4896-40ec-b145-beda125b9e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-61612cd3-310d-4e2b-aaef-d3f62f8d90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-f2c12cf3-bf2f-483a-bd88-fda5e5e5a681,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-e7d6d974-3d5d-400c-bc26-4a3a159d0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-2f2ce077-5d25-403b-9bc5-55ca3e4e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-7807e712-b004-42df-b58d-8ea1df596c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-09e5c015-a473-4cdb-beb0-b1fbbfe428aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952966960-172.17.0.17-1597273056020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-63aae586-8295-472d-87a1-28c1a76d2385,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-6f658c2d-7721-4e16-a4f1-c6cdbdb37318,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-4dba2126-e328-4cd9-b2f5-2d566c0d4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ae11cce0-1088-4c28-9b9c-307f6e31d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-658fc4f1-975e-4c16-a521-fe8c481043f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-5881cd35-dd2b-482b-a6a4-b02ec09e550b,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-60a24a57-3930-46bc-8e09-d0c0450822a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-ed99471f-19df-41b8-8646-db28e1c1d7b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952966960-172.17.0.17-1597273056020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-63aae586-8295-472d-87a1-28c1a76d2385,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-6f658c2d-7721-4e16-a4f1-c6cdbdb37318,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-4dba2126-e328-4cd9-b2f5-2d566c0d4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ae11cce0-1088-4c28-9b9c-307f6e31d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-658fc4f1-975e-4c16-a521-fe8c481043f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-5881cd35-dd2b-482b-a6a4-b02ec09e550b,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-60a24a57-3930-46bc-8e09-d0c0450822a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-ed99471f-19df-41b8-8646-db28e1c1d7b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219099522-172.17.0.17-1597273134456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-516d4be9-93e4-470e-bb08-9419d82b85ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-c8370eb1-c333-45ec-8768-b0642df17b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-1da437ca-7835-4839-a27d-b63290314ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-62db78a6-67ff-4ac2-841b-73e65ae62af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-41ca6ba1-6216-4e58-86ab-5ceda03dea82,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-7dc10180-976c-4a25-b4c5-04e4db91e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-685181e3-7a08-434f-8481-5ec112c942e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-5aefe107-5bc4-44a2-bde3-a9e889c89c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219099522-172.17.0.17-1597273134456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-516d4be9-93e4-470e-bb08-9419d82b85ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-c8370eb1-c333-45ec-8768-b0642df17b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-1da437ca-7835-4839-a27d-b63290314ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-62db78a6-67ff-4ac2-841b-73e65ae62af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-41ca6ba1-6216-4e58-86ab-5ceda03dea82,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-7dc10180-976c-4a25-b4c5-04e4db91e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-685181e3-7a08-434f-8481-5ec112c942e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-5aefe107-5bc4-44a2-bde3-a9e889c89c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842246705-172.17.0.17-1597273887341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-fb123a3f-8efb-454b-b149-ab38fe06f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-b5fba62f-c532-44f8-ad44-e9fd5694bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-abe98d0d-304d-450a-89a1-e8d3b85d6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-98850b75-f383-4e3a-8dd6-b3454749e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1fdd4994-2b6b-4abc-9a7a-e7120968d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-fd732bf7-1e30-4ec3-a929-ecd52e4d4e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-f0b3403d-f1d7-4c89-a335-1915dceaea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-d3b5d5db-b4ac-4909-a390-6644b73d5139,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842246705-172.17.0.17-1597273887341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-fb123a3f-8efb-454b-b149-ab38fe06f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-b5fba62f-c532-44f8-ad44-e9fd5694bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-abe98d0d-304d-450a-89a1-e8d3b85d6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-98850b75-f383-4e3a-8dd6-b3454749e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1fdd4994-2b6b-4abc-9a7a-e7120968d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-fd732bf7-1e30-4ec3-a929-ecd52e4d4e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-f0b3403d-f1d7-4c89-a335-1915dceaea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-d3b5d5db-b4ac-4909-a390-6644b73d5139,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302559952-172.17.0.17-1597274079507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-32690e4a-90fe-4294-8779-e16f191b0355,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-2bf69910-f56c-4e71-b054-839d93e18b38,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-fc5a3f40-777c-4f07-b24d-20710794fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-22309b4b-aee2-43a3-b523-674b939c8864,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-def812dc-5963-46ea-8886-4bb5c36620a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-a13548b6-d223-4a52-b55d-4438a44c80ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-88f43e13-2e93-409e-8239-1ccad63701f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-0ab4fa3d-ff23-46b9-bcaa-43fc68d7ead7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302559952-172.17.0.17-1597274079507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-32690e4a-90fe-4294-8779-e16f191b0355,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-2bf69910-f56c-4e71-b054-839d93e18b38,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-fc5a3f40-777c-4f07-b24d-20710794fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-22309b4b-aee2-43a3-b523-674b939c8864,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-def812dc-5963-46ea-8886-4bb5c36620a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-a13548b6-d223-4a52-b55d-4438a44c80ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-88f43e13-2e93-409e-8239-1ccad63701f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-0ab4fa3d-ff23-46b9-bcaa-43fc68d7ead7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851011506-172.17.0.17-1597274120100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-713b580f-d72d-468a-b42a-0be74ebf5881,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-3a7719d4-0058-4ea8-98c7-f85eb93b7040,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-d21da849-3633-4a24-9ac7-351da22eb51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-12b71d25-68eb-4cdb-af32-85221f1f47c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-75c770e5-740c-4a06-9443-0a9071ef5950,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-67979733-a9a4-4c30-9db1-c2270c69017f,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-0e83bfbc-59d2-4936-a352-0647f2483c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-056252c2-fa2b-4d18-9b95-8d89249fc085,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851011506-172.17.0.17-1597274120100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-713b580f-d72d-468a-b42a-0be74ebf5881,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-3a7719d4-0058-4ea8-98c7-f85eb93b7040,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-d21da849-3633-4a24-9ac7-351da22eb51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-12b71d25-68eb-4cdb-af32-85221f1f47c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-75c770e5-740c-4a06-9443-0a9071ef5950,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-67979733-a9a4-4c30-9db1-c2270c69017f,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-0e83bfbc-59d2-4936-a352-0647f2483c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-056252c2-fa2b-4d18-9b95-8d89249fc085,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505726198-172.17.0.17-1597274819071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-9ac3eeaf-91fa-45bb-a0ac-42b940e22356,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-407f2ad1-5e9d-47a1-9bb3-261072dd2a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-70cd712f-30d2-45a9-96a6-3c87715b1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-4fb0434a-b6fb-4530-bb0b-a7719f4b074b,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-0af817f6-7ac8-41b6-9a4f-0860ef0361ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4be465f7-4e6e-44a7-8c02-a4cb105e5c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-934262c9-6012-4b06-b35a-617043cbd393,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-b0c5b0b9-d02e-41b1-98d9-104212168569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505726198-172.17.0.17-1597274819071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-9ac3eeaf-91fa-45bb-a0ac-42b940e22356,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-407f2ad1-5e9d-47a1-9bb3-261072dd2a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-70cd712f-30d2-45a9-96a6-3c87715b1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-4fb0434a-b6fb-4530-bb0b-a7719f4b074b,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-0af817f6-7ac8-41b6-9a4f-0860ef0361ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4be465f7-4e6e-44a7-8c02-a4cb105e5c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-934262c9-6012-4b06-b35a-617043cbd393,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-b0c5b0b9-d02e-41b1-98d9-104212168569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970863187-172.17.0.17-1597274942137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-748bbd34-5005-41e3-94fe-12298469e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-d3b2637e-ebe9-4e93-9cc3-6c1a6adb9c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-c222b682-ec92-4119-9e2d-683bfc22b967,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-6cfc3acf-d527-4a64-8f4b-e5c2dadc62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-fa70dc6c-4598-426c-a192-db2a78caed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-9d58b5c2-f40c-44e2-9716-5ec0a6b58100,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-a1d9cad4-9c94-4cc2-b35a-84b0104ae231,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-44cbf7ab-aaf7-4696-9739-aaec9f105ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970863187-172.17.0.17-1597274942137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-748bbd34-5005-41e3-94fe-12298469e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-d3b2637e-ebe9-4e93-9cc3-6c1a6adb9c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-c222b682-ec92-4119-9e2d-683bfc22b967,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-6cfc3acf-d527-4a64-8f4b-e5c2dadc62e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-fa70dc6c-4598-426c-a192-db2a78caed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-9d58b5c2-f40c-44e2-9716-5ec0a6b58100,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-a1d9cad4-9c94-4cc2-b35a-84b0104ae231,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-44cbf7ab-aaf7-4696-9739-aaec9f105ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957798799-172.17.0.17-1597275065161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-5007ac11-4aab-409a-bb7a-1abd1860ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7ee1711a-b6c2-49a7-8afe-5a79d762c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-0c29a03b-5de1-49bb-ad0a-e37e72fe9d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-f0339736-a536-4f4a-94e2-8adaa0e19ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-bc581bac-b692-410a-8058-a9a30b7d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-d3567cf2-fbea-4f79-b958-d648ad0552f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-7cd64bae-218b-400e-bdf2-c1dbc706260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-b460fc08-8358-4d49-bdc1-c26c5cf2bf11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957798799-172.17.0.17-1597275065161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-5007ac11-4aab-409a-bb7a-1abd1860ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7ee1711a-b6c2-49a7-8afe-5a79d762c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-0c29a03b-5de1-49bb-ad0a-e37e72fe9d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-f0339736-a536-4f4a-94e2-8adaa0e19ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-bc581bac-b692-410a-8058-a9a30b7d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-d3567cf2-fbea-4f79-b958-d648ad0552f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-7cd64bae-218b-400e-bdf2-c1dbc706260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-b460fc08-8358-4d49-bdc1-c26c5cf2bf11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022422368-172.17.0.17-1597275144437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-c5f630f7-92ec-4614-8048-e1c69480d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-0db1ffc8-aae1-4c44-8b59-2410e5f1ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1008ab11-ad46-4e0c-900b-c219b2c0c340,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-8c979e04-93aa-4760-ae1a-f1e38bc9e965,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-221e00c7-dd3c-4a04-a03b-75b384872c04,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-b99eb466-cbb1-49eb-9d87-317f8ea75ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-7c3f4a32-5a63-4bc5-963e-cd527ef88c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-ef53507d-7beb-4e90-9465-179dcd7c2285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022422368-172.17.0.17-1597275144437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-c5f630f7-92ec-4614-8048-e1c69480d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-0db1ffc8-aae1-4c44-8b59-2410e5f1ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1008ab11-ad46-4e0c-900b-c219b2c0c340,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-8c979e04-93aa-4760-ae1a-f1e38bc9e965,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-221e00c7-dd3c-4a04-a03b-75b384872c04,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-b99eb466-cbb1-49eb-9d87-317f8ea75ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-7c3f4a32-5a63-4bc5-963e-cd527ef88c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-ef53507d-7beb-4e90-9465-179dcd7c2285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521241314-172.17.0.17-1597275172639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-d4e76c84-3db1-4521-bdaf-935173917ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-c15aabb3-f387-4fbe-a7c8-c597cf1e41c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-3d99a971-da4c-4db9-93e7-a68a439cb1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-5665bfef-2443-4d9f-a7bf-d80a6b533690,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-330ff9eb-aceb-4364-b26d-2ba43cac6b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ccf15431-275c-4cca-a2dd-b00a5af648c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-1dedcb60-c462-446a-9586-44361f3b35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d928fbd3-38e8-43d5-8f28-8b39c10ff090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521241314-172.17.0.17-1597275172639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-d4e76c84-3db1-4521-bdaf-935173917ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-c15aabb3-f387-4fbe-a7c8-c597cf1e41c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-3d99a971-da4c-4db9-93e7-a68a439cb1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-5665bfef-2443-4d9f-a7bf-d80a6b533690,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-330ff9eb-aceb-4364-b26d-2ba43cac6b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ccf15431-275c-4cca-a2dd-b00a5af648c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-1dedcb60-c462-446a-9586-44361f3b35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d928fbd3-38e8-43d5-8f28-8b39c10ff090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061455227-172.17.0.17-1597275297559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-46fd368e-3de5-4238-be49-5b1ffcd09b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-5170adb8-2adb-4fdb-b424-7cae7808848f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-28363f64-15b8-4fb8-a253-879fe4b4776b,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-faefb514-0d50-43c7-bdf0-72a8e0403dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-84b3700b-cd42-406e-b577-85103f4458de,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-dc2036c5-f2e7-44a1-9ef6-2cfa94bf6587,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-f205b3e3-910e-4fec-848d-c57dfa74c87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-99bfe1c3-3535-4d14-a866-1c5c72f5c35d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061455227-172.17.0.17-1597275297559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-46fd368e-3de5-4238-be49-5b1ffcd09b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-5170adb8-2adb-4fdb-b424-7cae7808848f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-28363f64-15b8-4fb8-a253-879fe4b4776b,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-faefb514-0d50-43c7-bdf0-72a8e0403dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-84b3700b-cd42-406e-b577-85103f4458de,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-dc2036c5-f2e7-44a1-9ef6-2cfa94bf6587,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-f205b3e3-910e-4fec-848d-c57dfa74c87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-99bfe1c3-3535-4d14-a866-1c5c72f5c35d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98718630-172.17.0.17-1597275375460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-daa587b0-bb58-40c5-804c-305481e767dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-4fd636c0-f764-4040-b488-0cabe980c279,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-a8c9d7e7-6209-491f-9c9e-89973ca497fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-81815417-6e54-443f-b39d-2295e0035317,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5e89c0e4-595b-44ad-895e-da00f32a4841,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-bfc1150e-eca5-4bf9-b9b5-0dc125202bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-742495f7-8ea2-4dac-9425-dcb514983108,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-838b43c0-6c35-4e28-90eb-69bb44b13517,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98718630-172.17.0.17-1597275375460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34463,DS-daa587b0-bb58-40c5-804c-305481e767dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-4fd636c0-f764-4040-b488-0cabe980c279,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-a8c9d7e7-6209-491f-9c9e-89973ca497fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-81815417-6e54-443f-b39d-2295e0035317,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5e89c0e4-595b-44ad-895e-da00f32a4841,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-bfc1150e-eca5-4bf9-b9b5-0dc125202bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-742495f7-8ea2-4dac-9425-dcb514983108,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-838b43c0-6c35-4e28-90eb-69bb44b13517,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206585507-172.17.0.17-1597275718826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-c2a6e580-129a-49bc-a9bc-a6e17d580c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-0b859ff3-bec8-4b3c-9b80-45d1b147b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-bbaf1817-95fd-496f-ad20-6acb49c80b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-294b3d02-f89f-4bfe-86e9-a899f27c7cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-f08d9538-9209-4941-bd9e-ca2943eb275d,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-12df72e1-10e3-4eca-8845-ed58b3aacd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-ca3da9b7-5be5-45bc-b837-4a406e46d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-48c3fff9-82e1-4549-9b9c-563862e2eab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206585507-172.17.0.17-1597275718826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-c2a6e580-129a-49bc-a9bc-a6e17d580c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-0b859ff3-bec8-4b3c-9b80-45d1b147b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-bbaf1817-95fd-496f-ad20-6acb49c80b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-294b3d02-f89f-4bfe-86e9-a899f27c7cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-f08d9538-9209-4941-bd9e-ca2943eb275d,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-12df72e1-10e3-4eca-8845-ed58b3aacd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-ca3da9b7-5be5-45bc-b837-4a406e46d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-48c3fff9-82e1-4549-9b9c-563862e2eab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509852333-172.17.0.17-1597275799557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-e98799a6-4050-41e7-9384-a4779cd6f239,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-03ec4df7-0289-499c-b126-5feb36f6cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-556841de-c516-49e8-bf36-1e0ce6bb6104,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-dd4d7d05-7fa4-4242-badd-af363f07b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-2a125df5-de14-4e90-a7c9-e79a086f1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7c3a3a73-80dc-44b8-ae7b-0baff1f2922c,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-70a2c264-26ae-4a58-a62c-db74d28895cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-574b7842-ca25-4b9c-9983-01e63fb92d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509852333-172.17.0.17-1597275799557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-e98799a6-4050-41e7-9384-a4779cd6f239,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-03ec4df7-0289-499c-b126-5feb36f6cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-556841de-c516-49e8-bf36-1e0ce6bb6104,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-dd4d7d05-7fa4-4242-badd-af363f07b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-2a125df5-de14-4e90-a7c9-e79a086f1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7c3a3a73-80dc-44b8-ae7b-0baff1f2922c,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-70a2c264-26ae-4a58-a62c-db74d28895cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-574b7842-ca25-4b9c-9983-01e63fb92d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76952670-172.17.0.17-1597276118894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-d0c2b4f6-97d2-4622-a74b-c84a65afc6be,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-051691f3-2219-4ad4-9d51-e8dec0653637,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-08b53bd7-3fb9-4a49-8bda-abddf0633725,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-40706b4e-548e-43c1-9553-f16b0c5ffd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-3055700c-769e-4194-8317-99bb15ac7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-3f274f20-cd8e-44ec-b0ce-baba0bbd21aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-37bedc20-39c9-47f9-b6b0-4c2aa8b1ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-6b2e2b91-5c8f-4596-82e2-3d771ae5da13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76952670-172.17.0.17-1597276118894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-d0c2b4f6-97d2-4622-a74b-c84a65afc6be,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-051691f3-2219-4ad4-9d51-e8dec0653637,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-08b53bd7-3fb9-4a49-8bda-abddf0633725,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-40706b4e-548e-43c1-9553-f16b0c5ffd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-3055700c-769e-4194-8317-99bb15ac7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-3f274f20-cd8e-44ec-b0ce-baba0bbd21aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-37bedc20-39c9-47f9-b6b0-4c2aa8b1ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-6b2e2b91-5c8f-4596-82e2-3d771ae5da13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883368817-172.17.0.17-1597276200432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-66bc6143-ee2d-4c5e-b28f-d987c7e3f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9fd3f6fa-a0dd-4db0-ad31-f25ec405fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4cb4333c-d9b4-4d92-9a88-ee50933eeade,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-f645de5d-5162-47ac-88de-223c37c276ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-836f6b17-4e14-4252-aa1d-3fd560b90a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8638d1e9-3bac-4235-9c22-39e61fc332f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-76fe6ef8-6b0b-4d10-a135-3ebeeaa45099,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-3beb453a-0a88-4dd7-b10d-aade278b9152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883368817-172.17.0.17-1597276200432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-66bc6143-ee2d-4c5e-b28f-d987c7e3f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9fd3f6fa-a0dd-4db0-ad31-f25ec405fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4cb4333c-d9b4-4d92-9a88-ee50933eeade,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-f645de5d-5162-47ac-88de-223c37c276ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-836f6b17-4e14-4252-aa1d-3fd560b90a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8638d1e9-3bac-4235-9c22-39e61fc332f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-76fe6ef8-6b0b-4d10-a135-3ebeeaa45099,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-3beb453a-0a88-4dd7-b10d-aade278b9152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124020022-172.17.0.17-1597276351551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-98774fcb-2e96-4747-8a4d-f98189c5e853,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9b1caea9-1eea-490d-aa46-64ddc8b211ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-bddb4e0f-fd3a-418c-b3ee-3eaf5ad4193d,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-3baa8786-78f8-4270-af34-06db4d4c64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-0416b112-0b9e-48f9-be32-37698cd10878,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-57c4b5ff-648a-4df9-8a48-f442805f632d,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-7c0cbc29-f45a-4ab4-97b6-5c8fd49c8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ed253643-a7ed-4c2d-97c1-8b58b399194c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124020022-172.17.0.17-1597276351551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-98774fcb-2e96-4747-8a4d-f98189c5e853,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9b1caea9-1eea-490d-aa46-64ddc8b211ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-bddb4e0f-fd3a-418c-b3ee-3eaf5ad4193d,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-3baa8786-78f8-4270-af34-06db4d4c64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-0416b112-0b9e-48f9-be32-37698cd10878,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-57c4b5ff-648a-4df9-8a48-f442805f632d,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-7c0cbc29-f45a-4ab4-97b6-5c8fd49c8a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ed253643-a7ed-4c2d-97c1-8b58b399194c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246269511-172.17.0.17-1597276469453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-125cc790-edc3-4698-819b-eaa22737c0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-9b119931-03a7-435a-985a-3e217b5b5174,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-af0e7fc2-d05a-4514-abb5-1c0844e29bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8c3a3c38-dedf-43f6-a344-c05f5f9673bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-062907b7-5aef-4778-80a0-acd30322ee61,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-6bcadcec-2b2c-478b-a812-c5098d91ffa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-973c725e-6c0d-4e84-92f8-4971f1427bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-c4b1dad0-5c94-44d5-aa95-b7a184fb6845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246269511-172.17.0.17-1597276469453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-125cc790-edc3-4698-819b-eaa22737c0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-9b119931-03a7-435a-985a-3e217b5b5174,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-af0e7fc2-d05a-4514-abb5-1c0844e29bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8c3a3c38-dedf-43f6-a344-c05f5f9673bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-062907b7-5aef-4778-80a0-acd30322ee61,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-6bcadcec-2b2c-478b-a812-c5098d91ffa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-973c725e-6c0d-4e84-92f8-4971f1427bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-c4b1dad0-5c94-44d5-aa95-b7a184fb6845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138096523-172.17.0.17-1597276702374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-2699790c-3449-42f0-8631-7537cf3ea0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-42ac1d4d-bcb2-4989-a7ac-cea298c732c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-86c14297-4b91-4ded-97be-33f1b97a65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-44f8da05-5860-45f7-870b-2862c9fb530e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-b3ed2bd0-5e9f-4f31-80a9-368ea335a03b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-e55ac341-97cb-4cdf-8488-1b012631125f,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-9d42ceee-45f8-4131-ac0c-029dcd4e2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-4c54a2e3-3983-40de-8ca7-bfee6dfa8000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138096523-172.17.0.17-1597276702374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-2699790c-3449-42f0-8631-7537cf3ea0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-42ac1d4d-bcb2-4989-a7ac-cea298c732c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-86c14297-4b91-4ded-97be-33f1b97a65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-44f8da05-5860-45f7-870b-2862c9fb530e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-b3ed2bd0-5e9f-4f31-80a9-368ea335a03b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-e55ac341-97cb-4cdf-8488-1b012631125f,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-9d42ceee-45f8-4131-ac0c-029dcd4e2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-4c54a2e3-3983-40de-8ca7-bfee6dfa8000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525196021-172.17.0.17-1597276788305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34495,DS-ebd4ebf4-c10b-4169-8572-f829bcfed081,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-982119b9-3538-4b2b-9d72-55ae4b6c4384,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-9511a39f-170b-4d20-aa94-492b5692ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-8a896918-b6b7-4c8a-8e7b-4c38749bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-a44384ed-514c-4676-98f9-c31a794255ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-5aec38d2-ae78-4c0a-848e-bb81a56a6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-81d91478-45fc-4111-bd9d-c1df548e88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-a567a046-61af-4ffc-99a3-229b3dd8767e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525196021-172.17.0.17-1597276788305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34495,DS-ebd4ebf4-c10b-4169-8572-f829bcfed081,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-982119b9-3538-4b2b-9d72-55ae4b6c4384,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-9511a39f-170b-4d20-aa94-492b5692ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-8a896918-b6b7-4c8a-8e7b-4c38749bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-a44384ed-514c-4676-98f9-c31a794255ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-5aec38d2-ae78-4c0a-848e-bb81a56a6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-81d91478-45fc-4111-bd9d-c1df548e88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-a567a046-61af-4ffc-99a3-229b3dd8767e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789561703-172.17.0.17-1597276861169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-d43a944e-084d-4feb-85fe-291f1935c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-435516c0-3786-4873-89f4-94cc8c4c2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-2e5ab4fc-383c-48e1-8baf-721149711338,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-8df92c96-a1e7-4b64-ab42-b202eb64d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-e7b5a359-e301-4b55-8771-ce23b14ed80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-10725292-808a-40f7-bc6c-d4d4a55d1050,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-c01b9f4b-3775-49af-a657-97d884a96d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-c6490e21-3797-4db3-9a2b-249ed1a15e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789561703-172.17.0.17-1597276861169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-d43a944e-084d-4feb-85fe-291f1935c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-435516c0-3786-4873-89f4-94cc8c4c2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-2e5ab4fc-383c-48e1-8baf-721149711338,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-8df92c96-a1e7-4b64-ab42-b202eb64d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-e7b5a359-e301-4b55-8771-ce23b14ed80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-10725292-808a-40f7-bc6c-d4d4a55d1050,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-c01b9f4b-3775-49af-a657-97d884a96d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-c6490e21-3797-4db3-9a2b-249ed1a15e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951029528-172.17.0.17-1597276937734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-553bd434-0a6c-42d9-9204-2a1d1fbb56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-05ec3c70-2d25-44b7-9238-74282b78808a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-f23e0bbc-8230-4b3a-a63d-6e0a6eaebc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8c11a208-cfcd-43a5-887b-2d80b1a54f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-0ca26460-d414-470e-8e12-af501b43f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d5cb4c8b-5f72-4bb1-bf27-de98300f3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5f59d67d-75f1-4b66-925f-05af348740a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-1367d422-fa24-4b8b-8c6d-13c7f2118d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951029528-172.17.0.17-1597276937734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-553bd434-0a6c-42d9-9204-2a1d1fbb56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-05ec3c70-2d25-44b7-9238-74282b78808a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-f23e0bbc-8230-4b3a-a63d-6e0a6eaebc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8c11a208-cfcd-43a5-887b-2d80b1a54f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-0ca26460-d414-470e-8e12-af501b43f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d5cb4c8b-5f72-4bb1-bf27-de98300f3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5f59d67d-75f1-4b66-925f-05af348740a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-1367d422-fa24-4b8b-8c6d-13c7f2118d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904413012-172.17.0.17-1597277371686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-c855bf0a-7c72-414e-8832-ca72cc6d788c,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-0308f023-9655-45f4-9c3f-b380a0216bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-4935aebe-4de7-453c-9228-50115a5065e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-54e5f001-7815-49fb-92c0-c92c78658927,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-31c34501-8fed-4007-b47b-c20b1da3a279,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-d74a3412-d40a-46e2-abe5-1ad58574063b,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-6d791afc-0796-49a6-988b-3186019cf7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-6dce7e1a-727c-43b8-a506-c34122d023c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904413012-172.17.0.17-1597277371686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-c855bf0a-7c72-414e-8832-ca72cc6d788c,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-0308f023-9655-45f4-9c3f-b380a0216bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-4935aebe-4de7-453c-9228-50115a5065e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-54e5f001-7815-49fb-92c0-c92c78658927,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-31c34501-8fed-4007-b47b-c20b1da3a279,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-d74a3412-d40a-46e2-abe5-1ad58574063b,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-6d791afc-0796-49a6-988b-3186019cf7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-6dce7e1a-727c-43b8-a506-c34122d023c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116425496-172.17.0.17-1597277456214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-6e62d563-a155-4a48-a5a6-44d073eebb81,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-60f72f15-8ad8-475b-a1d8-1794c5a68e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-4445f695-65fa-40b0-be9d-5e7fe06e98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-1308855b-8c3f-4473-9f58-65ec6a604311,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-551b7487-51ff-48c3-ac87-96d068ff2903,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-55925aa6-cd2e-4db2-afd7-66575d25efed,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-f47a5f59-1317-43a1-ba67-be1888505a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-95c721b7-7761-4196-95c0-133f0a7d95ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116425496-172.17.0.17-1597277456214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-6e62d563-a155-4a48-a5a6-44d073eebb81,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-60f72f15-8ad8-475b-a1d8-1794c5a68e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-4445f695-65fa-40b0-be9d-5e7fe06e98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-1308855b-8c3f-4473-9f58-65ec6a604311,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-551b7487-51ff-48c3-ac87-96d068ff2903,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-55925aa6-cd2e-4db2-afd7-66575d25efed,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-f47a5f59-1317-43a1-ba67-be1888505a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-95c721b7-7761-4196-95c0-133f0a7d95ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065763262-172.17.0.17-1597277497922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-aa7ba72d-1c75-45fd-ad54-0ed75b62f418,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-c2a1f538-f846-4214-95a1-0a5508067551,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-f511aba1-31a9-4b09-815e-f196b9d48a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-1fee20f2-7bbf-43bf-8a34-fd759dc20344,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-fbd6c57e-52f1-4a6c-83f7-b7583d7257d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-6d56b5ef-e06e-429f-8525-90d90ee2b239,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-756f7c1a-f239-4d14-87b8-f81ba0e503ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-10ef057b-7796-4355-9524-c57d160a1907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065763262-172.17.0.17-1597277497922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-aa7ba72d-1c75-45fd-ad54-0ed75b62f418,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-c2a1f538-f846-4214-95a1-0a5508067551,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-f511aba1-31a9-4b09-815e-f196b9d48a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-1fee20f2-7bbf-43bf-8a34-fd759dc20344,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-fbd6c57e-52f1-4a6c-83f7-b7583d7257d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-6d56b5ef-e06e-429f-8525-90d90ee2b239,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-756f7c1a-f239-4d14-87b8-f81ba0e503ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-10ef057b-7796-4355-9524-c57d160a1907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696693152-172.17.0.17-1597277538710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-92671e83-147d-4ea2-a542-93bab56ff0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-52bad4e3-449f-4580-b786-36a801a2a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d5362fd6-c6e9-4563-a980-7ffd4f4f3152,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-da9d3658-7773-4307-98b3-4196221fb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-492e6a0d-11ce-47bd-b5b0-ed93770f421b,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-55108c65-5d42-43c6-a12f-8e4ec741820e,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-1fe79120-c08d-4a8a-bda6-c91edb9cf66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e36775cb-3f09-4a03-8c68-0ca10f93a85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696693152-172.17.0.17-1597277538710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-92671e83-147d-4ea2-a542-93bab56ff0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-52bad4e3-449f-4580-b786-36a801a2a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d5362fd6-c6e9-4563-a980-7ffd4f4f3152,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-da9d3658-7773-4307-98b3-4196221fb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-492e6a0d-11ce-47bd-b5b0-ed93770f421b,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-55108c65-5d42-43c6-a12f-8e4ec741820e,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-1fe79120-c08d-4a8a-bda6-c91edb9cf66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e36775cb-3f09-4a03-8c68-0ca10f93a85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632494724-172.17.0.17-1597277577075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-55279b7b-f0d4-4cec-8236-f656fa163069,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-3ed7ad5f-4ac4-4486-8ecb-fef552f1ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-612798df-db15-46a6-a0f3-a140006dba50,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-249aaa42-6792-432c-8c34-6cd28872e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-3172edfb-bf88-40c2-bd52-8b7ccc6c042b,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-6bd86929-2e65-4290-b9a1-10887ff1ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-828ce6d0-79b7-47d5-883e-922b81fcd6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d848b636-798a-41f5-a6fa-f60be22cc66d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632494724-172.17.0.17-1597277577075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-55279b7b-f0d4-4cec-8236-f656fa163069,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-3ed7ad5f-4ac4-4486-8ecb-fef552f1ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-612798df-db15-46a6-a0f3-a140006dba50,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-249aaa42-6792-432c-8c34-6cd28872e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-3172edfb-bf88-40c2-bd52-8b7ccc6c042b,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-6bd86929-2e65-4290-b9a1-10887ff1ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-828ce6d0-79b7-47d5-883e-922b81fcd6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d848b636-798a-41f5-a6fa-f60be22cc66d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153333941-172.17.0.17-1597277898476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-eb390795-a06d-4aea-873b-00b326caf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-c82e496f-43d7-4994-9524-cf03aec60b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-ae4461fc-80fc-4a8d-908b-18348846438d,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-072037c5-8394-40d5-a734-851cd96f3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-61a5738d-db24-4de0-86ae-01d5a34d483d,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-4920c322-93b3-4ece-806e-3ae299fb3719,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-bef3c58f-4d7e-4943-9b1e-b492c1b3564c,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-149ccf7e-2eb3-4f77-ab45-a4eb30c61a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153333941-172.17.0.17-1597277898476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-eb390795-a06d-4aea-873b-00b326caf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-c82e496f-43d7-4994-9524-cf03aec60b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-ae4461fc-80fc-4a8d-908b-18348846438d,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-072037c5-8394-40d5-a734-851cd96f3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-61a5738d-db24-4de0-86ae-01d5a34d483d,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-4920c322-93b3-4ece-806e-3ae299fb3719,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-bef3c58f-4d7e-4943-9b1e-b492c1b3564c,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-149ccf7e-2eb3-4f77-ab45-a4eb30c61a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287692296-172.17.0.17-1597278023779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-fc8fe331-c872-4cf6-a065-465a1b9a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-98378b27-ef68-461b-a30d-a0cfb3630ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4e7c05e8-cc1d-4938-8a2e-51cfaf25d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ce155531-4281-40ea-ab35-2e8ab29795ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-3614a7f1-066b-4a48-8339-c56a3319fd36,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-cc659786-921d-4b66-b59d-d95fa64d2302,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-cf0ed577-b660-45bb-ab59-b7a9926ff032,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-85e4dc01-7a9f-472d-9299-1744a62f0585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287692296-172.17.0.17-1597278023779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-fc8fe331-c872-4cf6-a065-465a1b9a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-98378b27-ef68-461b-a30d-a0cfb3630ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4e7c05e8-cc1d-4938-8a2e-51cfaf25d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ce155531-4281-40ea-ab35-2e8ab29795ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-3614a7f1-066b-4a48-8339-c56a3319fd36,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-cc659786-921d-4b66-b59d-d95fa64d2302,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-cf0ed577-b660-45bb-ab59-b7a9926ff032,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-85e4dc01-7a9f-472d-9299-1744a62f0585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373410711-172.17.0.17-1597278228318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-c7830055-a931-4a1e-8e3a-d179e54a1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-00e63e7b-089a-4d86-b149-d75d56e1bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-034f5048-5471-4bfa-baef-ad0041020e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-b7381fa9-68c6-4da5-b73b-158e4cc7e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-f84065fd-d1bd-45d0-accb-f1cce6b730fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-ff86bd8c-e59c-4342-9454-05017b166caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-60fa65a2-10e9-4be2-bafa-c3e7a42852e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-18df2162-32ea-4fab-8a6c-6a8e95e40af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373410711-172.17.0.17-1597278228318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-c7830055-a931-4a1e-8e3a-d179e54a1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-00e63e7b-089a-4d86-b149-d75d56e1bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-034f5048-5471-4bfa-baef-ad0041020e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-b7381fa9-68c6-4da5-b73b-158e4cc7e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-f84065fd-d1bd-45d0-accb-f1cce6b730fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-ff86bd8c-e59c-4342-9454-05017b166caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-60fa65a2-10e9-4be2-bafa-c3e7a42852e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-18df2162-32ea-4fab-8a6c-6a8e95e40af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5916
