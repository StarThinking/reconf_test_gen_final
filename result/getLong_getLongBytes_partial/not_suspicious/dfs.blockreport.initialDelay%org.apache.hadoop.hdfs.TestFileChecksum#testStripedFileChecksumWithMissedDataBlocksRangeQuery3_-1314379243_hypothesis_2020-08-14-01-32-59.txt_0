reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743131327-172.17.0.13-1597369211881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-5cf4df74-9083-43ee-9a0f-7d7c66e95e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-0dcd5e36-9efd-4adf-bd31-98ff7399be51,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-a6d714b7-266b-430d-b0ab-e39011eac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-296c80f9-3f8f-4ee0-b132-2cf0faf4e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-46b53b84-643f-41e5-9957-dddffe5eb85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-87c1bcb5-dc20-4074-93c2-5cb493401b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-e54947bf-086e-4a8e-9c81-66b950fdad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-4b619b67-7494-4868-955f-17f614fbe716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743131327-172.17.0.13-1597369211881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-5cf4df74-9083-43ee-9a0f-7d7c66e95e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-0dcd5e36-9efd-4adf-bd31-98ff7399be51,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-a6d714b7-266b-430d-b0ab-e39011eac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-296c80f9-3f8f-4ee0-b132-2cf0faf4e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-46b53b84-643f-41e5-9957-dddffe5eb85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-87c1bcb5-dc20-4074-93c2-5cb493401b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-e54947bf-086e-4a8e-9c81-66b950fdad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-4b619b67-7494-4868-955f-17f614fbe716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939388559-172.17.0.13-1597369376882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-115ef5e0-fce0-4707-aa1c-4def177b3fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-8e698e44-df34-4331-b415-7f88987e6580,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-7feee890-6632-4373-88bc-40901be7558d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-d8fae3e7-eac3-4801-8ac4-c73572e79443,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-393bd421-5102-436d-bf94-39b6927621e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-e1a68981-d9fa-41fd-9820-cfb6863697ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-d0ddc31c-c62f-4ebe-b0f3-5078db737dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-08801a46-d863-46d6-9743-f68af1ed9bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939388559-172.17.0.13-1597369376882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-115ef5e0-fce0-4707-aa1c-4def177b3fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-8e698e44-df34-4331-b415-7f88987e6580,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-7feee890-6632-4373-88bc-40901be7558d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-d8fae3e7-eac3-4801-8ac4-c73572e79443,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-393bd421-5102-436d-bf94-39b6927621e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-e1a68981-d9fa-41fd-9820-cfb6863697ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-d0ddc31c-c62f-4ebe-b0f3-5078db737dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-08801a46-d863-46d6-9743-f68af1ed9bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378260119-172.17.0.13-1597369513111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-1c3a9ccf-0df7-49ab-9651-169b915299fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-09a608ea-3308-4621-a69c-3396feed3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-98331863-4291-4b83-8bc3-47603781110d,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-48aca8ea-c0d6-4593-a3a4-d76a5ff8c266,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-2cab04e7-4944-4113-92c6-ba85ae30fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-2f5656a9-0f7a-4fdd-b9fb-d420aed866f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8ad565b5-1575-490a-8939-ff8faf7994e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-481b0c02-69bd-454f-bcee-6695cd0f057f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378260119-172.17.0.13-1597369513111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-1c3a9ccf-0df7-49ab-9651-169b915299fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-09a608ea-3308-4621-a69c-3396feed3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-98331863-4291-4b83-8bc3-47603781110d,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-48aca8ea-c0d6-4593-a3a4-d76a5ff8c266,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-2cab04e7-4944-4113-92c6-ba85ae30fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-2f5656a9-0f7a-4fdd-b9fb-d420aed866f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8ad565b5-1575-490a-8939-ff8faf7994e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-481b0c02-69bd-454f-bcee-6695cd0f057f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786142159-172.17.0.13-1597370051482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-e2bf90a7-4f64-43d6-8cf0-46840a7257d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-8fd811af-1cd4-44a0-8022-f06dd2c883d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-cc213493-eaee-4b4c-a11f-8f7abdf16208,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-92029dd9-29d6-47f1-92c9-6404aecdfcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-f18afed3-5f80-4c55-8b49-6c02a5144527,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-64e25f56-341b-46ad-8c90-0929e0c6a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-e948b958-4335-47f7-98a0-515bb554544b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-81f5c1cb-5060-4dd2-9f24-eace651b5ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786142159-172.17.0.13-1597370051482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-e2bf90a7-4f64-43d6-8cf0-46840a7257d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-8fd811af-1cd4-44a0-8022-f06dd2c883d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-cc213493-eaee-4b4c-a11f-8f7abdf16208,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-92029dd9-29d6-47f1-92c9-6404aecdfcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-f18afed3-5f80-4c55-8b49-6c02a5144527,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-64e25f56-341b-46ad-8c90-0929e0c6a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-e948b958-4335-47f7-98a0-515bb554544b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-81f5c1cb-5060-4dd2-9f24-eace651b5ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132784211-172.17.0.13-1597370475833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-e5253c0e-84d4-47dd-afbd-fb59d2f8eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-7ce104bf-ed78-4b8d-8a83-d91d0c68eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-c01b94ad-49a1-4fe5-8a74-31f3c4d92c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-af3f03f7-0d50-4433-8762-8952aaa44aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-70e34ba4-ccca-4eb0-8987-7561ebcbdeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-168e1c1d-5cc5-44f3-8dc8-491504a361f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-63d6e334-6b9d-48b8-8841-3d6a37175df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-25ce19b9-8818-43c9-b87a-e44cc51faa2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132784211-172.17.0.13-1597370475833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-e5253c0e-84d4-47dd-afbd-fb59d2f8eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-7ce104bf-ed78-4b8d-8a83-d91d0c68eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-c01b94ad-49a1-4fe5-8a74-31f3c4d92c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-af3f03f7-0d50-4433-8762-8952aaa44aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-70e34ba4-ccca-4eb0-8987-7561ebcbdeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-168e1c1d-5cc5-44f3-8dc8-491504a361f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-63d6e334-6b9d-48b8-8841-3d6a37175df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-25ce19b9-8818-43c9-b87a-e44cc51faa2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484513840-172.17.0.13-1597371447924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-22a152e6-f025-46d7-ba49-14c869aaf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-12218626-01f4-455e-a424-b3ce7020d37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-0db76225-1d28-49da-afa6-8aca9cc6310a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-13c9c7bb-1ef6-4515-ae7f-e71470e92819,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e9dfe468-80cf-4aeb-84ec-39ae9d9af33c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-1493a6b9-e272-413c-8b17-2c9f8339b262,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-d55c9d7b-1be0-437d-960b-4ba3a0aab7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-639a18dd-ab11-413f-91be-d35c460e3fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484513840-172.17.0.13-1597371447924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-22a152e6-f025-46d7-ba49-14c869aaf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-12218626-01f4-455e-a424-b3ce7020d37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-0db76225-1d28-49da-afa6-8aca9cc6310a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-13c9c7bb-1ef6-4515-ae7f-e71470e92819,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e9dfe468-80cf-4aeb-84ec-39ae9d9af33c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-1493a6b9-e272-413c-8b17-2c9f8339b262,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-d55c9d7b-1be0-437d-960b-4ba3a0aab7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-639a18dd-ab11-413f-91be-d35c460e3fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360280651-172.17.0.13-1597371851059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-e7f2e0f4-2170-4ff0-bb6b-54984689f657,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-a22e7bee-5947-4fed-977f-3f5f9b145e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-31e4b71c-0fcd-482e-8c32-5d05407bc64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2a144301-6f54-4808-8e2e-0cbb48b40fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-d1b91e5d-a1f3-4f73-aad8-e39b480c29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-d8c8e1f3-f6a1-4990-9084-3f784fea0c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-03df0cee-fafc-48ef-b50f-56bdfa8a45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-b39b2d34-d5b6-4d11-b212-c5b07c3667be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360280651-172.17.0.13-1597371851059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-e7f2e0f4-2170-4ff0-bb6b-54984689f657,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-a22e7bee-5947-4fed-977f-3f5f9b145e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-31e4b71c-0fcd-482e-8c32-5d05407bc64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2a144301-6f54-4808-8e2e-0cbb48b40fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-d1b91e5d-a1f3-4f73-aad8-e39b480c29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-d8c8e1f3-f6a1-4990-9084-3f784fea0c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-03df0cee-fafc-48ef-b50f-56bdfa8a45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-b39b2d34-d5b6-4d11-b212-c5b07c3667be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022488708-172.17.0.13-1597371954053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-007f9351-9f92-4c3a-9704-5eaf1d53fa74,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-742cc477-c897-4108-893a-6e8bc667036d,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-6b5b40f6-dd99-48a7-a0af-a94772584759,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-6f612f65-e5c3-4ee3-b897-c15aa36553dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-802dc740-3525-49d3-9263-f7fdbad02c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-499b7429-101b-494f-8be3-aad1f6699e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-041af2bb-de98-4922-aac1-f7b686c2b936,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-88d7ecf5-18ae-4225-b3b8-a44776eac5fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022488708-172.17.0.13-1597371954053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-007f9351-9f92-4c3a-9704-5eaf1d53fa74,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-742cc477-c897-4108-893a-6e8bc667036d,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-6b5b40f6-dd99-48a7-a0af-a94772584759,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-6f612f65-e5c3-4ee3-b897-c15aa36553dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-802dc740-3525-49d3-9263-f7fdbad02c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-499b7429-101b-494f-8be3-aad1f6699e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-041af2bb-de98-4922-aac1-f7b686c2b936,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-88d7ecf5-18ae-4225-b3b8-a44776eac5fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668775822-172.17.0.13-1597372753755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-0f3b56d9-04db-4d94-9330-a51486d2e685,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-020a138c-f321-4887-931b-6ad64021bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-0eec244a-f0b0-4386-be50-85487a6e3814,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9286d3a1-26c9-47de-b42d-2e24a769b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-c1e75d47-54a4-4299-b86c-c97c92a776eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-8bea95f8-46a6-4c19-a008-d3dfec0bed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-1cbd3260-b109-40b0-91fc-5d7a3d30b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-4ebbf517-11a4-4901-b3dd-01697e5ec494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668775822-172.17.0.13-1597372753755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-0f3b56d9-04db-4d94-9330-a51486d2e685,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-020a138c-f321-4887-931b-6ad64021bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-0eec244a-f0b0-4386-be50-85487a6e3814,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9286d3a1-26c9-47de-b42d-2e24a769b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-c1e75d47-54a4-4299-b86c-c97c92a776eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-8bea95f8-46a6-4c19-a008-d3dfec0bed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-1cbd3260-b109-40b0-91fc-5d7a3d30b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-4ebbf517-11a4-4901-b3dd-01697e5ec494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739554548-172.17.0.13-1597372907231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-f0cb04ad-ac70-45e1-a67a-53d0d2a1293b,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-c48f7cc8-9c0c-45ec-8b96-9e0bcc8f49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-aab34b05-0f17-46ec-86c7-01b25a2fb292,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-3769cd99-51a8-42ec-b5bf-769e4d32b326,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-d305f9bd-8ef8-4d96-a252-2811d8a8d808,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-f98e776d-70c7-4c1d-bb24-8472abf182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-c877ed1e-4634-4deb-8ba1-2e5873701dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-5b457b38-4587-4b1c-9096-90073252b0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739554548-172.17.0.13-1597372907231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-f0cb04ad-ac70-45e1-a67a-53d0d2a1293b,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-c48f7cc8-9c0c-45ec-8b96-9e0bcc8f49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-aab34b05-0f17-46ec-86c7-01b25a2fb292,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-3769cd99-51a8-42ec-b5bf-769e4d32b326,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-d305f9bd-8ef8-4d96-a252-2811d8a8d808,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-f98e776d-70c7-4c1d-bb24-8472abf182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-c877ed1e-4634-4deb-8ba1-2e5873701dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-5b457b38-4587-4b1c-9096-90073252b0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900413195-172.17.0.13-1597373145426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-8bc1016a-f2a5-4cad-a78d-29a4a44115bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-e19dad1c-c206-47f3-bb8d-78fcb74d29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-3b81ee44-2d95-4624-9f0c-d2ed357d481e,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-14bec6c5-ea7d-4748-bce4-d515d11ed8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-da9118a1-89ff-4e19-945b-eedca0cb8965,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-c5c1a671-c38a-48b0-8285-8edaefc5c871,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-ed5d296b-c8d2-4db4-97fb-2705e92e801d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-8481593c-120a-4cfe-8b56-ca0effc15814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900413195-172.17.0.13-1597373145426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-8bc1016a-f2a5-4cad-a78d-29a4a44115bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-e19dad1c-c206-47f3-bb8d-78fcb74d29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-3b81ee44-2d95-4624-9f0c-d2ed357d481e,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-14bec6c5-ea7d-4748-bce4-d515d11ed8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-da9118a1-89ff-4e19-945b-eedca0cb8965,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-c5c1a671-c38a-48b0-8285-8edaefc5c871,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-ed5d296b-c8d2-4db4-97fb-2705e92e801d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-8481593c-120a-4cfe-8b56-ca0effc15814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908388846-172.17.0.13-1597373349402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-f3baa486-0a74-4b94-a29d-880d3c648546,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-739fb2db-992a-4e2e-9243-892e5022d6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-a8c593ea-0de7-4fcb-bb70-05bdfaf56061,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-839f6cbe-9300-4792-8350-4db060df7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-3d17d27c-956b-4b0b-b727-5ab74cc01c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-6217ad76-3a6e-4729-a88e-bcf6f73fd6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-0cf52fad-9546-476b-8bea-33e1a375567b,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-a99ff4f0-6cc6-4e9f-8df3-a06acbbce399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908388846-172.17.0.13-1597373349402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-f3baa486-0a74-4b94-a29d-880d3c648546,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-739fb2db-992a-4e2e-9243-892e5022d6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-a8c593ea-0de7-4fcb-bb70-05bdfaf56061,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-839f6cbe-9300-4792-8350-4db060df7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-3d17d27c-956b-4b0b-b727-5ab74cc01c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-6217ad76-3a6e-4729-a88e-bcf6f73fd6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-0cf52fad-9546-476b-8bea-33e1a375567b,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-a99ff4f0-6cc6-4e9f-8df3-a06acbbce399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723081405-172.17.0.13-1597373393687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-bb7b6773-d2fd-4456-a62a-6be31996d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-3f1d9bb2-e35c-49e1-8b4f-4fa1c563e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7fa7dc3d-ee77-42c1-81e2-cf73d0b33b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-f7aeceec-14e5-44e6-9008-98fc810b17b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-7505924a-7337-4f27-bccd-5808bb4152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-d960a9c7-e447-4f05-944e-432ac12610a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9ea8de91-8343-4416-bc2c-10d23ce5be89,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-ef687ca5-e50e-4bed-88a0-0d35405a8a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723081405-172.17.0.13-1597373393687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-bb7b6773-d2fd-4456-a62a-6be31996d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-3f1d9bb2-e35c-49e1-8b4f-4fa1c563e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7fa7dc3d-ee77-42c1-81e2-cf73d0b33b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-f7aeceec-14e5-44e6-9008-98fc810b17b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-7505924a-7337-4f27-bccd-5808bb4152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-d960a9c7-e447-4f05-944e-432ac12610a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9ea8de91-8343-4416-bc2c-10d23ce5be89,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-ef687ca5-e50e-4bed-88a0-0d35405a8a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677121897-172.17.0.13-1597373449521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34352,DS-21f31b50-7974-4e27-acf2-721af8112b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4b50d84b-93cc-4d73-8a55-39fa51c9a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-06690a0d-b524-4c59-8934-673acf3f1809,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-39a06b21-48aa-48e3-b27e-b824f36396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-51a93735-ca7d-444a-b24b-28467ef067d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-65c83c3e-a7ff-4c11-b375-a562a993f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-f0003fd7-d809-4ce9-afea-20b1b9422c49,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-94234b19-9fc1-4d66-9a26-3d2dcbef7207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677121897-172.17.0.13-1597373449521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34352,DS-21f31b50-7974-4e27-acf2-721af8112b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4b50d84b-93cc-4d73-8a55-39fa51c9a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-06690a0d-b524-4c59-8934-673acf3f1809,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-39a06b21-48aa-48e3-b27e-b824f36396a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-51a93735-ca7d-444a-b24b-28467ef067d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-65c83c3e-a7ff-4c11-b375-a562a993f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-f0003fd7-d809-4ce9-afea-20b1b9422c49,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-94234b19-9fc1-4d66-9a26-3d2dcbef7207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222898559-172.17.0.13-1597373593671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46056,DS-aa9284f1-4584-4b62-9b4a-46fe651097da,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-876ad487-639a-4b20-a681-82f50ffd173e,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-94a4de3c-1026-4df3-89f5-3fc58a62f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-926a04af-8726-43b5-8ba8-0db7a58ab910,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-94a71284-8004-4d40-84d0-bd5c0b987763,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-d006d7ad-c8a9-4fb2-84a2-bcbb5c8a8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-0400911b-1e47-4e80-96e7-c4847e26b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-9598a916-e51b-4588-b01b-06b9e4fa1736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222898559-172.17.0.13-1597373593671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46056,DS-aa9284f1-4584-4b62-9b4a-46fe651097da,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-876ad487-639a-4b20-a681-82f50ffd173e,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-94a4de3c-1026-4df3-89f5-3fc58a62f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-926a04af-8726-43b5-8ba8-0db7a58ab910,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-94a71284-8004-4d40-84d0-bd5c0b987763,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-d006d7ad-c8a9-4fb2-84a2-bcbb5c8a8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-0400911b-1e47-4e80-96e7-c4847e26b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-9598a916-e51b-4588-b01b-06b9e4fa1736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585065284-172.17.0.13-1597373724557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-6192fcc2-8760-42f2-b3d7-00c145a3557f,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-58034c23-63c2-4994-a6c0-9ff920f5c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e276fe64-9ac1-4c67-b9f1-a4277aefcb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c9bef28c-1d8f-456e-b701-617c5e738375,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-89b0c329-eb72-4750-9fcd-b0ff13acaa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-9e4d96cd-f234-4d40-b4ae-10875f43a65d,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-31885dba-5848-4ba3-8bc7-a1c60c7c8594,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1626385f-d581-4a92-a773-00b905e4d561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585065284-172.17.0.13-1597373724557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-6192fcc2-8760-42f2-b3d7-00c145a3557f,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-58034c23-63c2-4994-a6c0-9ff920f5c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e276fe64-9ac1-4c67-b9f1-a4277aefcb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c9bef28c-1d8f-456e-b701-617c5e738375,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-89b0c329-eb72-4750-9fcd-b0ff13acaa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-9e4d96cd-f234-4d40-b4ae-10875f43a65d,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-31885dba-5848-4ba3-8bc7-a1c60c7c8594,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1626385f-d581-4a92-a773-00b905e4d561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111003699-172.17.0.13-1597374066263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-c07b5316-0899-4c45-b72a-d86c65d32ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-6a6238fd-8c20-41b2-a9a4-cb44596a3aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-4088b5ef-7e0d-4825-ae2e-db5918abdc58,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-15b78790-e163-4558-8675-5b7ce8c06216,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-a28fda0a-7ab1-4c2d-956e-12d4cebad3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-5a6c01a4-5aad-4f9d-8a07-d0c285de73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-f97a5341-066d-4f53-9ee8-adbbe217649f,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-842d2694-a84e-4718-a842-22965e412c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111003699-172.17.0.13-1597374066263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-c07b5316-0899-4c45-b72a-d86c65d32ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-6a6238fd-8c20-41b2-a9a4-cb44596a3aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-4088b5ef-7e0d-4825-ae2e-db5918abdc58,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-15b78790-e163-4558-8675-5b7ce8c06216,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-a28fda0a-7ab1-4c2d-956e-12d4cebad3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-5a6c01a4-5aad-4f9d-8a07-d0c285de73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-f97a5341-066d-4f53-9ee8-adbbe217649f,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-842d2694-a84e-4718-a842-22965e412c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344988696-172.17.0.13-1597375269688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-595d91e0-6382-42f5-8384-ad3f55a8b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7f93ddab-a902-41b3-9987-ebde315bbf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-daf9c3b7-f524-483b-86c7-b0981c030b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-b4e51124-7abb-42ae-abc5-8c5259b68df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-ac803367-f184-4916-bc01-7bcaa7db20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ced8c132-1469-4da1-b8d0-d4a465aad27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-699fe977-6417-464e-ab92-87dc7bb617d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9eec1dbb-1229-4ba6-8086-dca0ef9b03a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344988696-172.17.0.13-1597375269688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-595d91e0-6382-42f5-8384-ad3f55a8b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7f93ddab-a902-41b3-9987-ebde315bbf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-daf9c3b7-f524-483b-86c7-b0981c030b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-b4e51124-7abb-42ae-abc5-8c5259b68df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-ac803367-f184-4916-bc01-7bcaa7db20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ced8c132-1469-4da1-b8d0-d4a465aad27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-699fe977-6417-464e-ab92-87dc7bb617d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9eec1dbb-1229-4ba6-8086-dca0ef9b03a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 7238
