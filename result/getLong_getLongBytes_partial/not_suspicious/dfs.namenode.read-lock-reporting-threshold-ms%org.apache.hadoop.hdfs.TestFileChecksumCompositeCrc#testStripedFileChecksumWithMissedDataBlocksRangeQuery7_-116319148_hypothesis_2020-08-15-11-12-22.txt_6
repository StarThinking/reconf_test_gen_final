reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483039732-172.17.0.3-1597489959758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-74f47701-73d0-4473-8169-0bda23de942b,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4dc3b1c0-2658-49f4-b1a3-1bc46d4ea02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-54ba45b2-acee-4af1-b801-a77d22596abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-f565c1fc-67fb-4a59-93ca-5ec5515c1407,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-e518bed4-4933-4547-a2cd-423705191424,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-5844fb27-bb24-4898-9d95-28d0ce9d6d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-88c252a0-6bb7-4842-9f2b-fc9e7df5a399,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-32418213-e90c-4671-aaae-985f4fa1a8ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483039732-172.17.0.3-1597489959758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-74f47701-73d0-4473-8169-0bda23de942b,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4dc3b1c0-2658-49f4-b1a3-1bc46d4ea02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-54ba45b2-acee-4af1-b801-a77d22596abd,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-f565c1fc-67fb-4a59-93ca-5ec5515c1407,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-e518bed4-4933-4547-a2cd-423705191424,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-5844fb27-bb24-4898-9d95-28d0ce9d6d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-88c252a0-6bb7-4842-9f2b-fc9e7df5a399,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-32418213-e90c-4671-aaae-985f4fa1a8ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516133740-172.17.0.3-1597490076411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-59b9c903-07e1-4bae-877d-601690d6f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-0f9760da-84d2-4da9-a3be-23982dc33d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-d4473089-2f73-435d-a6d5-889d22ea9580,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a13b1f76-2af6-4bc1-9e4f-2076bbc5b7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-7aeafe69-8a84-42f6-8517-7f081d393241,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-bba7803a-3fb7-4280-94a0-16ab5556cb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-6727996d-f18b-4dae-a186-40e12690d717,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-d9cac7f0-a440-4f28-b9d1-24ff1d3bcb90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516133740-172.17.0.3-1597490076411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-59b9c903-07e1-4bae-877d-601690d6f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-0f9760da-84d2-4da9-a3be-23982dc33d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-d4473089-2f73-435d-a6d5-889d22ea9580,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a13b1f76-2af6-4bc1-9e4f-2076bbc5b7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-7aeafe69-8a84-42f6-8517-7f081d393241,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-bba7803a-3fb7-4280-94a0-16ab5556cb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-6727996d-f18b-4dae-a186-40e12690d717,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-d9cac7f0-a440-4f28-b9d1-24ff1d3bcb90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540509388-172.17.0.3-1597490122016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-cbe647cb-1826-4ff6-a07c-0dd1111112ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-c36910a9-8826-42a2-a823-02814889f400,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-6b3582a5-af22-46bc-8f35-1ead6b604a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b9b3b7dc-63cb-46eb-96da-89d31798e497,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-fe25d9dd-b0e6-47fa-b7b2-ea0fcf54990d,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-1c84723b-2bea-44cd-ad39-4b22f332e465,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-39bf9b5a-146b-4657-9e05-30796983eebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-644ab8ba-26b7-42ae-8a6e-d64e6ea0d709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540509388-172.17.0.3-1597490122016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-cbe647cb-1826-4ff6-a07c-0dd1111112ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-c36910a9-8826-42a2-a823-02814889f400,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-6b3582a5-af22-46bc-8f35-1ead6b604a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b9b3b7dc-63cb-46eb-96da-89d31798e497,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-fe25d9dd-b0e6-47fa-b7b2-ea0fcf54990d,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-1c84723b-2bea-44cd-ad39-4b22f332e465,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-39bf9b5a-146b-4657-9e05-30796983eebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-644ab8ba-26b7-42ae-8a6e-d64e6ea0d709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416910911-172.17.0.3-1597490153634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-fa117214-5b51-4809-8346-e4ce1697dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-441f1893-59d6-40d1-841e-50a635d9d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-08c7933d-c777-4a1d-af24-3a105f4b731a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-444cf349-f6ee-4ed4-b572-4c3c4a14abac,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-0a8f855c-7ad7-4a09-9be4-5e9aaba589a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-07c76bcb-8280-4a9c-8940-8c33a91b8fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-80b4e8be-c2f7-441e-93b4-2201e231a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-2e0a83f9-2dbf-4b0d-8e43-6717ec50c76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416910911-172.17.0.3-1597490153634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-fa117214-5b51-4809-8346-e4ce1697dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-441f1893-59d6-40d1-841e-50a635d9d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-08c7933d-c777-4a1d-af24-3a105f4b731a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-444cf349-f6ee-4ed4-b572-4c3c4a14abac,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-0a8f855c-7ad7-4a09-9be4-5e9aaba589a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-07c76bcb-8280-4a9c-8940-8c33a91b8fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-80b4e8be-c2f7-441e-93b4-2201e231a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-2e0a83f9-2dbf-4b0d-8e43-6717ec50c76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880336698-172.17.0.3-1597490226685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-0e749cf9-7a89-4a0c-8535-9cd2a0ed744f,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-e2243755-be31-49c4-98af-256bc2e72aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-47da6494-372c-4be2-8d08-085af54380e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-2b41804f-1b90-45e4-9ba6-2b067d31ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-8d2353c4-2ef6-4901-8e72-686487c33c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-0b52d99a-69fc-4e76-af37-db1e4df6f370,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-8cfe4bd9-b2f4-4056-8754-a1e1138159f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-70b8990c-776e-4d9e-a7fe-6d7ff98d9946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880336698-172.17.0.3-1597490226685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-0e749cf9-7a89-4a0c-8535-9cd2a0ed744f,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-e2243755-be31-49c4-98af-256bc2e72aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-47da6494-372c-4be2-8d08-085af54380e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-2b41804f-1b90-45e4-9ba6-2b067d31ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-8d2353c4-2ef6-4901-8e72-686487c33c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-0b52d99a-69fc-4e76-af37-db1e4df6f370,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-8cfe4bd9-b2f4-4056-8754-a1e1138159f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-70b8990c-776e-4d9e-a7fe-6d7ff98d9946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217464130-172.17.0.3-1597490506750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-2f090215-265a-4f9f-b88f-1c014e32273f,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-d65b0a63-4e15-406b-ab8f-202191a58684,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f5cf4ddd-d094-4263-9983-0c0ed942963c,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-3b1c9570-e35f-44cf-8e80-a7b9c9b21669,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-a8c2a629-1ed6-4e50-8443-39aa2dbe8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-bad1b5f9-399c-4d51-bfc1-0817ee68b088,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-64a9839e-6c82-4e3e-aaa9-fb50fda1dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-aaf64a55-9125-4eaf-9faa-40094fac9bfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217464130-172.17.0.3-1597490506750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-2f090215-265a-4f9f-b88f-1c014e32273f,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-d65b0a63-4e15-406b-ab8f-202191a58684,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f5cf4ddd-d094-4263-9983-0c0ed942963c,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-3b1c9570-e35f-44cf-8e80-a7b9c9b21669,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-a8c2a629-1ed6-4e50-8443-39aa2dbe8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-bad1b5f9-399c-4d51-bfc1-0817ee68b088,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-64a9839e-6c82-4e3e-aaa9-fb50fda1dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-aaf64a55-9125-4eaf-9faa-40094fac9bfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904478466-172.17.0.3-1597490668617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-03998ea0-dbe4-4aea-acbb-341ddfeb51f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-bde4cbaf-7734-4642-a941-83064f185704,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-fbb74752-4728-426d-956a-6c44f7a74597,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-50ab11aa-9bcb-454f-8e73-a9d48df69aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0728cdcf-02e5-4280-a5f5-20d8feba69f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-2accd032-1806-4ebf-b4d9-5e9b8c2376ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-a857304a-b521-420f-bbab-7ab27648770d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-fd9e815a-b2c5-434b-aa0d-1e3f27ad2a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904478466-172.17.0.3-1597490668617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-03998ea0-dbe4-4aea-acbb-341ddfeb51f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-bde4cbaf-7734-4642-a941-83064f185704,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-fbb74752-4728-426d-956a-6c44f7a74597,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-50ab11aa-9bcb-454f-8e73-a9d48df69aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0728cdcf-02e5-4280-a5f5-20d8feba69f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-2accd032-1806-4ebf-b4d9-5e9b8c2376ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-a857304a-b521-420f-bbab-7ab27648770d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-fd9e815a-b2c5-434b-aa0d-1e3f27ad2a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015457100-172.17.0.3-1597491060663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45052,DS-37159e96-cd49-4374-9af8-9be30f89f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-f5711fca-edb9-446f-b8b5-5218512df6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-9fe01bcd-3105-404a-97da-eadcd88d244a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-fde71938-3a8d-4265-b663-e2d25881ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b69787d9-5976-49d6-8b08-d7d14b3b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-39ac9add-d71f-46c5-a334-1b24e6e7d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-2724db50-9151-400d-aa63-9c9a1887d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-b11bcc09-796e-422d-b572-39f2474d939f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015457100-172.17.0.3-1597491060663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45052,DS-37159e96-cd49-4374-9af8-9be30f89f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-f5711fca-edb9-446f-b8b5-5218512df6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-9fe01bcd-3105-404a-97da-eadcd88d244a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-fde71938-3a8d-4265-b663-e2d25881ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b69787d9-5976-49d6-8b08-d7d14b3b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-39ac9add-d71f-46c5-a334-1b24e6e7d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-2724db50-9151-400d-aa63-9c9a1887d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-b11bcc09-796e-422d-b572-39f2474d939f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455733658-172.17.0.3-1597491376613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40521,DS-da30ae18-df4f-4ee3-9f9e-85e6e0d57a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-3f63c1f0-cb8d-4f5b-8337-6b85c57f3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-c90ef1e8-a0f0-4ef8-a7e5-d754253b0734,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-268f982d-089a-443f-8c08-2551940647d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3c03414c-eba0-4974-8d4c-00f76c03e454,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-395ae654-e236-4997-9b7e-40cd18446ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-b02cec08-dc05-47e4-93a7-60abf1c72dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-fcdf9433-1b3b-4213-a9c1-23078f852bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455733658-172.17.0.3-1597491376613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40521,DS-da30ae18-df4f-4ee3-9f9e-85e6e0d57a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-3f63c1f0-cb8d-4f5b-8337-6b85c57f3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-c90ef1e8-a0f0-4ef8-a7e5-d754253b0734,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-268f982d-089a-443f-8c08-2551940647d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3c03414c-eba0-4974-8d4c-00f76c03e454,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-395ae654-e236-4997-9b7e-40cd18446ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-b02cec08-dc05-47e4-93a7-60abf1c72dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-fcdf9433-1b3b-4213-a9c1-23078f852bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154050464-172.17.0.3-1597491487723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-41cbc9a5-e2df-4adf-b529-55993c49d918,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-ee020540-c545-41d6-8881-395703924ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-54d524ab-3972-41ad-9105-b5d4e3464f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-2bd5eabd-9a55-4372-a2b7-870ad23f05af,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-d4a5c916-69eb-4a82-8d09-79d84c01bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-0ffc412d-2035-45d6-8e80-014e82e336ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d3341676-48c0-49b0-a05a-bdce22b0d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-20e8aa72-86e8-4c8d-825d-9e899bd2e105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154050464-172.17.0.3-1597491487723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-41cbc9a5-e2df-4adf-b529-55993c49d918,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-ee020540-c545-41d6-8881-395703924ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-54d524ab-3972-41ad-9105-b5d4e3464f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-2bd5eabd-9a55-4372-a2b7-870ad23f05af,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-d4a5c916-69eb-4a82-8d09-79d84c01bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-0ffc412d-2035-45d6-8e80-014e82e336ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d3341676-48c0-49b0-a05a-bdce22b0d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-20e8aa72-86e8-4c8d-825d-9e899bd2e105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613745831-172.17.0.3-1597491524655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-e14f88cf-1967-4819-854d-ada2afe1b058,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9ebabc79-19ed-4dea-87d2-c8c87f17c8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-12bfae58-d6fa-453d-98e2-9e653010fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-74e79b83-9ae7-420b-afa9-859522e56b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-204c7085-c8e0-4094-b3f2-888eea4086b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-b4dd6842-0ece-49bd-83d7-677bb4e8b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-3ac319f4-f073-4aa2-a7e4-15280f766c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-9dca2cac-5483-4db4-9570-c8117e3d7671,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613745831-172.17.0.3-1597491524655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-e14f88cf-1967-4819-854d-ada2afe1b058,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9ebabc79-19ed-4dea-87d2-c8c87f17c8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-12bfae58-d6fa-453d-98e2-9e653010fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-74e79b83-9ae7-420b-afa9-859522e56b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-204c7085-c8e0-4094-b3f2-888eea4086b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-b4dd6842-0ece-49bd-83d7-677bb4e8b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-3ac319f4-f073-4aa2-a7e4-15280f766c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-9dca2cac-5483-4db4-9570-c8117e3d7671,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600653166-172.17.0.3-1597491820923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-60f63bb1-11cb-43c1-91a9-ca770ee0969a,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-3e082155-1c14-4895-afae-a3228e39413c,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8868fbd5-c4f4-48b6-8076-c0d2804c9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-b7558cbe-df32-4e8f-ae48-cd4362fc3430,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-e151728e-a3d2-403a-a908-2f72a0eb1f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-33f77393-fe46-4ac6-9a8f-cbf3f07b2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-7bd11496-7012-4f38-a32e-ed5cd3bb318e,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-cef6047b-bee4-419e-bfe7-5a63d52a51b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600653166-172.17.0.3-1597491820923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-60f63bb1-11cb-43c1-91a9-ca770ee0969a,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-3e082155-1c14-4895-afae-a3228e39413c,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8868fbd5-c4f4-48b6-8076-c0d2804c9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-b7558cbe-df32-4e8f-ae48-cd4362fc3430,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-e151728e-a3d2-403a-a908-2f72a0eb1f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-33f77393-fe46-4ac6-9a8f-cbf3f07b2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-7bd11496-7012-4f38-a32e-ed5cd3bb318e,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-cef6047b-bee4-419e-bfe7-5a63d52a51b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111792293-172.17.0.3-1597492168974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-21a14255-52f7-404f-b3f2-a1e6851f04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-70674be4-0949-46d0-bb1b-1627445cdbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-fe58328e-0a64-4b01-a48d-18f7cff0b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-4362eaa8-1974-4ec7-991a-a22527a57e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-b2c1b787-b3ed-4d5f-a1f7-996591b179c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-79bb628b-8ff9-4f33-90e1-ffa570db63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-244e1894-0377-480d-bf20-9e51e7e69ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-106ba8ce-481e-40e1-ad63-535db2e0ffd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111792293-172.17.0.3-1597492168974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-21a14255-52f7-404f-b3f2-a1e6851f04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-70674be4-0949-46d0-bb1b-1627445cdbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-fe58328e-0a64-4b01-a48d-18f7cff0b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-4362eaa8-1974-4ec7-991a-a22527a57e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-b2c1b787-b3ed-4d5f-a1f7-996591b179c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-79bb628b-8ff9-4f33-90e1-ffa570db63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-244e1894-0377-480d-bf20-9e51e7e69ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-106ba8ce-481e-40e1-ad63-535db2e0ffd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35769091-172.17.0.3-1597492207367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-3b18bea2-fbb5-4be3-9079-c6fb23e0a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b89c00ea-7a08-4b17-a4f8-37e8a2654cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-06b4b9ce-23c1-4b95-8ba5-f974ef913b77,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-b4421a79-9548-4079-8c5d-4421dfbd0a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-fd1bd1b8-6659-460e-9528-7705009a8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-db638124-0dde-48bc-8a35-a98f7a8cad73,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-fa65e503-dec5-4c6b-9c02-9954124371f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-76f00cd6-3bdd-4b76-b6c5-3e91a4b0b4ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35769091-172.17.0.3-1597492207367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-3b18bea2-fbb5-4be3-9079-c6fb23e0a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b89c00ea-7a08-4b17-a4f8-37e8a2654cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-06b4b9ce-23c1-4b95-8ba5-f974ef913b77,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-b4421a79-9548-4079-8c5d-4421dfbd0a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-fd1bd1b8-6659-460e-9528-7705009a8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-db638124-0dde-48bc-8a35-a98f7a8cad73,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-fa65e503-dec5-4c6b-9c02-9954124371f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-76f00cd6-3bdd-4b76-b6c5-3e91a4b0b4ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710042014-172.17.0.3-1597492444195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-f05c3053-d8d4-4b14-8a42-645ca4ef0743,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5aeaea58-10b1-4189-8b4d-d0cf9d0d29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-546f3002-49f9-400e-a5c2-a787de2a1f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-5ee8b02b-1716-449d-8118-59b67fcc059a,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-f45a710e-dcb4-4808-8771-78fce9831629,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-08b5537e-4604-43b4-bd49-1b77f1d21286,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-4e49d358-cc5a-46f0-a7b0-1dfef8b4e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-6863bfba-d5f5-42e2-837b-b6454478567b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710042014-172.17.0.3-1597492444195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-f05c3053-d8d4-4b14-8a42-645ca4ef0743,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5aeaea58-10b1-4189-8b4d-d0cf9d0d29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-546f3002-49f9-400e-a5c2-a787de2a1f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-5ee8b02b-1716-449d-8118-59b67fcc059a,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-f45a710e-dcb4-4808-8771-78fce9831629,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-08b5537e-4604-43b4-bd49-1b77f1d21286,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-4e49d358-cc5a-46f0-a7b0-1dfef8b4e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-6863bfba-d5f5-42e2-837b-b6454478567b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789456272-172.17.0.3-1597492753203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-a9214c2f-5f7b-4002-b42c-0fd28db05261,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-e05877b3-d44b-405a-920e-7c0501486709,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-8925b6fb-c6fc-4a25-9c5c-bd31754be6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-c15a4436-dab7-48d7-b13c-5132f11028e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-487aeb12-401a-4548-a252-13a2922115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f34424ba-eadf-422e-8539-c2f3c783065e,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-381bd884-6e77-4b6d-bdcf-891a41e9d972,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2d552f56-f53a-421a-87bb-d2f2072095c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789456272-172.17.0.3-1597492753203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-a9214c2f-5f7b-4002-b42c-0fd28db05261,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-e05877b3-d44b-405a-920e-7c0501486709,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-8925b6fb-c6fc-4a25-9c5c-bd31754be6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-c15a4436-dab7-48d7-b13c-5132f11028e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-487aeb12-401a-4548-a252-13a2922115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f34424ba-eadf-422e-8539-c2f3c783065e,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-381bd884-6e77-4b6d-bdcf-891a41e9d972,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2d552f56-f53a-421a-87bb-d2f2072095c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838668626-172.17.0.3-1597492832323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-b218ebf6-c920-4648-9a8e-6b6569efea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-70a4c4a8-72ba-40ff-8d01-13b729506070,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4ee24c7d-95a6-4e4c-aced-6516ff245777,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-28155093-8e2a-4082-bdf6-a8cf509c35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-58927d61-3916-4741-a1b3-c3b9eb4298e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6d3febbc-635d-4d97-b3a1-7750d1c83e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1edd387a-5bec-4950-aca6-32d40da54415,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-23dd4fb0-40d4-4217-b80c-b93297dc78ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838668626-172.17.0.3-1597492832323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-b218ebf6-c920-4648-9a8e-6b6569efea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-70a4c4a8-72ba-40ff-8d01-13b729506070,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4ee24c7d-95a6-4e4c-aced-6516ff245777,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-28155093-8e2a-4082-bdf6-a8cf509c35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-58927d61-3916-4741-a1b3-c3b9eb4298e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6d3febbc-635d-4d97-b3a1-7750d1c83e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1edd387a-5bec-4950-aca6-32d40da54415,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-23dd4fb0-40d4-4217-b80c-b93297dc78ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308968890-172.17.0.3-1597493041759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-46afd04e-4b5b-46fb-b133-c8383fc81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-ce876cbd-8616-42b5-af69-72909898b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-96abc60a-4ac5-41cc-95fe-e4a28a3b2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-52f8c62b-ee75-4ec5-8fd1-db067d80c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-5df921f6-5aa0-496b-b536-b1effe04a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-8964ecb4-0d95-4c02-a544-ead176fc9653,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-505284b8-36ec-4ac4-8c45-8f1179775d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cb35a3e7-560b-407c-a156-9322ef8352f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308968890-172.17.0.3-1597493041759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-46afd04e-4b5b-46fb-b133-c8383fc81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-ce876cbd-8616-42b5-af69-72909898b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-96abc60a-4ac5-41cc-95fe-e4a28a3b2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-52f8c62b-ee75-4ec5-8fd1-db067d80c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-5df921f6-5aa0-496b-b536-b1effe04a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-8964ecb4-0d95-4c02-a544-ead176fc9653,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-505284b8-36ec-4ac4-8c45-8f1179775d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cb35a3e7-560b-407c-a156-9322ef8352f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488569782-172.17.0.3-1597493359259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-0a0eda6f-7258-4600-9d6d-ab9f6aec2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-2b1c36af-2d7e-4162-9857-45997c48797d,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-d48763e3-f7e2-4c26-8871-7d8af2b110b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-d09b32e9-0acb-43f7-a269-6ac852db02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-a4213095-c4e6-4a22-9b79-d9ae47130624,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2b2441cd-4b26-4d69-b0d3-de2f92a7d498,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-0438b2c8-8675-40f9-a01e-f41a338a712b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-2db1be44-944c-46de-9411-b2d2e8baccbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488569782-172.17.0.3-1597493359259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-0a0eda6f-7258-4600-9d6d-ab9f6aec2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-2b1c36af-2d7e-4162-9857-45997c48797d,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-d48763e3-f7e2-4c26-8871-7d8af2b110b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-d09b32e9-0acb-43f7-a269-6ac852db02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-a4213095-c4e6-4a22-9b79-d9ae47130624,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2b2441cd-4b26-4d69-b0d3-de2f92a7d498,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-0438b2c8-8675-40f9-a01e-f41a338a712b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-2db1be44-944c-46de-9411-b2d2e8baccbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652895054-172.17.0.3-1597493593153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-baf7c1a0-5d4f-4606-b729-898fac24625a,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-c1455308-650e-4bcb-9563-bd2a1c9b98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e0ededea-2e76-4009-839c-86066696a343,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-5b5029aa-43ce-42c1-9681-4f72c5c688e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-b12a1afd-79e6-4ca9-b61f-418cfbba48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-b39f3f61-c331-42cf-a593-b1bb0778798f,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-300bbc8f-f378-4db7-ad41-42be3f15989a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-f0bb8b32-7ffd-4e1a-bff7-728e5839b536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652895054-172.17.0.3-1597493593153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-baf7c1a0-5d4f-4606-b729-898fac24625a,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-c1455308-650e-4bcb-9563-bd2a1c9b98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e0ededea-2e76-4009-839c-86066696a343,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-5b5029aa-43ce-42c1-9681-4f72c5c688e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-b12a1afd-79e6-4ca9-b61f-418cfbba48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-b39f3f61-c331-42cf-a593-b1bb0778798f,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-300bbc8f-f378-4db7-ad41-42be3f15989a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-f0bb8b32-7ffd-4e1a-bff7-728e5839b536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964376968-172.17.0.3-1597493711039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-5fa67982-b4ef-4464-9776-e79882e2343f,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-83ef328a-7093-4d01-b6d5-2ce2ae36c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-1b94375d-de2e-4dc2-855a-8823ce14c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-dabba345-57d0-446a-942d-ce37f9469956,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-1593dd08-ccd2-4695-adc9-6ee489356d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-ae523332-b3fb-4c52-a6f0-cd074bbe83be,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-3bd751aa-e4af-4673-8a6e-f9ad1a1d0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-cf09f9c3-4af5-4aee-9b4f-3ec031a3e2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964376968-172.17.0.3-1597493711039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-5fa67982-b4ef-4464-9776-e79882e2343f,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-83ef328a-7093-4d01-b6d5-2ce2ae36c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-1b94375d-de2e-4dc2-855a-8823ce14c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-dabba345-57d0-446a-942d-ce37f9469956,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-1593dd08-ccd2-4695-adc9-6ee489356d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-ae523332-b3fb-4c52-a6f0-cd074bbe83be,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-3bd751aa-e4af-4673-8a6e-f9ad1a1d0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-cf09f9c3-4af5-4aee-9b4f-3ec031a3e2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466958246-172.17.0.3-1597493749995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-b162c70b-5a17-4196-8045-afbfc8248a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-97617a56-fb3a-4565-9bef-07874c2340c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-b3c44661-3a82-421d-867e-1951b6dc5c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-837985ec-1e84-4091-b94b-8ddc3fe758f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6f8441df-8237-452d-ac4e-974d7336baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-b5e17b07-4dbe-4390-9523-2ba73b870850,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-eb189eea-ccd0-49b8-b700-e7f68e52b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-106261fa-d32e-4b7f-9147-a925c22a57b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466958246-172.17.0.3-1597493749995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-b162c70b-5a17-4196-8045-afbfc8248a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-97617a56-fb3a-4565-9bef-07874c2340c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-b3c44661-3a82-421d-867e-1951b6dc5c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-837985ec-1e84-4091-b94b-8ddc3fe758f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6f8441df-8237-452d-ac4e-974d7336baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-b5e17b07-4dbe-4390-9523-2ba73b870850,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-eb189eea-ccd0-49b8-b700-e7f68e52b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-106261fa-d32e-4b7f-9147-a925c22a57b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94728582-172.17.0.3-1597493794152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-8ba5b616-9cc8-4f64-b0ac-f830445a6936,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-70fa251f-20ab-46fa-9a7b-7d40e0445dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-c2def1f3-5a73-4e14-8331-d80a53a99f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-69af283f-1b3b-4f09-a2bd-f7552d3f5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-a65ce00b-bd04-4dae-b9ff-40d8e9aace99,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f3c4dd42-1e40-4057-9c49-0b24452fb103,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9fe8e450-b0c3-4e18-969d-1b640985d294,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-fbf602dd-4cad-4d29-bd4a-95fd2c251110,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94728582-172.17.0.3-1597493794152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-8ba5b616-9cc8-4f64-b0ac-f830445a6936,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-70fa251f-20ab-46fa-9a7b-7d40e0445dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-c2def1f3-5a73-4e14-8331-d80a53a99f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-69af283f-1b3b-4f09-a2bd-f7552d3f5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-a65ce00b-bd04-4dae-b9ff-40d8e9aace99,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f3c4dd42-1e40-4057-9c49-0b24452fb103,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9fe8e450-b0c3-4e18-969d-1b640985d294,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-fbf602dd-4cad-4d29-bd4a-95fd2c251110,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487378875-172.17.0.3-1597494288362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45962,DS-05c9573a-68a5-4614-b807-9ea1b23d3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d25cd56b-3eff-41fd-906a-4d0cfa4dc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-dc4e799a-3492-4767-bb40-a9d372b50828,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-3bec5c1a-6572-4ad4-bac3-118f06e1872d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-4d08e173-c862-45b6-a153-ac072bcd1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-a5e0d491-050c-47e8-83f0-ac76fc301dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-270ff3e8-7c18-4b88-b92d-cfd3292a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-d0a4a296-f7f4-41e6-97c3-478c22a1d03c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487378875-172.17.0.3-1597494288362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45962,DS-05c9573a-68a5-4614-b807-9ea1b23d3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d25cd56b-3eff-41fd-906a-4d0cfa4dc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-dc4e799a-3492-4767-bb40-a9d372b50828,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-3bec5c1a-6572-4ad4-bac3-118f06e1872d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-4d08e173-c862-45b6-a153-ac072bcd1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-a5e0d491-050c-47e8-83f0-ac76fc301dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-270ff3e8-7c18-4b88-b92d-cfd3292a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-d0a4a296-f7f4-41e6-97c3-478c22a1d03c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627989430-172.17.0.3-1597494330959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-cc273718-f60d-4c28-9c96-cb883d71ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-c9c27325-cc98-4904-9461-e94f8b8d48a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-1d744762-5adb-4366-8982-3b5db5c9e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-f671e84e-8afe-464a-88a6-eb5655eadbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-1691c794-8c3f-4917-bb80-b26318565750,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-44e6ddf8-095f-4f10-9b2f-5392522616ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9a60688c-4309-4556-b239-352997a556af,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-25ba2c18-dfc3-4c95-aece-20eb16e8b525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627989430-172.17.0.3-1597494330959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-cc273718-f60d-4c28-9c96-cb883d71ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-c9c27325-cc98-4904-9461-e94f8b8d48a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-1d744762-5adb-4366-8982-3b5db5c9e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-f671e84e-8afe-464a-88a6-eb5655eadbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-1691c794-8c3f-4917-bb80-b26318565750,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-44e6ddf8-095f-4f10-9b2f-5392522616ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9a60688c-4309-4556-b239-352997a556af,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-25ba2c18-dfc3-4c95-aece-20eb16e8b525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313956408-172.17.0.3-1597494538437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-82af8903-d8ed-4e20-81c2-59df9cd1a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-be08bf84-5407-4baf-a846-d6bceb18910d,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-35bd27df-c7ec-4770-a152-6c8d19aee801,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-d42ee17a-f9bb-452a-92a7-b68c4ed8f487,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f121da88-e51f-4014-a39a-95fa38e67337,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-3aba44be-5518-4d0a-bb00-0900f35ba01c,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-9cd105f0-f292-4cc2-add7-919c17cefd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-6b1b58f6-7dbf-42bb-9230-a863da70c249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313956408-172.17.0.3-1597494538437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-82af8903-d8ed-4e20-81c2-59df9cd1a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-be08bf84-5407-4baf-a846-d6bceb18910d,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-35bd27df-c7ec-4770-a152-6c8d19aee801,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-d42ee17a-f9bb-452a-92a7-b68c4ed8f487,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f121da88-e51f-4014-a39a-95fa38e67337,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-3aba44be-5518-4d0a-bb00-0900f35ba01c,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-9cd105f0-f292-4cc2-add7-919c17cefd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-6b1b58f6-7dbf-42bb-9230-a863da70c249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554766566-172.17.0.3-1597494851505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-feec9fe5-83db-4642-8e18-824354f8daf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-e16d5cc3-d12a-480d-a28f-0a3dd5d9b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-73f997cf-da6e-4bab-ae3d-133433a0fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-de1ae507-4b94-423f-8375-93b2fadb1eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3a043f3f-622d-4edd-80a1-20fe9021bc90,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-9fbea6fa-c680-403c-873b-a95dcda5737b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-539933dc-a09a-4f79-ac5c-78e603293200,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-f20194a0-cb34-49f2-8ca1-7dd24b9f5f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554766566-172.17.0.3-1597494851505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-feec9fe5-83db-4642-8e18-824354f8daf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-e16d5cc3-d12a-480d-a28f-0a3dd5d9b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-73f997cf-da6e-4bab-ae3d-133433a0fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-de1ae507-4b94-423f-8375-93b2fadb1eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3a043f3f-622d-4edd-80a1-20fe9021bc90,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-9fbea6fa-c680-403c-873b-a95dcda5737b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-539933dc-a09a-4f79-ac5c-78e603293200,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-f20194a0-cb34-49f2-8ca1-7dd24b9f5f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861891181-172.17.0.3-1597495026886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-dfe5d2fb-e84c-44e8-ac1f-6c9176eda465,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-77066ac1-b902-4b82-9f64-0a7324ecd5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-c24c0c1a-8652-4eb3-b39a-808987c4a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-78ef997d-1d99-452e-b741-b15dfa17a106,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-f17a3e32-c4f1-4139-a879-de46195f735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-309bc12a-7690-4fde-8003-efe2bf3cad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-e3f22da1-b8d9-412f-b3f2-7e3708f05db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-171f0098-220f-4451-a61f-dad121c2cf19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861891181-172.17.0.3-1597495026886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-dfe5d2fb-e84c-44e8-ac1f-6c9176eda465,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-77066ac1-b902-4b82-9f64-0a7324ecd5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-c24c0c1a-8652-4eb3-b39a-808987c4a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-78ef997d-1d99-452e-b741-b15dfa17a106,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-f17a3e32-c4f1-4139-a879-de46195f735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-309bc12a-7690-4fde-8003-efe2bf3cad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-e3f22da1-b8d9-412f-b3f2-7e3708f05db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-171f0098-220f-4451-a61f-dad121c2cf19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570756675-172.17.0.3-1597495134638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-2792024a-da45-4669-a016-832948a39bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-0fc9ba1c-5c68-48be-b84b-a7672600e16a,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b05cc84b-59ce-47d4-ba2d-03cf3d03b892,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-fb3f1994-7019-4892-9c8a-eb18c65d035e,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-d1b692f5-ee59-456c-b3b2-49b2cafe368b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-7e018cf1-cdba-4360-9bb0-59ebcef5803b,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-c777d029-4317-4c37-bb91-ad04a7da1107,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-c1fe6c9a-c551-4173-a602-16483d07fb32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570756675-172.17.0.3-1597495134638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-2792024a-da45-4669-a016-832948a39bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-0fc9ba1c-5c68-48be-b84b-a7672600e16a,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b05cc84b-59ce-47d4-ba2d-03cf3d03b892,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-fb3f1994-7019-4892-9c8a-eb18c65d035e,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-d1b692f5-ee59-456c-b3b2-49b2cafe368b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-7e018cf1-cdba-4360-9bb0-59ebcef5803b,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-c777d029-4317-4c37-bb91-ad04a7da1107,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-c1fe6c9a-c551-4173-a602-16483d07fb32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334289989-172.17.0.3-1597495213634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-ed9464a0-36fb-457e-8a51-28d43ccded32,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-7d4336ed-5d19-45c5-8698-0259aaafa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3f4d70a3-b645-4f5b-8204-8508c992cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-f182082b-e74a-4f8c-bd82-26f0005ae23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-b6365a9b-f737-4ec6-8d89-30f2fb864ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8f39488f-c86e-40e4-a830-9cb178ca46f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-c16dd300-085a-47a5-a5f3-af246afd37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-f0fe160e-fcb4-4641-9b11-602b0ba5d35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334289989-172.17.0.3-1597495213634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-ed9464a0-36fb-457e-8a51-28d43ccded32,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-7d4336ed-5d19-45c5-8698-0259aaafa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3f4d70a3-b645-4f5b-8204-8508c992cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-f182082b-e74a-4f8c-bd82-26f0005ae23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-b6365a9b-f737-4ec6-8d89-30f2fb864ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8f39488f-c86e-40e4-a830-9cb178ca46f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-c16dd300-085a-47a5-a5f3-af246afd37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-f0fe160e-fcb4-4641-9b11-602b0ba5d35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963540363-172.17.0.3-1597495694468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-93f18020-ee92-434a-b74c-386ede15ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-c95d4adb-a463-4d23-8be9-35062bfc194e,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-68298711-a23d-4b76-856e-66a4da2b7b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-38749ea5-86d0-4f9b-8d59-c17676add1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-bfb23b94-887b-42c8-a6a1-34753df0d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-1e537a60-7915-47d6-b5ed-89e121816a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-8ee875c0-be13-4ab2-96bd-4ab296925c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-4360a490-582d-4be4-a744-7b397c175fd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963540363-172.17.0.3-1597495694468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-93f18020-ee92-434a-b74c-386ede15ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-c95d4adb-a463-4d23-8be9-35062bfc194e,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-68298711-a23d-4b76-856e-66a4da2b7b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-38749ea5-86d0-4f9b-8d59-c17676add1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-bfb23b94-887b-42c8-a6a1-34753df0d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-1e537a60-7915-47d6-b5ed-89e121816a84,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-8ee875c0-be13-4ab2-96bd-4ab296925c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-4360a490-582d-4be4-a744-7b397c175fd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5936
