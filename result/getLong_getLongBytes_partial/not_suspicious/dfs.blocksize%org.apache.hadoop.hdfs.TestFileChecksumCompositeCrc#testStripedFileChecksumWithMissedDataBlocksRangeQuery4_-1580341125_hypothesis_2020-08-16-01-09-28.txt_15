reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092678375-172.17.0.13-1597540450127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-169d3de7-53a7-4a03-bfad-c540048bc076,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-0c10b464-7857-44a6-838c-1139151cb605,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-edf03505-c6c9-4056-8d4f-f4ce3be7f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-f96ddccc-f748-41b5-ab61-f75bccbd263b,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-a66bcf5a-e28f-4c9f-b70b-7f42a1ded421,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-8c519ad9-ea85-4af3-9c8a-9b039360619e,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-3121e287-9c84-43df-9ed0-5eeeb020a690,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f868ac99-b903-4071-b70b-f59095bef972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092678375-172.17.0.13-1597540450127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-169d3de7-53a7-4a03-bfad-c540048bc076,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-0c10b464-7857-44a6-838c-1139151cb605,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-edf03505-c6c9-4056-8d4f-f4ce3be7f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-f96ddccc-f748-41b5-ab61-f75bccbd263b,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-a66bcf5a-e28f-4c9f-b70b-7f42a1ded421,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-8c519ad9-ea85-4af3-9c8a-9b039360619e,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-3121e287-9c84-43df-9ed0-5eeeb020a690,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f868ac99-b903-4071-b70b-f59095bef972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420587772-172.17.0.13-1597540704169:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-4a65ff56-9daa-4096-b129-0d47a7c0865d,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-498ee682-f992-445d-959c-8087bcb1822d,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-5a67d88d-ee2d-4c7a-9756-34b41985b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-9c7945b0-9d2e-46e7-835e-9ab9fca9f756,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7a462916-304d-4287-8ff2-3f1511fb8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-6ff91dbc-2257-40eb-a1d4-8fe22fc77251,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-ee5c903a-d849-4c2f-9e65-81163c303509,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-9bed3964-dfea-4ede-b6f4-4cb02df37932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420587772-172.17.0.13-1597540704169:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-4a65ff56-9daa-4096-b129-0d47a7c0865d,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-498ee682-f992-445d-959c-8087bcb1822d,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-5a67d88d-ee2d-4c7a-9756-34b41985b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-9c7945b0-9d2e-46e7-835e-9ab9fca9f756,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7a462916-304d-4287-8ff2-3f1511fb8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-6ff91dbc-2257-40eb-a1d4-8fe22fc77251,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-ee5c903a-d849-4c2f-9e65-81163c303509,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-9bed3964-dfea-4ede-b6f4-4cb02df37932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94038717-172.17.0.13-1597541073480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-49370c33-53b6-4172-951e-cb5d3cb6cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-942c804c-7659-49ce-8a3f-9866a7d3f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-b8f15036-bc7c-45bc-b2b9-8717c84917d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-55d5d5dd-6055-4c63-a3db-152b98a4a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-539bcf9c-5525-4dcf-925b-08c5da0e3860,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-d34f1b1b-4c03-41c3-8efa-a8adcbfcac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-7bafd5a5-2168-4181-8a30-e2fe627fc8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-19d628d7-cf9a-493f-8a3d-9e93df0ce547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94038717-172.17.0.13-1597541073480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-49370c33-53b6-4172-951e-cb5d3cb6cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-942c804c-7659-49ce-8a3f-9866a7d3f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-b8f15036-bc7c-45bc-b2b9-8717c84917d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-55d5d5dd-6055-4c63-a3db-152b98a4a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-539bcf9c-5525-4dcf-925b-08c5da0e3860,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-d34f1b1b-4c03-41c3-8efa-a8adcbfcac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-7bafd5a5-2168-4181-8a30-e2fe627fc8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-19d628d7-cf9a-493f-8a3d-9e93df0ce547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672603094-172.17.0.13-1597541387563:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-d0f77c7b-37c1-47d7-9f23-dc5a14013f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-8977abec-5f46-42ec-b953-7de559ee680e,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-81c09609-0255-472c-a938-917319d23679,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-7d988eb3-de0b-478e-b894-2069df065f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-f1a9ac8a-93e0-4ffa-bc99-d8ed44e79cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-a31c5003-9d62-4d01-ab62-8cab48b05f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-f9430fc3-a168-4cf1-9626-a0c9374f9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-fc02e99e-7a05-4c15-9863-dedff1fbd514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672603094-172.17.0.13-1597541387563:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-d0f77c7b-37c1-47d7-9f23-dc5a14013f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-8977abec-5f46-42ec-b953-7de559ee680e,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-81c09609-0255-472c-a938-917319d23679,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-7d988eb3-de0b-478e-b894-2069df065f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-f1a9ac8a-93e0-4ffa-bc99-d8ed44e79cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-a31c5003-9d62-4d01-ab62-8cab48b05f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-f9430fc3-a168-4cf1-9626-a0c9374f9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-fc02e99e-7a05-4c15-9863-dedff1fbd514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461132677-172.17.0.13-1597542529178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-8adae1e1-a16c-462c-8547-1d1f3d6a7741,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-bcfadb9b-c496-4017-8cb1-51a549944856,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-7b8771d1-56fd-48a2-a5e6-641956e2647f,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-60791c62-31d1-4e5d-ae28-15c6dc417402,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-648f612e-5cc3-41b4-a15a-25e3d863f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-bb47c4d9-22d6-40ce-a407-9bd1289d3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7c07adfd-d3b5-4a42-86f3-20c802ec2ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-3413d02d-7bcc-4e78-afb0-d8d891ad854a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461132677-172.17.0.13-1597542529178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-8adae1e1-a16c-462c-8547-1d1f3d6a7741,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-bcfadb9b-c496-4017-8cb1-51a549944856,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-7b8771d1-56fd-48a2-a5e6-641956e2647f,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-60791c62-31d1-4e5d-ae28-15c6dc417402,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-648f612e-5cc3-41b4-a15a-25e3d863f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-bb47c4d9-22d6-40ce-a407-9bd1289d3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7c07adfd-d3b5-4a42-86f3-20c802ec2ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-3413d02d-7bcc-4e78-afb0-d8d891ad854a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713377520-172.17.0.13-1597542907975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40689,DS-39492840-a35b-4b18-9c18-81ff0b5f7f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-12974615-c62a-44ce-975c-3ba9681cc6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-958ca8ed-1547-41c5-b9f6-0989d10b9752,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-7d866de4-2860-4dd7-8471-6e5f61028682,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-364cf7b5-b919-4efe-a5bf-262dc63aa706,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-6266c04a-d985-4ca3-b2f9-38284c349c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-922763f2-bf78-4c05-b605-e44b8040c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-8a3e0b6d-fb64-4ef3-91ad-e29c3f7289ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713377520-172.17.0.13-1597542907975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40689,DS-39492840-a35b-4b18-9c18-81ff0b5f7f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-12974615-c62a-44ce-975c-3ba9681cc6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-958ca8ed-1547-41c5-b9f6-0989d10b9752,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-7d866de4-2860-4dd7-8471-6e5f61028682,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-364cf7b5-b919-4efe-a5bf-262dc63aa706,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-6266c04a-d985-4ca3-b2f9-38284c349c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-922763f2-bf78-4c05-b605-e44b8040c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-8a3e0b6d-fb64-4ef3-91ad-e29c3f7289ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610146478-172.17.0.13-1597543189324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-6d633150-1746-4ff8-af2a-83a9a6adade4,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-88a0b246-ff99-49ac-ad25-adab40ca3850,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-38be0e52-d737-43b6-9123-bc85881fcc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-909f08d2-cbd0-4972-aec6-4399c3251368,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-76f9fea5-5b67-4e35-af86-902017733e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-2e6e9cda-6d7c-4399-92d2-a42742ca200c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1b95c118-4d67-49bf-b860-35fe5ea9540a,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-dc377ee5-aa30-4399-9d95-f700d890fb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610146478-172.17.0.13-1597543189324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-6d633150-1746-4ff8-af2a-83a9a6adade4,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-88a0b246-ff99-49ac-ad25-adab40ca3850,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-38be0e52-d737-43b6-9123-bc85881fcc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-909f08d2-cbd0-4972-aec6-4399c3251368,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-76f9fea5-5b67-4e35-af86-902017733e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-2e6e9cda-6d7c-4399-92d2-a42742ca200c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1b95c118-4d67-49bf-b860-35fe5ea9540a,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-dc377ee5-aa30-4399-9d95-f700d890fb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962746554-172.17.0.13-1597543300794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-59f3c650-529d-4464-be8f-976ead773e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-a0dcb665-9506-4c4a-a8d1-3ce86df7f862,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-dc2c834d-8e09-40d7-b79a-2ba7f53bb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-9b53d42a-6906-4932-8a0a-40098b410f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-75e7cf7b-8d91-47ed-a078-f05e92a07291,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-25dee3d1-2cf7-48f3-80b7-376c11a8488b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-38c9d85a-0da7-458c-b574-a6ea8d676b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-ec1f9804-a7d1-409f-9f2b-fe362c6cb1b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962746554-172.17.0.13-1597543300794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-59f3c650-529d-4464-be8f-976ead773e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-a0dcb665-9506-4c4a-a8d1-3ce86df7f862,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-dc2c834d-8e09-40d7-b79a-2ba7f53bb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-9b53d42a-6906-4932-8a0a-40098b410f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-75e7cf7b-8d91-47ed-a078-f05e92a07291,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-25dee3d1-2cf7-48f3-80b7-376c11a8488b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-38c9d85a-0da7-458c-b574-a6ea8d676b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-ec1f9804-a7d1-409f-9f2b-fe362c6cb1b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863286078-172.17.0.13-1597543588634:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-2d637a06-86aa-4aa0-a383-7aff295281d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-1fdcde05-65b6-446c-aa36-e2b04dcc634b,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-ee294938-6294-4073-8f47-c982e78a4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-f8ef60e7-05e4-47f5-b23e-04b03600963c,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-3d9d8ac4-4c21-4ac9-9b22-194aa5d7453e,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-31c21f3b-2641-4d62-a8e5-b8ef5ec0e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-e63cead1-70a8-46f5-8ac3-4459b6773602,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-f9366d59-7e1d-4362-aee5-b4e498d0950b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863286078-172.17.0.13-1597543588634:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-2d637a06-86aa-4aa0-a383-7aff295281d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-1fdcde05-65b6-446c-aa36-e2b04dcc634b,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-ee294938-6294-4073-8f47-c982e78a4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-f8ef60e7-05e4-47f5-b23e-04b03600963c,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-3d9d8ac4-4c21-4ac9-9b22-194aa5d7453e,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-31c21f3b-2641-4d62-a8e5-b8ef5ec0e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-e63cead1-70a8-46f5-8ac3-4459b6773602,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-f9366d59-7e1d-4362-aee5-b4e498d0950b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846242873-172.17.0.13-1597543693067:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-84a72d3c-b99a-434e-86de-99e7b53f25c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-82a1de45-430b-4edb-a527-3bc6151e38d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-870bea85-362a-43ae-b074-67c4e47f562e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-3b8cc62c-8215-4f89-91b1-4330c49b59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0bd66f75-8d8c-48f2-8ba0-47033582c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-2ce8c1b1-ea73-4a0d-a5ae-ff0cb27fc9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e11e3c5d-1e39-4a63-a405-0a82a02a02db,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-c2ea4d7a-803b-4de6-a196-644d70f3dc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846242873-172.17.0.13-1597543693067:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-84a72d3c-b99a-434e-86de-99e7b53f25c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-82a1de45-430b-4edb-a527-3bc6151e38d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-870bea85-362a-43ae-b074-67c4e47f562e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-3b8cc62c-8215-4f89-91b1-4330c49b59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0bd66f75-8d8c-48f2-8ba0-47033582c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-2ce8c1b1-ea73-4a0d-a5ae-ff0cb27fc9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e11e3c5d-1e39-4a63-a405-0a82a02a02db,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-c2ea4d7a-803b-4de6-a196-644d70f3dc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665598926-172.17.0.13-1597543734932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-4ccd5991-bd9d-4ef8-b26d-7419c597fcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-10ff4c0c-4ff7-4bdd-8cb6-1b9cec58785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-7cc0242d-85ad-4ecf-b6f5-028c0b71d5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-732845af-07c8-4cd6-b8ab-4246d3863c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-b8882fbd-2a7f-41e4-84c7-43670b5238a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-b23850b9-1e50-417c-b46d-8e787e99d1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-5c51a841-d37b-4377-b8bc-086c07183997,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c8362bd3-7240-4275-9366-ef0d6c5fb562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665598926-172.17.0.13-1597543734932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-4ccd5991-bd9d-4ef8-b26d-7419c597fcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-10ff4c0c-4ff7-4bdd-8cb6-1b9cec58785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-7cc0242d-85ad-4ecf-b6f5-028c0b71d5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-732845af-07c8-4cd6-b8ab-4246d3863c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-b8882fbd-2a7f-41e4-84c7-43670b5238a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-b23850b9-1e50-417c-b46d-8e787e99d1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-5c51a841-d37b-4377-b8bc-086c07183997,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c8362bd3-7240-4275-9366-ef0d6c5fb562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911861867-172.17.0.13-1597544116674:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-5a3dfa7e-70e4-4c05-8767-1a45ec04c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-83a8862b-f591-47cd-bdaa-b0a9455590f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-316f5e8c-6aeb-4c77-9943-f666725c1cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-23058697-c4b4-43aa-9163-71eb455d9e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-aeac389b-943f-4d5c-aad1-0d4e98ef2281,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f54b0658-64ea-48fc-96c7-7d418051e805,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-0625236d-0d11-4fd9-b1dc-d68123506a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-acddcb15-592b-4868-a529-20aa18a90caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911861867-172.17.0.13-1597544116674:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-5a3dfa7e-70e4-4c05-8767-1a45ec04c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-83a8862b-f591-47cd-bdaa-b0a9455590f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-316f5e8c-6aeb-4c77-9943-f666725c1cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-23058697-c4b4-43aa-9163-71eb455d9e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-aeac389b-943f-4d5c-aad1-0d4e98ef2281,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f54b0658-64ea-48fc-96c7-7d418051e805,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-0625236d-0d11-4fd9-b1dc-d68123506a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-acddcb15-592b-4868-a529-20aa18a90caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720653378-172.17.0.13-1597544222493:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-6ec5fb71-8baa-4bc1-9bd6-5112ae978f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-47f55a46-850c-497b-8a17-d0d141ada34c,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-10adaad3-9fea-44cb-9ff9-e1cf2666e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b1d70bc6-b066-4a02-8ab8-d8e0c3f50bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b89a7ab0-8942-4f12-906b-a873f399cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-871c7116-5dfb-4b75-9095-3bfe5cc12404,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-1ef668f4-d595-418d-bb3b-f0715614a749,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-5724af0b-c968-453a-a373-087049de5b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720653378-172.17.0.13-1597544222493:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-6ec5fb71-8baa-4bc1-9bd6-5112ae978f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-47f55a46-850c-497b-8a17-d0d141ada34c,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-10adaad3-9fea-44cb-9ff9-e1cf2666e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b1d70bc6-b066-4a02-8ab8-d8e0c3f50bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b89a7ab0-8942-4f12-906b-a873f399cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-871c7116-5dfb-4b75-9095-3bfe5cc12404,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-1ef668f4-d595-418d-bb3b-f0715614a749,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-5724af0b-c968-453a-a373-087049de5b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433819077-172.17.0.13-1597544332624:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-510f5b97-19d5-4908-9e2a-a5156d52c453,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-cc8e90f2-3c60-4b43-8341-6e7500e424e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-c0c75172-3eeb-4d01-bd05-e8d7f6e50761,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-61888e48-4e22-4156-a0e7-289f03ee155a,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-4df1db84-1293-4ef8-a6e3-577a74cfaa56,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-8e9404ec-9c36-45a3-992a-86d872757eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-b88b2fe9-5bab-4554-9f76-5257a3dfe92b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d22fac3e-7e94-44d8-bd5e-7c8c5c9a84d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433819077-172.17.0.13-1597544332624:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-510f5b97-19d5-4908-9e2a-a5156d52c453,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-cc8e90f2-3c60-4b43-8341-6e7500e424e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-c0c75172-3eeb-4d01-bd05-e8d7f6e50761,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-61888e48-4e22-4156-a0e7-289f03ee155a,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-4df1db84-1293-4ef8-a6e3-577a74cfaa56,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-8e9404ec-9c36-45a3-992a-86d872757eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-b88b2fe9-5bab-4554-9f76-5257a3dfe92b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d22fac3e-7e94-44d8-bd5e-7c8c5c9a84d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361117053-172.17.0.13-1597544993360:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-c889f6d1-c46d-4579-b23c-92b5c3a4635a,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-bcb36051-b245-4188-84f5-a89f92ada827,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-81d231de-4b78-4ac6-80dd-87a2cb95a199,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-d24774a0-2a3e-46f8-bea0-4ece23824fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-3ec4e30a-5f88-4a34-ad1a-adf6f3be4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-8356befc-fd28-4875-aac4-e65104590a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-8b5b59f3-0658-4f2f-8288-567f1b835806,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-4ce0d116-156a-4412-8278-3f4eab181583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361117053-172.17.0.13-1597544993360:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-c889f6d1-c46d-4579-b23c-92b5c3a4635a,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-bcb36051-b245-4188-84f5-a89f92ada827,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-81d231de-4b78-4ac6-80dd-87a2cb95a199,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-d24774a0-2a3e-46f8-bea0-4ece23824fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-3ec4e30a-5f88-4a34-ad1a-adf6f3be4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-8356befc-fd28-4875-aac4-e65104590a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-8b5b59f3-0658-4f2f-8288-567f1b835806,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-4ce0d116-156a-4412-8278-3f4eab181583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997873285-172.17.0.13-1597545225884:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-becffefe-e3ef-4b8c-990b-b7df2fc70747,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-20817382-b2c5-45ff-b4b5-d18341068ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-c315fb7e-101a-478f-972a-d565288898e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-1fc37441-8f58-435b-98e3-380928cf14a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-8d50664e-28e4-42aa-8381-55829d14db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-c1ee1c6a-113a-47f5-8d76-9bd6ecfc3d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-050ff53b-0f42-42f7-a447-84e1c4455730,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-e84dac7a-0156-4e00-b350-33f8a0331c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997873285-172.17.0.13-1597545225884:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-becffefe-e3ef-4b8c-990b-b7df2fc70747,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-20817382-b2c5-45ff-b4b5-d18341068ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-c315fb7e-101a-478f-972a-d565288898e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-1fc37441-8f58-435b-98e3-380928cf14a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-8d50664e-28e4-42aa-8381-55829d14db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-c1ee1c6a-113a-47f5-8d76-9bd6ecfc3d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-050ff53b-0f42-42f7-a447-84e1c4455730,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-e84dac7a-0156-4e00-b350-33f8a0331c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751970507-172.17.0.13-1597545392027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-f3aba554-5ef1-4107-80fd-898baf0b32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-55a53dd6-025f-4da6-aef5-201be6cdb0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-f7b9c170-400c-4478-8e63-0d8b6c4c142b,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-cb582046-3209-4ea7-aca7-8ffdb1891a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f38e5820-d812-43b3-a16c-7f3160257a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-6b2b7be3-d808-454c-9f4b-07015a0e8e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-b17a6a62-679f-4b6e-b7d8-33caaffdf216,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-8825654c-5a89-44a6-9f2b-cafe5d67177c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751970507-172.17.0.13-1597545392027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-f3aba554-5ef1-4107-80fd-898baf0b32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-55a53dd6-025f-4da6-aef5-201be6cdb0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-f7b9c170-400c-4478-8e63-0d8b6c4c142b,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-cb582046-3209-4ea7-aca7-8ffdb1891a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f38e5820-d812-43b3-a16c-7f3160257a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-6b2b7be3-d808-454c-9f4b-07015a0e8e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-b17a6a62-679f-4b6e-b7d8-33caaffdf216,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-8825654c-5a89-44a6-9f2b-cafe5d67177c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866327965-172.17.0.13-1597545493413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42339,DS-4d66ac8a-cc69-44d2-971f-f653642206c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-50fac7ac-1646-4c87-8952-fa0da21aa424,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-784d2f85-68ff-40cf-b49b-501505678356,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-54a194d3-8bae-40b4-8cae-d0a2851fb77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d262e30e-ff3e-4631-b3eb-7dbc8ac7635c,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-35c21421-961f-40d1-ae78-0bbc6f6aee70,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-ba2e2768-9bf2-40f7-8da0-f6c489afdb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-a13b73ef-bc1d-41af-a6cc-4cc5d6f92099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866327965-172.17.0.13-1597545493413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42339,DS-4d66ac8a-cc69-44d2-971f-f653642206c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-50fac7ac-1646-4c87-8952-fa0da21aa424,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-784d2f85-68ff-40cf-b49b-501505678356,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-54a194d3-8bae-40b4-8cae-d0a2851fb77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d262e30e-ff3e-4631-b3eb-7dbc8ac7635c,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-35c21421-961f-40d1-ae78-0bbc6f6aee70,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-ba2e2768-9bf2-40f7-8da0-f6c489afdb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-a13b73ef-bc1d-41af-a6cc-4cc5d6f92099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5476
