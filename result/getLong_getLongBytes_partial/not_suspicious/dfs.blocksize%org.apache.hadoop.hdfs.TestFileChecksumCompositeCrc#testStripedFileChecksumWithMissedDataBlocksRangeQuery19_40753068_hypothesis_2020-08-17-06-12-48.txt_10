reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31426588-172.17.0.8-1597646378804:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-4b64af80-5205-4b20-802e-a9ae93500da8,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1285a634-0459-4bd0-b573-77484bc8ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-32ffb038-57e9-4fdc-88a0-e82f8f41dcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-3edc297f-b5d2-4452-9e68-cc0a9f73b0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-b6beaae7-1fdf-4c8c-9f34-b755597d16a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-4c8ac7bd-ca14-4328-8200-8de32a48ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5a6358e7-bd20-46b7-abb7-eb219ed12e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-acf930fd-5451-4f5b-b46a-9937d81e923e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31426588-172.17.0.8-1597646378804:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-4b64af80-5205-4b20-802e-a9ae93500da8,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1285a634-0459-4bd0-b573-77484bc8ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-32ffb038-57e9-4fdc-88a0-e82f8f41dcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-3edc297f-b5d2-4452-9e68-cc0a9f73b0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-b6beaae7-1fdf-4c8c-9f34-b755597d16a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-4c8ac7bd-ca14-4328-8200-8de32a48ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5a6358e7-bd20-46b7-abb7-eb219ed12e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-acf930fd-5451-4f5b-b46a-9937d81e923e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643443583-172.17.0.8-1597646666770:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42655,DS-8c918be9-988c-48d7-89cc-59758a2ce7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-32d1ada4-dd66-4cab-b4f8-8379d9d7969d,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-58be439b-ccba-4f22-9d0c-2243ff23b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-4d5bec54-d129-401a-8e76-7fb3cbbe00f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-cda4ea03-9819-4c10-9753-ab913c80f159,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f11bdb65-2509-4f47-ad47-d036bc3775a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-81e3cd7c-2f62-4844-9e89-96e02841fc42,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a952a0ca-6282-4bd4-8096-09e7756e7c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643443583-172.17.0.8-1597646666770:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42655,DS-8c918be9-988c-48d7-89cc-59758a2ce7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-32d1ada4-dd66-4cab-b4f8-8379d9d7969d,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-58be439b-ccba-4f22-9d0c-2243ff23b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-4d5bec54-d129-401a-8e76-7fb3cbbe00f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-cda4ea03-9819-4c10-9753-ab913c80f159,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f11bdb65-2509-4f47-ad47-d036bc3775a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-81e3cd7c-2f62-4844-9e89-96e02841fc42,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-a952a0ca-6282-4bd4-8096-09e7756e7c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159441594-172.17.0.8-1597646897415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-336ea9b0-e0d2-498b-883a-38d23ebbc699,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-3b515daf-0b21-4cdd-bfae-52bd9f174d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-efb2c271-6ca1-4707-a39e-ab8e2c10ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-caee15a2-62db-4be8-93fd-a77531bffd21,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-063a2057-45af-4bf6-95bf-44f6a507e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-e3e06b26-b83d-486b-afad-bf0579710bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-0eeb3da8-3938-45af-b90c-500804f68e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-39c673f4-d3a1-4d70-b5f9-520078be4926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159441594-172.17.0.8-1597646897415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-336ea9b0-e0d2-498b-883a-38d23ebbc699,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-3b515daf-0b21-4cdd-bfae-52bd9f174d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-efb2c271-6ca1-4707-a39e-ab8e2c10ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-caee15a2-62db-4be8-93fd-a77531bffd21,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-063a2057-45af-4bf6-95bf-44f6a507e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-e3e06b26-b83d-486b-afad-bf0579710bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-0eeb3da8-3938-45af-b90c-500804f68e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-39c673f4-d3a1-4d70-b5f9-520078be4926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5904387-172.17.0.8-1597647511368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-e69f86fb-bf0b-4c8c-9bad-cf8eab3b00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-63648919-eb9a-401c-9483-30ffd525c2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3685a7af-e191-43f1-bc3b-c652d61ba6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-7ed7612b-7bb3-405f-8def-04bd68c80f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-c547ec13-6c13-4fe4-a52b-91aef10d71da,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-bbf0cfe2-c5d6-46ea-ae3a-4b1290c9827d,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-c081724a-c14a-401d-b44f-3f0c40641b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-6d81b16f-9a15-4f10-9940-fa0b170d3079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5904387-172.17.0.8-1597647511368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-e69f86fb-bf0b-4c8c-9bad-cf8eab3b00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-63648919-eb9a-401c-9483-30ffd525c2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3685a7af-e191-43f1-bc3b-c652d61ba6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-7ed7612b-7bb3-405f-8def-04bd68c80f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-c547ec13-6c13-4fe4-a52b-91aef10d71da,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-bbf0cfe2-c5d6-46ea-ae3a-4b1290c9827d,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-c081724a-c14a-401d-b44f-3f0c40641b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-6d81b16f-9a15-4f10-9940-fa0b170d3079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919637461-172.17.0.8-1597647969340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-9fb1ae2a-1861-4530-be79-abd462b11e59,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-03b36800-1002-44e5-8b39-5c8017812b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-5a8d5d82-6af9-4837-b6b9-e24a45572a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-41918688-b7d8-47c0-b75e-1c826593a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3f19b1ef-37c1-4a80-bae0-cb0360111f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-cbb84ccd-c4b2-4d0e-810d-65a42e21bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-2407df7d-cfbb-457f-b1df-cbd1d8bab0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-b0d602b7-8765-4db8-8094-cfc2e7492321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919637461-172.17.0.8-1597647969340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-9fb1ae2a-1861-4530-be79-abd462b11e59,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-03b36800-1002-44e5-8b39-5c8017812b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-5a8d5d82-6af9-4837-b6b9-e24a45572a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-41918688-b7d8-47c0-b75e-1c826593a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3f19b1ef-37c1-4a80-bae0-cb0360111f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-cbb84ccd-c4b2-4d0e-810d-65a42e21bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-2407df7d-cfbb-457f-b1df-cbd1d8bab0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-b0d602b7-8765-4db8-8094-cfc2e7492321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833186333-172.17.0.8-1597648063035:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-75a5bd65-a687-47ee-ae23-76079c289b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-ff48e12e-e00b-4b68-95b8-24a1d80c0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6affd7b7-722c-4def-9fe7-bb0175837a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-32cc9d83-18fc-4df9-94e7-a76908d24a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-52e354f9-0749-42bb-8736-89f9d5061f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1a983a7d-a690-4548-9935-7331fd4bd008,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e12fa79a-2aea-486c-aa29-eeb3fe5d63ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-8820d225-3e6c-4050-b853-48de659ad790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833186333-172.17.0.8-1597648063035:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-75a5bd65-a687-47ee-ae23-76079c289b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-ff48e12e-e00b-4b68-95b8-24a1d80c0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6affd7b7-722c-4def-9fe7-bb0175837a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-32cc9d83-18fc-4df9-94e7-a76908d24a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-52e354f9-0749-42bb-8736-89f9d5061f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1a983a7d-a690-4548-9935-7331fd4bd008,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e12fa79a-2aea-486c-aa29-eeb3fe5d63ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-8820d225-3e6c-4050-b853-48de659ad790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359314351-172.17.0.8-1597648201808:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-a8fc8b40-fa95-481d-9ca6-d2c35196192b,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-d5753ee1-1f6d-4062-a236-f0c67d266c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-6d0a7ab2-785c-4cec-9282-b5b6dedd442c,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-67daa032-91d8-4c1d-867b-34f5d6c408b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-751aa9a9-f0d8-48bd-8b1e-43e93350797e,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-ca0c4eac-f13f-46f2-bb23-5e9c1dbbc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6af8cc86-b53c-40b7-88e8-a6cb9a118ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-e18b2ddf-1339-4fa2-a1fc-05d900dc8c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359314351-172.17.0.8-1597648201808:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-a8fc8b40-fa95-481d-9ca6-d2c35196192b,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-d5753ee1-1f6d-4062-a236-f0c67d266c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-6d0a7ab2-785c-4cec-9282-b5b6dedd442c,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-67daa032-91d8-4c1d-867b-34f5d6c408b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-751aa9a9-f0d8-48bd-8b1e-43e93350797e,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-ca0c4eac-f13f-46f2-bb23-5e9c1dbbc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6af8cc86-b53c-40b7-88e8-a6cb9a118ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-e18b2ddf-1339-4fa2-a1fc-05d900dc8c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959486670-172.17.0.8-1597648426769:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-f7e3520a-dd2c-4695-9913-55c52967c7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-4678c072-5c7c-4d92-910f-c4dca27b3629,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-91109918-37fb-40e3-9149-859cd88d4178,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-f8347da0-680a-4e6b-ba8e-c06afb4495ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-915bca40-72e3-4260-ab7a-e7dd2042a994,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-fd1c3e21-34a4-4ae4-8948-abd0a1c5d5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-e5e18ec8-8cec-4370-8734-4964e58c12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-612d432a-3c99-4628-8145-bc885ebb3058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959486670-172.17.0.8-1597648426769:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-f7e3520a-dd2c-4695-9913-55c52967c7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-4678c072-5c7c-4d92-910f-c4dca27b3629,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-91109918-37fb-40e3-9149-859cd88d4178,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-f8347da0-680a-4e6b-ba8e-c06afb4495ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-915bca40-72e3-4260-ab7a-e7dd2042a994,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-fd1c3e21-34a4-4ae4-8948-abd0a1c5d5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-e5e18ec8-8cec-4370-8734-4964e58c12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-612d432a-3c99-4628-8145-bc885ebb3058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048438535-172.17.0.8-1597649541692:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-c41b4c22-a4a2-4f54-b72a-2bb4e49990a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7d632a4e-0100-454a-989e-c2c8c71cdac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-6501a826-a961-49c9-a2ce-9f87d0ccdf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5e32dc1e-ed22-49cf-bba9-75498aa8b024,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-6a093159-db89-4de5-996e-da7db5ded0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-ca073ac9-8b2c-45db-a0fa-1fc4e6e2d11a,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-65e99980-65b0-4389-ae58-7d720baccc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-a2635c48-1d20-4cb6-a662-747d04945c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048438535-172.17.0.8-1597649541692:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-c41b4c22-a4a2-4f54-b72a-2bb4e49990a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7d632a4e-0100-454a-989e-c2c8c71cdac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-6501a826-a961-49c9-a2ce-9f87d0ccdf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5e32dc1e-ed22-49cf-bba9-75498aa8b024,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-6a093159-db89-4de5-996e-da7db5ded0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-ca073ac9-8b2c-45db-a0fa-1fc4e6e2d11a,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-65e99980-65b0-4389-ae58-7d720baccc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-a2635c48-1d20-4cb6-a662-747d04945c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444776088-172.17.0.8-1597649622918:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-04e9aae2-61d2-4610-9f9d-d36f1a0a44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-86c48473-f3b2-4f32-a3b1-97ee73088ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f3b53cda-91a9-4b03-a5c0-30e36fa7c482,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-5e22d576-e445-4014-a47b-8f850387be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-39b021d3-10fa-4626-8b42-22ebc65fedae,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-e03f860c-fbe2-4bbc-a26c-13c2d2d37438,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a8068eaa-2831-4d51-a2b4-a6079388007c,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-0282db6c-743c-40a3-8ab5-91f2468857c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444776088-172.17.0.8-1597649622918:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-04e9aae2-61d2-4610-9f9d-d36f1a0a44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-86c48473-f3b2-4f32-a3b1-97ee73088ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f3b53cda-91a9-4b03-a5c0-30e36fa7c482,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-5e22d576-e445-4014-a47b-8f850387be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-39b021d3-10fa-4626-8b42-22ebc65fedae,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-e03f860c-fbe2-4bbc-a26c-13c2d2d37438,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a8068eaa-2831-4d51-a2b4-a6079388007c,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-0282db6c-743c-40a3-8ab5-91f2468857c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170715146-172.17.0.8-1597649662247:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-bf5f751a-ff00-439a-9f2d-5c97f4c62a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-426eb3bb-fc81-4166-9159-72e877b5c922,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-8c5184c1-0fe5-4795-b6e3-b306a39ecb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-8426be6f-c605-454a-8c01-acf07fa96122,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-0ef2add1-84f2-4ee7-be02-3e1bc807a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-abbc87d4-d770-445b-9ac3-15e82272ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-74521bd4-a98b-4207-ba3a-387837672aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-1e4ce3c9-ce8e-45a0-a685-540b64dff5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170715146-172.17.0.8-1597649662247:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-bf5f751a-ff00-439a-9f2d-5c97f4c62a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-426eb3bb-fc81-4166-9159-72e877b5c922,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-8c5184c1-0fe5-4795-b6e3-b306a39ecb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-8426be6f-c605-454a-8c01-acf07fa96122,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-0ef2add1-84f2-4ee7-be02-3e1bc807a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-abbc87d4-d770-445b-9ac3-15e82272ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-74521bd4-a98b-4207-ba3a-387837672aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-1e4ce3c9-ce8e-45a0-a685-540b64dff5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100064488-172.17.0.8-1597649792992:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-961acc78-2d64-499d-a4d4-aaef02ee84d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-89504ad6-4b0e-40d0-b1eb-08ead8dfc1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-345b8228-79bb-4c6a-a542-6f5955d5b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-0f85557a-cace-4fe9-9198-4ecec898d268,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-f82f6e6b-f271-4c42-b861-a890cde4bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-5720155f-c214-4b57-99c2-4032be2688df,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-8f874f88-142f-42f5-9cec-bb124524960d,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-c8e2794d-d7ef-4e84-acb7-0aacfe918e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100064488-172.17.0.8-1597649792992:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-961acc78-2d64-499d-a4d4-aaef02ee84d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-89504ad6-4b0e-40d0-b1eb-08ead8dfc1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-345b8228-79bb-4c6a-a542-6f5955d5b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-0f85557a-cace-4fe9-9198-4ecec898d268,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-f82f6e6b-f271-4c42-b861-a890cde4bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-5720155f-c214-4b57-99c2-4032be2688df,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-8f874f88-142f-42f5-9cec-bb124524960d,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-c8e2794d-d7ef-4e84-acb7-0aacfe918e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936515252-172.17.0.8-1597650279946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42119,DS-61ab414c-b354-4b33-a654-7d5a77cdaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-784f2ed7-3811-4149-a271-cc0992181319,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-426ef089-d961-4c46-9eb1-d616fecbbff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-3bd34a0b-078f-444f-8e91-c8be343bda11,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-6d80eb10-fd9b-490a-8839-ee937d8dcc83,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-5b2f85b0-7408-4179-882b-6f9b0010298f,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-5d56a6c8-bca9-4791-94e9-193260eda33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-2a90a205-f7db-431a-b9ea-14a8c39f0d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936515252-172.17.0.8-1597650279946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42119,DS-61ab414c-b354-4b33-a654-7d5a77cdaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-784f2ed7-3811-4149-a271-cc0992181319,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-426ef089-d961-4c46-9eb1-d616fecbbff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-3bd34a0b-078f-444f-8e91-c8be343bda11,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-6d80eb10-fd9b-490a-8839-ee937d8dcc83,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-5b2f85b0-7408-4179-882b-6f9b0010298f,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-5d56a6c8-bca9-4791-94e9-193260eda33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-2a90a205-f7db-431a-b9ea-14a8c39f0d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513807398-172.17.0.8-1597650585201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45545,DS-2a7c24fd-1118-43bf-9955-3393577c4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-a9efda6e-9f54-4b96-979a-11dfe90c6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-91a2def4-5709-48a8-9e3f-bd6aae9803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-fb414adf-7e02-4525-a23b-3eebb57ea78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-25f790c7-0382-49f0-a8ce-b5bbd844bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-a1942c08-0439-4db7-b240-506c544d668b,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-10eff410-0045-4762-bfa8-f3a612f5bb75,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d511051d-0f52-4581-9da8-2f0ce642ae22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513807398-172.17.0.8-1597650585201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45545,DS-2a7c24fd-1118-43bf-9955-3393577c4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-a9efda6e-9f54-4b96-979a-11dfe90c6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-91a2def4-5709-48a8-9e3f-bd6aae9803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-fb414adf-7e02-4525-a23b-3eebb57ea78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-25f790c7-0382-49f0-a8ce-b5bbd844bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-a1942c08-0439-4db7-b240-506c544d668b,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-10eff410-0045-4762-bfa8-f3a612f5bb75,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d511051d-0f52-4581-9da8-2f0ce642ae22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429464084-172.17.0.8-1597651427828:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-9146b74f-12b4-4e88-be73-d97fe2a02832,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-b09d0895-5d00-4104-8175-2471019354d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-845897a5-8b8d-4947-b0fc-7c8e42b0646e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-a134b689-a638-432e-9977-98fa2ab2ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-e31a75f4-c71d-4e3d-a35c-9f2aa84936f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-68a0375b-bbaa-451c-beee-ac62b1942226,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-75cd0191-67fb-4ac1-b3c9-ce45ff713cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-1545bd5d-31f1-451e-a509-ab6b2a6584d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429464084-172.17.0.8-1597651427828:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-9146b74f-12b4-4e88-be73-d97fe2a02832,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-b09d0895-5d00-4104-8175-2471019354d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-845897a5-8b8d-4947-b0fc-7c8e42b0646e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-a134b689-a638-432e-9977-98fa2ab2ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-e31a75f4-c71d-4e3d-a35c-9f2aa84936f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-68a0375b-bbaa-451c-beee-ac62b1942226,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-75cd0191-67fb-4ac1-b3c9-ce45ff713cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-1545bd5d-31f1-451e-a509-ab6b2a6584d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229073566-172.17.0.8-1597651632329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-a7cc2205-973b-44ba-bb4c-0c3ac8081751,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-5e29cb2c-2dfc-4de9-8e03-2768136c5557,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-62affe25-02c6-40fb-838f-a33bb202b559,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-04d0a68f-8cef-47ee-a21a-6c2a1b4a0772,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-204cfb01-8030-49f6-b6d1-7f68c4f568cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-2abde1a6-5179-44b1-b03c-0e3d088ac578,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-e09df174-2bff-4f59-8a14-6816eec7bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-6fc42f60-4d24-48a3-b19b-418cee148039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229073566-172.17.0.8-1597651632329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-a7cc2205-973b-44ba-bb4c-0c3ac8081751,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-5e29cb2c-2dfc-4de9-8e03-2768136c5557,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-62affe25-02c6-40fb-838f-a33bb202b559,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-04d0a68f-8cef-47ee-a21a-6c2a1b4a0772,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-204cfb01-8030-49f6-b6d1-7f68c4f568cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-2abde1a6-5179-44b1-b03c-0e3d088ac578,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-e09df174-2bff-4f59-8a14-6816eec7bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-6fc42f60-4d24-48a3-b19b-418cee148039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7202
