reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709847212-172.17.0.10-1597476399302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-bfa521d7-618a-46d1-9a4d-8e436175763d,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-06072430-b472-4c06-81ec-9218b9fdebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-963e7c70-2a9d-4a54-8186-2cf76050d306,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-9a8516b5-6c56-4ec9-8ff8-e5bcdd673686,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a6462058-c5c0-41a9-9713-7b07cfe380fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-c86471ba-dbed-4a8b-92ef-e79d5614a3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-08125817-2114-4cef-8d26-a1879619ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-56486a1f-1f1d-415f-a64b-990b49e9bf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709847212-172.17.0.10-1597476399302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-bfa521d7-618a-46d1-9a4d-8e436175763d,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-06072430-b472-4c06-81ec-9218b9fdebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-963e7c70-2a9d-4a54-8186-2cf76050d306,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-9a8516b5-6c56-4ec9-8ff8-e5bcdd673686,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a6462058-c5c0-41a9-9713-7b07cfe380fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-c86471ba-dbed-4a8b-92ef-e79d5614a3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-08125817-2114-4cef-8d26-a1879619ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-56486a1f-1f1d-415f-a64b-990b49e9bf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964478057-172.17.0.10-1597476566072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38338,DS-bfe16c6e-c936-49e9-9f3c-20b8cf7a25ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-3b5996c0-8476-487a-9727-b1180de54b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-e9c784b3-62c7-4b35-a3ce-a59598fd883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-d1a3e146-2c75-4496-bf2e-0cab5d91ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-5a0d961d-8409-4968-82ff-c8b85d98de62,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-3622f276-3f8b-4a6d-a45a-be89c1593cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-0e1ebed3-d063-4ca7-8436-b7958f7b969d,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-ee2792a2-5bb1-4d61-b354-01e695c4782e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964478057-172.17.0.10-1597476566072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38338,DS-bfe16c6e-c936-49e9-9f3c-20b8cf7a25ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-3b5996c0-8476-487a-9727-b1180de54b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-e9c784b3-62c7-4b35-a3ce-a59598fd883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-d1a3e146-2c75-4496-bf2e-0cab5d91ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-5a0d961d-8409-4968-82ff-c8b85d98de62,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-3622f276-3f8b-4a6d-a45a-be89c1593cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-0e1ebed3-d063-4ca7-8436-b7958f7b969d,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-ee2792a2-5bb1-4d61-b354-01e695c4782e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557988783-172.17.0.10-1597477021064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-358ac3ac-9a48-45ff-a4f1-9ba476ab12cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-9573b7c6-609f-4ac6-8fc4-64cd292c232d,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-9445479a-8b55-43fd-b354-0b4076af129a,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-de280037-41c5-45ea-84aa-1bfd0cef3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-80d3f759-32df-4279-907f-e59a10edb777,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-f9d1ddc6-cf39-4fee-bb2d-6d3393dce494,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-4757db80-bb6e-4c11-b71f-158759b206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-e329c385-e594-4459-abfa-1ac41aaf2ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557988783-172.17.0.10-1597477021064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-358ac3ac-9a48-45ff-a4f1-9ba476ab12cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-9573b7c6-609f-4ac6-8fc4-64cd292c232d,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-9445479a-8b55-43fd-b354-0b4076af129a,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-de280037-41c5-45ea-84aa-1bfd0cef3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-80d3f759-32df-4279-907f-e59a10edb777,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-f9d1ddc6-cf39-4fee-bb2d-6d3393dce494,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-4757db80-bb6e-4c11-b71f-158759b206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-e329c385-e594-4459-abfa-1ac41aaf2ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606517407-172.17.0.10-1597477390903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-b9b36cd2-a1f5-49aa-bf91-9d03a62d3f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5eb8c3eb-79a5-4577-88bf-d7162089141a,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-bf0fea25-9e82-48a7-ae5d-ee721a34ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-15da7d7a-a8f9-4d57-89ff-5e339ed3a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-c6018b51-c8e0-4b3d-aab2-912fd6db6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-af91c03c-3d14-4c6d-a80d-f6cec17fb213,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-fb49b173-2fe2-4647-905a-5550b9e2d731,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-4f544cc0-894d-46dd-b5b7-d2ace2ed5b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606517407-172.17.0.10-1597477390903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-b9b36cd2-a1f5-49aa-bf91-9d03a62d3f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5eb8c3eb-79a5-4577-88bf-d7162089141a,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-bf0fea25-9e82-48a7-ae5d-ee721a34ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-15da7d7a-a8f9-4d57-89ff-5e339ed3a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-c6018b51-c8e0-4b3d-aab2-912fd6db6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-af91c03c-3d14-4c6d-a80d-f6cec17fb213,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-fb49b173-2fe2-4647-905a-5550b9e2d731,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-4f544cc0-894d-46dd-b5b7-d2ace2ed5b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209460224-172.17.0.10-1597477611906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-7bef0118-fa13-4dcd-8e3e-ac30c17b123e,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-9f6fd052-66cf-4961-b183-c1bab49207bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-21f5090c-9bc9-4f29-abff-4972462380ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-afb36e9b-aa67-46bf-9895-b82209003d03,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-627bc22c-77b7-4430-9e58-736d1cde76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-25921f4b-373d-4d3d-97bc-62bac42ac664,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-06f778d8-8213-44ce-a33d-31b12839192d,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-7668b134-5c3b-4a4b-b3a0-80119ba5e827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209460224-172.17.0.10-1597477611906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-7bef0118-fa13-4dcd-8e3e-ac30c17b123e,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-9f6fd052-66cf-4961-b183-c1bab49207bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-21f5090c-9bc9-4f29-abff-4972462380ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-afb36e9b-aa67-46bf-9895-b82209003d03,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-627bc22c-77b7-4430-9e58-736d1cde76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-25921f4b-373d-4d3d-97bc-62bac42ac664,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-06f778d8-8213-44ce-a33d-31b12839192d,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-7668b134-5c3b-4a4b-b3a0-80119ba5e827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679549437-172.17.0.10-1597478072979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-b23403fa-19f4-4902-b10f-b4591b3a875e,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-c45a07d5-e3d3-4a8a-a867-e20bca4493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-bbbcf3fd-4a45-4e2c-bda1-1fd003ff9abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ef993582-38ad-4ac4-8a94-42d23f1a7998,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-040759df-cc4b-4378-bb73-d9f738e43dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9ac36036-af28-48d9-ba53-27f0ebd1c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-07b5868a-0911-4dba-b028-39d12dad93f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-99f9cd07-1b95-4217-b86c-acf80c3e9d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679549437-172.17.0.10-1597478072979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-b23403fa-19f4-4902-b10f-b4591b3a875e,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-c45a07d5-e3d3-4a8a-a867-e20bca4493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-bbbcf3fd-4a45-4e2c-bda1-1fd003ff9abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ef993582-38ad-4ac4-8a94-42d23f1a7998,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-040759df-cc4b-4378-bb73-d9f738e43dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9ac36036-af28-48d9-ba53-27f0ebd1c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-07b5868a-0911-4dba-b028-39d12dad93f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-99f9cd07-1b95-4217-b86c-acf80c3e9d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121894559-172.17.0.10-1597478356673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35887,DS-5a0be22e-8af2-417e-baff-5f1eff766c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-e5d0fe1c-539b-4dc4-8301-85129d54b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-a14ea281-c431-47e5-a7e6-18e1fe12f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-948469ae-f857-4fbd-9d6b-855bf7617475,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-53634795-0516-4328-b934-d9904c387682,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ef9017ad-edda-412b-899d-cf190c692421,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-b2f16e8c-ff07-4799-96c1-e2a3cd4f1fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-ba42c233-d258-4239-8cc8-b2ea326776c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121894559-172.17.0.10-1597478356673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35887,DS-5a0be22e-8af2-417e-baff-5f1eff766c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-e5d0fe1c-539b-4dc4-8301-85129d54b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-a14ea281-c431-47e5-a7e6-18e1fe12f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-948469ae-f857-4fbd-9d6b-855bf7617475,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-53634795-0516-4328-b934-d9904c387682,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ef9017ad-edda-412b-899d-cf190c692421,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-b2f16e8c-ff07-4799-96c1-e2a3cd4f1fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-ba42c233-d258-4239-8cc8-b2ea326776c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137930744-172.17.0.10-1597478401161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-8ea873c1-7e81-4b7b-8c7d-0ee28f291173,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-b8ddb946-a1a0-40a4-bc4c-a48880250a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-b3bb2d35-77e9-4ae2-bb24-e44c98f37a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-1f7f348b-5498-4e97-a335-62452f72c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-bae575ef-cb48-465b-9a74-ffbb01953f73,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-2601c822-c293-42b1-b58c-9dd8cb2f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-694b3142-9dbf-4f5b-b128-d5044655bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-a1031db2-8ce0-4b3c-9e54-825a7dcbf77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137930744-172.17.0.10-1597478401161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-8ea873c1-7e81-4b7b-8c7d-0ee28f291173,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-b8ddb946-a1a0-40a4-bc4c-a48880250a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-b3bb2d35-77e9-4ae2-bb24-e44c98f37a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-1f7f348b-5498-4e97-a335-62452f72c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-bae575ef-cb48-465b-9a74-ffbb01953f73,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-2601c822-c293-42b1-b58c-9dd8cb2f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-694b3142-9dbf-4f5b-b128-d5044655bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-a1031db2-8ce0-4b3c-9e54-825a7dcbf77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406773966-172.17.0.10-1597479184189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-0a0707b4-f4cc-4cfb-9909-9c61640323fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-85dd18c8-2369-4493-8596-3a13955fd6db,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-5285f811-dd36-42af-a69b-b458d8df70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-a7a36af6-36d4-48c6-8c63-5c5a2e9b1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-bd729571-fb70-42a8-91af-691bf3d25258,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-68c3be79-8649-491d-9247-91850138a835,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-98fbfb4e-8741-46b0-a720-062fc951469a,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-035a4e9c-83b0-4055-8674-b48e80bcbc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406773966-172.17.0.10-1597479184189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-0a0707b4-f4cc-4cfb-9909-9c61640323fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-85dd18c8-2369-4493-8596-3a13955fd6db,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-5285f811-dd36-42af-a69b-b458d8df70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-a7a36af6-36d4-48c6-8c63-5c5a2e9b1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-bd729571-fb70-42a8-91af-691bf3d25258,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-68c3be79-8649-491d-9247-91850138a835,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-98fbfb4e-8741-46b0-a720-062fc951469a,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-035a4e9c-83b0-4055-8674-b48e80bcbc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215771484-172.17.0.10-1597479419850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-e4b8e8bf-a512-49fc-a760-9efe4d9338d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7250c43d-5a41-4997-b528-d0bad7ec4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-d194d8bf-d85b-4e45-bcad-5cb897169cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-4a205e34-7589-42d6-8e0d-ef430ea76d82,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-22a9858b-e760-4aac-aab0-86fb850ec317,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-0adc7218-8854-48d5-a9cf-6004b850cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fddc425e-5f49-4fd9-852c-87b5f7c2a571,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-c424340e-a15c-4753-b7e2-7c4e247d188b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215771484-172.17.0.10-1597479419850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-e4b8e8bf-a512-49fc-a760-9efe4d9338d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7250c43d-5a41-4997-b528-d0bad7ec4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-d194d8bf-d85b-4e45-bcad-5cb897169cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-4a205e34-7589-42d6-8e0d-ef430ea76d82,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-22a9858b-e760-4aac-aab0-86fb850ec317,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-0adc7218-8854-48d5-a9cf-6004b850cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fddc425e-5f49-4fd9-852c-87b5f7c2a571,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-c424340e-a15c-4753-b7e2-7c4e247d188b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387113825-172.17.0.10-1597480290318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-8f83b5d2-5d6a-48d7-8be8-f6a67cbc702c,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-426862a5-28b2-4b8c-b960-0a5d5458b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f90a5dfb-e9cd-4c3c-b9a6-ca38f1c2a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d1f5b13b-2167-4fc6-8cda-35651b1cf9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-e31ba292-0376-40a4-8073-2514bacc8407,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-2931476a-1678-45c0-b4b7-5636e0eb803f,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-f181b8e9-217b-416a-b400-7410a853b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-7df5266c-98c4-4fc6-9270-4f68b9a14456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387113825-172.17.0.10-1597480290318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-8f83b5d2-5d6a-48d7-8be8-f6a67cbc702c,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-426862a5-28b2-4b8c-b960-0a5d5458b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f90a5dfb-e9cd-4c3c-b9a6-ca38f1c2a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d1f5b13b-2167-4fc6-8cda-35651b1cf9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-e31ba292-0376-40a4-8073-2514bacc8407,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-2931476a-1678-45c0-b4b7-5636e0eb803f,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-f181b8e9-217b-416a-b400-7410a853b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-7df5266c-98c4-4fc6-9270-4f68b9a14456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138994923-172.17.0.10-1597480618585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-a67f1b51-90f7-4e76-81bb-5bc02390263b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-3b841a9f-06df-48ea-9daf-c04f51eb04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-719a83cd-d7f9-4910-af24-b57cfa3bdf67,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-23357799-1bd2-4f88-9757-c4262c8cbc79,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-b659240f-2643-4827-9cc9-7b6db263abab,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-69c0408a-115d-427a-beb8-bbbd938b788c,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-c18eeb03-5358-41b4-82f4-99c77e26b55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-ac83068c-dc2f-4ab9-9af8-c562b4953a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138994923-172.17.0.10-1597480618585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-a67f1b51-90f7-4e76-81bb-5bc02390263b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-3b841a9f-06df-48ea-9daf-c04f51eb04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-719a83cd-d7f9-4910-af24-b57cfa3bdf67,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-23357799-1bd2-4f88-9757-c4262c8cbc79,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-b659240f-2643-4827-9cc9-7b6db263abab,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-69c0408a-115d-427a-beb8-bbbd938b788c,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-c18eeb03-5358-41b4-82f4-99c77e26b55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-ac83068c-dc2f-4ab9-9af8-c562b4953a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74227439-172.17.0.10-1597481311589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-808feaec-a1d5-48f0-8085-61396d13f635,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9aca9d00-b0be-4ba9-981c-87dd0c7d0f45,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-1967eccc-31fc-40d4-ba73-e41c9d986143,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-63b70173-9bb4-4332-8dba-2835400036b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-3d9f0a30-9182-4261-86bd-efae647613cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-f5953c00-9cf5-4953-8a48-8b6ede69501f,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-9ab56e1f-0aa5-4120-8962-331b6156b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-0b5b87f5-79d3-49df-a717-2a7a6c7b561f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74227439-172.17.0.10-1597481311589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-808feaec-a1d5-48f0-8085-61396d13f635,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9aca9d00-b0be-4ba9-981c-87dd0c7d0f45,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-1967eccc-31fc-40d4-ba73-e41c9d986143,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-63b70173-9bb4-4332-8dba-2835400036b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-3d9f0a30-9182-4261-86bd-efae647613cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-f5953c00-9cf5-4953-8a48-8b6ede69501f,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-9ab56e1f-0aa5-4120-8962-331b6156b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-0b5b87f5-79d3-49df-a717-2a7a6c7b561f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830889696-172.17.0.10-1597481404096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-2730dccd-fd4a-4366-95af-f6acada27be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7814abe8-4337-423c-a460-c7226f16c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-082493ba-75ba-4877-a29b-c1e6710e52c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-e00384af-cae8-4d7b-b91b-c03d7b8749cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-c0780261-8e30-4270-bd24-40b945dc6022,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-a869751b-8ee5-46c6-9f91-92f2a4565602,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-85b64c87-c4f7-4474-b105-84a35e19355f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-f5e86b22-79da-4109-abf1-4048261b39c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830889696-172.17.0.10-1597481404096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-2730dccd-fd4a-4366-95af-f6acada27be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7814abe8-4337-423c-a460-c7226f16c47f,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-082493ba-75ba-4877-a29b-c1e6710e52c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-e00384af-cae8-4d7b-b91b-c03d7b8749cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-c0780261-8e30-4270-bd24-40b945dc6022,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-a869751b-8ee5-46c6-9f91-92f2a4565602,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-85b64c87-c4f7-4474-b105-84a35e19355f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-f5e86b22-79da-4109-abf1-4048261b39c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989172045-172.17.0.10-1597481495619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-8c049d0a-94e9-4f68-a38a-e19e545d2573,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-aebec0e3-a74e-429e-afa4-cf8d71dfca86,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-e8588e32-9d7c-4019-9951-d019cc9e9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1a134154-c30b-49ba-8273-31a392e25d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-6652a3ca-3d05-404b-8239-d389d0156a79,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-bff73919-904d-433c-a8ff-802dd8ce78fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-47845338-2b1f-4d89-ad00-df7f515d6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-5e09a56f-aedc-4ec0-b64b-a22f40dc30df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989172045-172.17.0.10-1597481495619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-8c049d0a-94e9-4f68-a38a-e19e545d2573,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-aebec0e3-a74e-429e-afa4-cf8d71dfca86,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-e8588e32-9d7c-4019-9951-d019cc9e9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1a134154-c30b-49ba-8273-31a392e25d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-6652a3ca-3d05-404b-8239-d389d0156a79,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-bff73919-904d-433c-a8ff-802dd8ce78fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-47845338-2b1f-4d89-ad00-df7f515d6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-5e09a56f-aedc-4ec0-b64b-a22f40dc30df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377341921-172.17.0.10-1597481544542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-4ba91644-babf-449b-9a47-a434ec4ae5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-0116097a-4f6f-41b9-a09a-640d2cc91370,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-a98c8157-1bf4-44fb-9f47-ca48beee2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-e2043d6a-548e-4d95-9e06-253d39ad5c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-7db59ec6-ed68-473a-bc4e-daeeafcd8700,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-c408b1b6-06b2-4e23-b976-2fac3a78dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-0f5f0562-7732-48f9-9bca-ba44a963b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-52360b38-5e4c-40d6-8ea8-acf41a2b029b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377341921-172.17.0.10-1597481544542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-4ba91644-babf-449b-9a47-a434ec4ae5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-0116097a-4f6f-41b9-a09a-640d2cc91370,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-a98c8157-1bf4-44fb-9f47-ca48beee2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-e2043d6a-548e-4d95-9e06-253d39ad5c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-7db59ec6-ed68-473a-bc4e-daeeafcd8700,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-c408b1b6-06b2-4e23-b976-2fac3a78dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-0f5f0562-7732-48f9-9bca-ba44a963b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-52360b38-5e4c-40d6-8ea8-acf41a2b029b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575215339-172.17.0.10-1597481597165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-d4e94d7e-4cbe-4c45-bd80-77e6134c6c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-61fbfaea-43e5-4b68-a91d-746de354f693,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-182ff710-a5bb-4701-83a3-b2dfb5a659c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-30ed1cb8-b088-42ab-b38c-603e9106e16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-0e2f5bae-5d9e-46db-b6dc-0c4bf041a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-6b3bd620-737f-4e3b-b033-aa5e16e57540,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-8657ff0c-7561-45ba-ae1b-10837190d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-fa4500e2-cf01-42e0-8112-821b49bfdbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575215339-172.17.0.10-1597481597165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-d4e94d7e-4cbe-4c45-bd80-77e6134c6c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-61fbfaea-43e5-4b68-a91d-746de354f693,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-182ff710-a5bb-4701-83a3-b2dfb5a659c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-30ed1cb8-b088-42ab-b38c-603e9106e16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-0e2f5bae-5d9e-46db-b6dc-0c4bf041a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-6b3bd620-737f-4e3b-b033-aa5e16e57540,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-8657ff0c-7561-45ba-ae1b-10837190d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-fa4500e2-cf01-42e0-8112-821b49bfdbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485615417-172.17.0.10-1597481986383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-deb7279b-dc91-4171-97ee-26d9d54d3a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-ab4eb7b2-74c9-4dfb-83b2-8eaa56fcb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f1e864dd-9c3e-437d-bac0-fdcb67736957,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-9b95f872-eda2-4e0a-ac4e-d377940d1e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-0d9ebda6-5bb1-435c-9c56-985c40c35d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-3601dcb5-9178-4c67-94a4-f25572af5124,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-81742852-897c-444b-9e74-f5b3f86598b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f372d54a-9e6c-4c58-b323-4a50e297a6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485615417-172.17.0.10-1597481986383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-deb7279b-dc91-4171-97ee-26d9d54d3a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-ab4eb7b2-74c9-4dfb-83b2-8eaa56fcb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f1e864dd-9c3e-437d-bac0-fdcb67736957,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-9b95f872-eda2-4e0a-ac4e-d377940d1e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-0d9ebda6-5bb1-435c-9c56-985c40c35d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-3601dcb5-9178-4c67-94a4-f25572af5124,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-81742852-897c-444b-9e74-f5b3f86598b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f372d54a-9e6c-4c58-b323-4a50e297a6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429747298-172.17.0.10-1597482313302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-d5542025-d616-4895-a438-f8527c55b359,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-ce248ccb-eeb3-43c8-824e-9219df8517b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9db05f44-6eab-4242-8c48-b25065c92141,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-bda2d6db-d1be-49bd-bb4a-6f2167daa8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-49c43aef-e4b4-46d5-9d48-adc9c75c13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-ecae6ece-8e5b-40cc-8da8-1ea7494f92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-f6a435f7-47af-41b6-a309-be61f470ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-b3ee3029-d2ce-48bd-87b3-864fa1af857d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429747298-172.17.0.10-1597482313302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-d5542025-d616-4895-a438-f8527c55b359,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-ce248ccb-eeb3-43c8-824e-9219df8517b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9db05f44-6eab-4242-8c48-b25065c92141,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-bda2d6db-d1be-49bd-bb4a-6f2167daa8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-49c43aef-e4b4-46d5-9d48-adc9c75c13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-ecae6ece-8e5b-40cc-8da8-1ea7494f92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-f6a435f7-47af-41b6-a309-be61f470ad30,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-b3ee3029-d2ce-48bd-87b3-864fa1af857d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434496712-172.17.0.10-1597482356286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-146c92ec-9339-4c5b-9593-5da0f66354f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-d7f76862-48d9-411c-8f1f-ad79a8542e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-049963ae-a2e3-42da-913a-aced583becf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-a8a090d7-79a7-47e9-b6d4-74e17a5a9457,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-c6eafdeb-a6b8-4f44-9844-aeff813e3ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-9bb94522-9ccb-4929-a5e6-3daf6ad827f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-b8213fc2-ee7d-4f0c-a30d-35895dffdf97,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-45b5f7c3-23ad-45cc-9f16-2934494b1425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434496712-172.17.0.10-1597482356286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-146c92ec-9339-4c5b-9593-5da0f66354f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-d7f76862-48d9-411c-8f1f-ad79a8542e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-049963ae-a2e3-42da-913a-aced583becf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-a8a090d7-79a7-47e9-b6d4-74e17a5a9457,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-c6eafdeb-a6b8-4f44-9844-aeff813e3ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-9bb94522-9ccb-4929-a5e6-3daf6ad827f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-b8213fc2-ee7d-4f0c-a30d-35895dffdf97,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-45b5f7c3-23ad-45cc-9f16-2934494b1425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395521309-172.17.0.10-1597482653665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-efcbfb34-0bb4-4df5-9f1e-ef666e217de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-c3becbfe-a7a0-43f5-ac31-3ad99e53ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-af43554c-7619-4e83-952c-cc163617a332,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-737830e5-4da7-4aaf-868f-3317e6f70926,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-2dbbf84a-618b-43b1-8e94-bc1878325043,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-b4aada01-09bc-45a3-a0e8-d88067cc2ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-e4c3fed4-f50f-4b95-b344-bbbbca1feb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-a0179305-bd8d-4376-b95e-603c320596cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395521309-172.17.0.10-1597482653665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40231,DS-efcbfb34-0bb4-4df5-9f1e-ef666e217de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-c3becbfe-a7a0-43f5-ac31-3ad99e53ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-af43554c-7619-4e83-952c-cc163617a332,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-737830e5-4da7-4aaf-868f-3317e6f70926,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-2dbbf84a-618b-43b1-8e94-bc1878325043,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-b4aada01-09bc-45a3-a0e8-d88067cc2ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-e4c3fed4-f50f-4b95-b344-bbbbca1feb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-a0179305-bd8d-4376-b95e-603c320596cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311868362-172.17.0.10-1597483077385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-27c256c8-bd3e-4de6-a614-7f375d33e329,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1ba7ce55-142f-43b4-bf04-e6bd969238cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-c8337a2a-ad4d-43ba-897f-5076de8746b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-9368ac8e-6ed1-4c30-ba49-e644840b742a,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ee0d22db-c749-46bc-bd5a-4a4e9ea46ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-842172b1-5d5a-4f5a-a6fd-fd230ff0d068,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-7d5a6267-0768-4ca0-88ee-99bfa57836ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-7ad71c96-cd3c-49d8-a75c-99ed85c4ca8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311868362-172.17.0.10-1597483077385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-27c256c8-bd3e-4de6-a614-7f375d33e329,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1ba7ce55-142f-43b4-bf04-e6bd969238cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-c8337a2a-ad4d-43ba-897f-5076de8746b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-9368ac8e-6ed1-4c30-ba49-e644840b742a,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ee0d22db-c749-46bc-bd5a-4a4e9ea46ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-842172b1-5d5a-4f5a-a6fd-fd230ff0d068,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-7d5a6267-0768-4ca0-88ee-99bfa57836ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-7ad71c96-cd3c-49d8-a75c-99ed85c4ca8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6913
