reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226709361-172.17.0.7-1597725646561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-0ee994aa-d6b0-4d3e-b904-1110edfd284f,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-cbbdb314-2cca-49d1-acc3-0b7f48f6deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-4b651493-9dda-43a3-98c5-413031fcc6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-3ed8262a-d6e0-4dce-9293-480e6112b7df,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b28c8e71-abba-4b0c-906f-05aa85931067,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-7a1ef152-a1c5-45ca-a91c-3ac83145c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-188e0ee2-1960-4dce-9751-04eeefeb319b,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-3d31e19b-0b0b-46c1-b4da-9f7b9e7e5a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226709361-172.17.0.7-1597725646561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-0ee994aa-d6b0-4d3e-b904-1110edfd284f,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-cbbdb314-2cca-49d1-acc3-0b7f48f6deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-4b651493-9dda-43a3-98c5-413031fcc6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-3ed8262a-d6e0-4dce-9293-480e6112b7df,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-b28c8e71-abba-4b0c-906f-05aa85931067,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-7a1ef152-a1c5-45ca-a91c-3ac83145c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-188e0ee2-1960-4dce-9751-04eeefeb319b,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-3d31e19b-0b0b-46c1-b4da-9f7b9e7e5a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730534754-172.17.0.7-1597725730131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-5119e558-e052-4e9b-82d3-2f9d3ac4f684,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-41957a29-7a6c-450d-9d7a-3e3d6165f803,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-5b6666b9-ab3b-4f7a-9e58-a0449551bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-713b9704-ffa1-4247-9f90-21078dca5c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6d887c33-1c19-44ac-a451-241b7538f587,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-180bb290-cb82-4bfd-af61-24e92c3caac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-54c27020-1ef6-4753-a60c-2aaf600060aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-d9786316-9e86-4835-89a1-2eb0d0b4c138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730534754-172.17.0.7-1597725730131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-5119e558-e052-4e9b-82d3-2f9d3ac4f684,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-41957a29-7a6c-450d-9d7a-3e3d6165f803,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-5b6666b9-ab3b-4f7a-9e58-a0449551bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-713b9704-ffa1-4247-9f90-21078dca5c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6d887c33-1c19-44ac-a451-241b7538f587,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-180bb290-cb82-4bfd-af61-24e92c3caac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-54c27020-1ef6-4753-a60c-2aaf600060aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-d9786316-9e86-4835-89a1-2eb0d0b4c138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761184640-172.17.0.7-1597726240217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35611,DS-04ff4142-e6bd-4e22-8ad6-96edcd0fdca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-57a2f608-6d1a-4deb-970f-a7c15b635baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-18ccfb61-94d0-4b3c-a6e7-5be5fc76c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-cbde6921-8370-4c1d-99e7-6ffea187d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-e7f6e16b-e409-40ed-b2f4-109895d12913,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-7981619b-d939-47dc-bd7d-584631712280,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-470d4ab0-9079-4c7e-bb13-60f4dd0214ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-ee56d5f9-78ed-41b9-81b7-1edb2953bf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761184640-172.17.0.7-1597726240217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35611,DS-04ff4142-e6bd-4e22-8ad6-96edcd0fdca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-57a2f608-6d1a-4deb-970f-a7c15b635baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-18ccfb61-94d0-4b3c-a6e7-5be5fc76c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-cbde6921-8370-4c1d-99e7-6ffea187d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-e7f6e16b-e409-40ed-b2f4-109895d12913,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-7981619b-d939-47dc-bd7d-584631712280,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-470d4ab0-9079-4c7e-bb13-60f4dd0214ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-ee56d5f9-78ed-41b9-81b7-1edb2953bf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027163739-172.17.0.7-1597726366255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-870deda3-782c-4752-bfb5-2fa388b4ff20,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6e76d104-6792-4dd5-bbd8-ca2f0373ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-41d55e0f-951d-4dd6-a61d-b130bb070b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-117466a3-6af6-4f01-b0f7-42b375466743,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-f94a0040-de1d-4985-9d7b-603d111d02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-d64efc09-7564-4aee-9f13-5de9a194c33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-885e74c2-b98e-4e2c-adf1-be46143c3f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-5c25c879-8875-4049-a651-244e34bdc65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027163739-172.17.0.7-1597726366255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-870deda3-782c-4752-bfb5-2fa388b4ff20,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6e76d104-6792-4dd5-bbd8-ca2f0373ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-41d55e0f-951d-4dd6-a61d-b130bb070b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-117466a3-6af6-4f01-b0f7-42b375466743,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-f94a0040-de1d-4985-9d7b-603d111d02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-d64efc09-7564-4aee-9f13-5de9a194c33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-885e74c2-b98e-4e2c-adf1-be46143c3f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-5c25c879-8875-4049-a651-244e34bdc65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003055304-172.17.0.7-1597726731143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-2e4ea583-d1ef-480b-918e-1d0201dae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-4a18a034-f832-47a0-ad44-1961c99f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-cf083484-ee46-4450-9b18-8badf7b3fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-05a41805-6542-4807-9496-eb54fdb4c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-3b28ddcf-f35d-4c8e-9ec7-e99cd37e179c,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a0b761cf-416d-413d-8112-8ab6d8debc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-b6b64268-f409-43e9-bb30-5e491758ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-d4384fa3-dfcb-418c-a525-39a7645856f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003055304-172.17.0.7-1597726731143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-2e4ea583-d1ef-480b-918e-1d0201dae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-4a18a034-f832-47a0-ad44-1961c99f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-cf083484-ee46-4450-9b18-8badf7b3fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-05a41805-6542-4807-9496-eb54fdb4c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-3b28ddcf-f35d-4c8e-9ec7-e99cd37e179c,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a0b761cf-416d-413d-8112-8ab6d8debc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-b6b64268-f409-43e9-bb30-5e491758ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-d4384fa3-dfcb-418c-a525-39a7645856f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892430257-172.17.0.7-1597727035047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-c743b03d-1e13-48df-a149-6d1ef975843b,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-e70688a1-852f-40a2-b6fb-1be4b678836e,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-a312fac9-1518-4162-8015-1e5f8211bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-ea4f421a-dc38-4b89-aee2-c8b9ef6d9f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-f250c212-f3e0-4499-b36b-1cafbf5e1406,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-65975bb9-bd76-44de-a8fd-dc75d8af3427,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-98ce6428-9046-42c4-bda9-0e4161395420,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-51d12d34-181b-4014-8774-745a06ea3b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892430257-172.17.0.7-1597727035047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-c743b03d-1e13-48df-a149-6d1ef975843b,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-e70688a1-852f-40a2-b6fb-1be4b678836e,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-a312fac9-1518-4162-8015-1e5f8211bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-ea4f421a-dc38-4b89-aee2-c8b9ef6d9f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-f250c212-f3e0-4499-b36b-1cafbf5e1406,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-65975bb9-bd76-44de-a8fd-dc75d8af3427,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-98ce6428-9046-42c4-bda9-0e4161395420,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-51d12d34-181b-4014-8774-745a06ea3b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878196294-172.17.0.7-1597727792558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-25809b79-4207-4fc1-938a-35d09a6ce880,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-54f09c61-032a-4f15-9d60-ea67df9d3874,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-dccaeec9-e225-4391-92a1-27b14b1666a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-40971eb4-7a81-4159-8bac-cbbb2f2b019f,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-7bc49e93-cf0d-499f-9b83-064c2b3b74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-b41588ec-d5f2-488d-9c1c-374b229a5be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8e1617b3-44f4-40e6-91e0-0d03caf08e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-35a5f3d2-92cc-4e1b-b1cc-09fa9fc9a2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878196294-172.17.0.7-1597727792558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-25809b79-4207-4fc1-938a-35d09a6ce880,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-54f09c61-032a-4f15-9d60-ea67df9d3874,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-dccaeec9-e225-4391-92a1-27b14b1666a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-40971eb4-7a81-4159-8bac-cbbb2f2b019f,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-7bc49e93-cf0d-499f-9b83-064c2b3b74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-b41588ec-d5f2-488d-9c1c-374b229a5be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8e1617b3-44f4-40e6-91e0-0d03caf08e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-35a5f3d2-92cc-4e1b-b1cc-09fa9fc9a2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184622104-172.17.0.7-1597727913861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-d2daf69d-d64c-4319-a001-108192f40480,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-8c3217ea-03df-4e6c-8a18-f122985cef58,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-84935242-fa18-48ec-b747-e60d2403afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-564ac225-b3fd-4e85-95e9-f4771ab8bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4c0b041a-ade7-481a-a4cf-6e97af9cc7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7687a11f-333a-4f03-a175-8daf72263c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-0e061989-2e71-4885-83c9-78d2d948228e,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-43f3a0f9-183e-4983-ae34-e24983197f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184622104-172.17.0.7-1597727913861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-d2daf69d-d64c-4319-a001-108192f40480,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-8c3217ea-03df-4e6c-8a18-f122985cef58,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-84935242-fa18-48ec-b747-e60d2403afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-564ac225-b3fd-4e85-95e9-f4771ab8bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4c0b041a-ade7-481a-a4cf-6e97af9cc7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7687a11f-333a-4f03-a175-8daf72263c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-0e061989-2e71-4885-83c9-78d2d948228e,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-43f3a0f9-183e-4983-ae34-e24983197f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035919795-172.17.0.7-1597728695447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36485,DS-39148fc3-cf12-4e02-ae10-9c452a990a12,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-1a14d2a5-a3b8-4ddf-898d-147a9b011951,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-87bae33e-b246-4084-824d-a03fc65963d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-533e72ff-3207-47a5-acbf-9a86a8cf5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-cee1d509-a61f-4ff1-bf07-280cff882758,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-1e594ea3-5d7c-4490-b787-970b7d4962dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-71320029-5a97-426c-a205-6f3bd733bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-0426a272-764c-4322-80ba-3feee2a58a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035919795-172.17.0.7-1597728695447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36485,DS-39148fc3-cf12-4e02-ae10-9c452a990a12,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-1a14d2a5-a3b8-4ddf-898d-147a9b011951,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-87bae33e-b246-4084-824d-a03fc65963d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-533e72ff-3207-47a5-acbf-9a86a8cf5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-cee1d509-a61f-4ff1-bf07-280cff882758,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-1e594ea3-5d7c-4490-b787-970b7d4962dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-71320029-5a97-426c-a205-6f3bd733bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-0426a272-764c-4322-80ba-3feee2a58a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480532497-172.17.0.7-1597729632540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-2d2699d0-994c-499d-9ecd-da9a62ef5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e69eb68d-29d4-43b1-bba4-05b7b150bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-301cda04-76c9-4e3c-88c7-e550b8909d22,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-87633a44-db96-4e81-a54c-91e608afbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-f33de471-1b7f-4259-8e4a-714d74034489,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5917e937-aff7-4be5-bc10-b3ff7a8fbd34,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-94bfb3fd-f95b-4ec4-853d-3ff89dceae21,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-ad4cf8e1-59af-48d0-881f-46aafbb36c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480532497-172.17.0.7-1597729632540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-2d2699d0-994c-499d-9ecd-da9a62ef5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e69eb68d-29d4-43b1-bba4-05b7b150bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-301cda04-76c9-4e3c-88c7-e550b8909d22,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-87633a44-db96-4e81-a54c-91e608afbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-f33de471-1b7f-4259-8e4a-714d74034489,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5917e937-aff7-4be5-bc10-b3ff7a8fbd34,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-94bfb3fd-f95b-4ec4-853d-3ff89dceae21,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-ad4cf8e1-59af-48d0-881f-46aafbb36c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892127895-172.17.0.7-1597729995243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-d65c66b7-8476-4f9f-b840-e752a8f58a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-8f7d3d12-a66c-4c9a-9abe-f3efef6dcb86,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-17991adf-18cc-4848-ac17-27dc3c31b57c,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-d093f84a-3c91-4522-829e-b9f4d55cbbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-014910c6-76d7-4a1c-af77-91142ef17d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1215a6e7-13e5-466e-b9f6-02812592e697,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-98b4ea9c-87cb-4314-a60e-7b2fcd02f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-c31ea59e-8dc6-4e2a-9dec-2ced375e1a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892127895-172.17.0.7-1597729995243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-d65c66b7-8476-4f9f-b840-e752a8f58a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-8f7d3d12-a66c-4c9a-9abe-f3efef6dcb86,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-17991adf-18cc-4848-ac17-27dc3c31b57c,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-d093f84a-3c91-4522-829e-b9f4d55cbbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-014910c6-76d7-4a1c-af77-91142ef17d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1215a6e7-13e5-466e-b9f6-02812592e697,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-98b4ea9c-87cb-4314-a60e-7b2fcd02f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-c31ea59e-8dc6-4e2a-9dec-2ced375e1a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455519106-172.17.0.7-1597730237478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-835aa22f-6ea9-4585-9ec4-a2747c90d679,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e622ae31-8c04-4f05-8392-8ecf5d38215e,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-ac399c7a-4e9d-471c-854c-a4be8928537c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-dbe30b41-25b5-40eb-9881-04175f757d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-b83174ba-244d-464b-96e1-65cdb7bb17d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-8cbfd142-69c6-4833-9b6e-678d247f5481,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-ec3d41a9-bcc6-4711-a6eb-9f6ac58b8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c84cb8d4-1670-4ff7-a980-82dcd8fce256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455519106-172.17.0.7-1597730237478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-835aa22f-6ea9-4585-9ec4-a2747c90d679,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e622ae31-8c04-4f05-8392-8ecf5d38215e,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-ac399c7a-4e9d-471c-854c-a4be8928537c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-dbe30b41-25b5-40eb-9881-04175f757d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-b83174ba-244d-464b-96e1-65cdb7bb17d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-8cbfd142-69c6-4833-9b6e-678d247f5481,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-ec3d41a9-bcc6-4711-a6eb-9f6ac58b8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c84cb8d4-1670-4ff7-a980-82dcd8fce256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965933470-172.17.0.7-1597730318713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-3db92545-37bf-4f2c-b424-fabb9e3b098d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-6e67209a-0903-4529-8f92-9c446063251e,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-aac895ee-f40f-4582-9566-1bd3dfb6a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-6b2cf5f9-1a6a-44a2-8c30-c34be7df227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-5c08d1e9-91bf-41a4-a542-75db4410ec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-9a723b01-805f-4f0b-851b-69e8d92f6866,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-d78e4b6a-5401-43b8-8e83-b363f82edc22,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-99bd9d97-fcc7-4788-bdb9-c60ea361cdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965933470-172.17.0.7-1597730318713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-3db92545-37bf-4f2c-b424-fabb9e3b098d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-6e67209a-0903-4529-8f92-9c446063251e,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-aac895ee-f40f-4582-9566-1bd3dfb6a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-6b2cf5f9-1a6a-44a2-8c30-c34be7df227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-5c08d1e9-91bf-41a4-a542-75db4410ec0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-9a723b01-805f-4f0b-851b-69e8d92f6866,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-d78e4b6a-5401-43b8-8e83-b363f82edc22,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-99bd9d97-fcc7-4788-bdb9-c60ea361cdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635966858-172.17.0.7-1597730883284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-4d0c12a4-f32a-40ae-bfec-c237e146622f,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-b66d054a-d187-4be5-a05b-ef99771178fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6fc873fb-9190-4d10-a437-d6a11b41adac,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-f693069a-b340-4bdd-9ce7-500dd3310b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e5c19dbf-e4d9-44f2-ae19-a17c2f66c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-0e1415a7-6dd1-4616-a17d-c7792e91a62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-52a3487b-4b6b-4203-baf5-e4a7eb584efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-952f71b0-ea75-450d-aea4-fee9edd78e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635966858-172.17.0.7-1597730883284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-4d0c12a4-f32a-40ae-bfec-c237e146622f,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-b66d054a-d187-4be5-a05b-ef99771178fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6fc873fb-9190-4d10-a437-d6a11b41adac,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-f693069a-b340-4bdd-9ce7-500dd3310b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e5c19dbf-e4d9-44f2-ae19-a17c2f66c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-0e1415a7-6dd1-4616-a17d-c7792e91a62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-52a3487b-4b6b-4203-baf5-e4a7eb584efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-952f71b0-ea75-450d-aea4-fee9edd78e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5810
