reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113847287-172.17.0.12-1597525330322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-8167d8a3-39b5-41ff-82fe-39be1d5f75af,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-ce70e9cc-3c87-4e60-bb23-4f6a03a6bb28,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-426b0007-6de7-4ac7-88c1-681e343fb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-140f0738-26fc-49c2-b740-bf9dde6c33a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f751c702-1aba-4ea9-80b6-61eabe8b6d15,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-a9320670-6e29-45fb-a62a-0cda4c24ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-34c306d1-e49c-459d-bb0c-b6ed8104776f,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-a80c5ecb-2de2-492f-a866-e17d715e8002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113847287-172.17.0.12-1597525330322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-8167d8a3-39b5-41ff-82fe-39be1d5f75af,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-ce70e9cc-3c87-4e60-bb23-4f6a03a6bb28,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-426b0007-6de7-4ac7-88c1-681e343fb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-140f0738-26fc-49c2-b740-bf9dde6c33a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f751c702-1aba-4ea9-80b6-61eabe8b6d15,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-a9320670-6e29-45fb-a62a-0cda4c24ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-34c306d1-e49c-459d-bb0c-b6ed8104776f,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-a80c5ecb-2de2-492f-a866-e17d715e8002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056347528-172.17.0.12-1597525370037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-6bd66fc3-86e3-45c6-bf8b-07d1760668a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-73f89f67-9583-4d58-b2e5-c42d81beffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-578ad19c-c9a1-42a1-a9a0-b6dd65b2e3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-190b667c-3199-4733-aa10-37b702ec14eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-26441b5e-4c3f-4820-8123-c64bc8b23f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-fb096ed4-3dfc-437e-afc4-f9257b544786,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-6f8c64ea-d2c9-40ea-a0d1-974f0a13fba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-d6e97ac0-775d-43cc-a281-ebd46c977dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056347528-172.17.0.12-1597525370037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-6bd66fc3-86e3-45c6-bf8b-07d1760668a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-73f89f67-9583-4d58-b2e5-c42d81beffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-578ad19c-c9a1-42a1-a9a0-b6dd65b2e3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-190b667c-3199-4733-aa10-37b702ec14eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-26441b5e-4c3f-4820-8123-c64bc8b23f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-fb096ed4-3dfc-437e-afc4-f9257b544786,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-6f8c64ea-d2c9-40ea-a0d1-974f0a13fba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-d6e97ac0-775d-43cc-a281-ebd46c977dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619569222-172.17.0.12-1597525441474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34538,DS-725e1bd4-87ed-43ba-b897-12f9d332b493,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-691094af-a62f-4b73-af82-af5f112340f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-c51e2fdb-868c-438b-8113-e07557e85e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-ec110c75-8895-44a3-9e74-c735e410c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-9b4cd791-5be8-4017-ae3e-2c412f913823,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-7a2724a8-a9fc-4603-9e26-029cab94e434,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-ad3fac38-6bb3-49dd-8381-71a57241cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-af61fc53-3e95-45b2-a72a-333585bb0ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619569222-172.17.0.12-1597525441474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34538,DS-725e1bd4-87ed-43ba-b897-12f9d332b493,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-691094af-a62f-4b73-af82-af5f112340f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-c51e2fdb-868c-438b-8113-e07557e85e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-ec110c75-8895-44a3-9e74-c735e410c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-9b4cd791-5be8-4017-ae3e-2c412f913823,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-7a2724a8-a9fc-4603-9e26-029cab94e434,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-ad3fac38-6bb3-49dd-8381-71a57241cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-af61fc53-3e95-45b2-a72a-333585bb0ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252054061-172.17.0.12-1597525885518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32821,DS-84ee5e81-a61a-40b9-9cc2-9f0b803cf4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-9205602c-7a8e-4799-8f40-4a522b8846d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-82701d7a-c0f1-4279-b93d-e02c5609d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-be5a44bc-360e-4a87-b354-9527d0c79e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-298a8836-07b0-48fd-aa46-9ea14953d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-3c6711b5-7bb5-49b9-aac1-998d5ae6be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-513b4aa1-db25-4d43-b00c-56f3b78b3f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f04dc8c5-4f69-4458-8a7a-c80e6e39b25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252054061-172.17.0.12-1597525885518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32821,DS-84ee5e81-a61a-40b9-9cc2-9f0b803cf4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-9205602c-7a8e-4799-8f40-4a522b8846d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-82701d7a-c0f1-4279-b93d-e02c5609d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-be5a44bc-360e-4a87-b354-9527d0c79e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-298a8836-07b0-48fd-aa46-9ea14953d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-3c6711b5-7bb5-49b9-aac1-998d5ae6be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-513b4aa1-db25-4d43-b00c-56f3b78b3f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f04dc8c5-4f69-4458-8a7a-c80e6e39b25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312482110-172.17.0.12-1597526357466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-e2d00956-5f00-43a8-a788-1bbab7143203,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-8bf4d390-6118-4d8d-a2f3-9eb94ad58715,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-852820fc-3297-40b5-8f9b-31b02b889f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ad4c84e9-bd7e-4d7d-8b2e-a9236a124b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f85d034c-bef9-4d76-b456-3402938a28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-e588ac18-99b9-4d44-b829-225ec0b8a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-ff5c395d-0fe3-43e8-95e8-81b93bbfa37b,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-7d81a176-2b34-46a8-9d5c-9a34313dba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312482110-172.17.0.12-1597526357466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-e2d00956-5f00-43a8-a788-1bbab7143203,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-8bf4d390-6118-4d8d-a2f3-9eb94ad58715,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-852820fc-3297-40b5-8f9b-31b02b889f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ad4c84e9-bd7e-4d7d-8b2e-a9236a124b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f85d034c-bef9-4d76-b456-3402938a28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-e588ac18-99b9-4d44-b829-225ec0b8a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-ff5c395d-0fe3-43e8-95e8-81b93bbfa37b,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-7d81a176-2b34-46a8-9d5c-9a34313dba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370229993-172.17.0.12-1597526552299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-4353bbcf-65bd-4d93-990a-f1e54788c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-15cad0f4-c3fd-41a6-a589-668199c91a38,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-29e997fe-d94a-4651-be21-ad9cb82ffd95,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-0dbd97f7-4cca-4100-ac9a-0c8a11c60534,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-20a156a7-471b-4c80-9068-20b77c2058d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-3da53f87-33d9-49d3-985a-6279f7fafbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-a692b8e9-7b90-4462-8dec-043edbeaade9,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6d1ad7f2-3f9c-4e6d-acc9-d6976a50b4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370229993-172.17.0.12-1597526552299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-4353bbcf-65bd-4d93-990a-f1e54788c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-15cad0f4-c3fd-41a6-a589-668199c91a38,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-29e997fe-d94a-4651-be21-ad9cb82ffd95,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-0dbd97f7-4cca-4100-ac9a-0c8a11c60534,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-20a156a7-471b-4c80-9068-20b77c2058d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-3da53f87-33d9-49d3-985a-6279f7fafbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-a692b8e9-7b90-4462-8dec-043edbeaade9,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6d1ad7f2-3f9c-4e6d-acc9-d6976a50b4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975268832-172.17.0.12-1597526861824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38174,DS-2b2b1770-645d-4c15-b506-dc7b74f2bd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-be7184cd-1e4d-495a-b4c0-1239dada5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b4313531-c16b-4d31-be5a-6a063ebdd99f,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-2816eb7a-5b24-46c2-8127-5e9ab15b7414,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-8825cfa2-ceca-4cc4-a041-eaec7b2f94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-9c57e4b8-df53-4dd0-ba07-c0ed257f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-ac1aa60b-5253-484a-8b43-03ea0e1b427b,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-59347070-745b-46bd-9e75-b103a877b53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975268832-172.17.0.12-1597526861824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38174,DS-2b2b1770-645d-4c15-b506-dc7b74f2bd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-be7184cd-1e4d-495a-b4c0-1239dada5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b4313531-c16b-4d31-be5a-6a063ebdd99f,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-2816eb7a-5b24-46c2-8127-5e9ab15b7414,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-8825cfa2-ceca-4cc4-a041-eaec7b2f94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-9c57e4b8-df53-4dd0-ba07-c0ed257f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-ac1aa60b-5253-484a-8b43-03ea0e1b427b,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-59347070-745b-46bd-9e75-b103a877b53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020501258-172.17.0.12-1597527787242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37487,DS-5d826f47-7936-425a-9c8f-28c62e89d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-aa184011-ba8c-472d-b7e6-94fe05526071,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-0fa8eb7d-3413-47f8-82b6-519d6ceffbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-bcb8997f-f781-475c-80d7-ac81fb8730e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-89903f45-38fc-4f1b-b694-abfd56d9d674,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-8643649c-a083-46c1-918a-cb7435646d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-1dc02edb-c9e4-4e4d-878c-83ee41a5e816,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-2f431c0b-f747-4825-830d-9729b5261fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020501258-172.17.0.12-1597527787242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37487,DS-5d826f47-7936-425a-9c8f-28c62e89d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-aa184011-ba8c-472d-b7e6-94fe05526071,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-0fa8eb7d-3413-47f8-82b6-519d6ceffbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-bcb8997f-f781-475c-80d7-ac81fb8730e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-89903f45-38fc-4f1b-b694-abfd56d9d674,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-8643649c-a083-46c1-918a-cb7435646d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-1dc02edb-c9e4-4e4d-878c-83ee41a5e816,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-2f431c0b-f747-4825-830d-9729b5261fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621801626-172.17.0.12-1597527907806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-1b8dabd3-a4ec-4507-b9a4-5ab61c0f30b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-3b0d0b23-2046-4325-b7a8-cf7d0b912096,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-536d92af-9267-4399-8587-144fb05316fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-2c3d2dea-f52e-48c2-a2ef-544f6ec95b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-1b120b69-dc12-4f4c-b22a-723b8fcfc8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8c099035-6395-4079-93e0-0a4c6d7d3083,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-9bbf3496-d798-4d40-9616-2e6879f1bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-62bad8eb-a273-4ce2-99ec-6cfd3ce553e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621801626-172.17.0.12-1597527907806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-1b8dabd3-a4ec-4507-b9a4-5ab61c0f30b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-3b0d0b23-2046-4325-b7a8-cf7d0b912096,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-536d92af-9267-4399-8587-144fb05316fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-2c3d2dea-f52e-48c2-a2ef-544f6ec95b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-1b120b69-dc12-4f4c-b22a-723b8fcfc8be,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8c099035-6395-4079-93e0-0a4c6d7d3083,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-9bbf3496-d798-4d40-9616-2e6879f1bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-62bad8eb-a273-4ce2-99ec-6cfd3ce553e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428075655-172.17.0.12-1597529416122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43261,DS-b5d502d2-a22e-4a16-9992-137502fadca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-728cad68-35d4-4482-9c77-7da2a68478c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-8f2966f5-e842-4dd1-aeed-ec0ef195f375,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-499f9cde-7ad5-4829-984d-2a10c375d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-ea727990-dfc1-4345-ae4c-aa653cfaf93d,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-87459076-0ea7-49dc-9941-219f62b954cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-5ec45f0b-8921-41bc-be19-7151a0280a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e6d39719-42b3-4a9a-990d-fb4ae25daa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428075655-172.17.0.12-1597529416122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43261,DS-b5d502d2-a22e-4a16-9992-137502fadca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-728cad68-35d4-4482-9c77-7da2a68478c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-8f2966f5-e842-4dd1-aeed-ec0ef195f375,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-499f9cde-7ad5-4829-984d-2a10c375d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-ea727990-dfc1-4345-ae4c-aa653cfaf93d,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-87459076-0ea7-49dc-9941-219f62b954cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-5ec45f0b-8921-41bc-be19-7151a0280a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e6d39719-42b3-4a9a-990d-fb4ae25daa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001448033-172.17.0.12-1597529541496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-d5bccb6a-bcb8-45b2-915a-d669ce89d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-9e07acda-bc4b-4cdb-a4b5-d7c01ad820d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-17e4b439-b53c-40e8-8721-4bd76f918d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-5cd165fa-4cb1-44db-8b33-5101639f540c,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-fae14c41-ed10-4880-b373-e1f866481fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-24758826-9b91-499c-804a-709bcdc1ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-9f4a3d77-8e58-4b1b-88b5-571823194f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-770ae163-3644-4910-b6ed-690c77e06aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001448033-172.17.0.12-1597529541496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-d5bccb6a-bcb8-45b2-915a-d669ce89d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-9e07acda-bc4b-4cdb-a4b5-d7c01ad820d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-17e4b439-b53c-40e8-8721-4bd76f918d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-5cd165fa-4cb1-44db-8b33-5101639f540c,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-fae14c41-ed10-4880-b373-e1f866481fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-24758826-9b91-499c-804a-709bcdc1ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-9f4a3d77-8e58-4b1b-88b5-571823194f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-770ae163-3644-4910-b6ed-690c77e06aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091025293-172.17.0.12-1597529928435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-36581304-8b38-4766-91fc-ceae6b105534,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-561204fa-9b94-441a-a84f-38c56ff8b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-fcb2970d-11ed-4623-a5c2-cb81c3875e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-69a8da1b-fbaf-45b8-9760-0ccde6691645,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b67989da-c8d1-4cd6-a3bf-08df8ab9fb65,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-be9a5d6e-2bee-4f4c-85a7-ed912cb46434,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-1f0e5d07-06e1-499c-9594-943367502d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-450f3bd5-7d25-4cad-9cb3-f2ab8e5cb5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091025293-172.17.0.12-1597529928435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-36581304-8b38-4766-91fc-ceae6b105534,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-561204fa-9b94-441a-a84f-38c56ff8b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-fcb2970d-11ed-4623-a5c2-cb81c3875e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-69a8da1b-fbaf-45b8-9760-0ccde6691645,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b67989da-c8d1-4cd6-a3bf-08df8ab9fb65,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-be9a5d6e-2bee-4f4c-85a7-ed912cb46434,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-1f0e5d07-06e1-499c-9594-943367502d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-450f3bd5-7d25-4cad-9cb3-f2ab8e5cb5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080478956-172.17.0.12-1597529967894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37925,DS-8f20ab0f-67d4-44a9-8991-ad271dd61c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d3816b16-a4cc-43ba-988a-829acddbaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-264dde98-8da1-4604-8c11-01b5abf8fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-f0dd19d5-b2d9-4968-80a2-0d5fecba32a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-21026bec-0dec-4087-b419-246393efca19,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-7ed0dcc4-5f19-4770-8c22-7c5c71676b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-fb8e072e-8607-4995-a083-e202c8ecb7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-b68a43e0-1827-4866-afee-8aae225cc355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080478956-172.17.0.12-1597529967894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37925,DS-8f20ab0f-67d4-44a9-8991-ad271dd61c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d3816b16-a4cc-43ba-988a-829acddbaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-264dde98-8da1-4604-8c11-01b5abf8fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-f0dd19d5-b2d9-4968-80a2-0d5fecba32a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-21026bec-0dec-4087-b419-246393efca19,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-7ed0dcc4-5f19-4770-8c22-7c5c71676b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-fb8e072e-8607-4995-a083-e202c8ecb7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-b68a43e0-1827-4866-afee-8aae225cc355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5675
