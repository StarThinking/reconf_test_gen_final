reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925496965-172.17.0.12-1597639863555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-720efb83-b058-4c4c-b657-f654406df2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-9ea8061f-fb3b-460d-a921-e51874fac845,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3c4520c2-89f6-42d5-9750-a828ed02a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-605d829c-98d8-45bf-8e55-ef8c8e3f2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-89e9de58-4515-45b5-b1d3-3e958439baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-a3b3947e-2a5c-4792-88af-f989a2aee680,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-4ad497d6-7e81-4b3f-92fe-ff7011ba0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-cce5dea8-030a-4b2e-848b-f261440feb82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925496965-172.17.0.12-1597639863555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-720efb83-b058-4c4c-b657-f654406df2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-9ea8061f-fb3b-460d-a921-e51874fac845,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3c4520c2-89f6-42d5-9750-a828ed02a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-605d829c-98d8-45bf-8e55-ef8c8e3f2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-89e9de58-4515-45b5-b1d3-3e958439baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-a3b3947e-2a5c-4792-88af-f989a2aee680,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-4ad497d6-7e81-4b3f-92fe-ff7011ba0a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-cce5dea8-030a-4b2e-848b-f261440feb82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074191022-172.17.0.12-1597640004209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44116,DS-f4cf7c87-160b-4187-8e68-c6e2e06ca696,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-2c509fd2-1db9-4025-ab77-de5f098c0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-fedf402a-3860-4e91-bbba-130c1633510b,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-5bfc120a-cc61-45fb-a6f8-92fafcd4ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-10421f05-86fb-43ee-abb3-13254a94850d,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-55bf8270-317c-48e5-a42b-a90f5f2570d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-4156f91b-41af-4aa3-aedb-52cd40e02c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-d1836eb6-c475-4dea-9167-79b6478aff9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074191022-172.17.0.12-1597640004209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44116,DS-f4cf7c87-160b-4187-8e68-c6e2e06ca696,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-2c509fd2-1db9-4025-ab77-de5f098c0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-fedf402a-3860-4e91-bbba-130c1633510b,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-5bfc120a-cc61-45fb-a6f8-92fafcd4ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-10421f05-86fb-43ee-abb3-13254a94850d,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-55bf8270-317c-48e5-a42b-a90f5f2570d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-4156f91b-41af-4aa3-aedb-52cd40e02c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-d1836eb6-c475-4dea-9167-79b6478aff9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826421779-172.17.0.12-1597640317793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-6a3d3441-0f52-41a4-8781-6d6d6b023f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b2c621a6-2199-43a0-b4f0-21eb62f3e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-f536fa2f-9d36-49f9-b9a8-570a48db2ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-4a6fe56f-efe1-4373-9607-001f0c5e00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-92de97ca-28a3-4427-a278-d79a148159af,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-c5b81cec-aed8-4188-b25a-51d857bfb0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-b6beaa6f-0467-4d6d-9a3c-e03a50713205,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-231285e1-914b-43a3-862c-375b0ae199b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826421779-172.17.0.12-1597640317793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-6a3d3441-0f52-41a4-8781-6d6d6b023f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b2c621a6-2199-43a0-b4f0-21eb62f3e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-f536fa2f-9d36-49f9-b9a8-570a48db2ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-4a6fe56f-efe1-4373-9607-001f0c5e00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-92de97ca-28a3-4427-a278-d79a148159af,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-c5b81cec-aed8-4188-b25a-51d857bfb0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-b6beaa6f-0467-4d6d-9a3c-e03a50713205,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-231285e1-914b-43a3-862c-375b0ae199b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374390916-172.17.0.12-1597640714587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-d791aa1c-6b5d-431e-8eb3-609fc5401c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-0724acb1-eca3-4c34-b05f-23528e4bd0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-aa53cbb9-2f10-4177-962c-6a8e5a5ade5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-e31d1d1a-662b-494f-a604-e5080fe5aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-b2ba1ef9-487d-40fd-9ca2-5a5b4867bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-e6b34d4a-9020-43b5-9479-009f7f64fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-b9f40922-df4e-46c9-82a9-f0d9c00a626c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-1255850e-2191-4f2a-a2bf-a82ecf5d671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374390916-172.17.0.12-1597640714587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-d791aa1c-6b5d-431e-8eb3-609fc5401c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-0724acb1-eca3-4c34-b05f-23528e4bd0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-aa53cbb9-2f10-4177-962c-6a8e5a5ade5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-e31d1d1a-662b-494f-a604-e5080fe5aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-b2ba1ef9-487d-40fd-9ca2-5a5b4867bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-e6b34d4a-9020-43b5-9479-009f7f64fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-b9f40922-df4e-46c9-82a9-f0d9c00a626c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-1255850e-2191-4f2a-a2bf-a82ecf5d671d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956521730-172.17.0.12-1597640988640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-3ca97f69-7409-4ac4-9ac0-132db6d05463,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-c9872546-c1b3-40db-9ff8-2430670a9c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-f9c7552b-6cc0-4824-93b2-35e6ce7e7089,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-35d892ef-c31d-4af7-aea2-03cfdb8e778a,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-0c324136-fef6-4899-9828-4d346f04b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-0efa89f8-dedf-4c90-8004-732e5545ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-edc0b2d6-d4db-432c-9690-bf0f3cb2970f,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-3566410f-643b-4c32-9eb1-4d4d7b3c0f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956521730-172.17.0.12-1597640988640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-3ca97f69-7409-4ac4-9ac0-132db6d05463,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-c9872546-c1b3-40db-9ff8-2430670a9c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-f9c7552b-6cc0-4824-93b2-35e6ce7e7089,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-35d892ef-c31d-4af7-aea2-03cfdb8e778a,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-0c324136-fef6-4899-9828-4d346f04b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-0efa89f8-dedf-4c90-8004-732e5545ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-edc0b2d6-d4db-432c-9690-bf0f3cb2970f,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-3566410f-643b-4c32-9eb1-4d4d7b3c0f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136622527-172.17.0.12-1597641365212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41434,DS-f8b2b8c5-40aa-430c-bc4d-eb5b76fc3452,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-fb3bfe14-f7bb-487d-980c-c8132a485327,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-34fbc29d-afce-4b39-b48f-ec2908129332,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-57c1c26b-1b4d-4ede-98f0-318f92d75b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8f2b98e0-6b70-408c-a33e-0bef253a903d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-8fd62c53-7356-4ee3-a5c0-fa1c7d523847,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-762cf7e1-62ae-4279-893c-4c6d66902cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-7cbbe643-1c2c-40d8-a94e-d6c32e7826ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136622527-172.17.0.12-1597641365212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41434,DS-f8b2b8c5-40aa-430c-bc4d-eb5b76fc3452,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-fb3bfe14-f7bb-487d-980c-c8132a485327,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-34fbc29d-afce-4b39-b48f-ec2908129332,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-57c1c26b-1b4d-4ede-98f0-318f92d75b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8f2b98e0-6b70-408c-a33e-0bef253a903d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-8fd62c53-7356-4ee3-a5c0-fa1c7d523847,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-762cf7e1-62ae-4279-893c-4c6d66902cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-7cbbe643-1c2c-40d8-a94e-d6c32e7826ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937511462-172.17.0.12-1597641530152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-e539fe3a-25a1-4af9-99c7-0fae735dbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-78f1bcfb-e729-446b-8bcc-9e98a8258a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-812193fe-977f-40cb-b0f9-dc7d2e654d49,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b4b8d8e3-54ac-43f7-bfa0-b10db0c25c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-e9e7539a-3452-461a-abe1-a26ce8c771ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-7eda5348-4205-4c34-a669-7579fca1f69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-97c35c26-c47a-4e3e-92a1-ffc8f63c53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a0d4441a-8b9b-44f4-a962-cdc9e3dae7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937511462-172.17.0.12-1597641530152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-e539fe3a-25a1-4af9-99c7-0fae735dbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-78f1bcfb-e729-446b-8bcc-9e98a8258a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-812193fe-977f-40cb-b0f9-dc7d2e654d49,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b4b8d8e3-54ac-43f7-bfa0-b10db0c25c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-e9e7539a-3452-461a-abe1-a26ce8c771ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-7eda5348-4205-4c34-a669-7579fca1f69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-97c35c26-c47a-4e3e-92a1-ffc8f63c53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a0d4441a-8b9b-44f4-a962-cdc9e3dae7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642659771-172.17.0.12-1597641896804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-e02756af-cf69-41a9-8e72-cf2fc67fc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-ef0ec89b-eb57-471e-a9d8-4e6d99f4fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-00b0ef9f-e31c-479d-afd3-f55340894c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-73fac0eb-ba4a-4f6b-b241-31d884d25329,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-f89c6443-9ff8-4731-9b08-d0e08dea9560,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8918b3d2-8668-4c42-b335-874120a0a73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-a36a06d4-d906-445d-bed3-e1842fb6c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-b2f55385-ecbc-4517-a6db-dc2ade23c8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642659771-172.17.0.12-1597641896804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-e02756af-cf69-41a9-8e72-cf2fc67fc49f,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-ef0ec89b-eb57-471e-a9d8-4e6d99f4fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-00b0ef9f-e31c-479d-afd3-f55340894c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-73fac0eb-ba4a-4f6b-b241-31d884d25329,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-f89c6443-9ff8-4731-9b08-d0e08dea9560,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8918b3d2-8668-4c42-b335-874120a0a73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-a36a06d4-d906-445d-bed3-e1842fb6c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-b2f55385-ecbc-4517-a6db-dc2ade23c8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781082174-172.17.0.12-1597641996645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-ef109536-8a5b-43ad-a1c7-8e2328226e19,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-71d37ad6-1ace-4608-9711-7081f561b599,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-e7341695-e782-495c-a604-720a5b0d74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-3645fbfd-74fc-4f62-9ee0-db4a21b4ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-224356e7-86f1-47ae-92ed-e598842a5210,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-b62a3449-83b9-4801-9edc-a1ab7b4625a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-f4b5a5d2-7432-4a43-bb29-8d849153f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-d4a03faf-5315-42e7-9548-ca76e20092cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781082174-172.17.0.12-1597641996645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-ef109536-8a5b-43ad-a1c7-8e2328226e19,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-71d37ad6-1ace-4608-9711-7081f561b599,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-e7341695-e782-495c-a604-720a5b0d74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-3645fbfd-74fc-4f62-9ee0-db4a21b4ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-224356e7-86f1-47ae-92ed-e598842a5210,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-b62a3449-83b9-4801-9edc-a1ab7b4625a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-f4b5a5d2-7432-4a43-bb29-8d849153f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-d4a03faf-5315-42e7-9548-ca76e20092cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766068317-172.17.0.12-1597642065853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43344,DS-1ebd8eaf-47e5-4adc-b5c6-21da1951c609,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-6781a37b-025a-45ec-b677-1a9d02041e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-5a720a7d-4204-4c32-a499-cc886d310f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6bb579ed-2f8e-47d2-9358-e54aa4d17580,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-c84e0330-b31a-45c4-830d-4962de71017d,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-f88d485f-d876-47e5-9ce7-b911ba58a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-a57c02d2-cc8e-450c-bd7d-b6ad96e1546b,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d87859c4-2f62-4a7c-ae2b-60b12fea726b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766068317-172.17.0.12-1597642065853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43344,DS-1ebd8eaf-47e5-4adc-b5c6-21da1951c609,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-6781a37b-025a-45ec-b677-1a9d02041e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-5a720a7d-4204-4c32-a499-cc886d310f18,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6bb579ed-2f8e-47d2-9358-e54aa4d17580,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-c84e0330-b31a-45c4-830d-4962de71017d,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-f88d485f-d876-47e5-9ce7-b911ba58a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-a57c02d2-cc8e-450c-bd7d-b6ad96e1546b,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d87859c4-2f62-4a7c-ae2b-60b12fea726b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731500346-172.17.0.12-1597642825114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-f5031820-44f9-4f3c-b9b9-6480ed148b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-ae28e666-61aa-4016-8b78-0a1cfcb85fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-958ae846-d042-44e6-ad80-a785b406774e,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-f7424366-1e54-47c3-916e-f1505ecc5865,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-241ad212-4ec5-4f83-858e-acc759faa548,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-f1388b68-ebc0-4d68-ac21-fec70dde46eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-6216678e-addf-4434-81bb-e27fa764b73d,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-29add3d5-4344-49b4-9c7d-caf274ffb791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731500346-172.17.0.12-1597642825114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-f5031820-44f9-4f3c-b9b9-6480ed148b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-ae28e666-61aa-4016-8b78-0a1cfcb85fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-958ae846-d042-44e6-ad80-a785b406774e,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-f7424366-1e54-47c3-916e-f1505ecc5865,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-241ad212-4ec5-4f83-858e-acc759faa548,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-f1388b68-ebc0-4d68-ac21-fec70dde46eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-6216678e-addf-4434-81bb-e27fa764b73d,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-29add3d5-4344-49b4-9c7d-caf274ffb791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355985010-172.17.0.12-1597642934533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-d5d66c89-dc1d-45d0-a686-66f19168ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-e563dfab-5b43-4059-b040-cc5b55dfa09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-d42ce286-28fc-44b3-abe3-5ecc1c154c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-c586427e-2bfe-437e-a687-8d89d7ef1232,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-ecb14561-70f5-48e9-8bb1-0ddeb5456eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-e9e752df-ad9b-40fb-a45b-cffe83f57ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e3f7585a-00e0-4de2-835f-ab8586766ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-9f88c87a-205d-4d49-93e9-d3cfda4c3984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355985010-172.17.0.12-1597642934533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-d5d66c89-dc1d-45d0-a686-66f19168ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-e563dfab-5b43-4059-b040-cc5b55dfa09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-d42ce286-28fc-44b3-abe3-5ecc1c154c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-c586427e-2bfe-437e-a687-8d89d7ef1232,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-ecb14561-70f5-48e9-8bb1-0ddeb5456eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-e9e752df-ad9b-40fb-a45b-cffe83f57ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e3f7585a-00e0-4de2-835f-ab8586766ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-9f88c87a-205d-4d49-93e9-d3cfda4c3984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159016450-172.17.0.12-1597644551660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-4423cf2f-ce8e-4dcc-b1aa-b2e662eae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-576afaf1-a992-46f5-aaac-5e344fbb8a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-a6f85938-344d-41ec-aaeb-395a1e0ac2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-09b182e4-77bb-477b-ad8d-517b37e123da,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b75acd6b-b3a7-42b4-bfc2-8dd3466c060a,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-ed5e45d5-e042-44ad-87c3-9c92f78262cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-cc17c3b4-458b-4be6-9af5-f490ea353c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-d7fa6cac-b0a4-47e9-b4c7-18bd16483008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159016450-172.17.0.12-1597644551660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-4423cf2f-ce8e-4dcc-b1aa-b2e662eae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-576afaf1-a992-46f5-aaac-5e344fbb8a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-a6f85938-344d-41ec-aaeb-395a1e0ac2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-09b182e4-77bb-477b-ad8d-517b37e123da,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b75acd6b-b3a7-42b4-bfc2-8dd3466c060a,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-ed5e45d5-e042-44ad-87c3-9c92f78262cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-cc17c3b4-458b-4be6-9af5-f490ea353c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-d7fa6cac-b0a4-47e9-b4c7-18bd16483008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5377
