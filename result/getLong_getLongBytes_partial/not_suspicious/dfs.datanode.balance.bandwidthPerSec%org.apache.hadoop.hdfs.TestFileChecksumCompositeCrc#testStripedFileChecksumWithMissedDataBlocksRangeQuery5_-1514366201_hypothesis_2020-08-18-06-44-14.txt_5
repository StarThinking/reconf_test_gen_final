reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214766394-172.17.0.12-1597733354491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45429,DS-da07f067-29c7-4f3a-8064-2827b0e42d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-7c4fc0a1-f4e2-4d7f-8790-0b2240d91f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9ab1d6af-1427-4377-bbdb-e9323005bb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-c65af4e1-9584-4528-86fa-2fbc4274aaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-8ae65f39-b4d1-4f11-b9d2-021ba12e6403,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-2cac2031-73dc-41d1-b57c-ecf9b89d94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-9a65bafc-3892-4425-9698-ccd433210b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-45012060-869c-452b-9aa1-4c969f389ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214766394-172.17.0.12-1597733354491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45429,DS-da07f067-29c7-4f3a-8064-2827b0e42d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-7c4fc0a1-f4e2-4d7f-8790-0b2240d91f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9ab1d6af-1427-4377-bbdb-e9323005bb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-c65af4e1-9584-4528-86fa-2fbc4274aaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-8ae65f39-b4d1-4f11-b9d2-021ba12e6403,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-2cac2031-73dc-41d1-b57c-ecf9b89d94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-9a65bafc-3892-4425-9698-ccd433210b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-45012060-869c-452b-9aa1-4c969f389ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808756942-172.17.0.12-1597733906596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-bafa911d-a971-4bb2-bba9-3c23cd0bcf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f0af2a14-4033-4b02-9e4a-68628d7c89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a18704b9-f7f4-43da-bfc9-c6f1fe46d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-96644e6d-efc8-45c5-b637-48cd55aaac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-29f6eccc-4887-4b10-a189-92736bb99893,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e794e961-e4cf-4050-9a43-2d82b7f5814a,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-876b3471-cf0d-4051-8146-9a0f6bfdc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-9f1716c3-1e39-43fb-8cc9-5dc157deb838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808756942-172.17.0.12-1597733906596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-bafa911d-a971-4bb2-bba9-3c23cd0bcf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f0af2a14-4033-4b02-9e4a-68628d7c89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a18704b9-f7f4-43da-bfc9-c6f1fe46d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-96644e6d-efc8-45c5-b637-48cd55aaac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-29f6eccc-4887-4b10-a189-92736bb99893,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e794e961-e4cf-4050-9a43-2d82b7f5814a,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-876b3471-cf0d-4051-8146-9a0f6bfdc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-9f1716c3-1e39-43fb-8cc9-5dc157deb838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430737340-172.17.0.12-1597734107391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-b2285f84-c70d-49e0-80cd-2efd85c6bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-fb76e68f-3e8b-4d21-9566-8c1409a1c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-fd8636c0-ad4a-425c-8915-a2fa7a09e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-5211bba9-a1af-4e94-9364-c3dac59a7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-68179fa6-2e0c-4ed6-8b47-14d4e1415459,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-0ca6f389-4feb-49d4-b19a-e345a76f2e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-a0262b8c-69f7-46ea-831a-70d646e34001,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-a18e24be-0083-4356-97d1-91144c18b9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430737340-172.17.0.12-1597734107391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-b2285f84-c70d-49e0-80cd-2efd85c6bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-fb76e68f-3e8b-4d21-9566-8c1409a1c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-fd8636c0-ad4a-425c-8915-a2fa7a09e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-5211bba9-a1af-4e94-9364-c3dac59a7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-68179fa6-2e0c-4ed6-8b47-14d4e1415459,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-0ca6f389-4feb-49d4-b19a-e345a76f2e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-a0262b8c-69f7-46ea-831a-70d646e34001,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-a18e24be-0083-4356-97d1-91144c18b9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408053459-172.17.0.12-1597734175918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-bc5ab2b4-0390-44e7-ba15-e0fe5d271390,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-78d15e4d-dff9-492a-9d9e-ff8306e83651,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-9c01e99f-619e-4a24-85f7-846fe3115262,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-aed14983-26c2-4e4c-a9ea-92821018ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-d1fc26d3-e0e4-48b2-89dc-d65623a17aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-a825372b-c08e-45f6-b6a2-717346a8e946,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c1397425-38f6-4260-90ed-9e5d44f42953,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-379feafd-2d3e-4266-90d3-db92ee694263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408053459-172.17.0.12-1597734175918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-bc5ab2b4-0390-44e7-ba15-e0fe5d271390,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-78d15e4d-dff9-492a-9d9e-ff8306e83651,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-9c01e99f-619e-4a24-85f7-846fe3115262,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-aed14983-26c2-4e4c-a9ea-92821018ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-d1fc26d3-e0e4-48b2-89dc-d65623a17aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-a825372b-c08e-45f6-b6a2-717346a8e946,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c1397425-38f6-4260-90ed-9e5d44f42953,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-379feafd-2d3e-4266-90d3-db92ee694263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871505552-172.17.0.12-1597734451573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-b2f6bfeb-e0a9-4be8-a488-b5c198615e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-4ec04145-8b20-425a-a243-22c439684f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2a390b3f-cc4b-479e-bd17-5f63377737f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-46bd7c06-46bb-48b7-8cc1-7496157d1d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-9df25503-149e-462c-af54-2c8ea8fd4095,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-dad6025c-0f67-4d2d-bce1-0bff11d532c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-0fcb7803-b696-4b50-a7ff-0fe117b4329b,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-b1c0b470-17f1-4a9c-9c79-4974d258caf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871505552-172.17.0.12-1597734451573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-b2f6bfeb-e0a9-4be8-a488-b5c198615e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-4ec04145-8b20-425a-a243-22c439684f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2a390b3f-cc4b-479e-bd17-5f63377737f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-46bd7c06-46bb-48b7-8cc1-7496157d1d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-9df25503-149e-462c-af54-2c8ea8fd4095,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-dad6025c-0f67-4d2d-bce1-0bff11d532c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-0fcb7803-b696-4b50-a7ff-0fe117b4329b,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-b1c0b470-17f1-4a9c-9c79-4974d258caf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360298778-172.17.0.12-1597735000467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-8bdb2167-7b69-4035-9496-181f583960ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-14756491-a4b4-417a-934d-33e587342a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-9d9491df-633b-49cb-9382-567e24eddd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-6ff28bd3-3651-40e7-8765-cc4f21594cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-3a8536ac-17b8-4a10-bd3e-d809220c1afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-b1a904f1-9436-44c6-b473-0791512a6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-cc897487-b962-4b04-9cc2-5a13e356f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-e92ff428-0099-4d11-8323-78864cca0b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360298778-172.17.0.12-1597735000467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-8bdb2167-7b69-4035-9496-181f583960ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-14756491-a4b4-417a-934d-33e587342a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-9d9491df-633b-49cb-9382-567e24eddd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-6ff28bd3-3651-40e7-8765-cc4f21594cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-3a8536ac-17b8-4a10-bd3e-d809220c1afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-b1a904f1-9436-44c6-b473-0791512a6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-cc897487-b962-4b04-9cc2-5a13e356f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-e92ff428-0099-4d11-8323-78864cca0b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473787502-172.17.0.12-1597735514268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-f1ac50e6-3207-4e0d-8771-2e2aaed9ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-a770082c-0cad-4ec7-b5b1-1cbf107558fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-0273e9f5-fae0-4384-a4ec-16dd86a51fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-aa8c6f70-5eb8-4d65-9c9f-9de88adb5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-d4162542-a96b-4439-9274-f235c715bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-85f6b550-d9dd-429e-93a5-cc903d392857,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-729ca356-9880-461b-bf1e-5e58e12f0e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-fd50ca29-7392-40da-a584-4652a57be4ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473787502-172.17.0.12-1597735514268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-f1ac50e6-3207-4e0d-8771-2e2aaed9ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-a770082c-0cad-4ec7-b5b1-1cbf107558fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-0273e9f5-fae0-4384-a4ec-16dd86a51fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-aa8c6f70-5eb8-4d65-9c9f-9de88adb5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-d4162542-a96b-4439-9274-f235c715bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-85f6b550-d9dd-429e-93a5-cc903d392857,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-729ca356-9880-461b-bf1e-5e58e12f0e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-fd50ca29-7392-40da-a584-4652a57be4ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745267301-172.17.0.12-1597735551550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-057cfb02-d3b5-42fa-acf8-9baffda9fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-8f5127c0-866a-4d5c-a9cb-d0cb15c4f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-5553d83a-e49c-4896-8d9f-9fcdc74b6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-9b6e9be9-2050-491e-930d-e77d351f135a,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-a3ff5b9f-9258-45da-8849-99fbe747d37a,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-1a5a7aa7-9003-428e-b58c-25a3fd139390,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-9a58e6aa-37ef-4d7f-86d1-3f38e27dfef7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-ef637b96-94dd-4431-970a-cbfcb78281a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745267301-172.17.0.12-1597735551550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-057cfb02-d3b5-42fa-acf8-9baffda9fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-8f5127c0-866a-4d5c-a9cb-d0cb15c4f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-5553d83a-e49c-4896-8d9f-9fcdc74b6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-9b6e9be9-2050-491e-930d-e77d351f135a,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-a3ff5b9f-9258-45da-8849-99fbe747d37a,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-1a5a7aa7-9003-428e-b58c-25a3fd139390,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-9a58e6aa-37ef-4d7f-86d1-3f38e27dfef7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-ef637b96-94dd-4431-970a-cbfcb78281a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054050046-172.17.0.12-1597736389957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-b9c4a541-19b1-464a-8371-920784b20cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-9ab187c0-8452-4c30-a35b-adae3242a340,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5f9b1c8f-49cc-475e-a30a-cb0a4c959fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-40bf960e-b8f7-45b2-9c2c-b7650ae36ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-f3cff7b6-0911-4e52-845f-a188e18f6119,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-cb6427e0-7d67-4f34-ac86-d234572177ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-3d29ae47-730d-487b-9284-6a46c078ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-09b5be4e-2deb-4a40-b7f7-9ea24fb2b281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054050046-172.17.0.12-1597736389957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-b9c4a541-19b1-464a-8371-920784b20cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-9ab187c0-8452-4c30-a35b-adae3242a340,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5f9b1c8f-49cc-475e-a30a-cb0a4c959fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-40bf960e-b8f7-45b2-9c2c-b7650ae36ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-f3cff7b6-0911-4e52-845f-a188e18f6119,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-cb6427e0-7d67-4f34-ac86-d234572177ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-3d29ae47-730d-487b-9284-6a46c078ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-09b5be4e-2deb-4a40-b7f7-9ea24fb2b281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781037708-172.17.0.12-1597736614028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41341,DS-c2173ef1-7647-45b8-8941-3ccb65fc9ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-9ff5c33d-5f85-4bcc-9483-570df3588849,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6abe841e-e041-4be6-abb7-7adf410c63bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9517dff9-1a42-4123-b08b-2b89eae0974e,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d0b35652-15b3-4016-91c6-ddbc4a6045a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-0af7c27b-d873-4a2e-907e-6168e81e36e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-ff03f107-b7ca-406f-8102-4bbf496d732d,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-682f7459-055f-4350-b808-c28185d81eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781037708-172.17.0.12-1597736614028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41341,DS-c2173ef1-7647-45b8-8941-3ccb65fc9ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-9ff5c33d-5f85-4bcc-9483-570df3588849,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6abe841e-e041-4be6-abb7-7adf410c63bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9517dff9-1a42-4123-b08b-2b89eae0974e,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d0b35652-15b3-4016-91c6-ddbc4a6045a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-0af7c27b-d873-4a2e-907e-6168e81e36e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-ff03f107-b7ca-406f-8102-4bbf496d732d,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-682f7459-055f-4350-b808-c28185d81eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877197794-172.17.0.12-1597736656658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43376,DS-2a9bd9c8-7c2b-4220-9b4e-8b144dd06624,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-c8a6815e-e736-4363-b50a-de9a7fc5fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-f4123c76-be34-491e-9d71-575de5c6bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-357991ef-8783-45cf-b7c8-8372b868cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-03be16ba-13f5-45ac-ba2a-d3adade4f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-8111f77d-99d1-4af9-8737-19d7f25a2c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-6370b091-ad0f-48c0-8bef-16bf295873c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-f187d7e6-2622-48c1-b077-59a13cd4bd17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877197794-172.17.0.12-1597736656658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43376,DS-2a9bd9c8-7c2b-4220-9b4e-8b144dd06624,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-c8a6815e-e736-4363-b50a-de9a7fc5fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-f4123c76-be34-491e-9d71-575de5c6bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-357991ef-8783-45cf-b7c8-8372b868cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-03be16ba-13f5-45ac-ba2a-d3adade4f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-8111f77d-99d1-4af9-8737-19d7f25a2c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-6370b091-ad0f-48c0-8bef-16bf295873c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-f187d7e6-2622-48c1-b077-59a13cd4bd17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28614574-172.17.0.12-1597736722253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-00910b7a-337f-49c2-bded-44456519857c,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-3218cd8b-715c-4d9b-a73b-27e220f337e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1a0a1fdd-d2df-4736-9c98-470a5f6309da,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-554d65bb-e45b-4dba-ace1-0ab10f54e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7d8389d3-5830-4e4c-88cb-6f7133cfdadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-2ed005ee-db47-4ec2-9b12-d280202c2d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-56760789-7231-4d24-9a9a-77bb6a75c786,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-4fab8336-6aac-4ebb-a950-cd05937f19b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28614574-172.17.0.12-1597736722253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-00910b7a-337f-49c2-bded-44456519857c,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-3218cd8b-715c-4d9b-a73b-27e220f337e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1a0a1fdd-d2df-4736-9c98-470a5f6309da,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-554d65bb-e45b-4dba-ace1-0ab10f54e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7d8389d3-5830-4e4c-88cb-6f7133cfdadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-2ed005ee-db47-4ec2-9b12-d280202c2d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-56760789-7231-4d24-9a9a-77bb6a75c786,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-4fab8336-6aac-4ebb-a950-cd05937f19b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883581584-172.17.0.12-1597736786084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-487ad1c8-37e5-44b1-991d-c51c03f40ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d0166cf5-4704-4c9d-84c7-ccb00e3abd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-34fbe498-1a27-4a9c-9ee9-e77800a5fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d68bc891-6f2a-4fa2-8964-2162dbd00af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e8570b66-1d23-499b-b86f-ce63a79385f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-25606953-aa10-416a-abed-73ec5f8b4c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-5af3df5c-639b-4670-bb13-d966b5c8826f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-62897a3a-354b-4ee3-8f09-e30b55e7a182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883581584-172.17.0.12-1597736786084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-487ad1c8-37e5-44b1-991d-c51c03f40ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-d0166cf5-4704-4c9d-84c7-ccb00e3abd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-34fbe498-1a27-4a9c-9ee9-e77800a5fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-d68bc891-6f2a-4fa2-8964-2162dbd00af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e8570b66-1d23-499b-b86f-ce63a79385f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-25606953-aa10-416a-abed-73ec5f8b4c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-5af3df5c-639b-4670-bb13-d966b5c8826f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-62897a3a-354b-4ee3-8f09-e30b55e7a182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059304712-172.17.0.12-1597737458067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41776,DS-f80df3ec-f357-4899-b388-070ccf9a3400,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-e4d33b48-1853-4323-865c-ce0fd6aac940,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-449bc7cb-4b1e-48b0-a97b-bcc6b96d454c,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-367e3a6c-ae13-4c4c-a99c-6de0971d45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-eeed211d-d9b0-4b33-bb60-59bfa0f274fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-5ab1e4a7-63b9-4206-a760-6b1f71d572ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-021d5315-4b08-4e94-bd90-faa456c7095b,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-465f6643-7034-4968-8bd6-3d03ec1d1ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059304712-172.17.0.12-1597737458067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41776,DS-f80df3ec-f357-4899-b388-070ccf9a3400,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-e4d33b48-1853-4323-865c-ce0fd6aac940,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-449bc7cb-4b1e-48b0-a97b-bcc6b96d454c,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-367e3a6c-ae13-4c4c-a99c-6de0971d45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-eeed211d-d9b0-4b33-bb60-59bfa0f274fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-5ab1e4a7-63b9-4206-a760-6b1f71d572ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-021d5315-4b08-4e94-bd90-faa456c7095b,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-465f6643-7034-4968-8bd6-3d03ec1d1ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703872580-172.17.0.12-1597738674002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-f1126fd5-eec0-49c7-b5a7-e1c98bbbcdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-ec1845c6-0fad-40ec-a324-69b150a5c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-0b8ebc04-c048-49de-9bf9-a37359b0a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-3e4158f5-ead0-4891-9b3d-d1fa8db0524a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-0e8e5d3c-d2e8-402d-b7f7-54a02f985fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-56e89607-84e9-4847-881a-bba905dcd312,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-890a24b7-f9c4-4595-9a6c-b860af5a06e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-feed81f0-d5ad-4a03-86bc-be8167fcf636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703872580-172.17.0.12-1597738674002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-f1126fd5-eec0-49c7-b5a7-e1c98bbbcdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-ec1845c6-0fad-40ec-a324-69b150a5c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-0b8ebc04-c048-49de-9bf9-a37359b0a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-3e4158f5-ead0-4891-9b3d-d1fa8db0524a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-0e8e5d3c-d2e8-402d-b7f7-54a02f985fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-56e89607-84e9-4847-881a-bba905dcd312,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-890a24b7-f9c4-4595-9a6c-b860af5a06e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-feed81f0-d5ad-4a03-86bc-be8167fcf636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 1m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832794422-172.17.0.12-1597738794415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-8522b007-ddc6-4b59-8087-7daa39c7055d,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-37d886c3-92e3-4b4f-b5a8-1e681d1912b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-118e4c82-9021-459f-8345-4644dffcddca,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-33a330c7-632c-4659-9ce3-ad85a559ddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-920917a7-5397-4017-834a-6b2d2c6476b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-47044e63-02e7-4203-9c2b-16acd90d84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-9381ff67-a186-4d86-a966-67d0d28fe0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-2d53705d-43d4-43c0-8ad5-59f0d260f5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832794422-172.17.0.12-1597738794415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-8522b007-ddc6-4b59-8087-7daa39c7055d,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-37d886c3-92e3-4b4f-b5a8-1e681d1912b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-118e4c82-9021-459f-8345-4644dffcddca,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-33a330c7-632c-4659-9ce3-ad85a559ddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-920917a7-5397-4017-834a-6b2d2c6476b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-47044e63-02e7-4203-9c2b-16acd90d84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-9381ff67-a186-4d86-a966-67d0d28fe0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-2d53705d-43d4-43c0-8ad5-59f0d260f5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5764
