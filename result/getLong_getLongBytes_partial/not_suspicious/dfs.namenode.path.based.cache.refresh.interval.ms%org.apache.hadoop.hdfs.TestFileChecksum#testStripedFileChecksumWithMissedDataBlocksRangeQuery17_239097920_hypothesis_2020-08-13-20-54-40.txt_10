reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804363720-172.17.0.18-1597353023877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-d38e40c7-e94b-4d54-b147-0da232953e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-534944c7-3680-4c8b-a987-a627b8e787b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-2ad8b209-6c4c-4d0c-b877-8238282b745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-cc0803ea-f141-4647-a455-8091ed81cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-400d033a-853e-45ff-9b9c-cb27d10d96e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-210ea479-6f01-45ef-aa36-ae2bb2b5c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-1e23d6c4-d5e4-4374-8fb7-c7c6c854b587,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-69fed1e6-2afd-4061-99d5-2a849e0b989b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804363720-172.17.0.18-1597353023877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-d38e40c7-e94b-4d54-b147-0da232953e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-534944c7-3680-4c8b-a987-a627b8e787b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-2ad8b209-6c4c-4d0c-b877-8238282b745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-cc0803ea-f141-4647-a455-8091ed81cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-400d033a-853e-45ff-9b9c-cb27d10d96e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-210ea479-6f01-45ef-aa36-ae2bb2b5c105,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-1e23d6c4-d5e4-4374-8fb7-c7c6c854b587,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-69fed1e6-2afd-4061-99d5-2a849e0b989b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215215254-172.17.0.18-1597354165785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38413,DS-139e4bd6-c98e-4421-9a8b-f616af4c568a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-38238ab5-161d-4ebe-9bb7-86dd466190c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-38513987-f179-4d91-8593-7f9acf1bb343,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-86f8bd55-cb88-49e9-a8dd-5f0f3a704021,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-b7218ca8-931a-49b3-b6a1-69d36a87ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-0793f165-8666-4959-9c34-52f99db104d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-d19d286b-d23a-40a0-91b3-f22629e7d7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-dcdcb911-d2d8-43f1-87e5-bd4bde3f2464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215215254-172.17.0.18-1597354165785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38413,DS-139e4bd6-c98e-4421-9a8b-f616af4c568a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-38238ab5-161d-4ebe-9bb7-86dd466190c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-38513987-f179-4d91-8593-7f9acf1bb343,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-86f8bd55-cb88-49e9-a8dd-5f0f3a704021,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-b7218ca8-931a-49b3-b6a1-69d36a87ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-0793f165-8666-4959-9c34-52f99db104d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-d19d286b-d23a-40a0-91b3-f22629e7d7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-dcdcb911-d2d8-43f1-87e5-bd4bde3f2464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611803109-172.17.0.18-1597354464300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-1d703dcd-33d6-4033-b7a3-e3a5a1fcd0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-deb8c250-696a-421c-9b78-cd5dbc6f521e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-45d280c5-eadc-4f5e-b15f-7d358beebd96,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-2f564bfd-120a-4d11-a936-fb3459a022c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-ad9d8143-771b-46fc-b746-fe78e8c2dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-73b0f363-e447-491e-9620-6a95d0377d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-7a068efe-db5a-4176-9de2-e33d9a6a9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-7dfd84f8-6bc3-4d4c-bdef-e946092afc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611803109-172.17.0.18-1597354464300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-1d703dcd-33d6-4033-b7a3-e3a5a1fcd0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-deb8c250-696a-421c-9b78-cd5dbc6f521e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-45d280c5-eadc-4f5e-b15f-7d358beebd96,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-2f564bfd-120a-4d11-a936-fb3459a022c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-ad9d8143-771b-46fc-b746-fe78e8c2dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-73b0f363-e447-491e-9620-6a95d0377d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-7a068efe-db5a-4176-9de2-e33d9a6a9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-7dfd84f8-6bc3-4d4c-bdef-e946092afc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152916972-172.17.0.18-1597354984256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-770b40a7-24a1-4f4c-a402-749687f89f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b0f0bfad-8979-40f4-aebb-dc0fdeaff470,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-76522e7d-6690-4937-9005-03b1e95e3523,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-5911a699-5829-45c4-a0ec-263b813d2905,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-acceee68-1b1c-4904-a462-c75697b4f071,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-238f7320-03dc-486c-b1a8-5f5eb8319ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-5b7e5356-edb7-4f94-8909-23dcfa131e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-33cb52f7-f3eb-434e-9fd2-934a25991559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152916972-172.17.0.18-1597354984256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-770b40a7-24a1-4f4c-a402-749687f89f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b0f0bfad-8979-40f4-aebb-dc0fdeaff470,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-76522e7d-6690-4937-9005-03b1e95e3523,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-5911a699-5829-45c4-a0ec-263b813d2905,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-acceee68-1b1c-4904-a462-c75697b4f071,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-238f7320-03dc-486c-b1a8-5f5eb8319ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-5b7e5356-edb7-4f94-8909-23dcfa131e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-33cb52f7-f3eb-434e-9fd2-934a25991559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130084907-172.17.0.18-1597355286078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44879,DS-175038d7-6244-476b-925c-2bd2a7cd2087,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-82323a3e-3667-4278-8570-ab9875d08f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-a00d9902-66ed-4d1c-8b91-ae3f3276af83,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-6df84f2b-08a6-4fc5-9746-b67b5511e360,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-34b60180-0338-4ddd-9785-635bc1e2780c,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-c44eb21f-c859-4013-80c4-7755f0c6bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-d78e9b4c-c064-404b-9131-7275534c6565,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-0d1b9977-e280-451f-94ca-3c6312cc7cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130084907-172.17.0.18-1597355286078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44879,DS-175038d7-6244-476b-925c-2bd2a7cd2087,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-82323a3e-3667-4278-8570-ab9875d08f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-a00d9902-66ed-4d1c-8b91-ae3f3276af83,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-6df84f2b-08a6-4fc5-9746-b67b5511e360,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-34b60180-0338-4ddd-9785-635bc1e2780c,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-c44eb21f-c859-4013-80c4-7755f0c6bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-d78e9b4c-c064-404b-9131-7275534c6565,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-0d1b9977-e280-451f-94ca-3c6312cc7cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238611357-172.17.0.18-1597355955358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-a501b735-d380-4c89-8e12-3becf7bc9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b08c60ee-d975-48ec-a243-2a6991d1dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-fe705e6c-adb4-4a5a-841c-fceee8303e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-a2824840-567c-4e44-add5-8995085414b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-6dd4078c-00b3-4237-ab55-d52a4dec7030,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-bc6ea2fe-d7f5-45a1-b26e-bf44191b5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-35b64ec1-84bf-4f8d-a58b-3c2e2045f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-c7b3f3bb-7fdb-43e8-bb49-1d4c4eb06fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238611357-172.17.0.18-1597355955358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-a501b735-d380-4c89-8e12-3becf7bc9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b08c60ee-d975-48ec-a243-2a6991d1dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-fe705e6c-adb4-4a5a-841c-fceee8303e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-a2824840-567c-4e44-add5-8995085414b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-6dd4078c-00b3-4237-ab55-d52a4dec7030,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-bc6ea2fe-d7f5-45a1-b26e-bf44191b5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-35b64ec1-84bf-4f8d-a58b-3c2e2045f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-c7b3f3bb-7fdb-43e8-bb49-1d4c4eb06fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597467021-172.17.0.18-1597356556333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-37ce3294-dfd3-48a0-995d-611ee8eb3ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-11869038-32e9-4ed0-8372-ed0b9f13205a,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-30536ef9-3b54-4ec5-b945-11d462b357f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-a2a0fda9-0653-433a-beac-b83ccb70e237,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-aabe9c26-bfe7-4307-a95b-81ef20c79739,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-099a3f9f-9761-4996-961f-f645c4d3373a,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-2ba8eb06-07c6-47a8-a81b-b1478a5b1272,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-0677e310-7dda-4c79-8eb9-7f3e22a06ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597467021-172.17.0.18-1597356556333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-37ce3294-dfd3-48a0-995d-611ee8eb3ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-11869038-32e9-4ed0-8372-ed0b9f13205a,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-30536ef9-3b54-4ec5-b945-11d462b357f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-a2a0fda9-0653-433a-beac-b83ccb70e237,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-aabe9c26-bfe7-4307-a95b-81ef20c79739,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-099a3f9f-9761-4996-961f-f645c4d3373a,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-2ba8eb06-07c6-47a8-a81b-b1478a5b1272,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-0677e310-7dda-4c79-8eb9-7f3e22a06ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171663338-172.17.0.18-1597356746836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-e7b0b0b3-b5eb-4a30-8259-a6066aa033f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-c759a98e-84f7-4ee6-8eba-bbec25ee33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a5e52f8c-0787-4cfe-87c6-fe98f7638655,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1df47847-4ed3-41b3-9068-03c7074a089b,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-88a35e97-ce2c-4522-9869-01adbb456cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-3b44c631-fd09-479e-9fa5-bb4d75e788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-8ed21494-db16-479a-8379-8f20f5affa04,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-e14f4ce5-dc98-484f-9466-ab1d46987200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171663338-172.17.0.18-1597356746836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-e7b0b0b3-b5eb-4a30-8259-a6066aa033f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-c759a98e-84f7-4ee6-8eba-bbec25ee33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a5e52f8c-0787-4cfe-87c6-fe98f7638655,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1df47847-4ed3-41b3-9068-03c7074a089b,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-88a35e97-ce2c-4522-9869-01adbb456cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-3b44c631-fd09-479e-9fa5-bb4d75e788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-8ed21494-db16-479a-8379-8f20f5affa04,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-e14f4ce5-dc98-484f-9466-ab1d46987200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249917863-172.17.0.18-1597357203116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-ece8effc-1dcb-4010-8ebb-7e6768107552,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-d122a6a3-a8f7-4a07-bf07-965aeced8533,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-54b9f1f5-1800-419e-8250-def69adc3352,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-e8895747-2fd3-4dcd-997f-eb147fd47ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-4c36a2a0-2974-4153-8a9b-859967859962,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-03c187eb-169c-47ba-8a18-3f7a65b5c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-0675ef44-f837-4269-ac9d-3aea76799d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e44899e6-53e4-4ac7-a490-48be0aeb8e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249917863-172.17.0.18-1597357203116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-ece8effc-1dcb-4010-8ebb-7e6768107552,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-d122a6a3-a8f7-4a07-bf07-965aeced8533,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-54b9f1f5-1800-419e-8250-def69adc3352,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-e8895747-2fd3-4dcd-997f-eb147fd47ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-4c36a2a0-2974-4153-8a9b-859967859962,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-03c187eb-169c-47ba-8a18-3f7a65b5c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-0675ef44-f837-4269-ac9d-3aea76799d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e44899e6-53e4-4ac7-a490-48be0aeb8e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097813786-172.17.0.18-1597357385240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-8129ec08-f91c-42de-ab86-24b3aff56a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-6ef56217-3658-4b7e-9bed-0aa23c2bb62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e64db9d8-3363-47bb-be8d-b035ddc2fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-6d7c35d6-c46f-42f2-96c0-fe41c5319718,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-a07b707f-0a49-41d6-be4b-ecebee55fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-97510c5c-70eb-4c2e-a639-e3f71d3b8af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-3dfb4e50-704c-42e6-a019-974042a87132,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-21066100-cfdc-4c8e-bce1-0858644412cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097813786-172.17.0.18-1597357385240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-8129ec08-f91c-42de-ab86-24b3aff56a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-6ef56217-3658-4b7e-9bed-0aa23c2bb62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e64db9d8-3363-47bb-be8d-b035ddc2fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-6d7c35d6-c46f-42f2-96c0-fe41c5319718,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-a07b707f-0a49-41d6-be4b-ecebee55fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-97510c5c-70eb-4c2e-a639-e3f71d3b8af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-3dfb4e50-704c-42e6-a019-974042a87132,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-21066100-cfdc-4c8e-bce1-0858644412cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155458684-172.17.0.18-1597357428353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-c7d9a5fb-6e6b-4060-a4e1-9148be99ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-de0ce146-2fcf-45cb-95c6-ecd1df78c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-d1d654e6-2361-4b78-aeb1-e32b2e103709,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-d1ced3ca-9e13-495b-9cbb-64fbcb4f87c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-9e064202-7ff9-48cc-93a2-eb7cfb4a0237,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dd0b9fcd-6ca2-46a4-b6b0-bd04d0bc9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-01cdc7d5-690b-4b9e-8f39-18441bb64439,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-8d31813a-e420-4996-b0c7-ee91ddd304c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155458684-172.17.0.18-1597357428353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-c7d9a5fb-6e6b-4060-a4e1-9148be99ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-de0ce146-2fcf-45cb-95c6-ecd1df78c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-d1d654e6-2361-4b78-aeb1-e32b2e103709,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-d1ced3ca-9e13-495b-9cbb-64fbcb4f87c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-9e064202-7ff9-48cc-93a2-eb7cfb4a0237,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dd0b9fcd-6ca2-46a4-b6b0-bd04d0bc9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-01cdc7d5-690b-4b9e-8f39-18441bb64439,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-8d31813a-e420-4996-b0c7-ee91ddd304c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882628389-172.17.0.18-1597357659653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-23ed5b33-a835-4c96-8d70-0d298bfb75b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-fc0b1703-40c1-4047-a463-a2dfea4e8009,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-49fefce8-fceb-4e12-afba-36364b4bcbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-d739af36-d8a9-46a4-a52a-6994867be17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-b2d21a2e-bc12-4c32-8448-02ede6146535,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-19f48292-54b2-4378-8a13-4a054b09161b,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-a14ea7da-0fd5-45e9-9716-a53635a04fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-4117085c-4ab2-47bb-b21a-f1d77fd9b033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882628389-172.17.0.18-1597357659653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-23ed5b33-a835-4c96-8d70-0d298bfb75b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-fc0b1703-40c1-4047-a463-a2dfea4e8009,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-49fefce8-fceb-4e12-afba-36364b4bcbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-d739af36-d8a9-46a4-a52a-6994867be17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-b2d21a2e-bc12-4c32-8448-02ede6146535,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-19f48292-54b2-4378-8a13-4a054b09161b,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-a14ea7da-0fd5-45e9-9716-a53635a04fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-4117085c-4ab2-47bb-b21a-f1d77fd9b033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904044965-172.17.0.18-1597358187550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-a0d8cf07-9be7-4041-bc0c-1f57fb07c834,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-c9679e1c-8a74-4aff-9a3a-d97986aa9761,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-8753f06b-24f6-4c36-b421-122fa31327a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-0d7e724d-4474-41c5-b4e9-94a2c077175d,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-2b42bc3e-d648-4d2f-9a33-8cada4a4970c,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-d2169e03-0cba-4bdf-962b-0bf5691ea44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-acb21091-611b-4f99-94c5-20d231d56587,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-cdd778d6-8668-4e4f-a08b-87f8e0c8de52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904044965-172.17.0.18-1597358187550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-a0d8cf07-9be7-4041-bc0c-1f57fb07c834,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-c9679e1c-8a74-4aff-9a3a-d97986aa9761,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-8753f06b-24f6-4c36-b421-122fa31327a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-0d7e724d-4474-41c5-b4e9-94a2c077175d,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-2b42bc3e-d648-4d2f-9a33-8cada4a4970c,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-d2169e03-0cba-4bdf-962b-0bf5691ea44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-acb21091-611b-4f99-94c5-20d231d56587,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-cdd778d6-8668-4e4f-a08b-87f8e0c8de52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507851799-172.17.0.18-1597358334085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-07cbd71f-c4a5-46a5-9ca4-bad77d258564,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-3774f78d-5362-47c9-a0dc-4e1a3af61249,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-74999b66-0a00-4ae1-abd9-18972832b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-60207d65-d540-4392-8266-922ef87c0b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-34fedf9a-f7fe-40d4-b296-86d4cbe1f76a,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-ee7b1698-2d85-4b93-a668-11ca205c8dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2ac535c5-204f-4b41-baef-ec43e1188c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-0d61fa2c-f771-4350-8c2c-ab3fa4b8e094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507851799-172.17.0.18-1597358334085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-07cbd71f-c4a5-46a5-9ca4-bad77d258564,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-3774f78d-5362-47c9-a0dc-4e1a3af61249,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-74999b66-0a00-4ae1-abd9-18972832b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-60207d65-d540-4392-8266-922ef87c0b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-34fedf9a-f7fe-40d4-b296-86d4cbe1f76a,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-ee7b1698-2d85-4b93-a668-11ca205c8dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-2ac535c5-204f-4b41-baef-ec43e1188c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-0d61fa2c-f771-4350-8c2c-ab3fa4b8e094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33451308-172.17.0.18-1597358433922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33500,DS-a5cf6dc7-44b0-46d4-ab0f-5a4ca0c30118,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-2576ae70-bf6b-4ca7-a4bb-1f384d35e632,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-023441de-9c96-40eb-8b4a-9b5aaaf1118e,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-c0102f07-889e-4f76-afc1-f72eeab6f362,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-72a33777-7a3b-4efa-ab67-04383735a273,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-aa5c4c5a-1442-473c-af4d-06909d479bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-6c64c441-c4da-499c-9ba1-ef9cb53eb0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-3b135189-6de4-40a1-99e6-611dcbd2d190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33451308-172.17.0.18-1597358433922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33500,DS-a5cf6dc7-44b0-46d4-ab0f-5a4ca0c30118,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-2576ae70-bf6b-4ca7-a4bb-1f384d35e632,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-023441de-9c96-40eb-8b4a-9b5aaaf1118e,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-c0102f07-889e-4f76-afc1-f72eeab6f362,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-72a33777-7a3b-4efa-ab67-04383735a273,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-aa5c4c5a-1442-473c-af4d-06909d479bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-6c64c441-c4da-499c-9ba1-ef9cb53eb0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-3b135189-6de4-40a1-99e6-611dcbd2d190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361704014-172.17.0.18-1597358694846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-42e38093-cf99-42cf-ad02-91b2ddd8300e,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-7d30621a-a5ad-48e8-9f54-644057792176,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-4f67866b-dbb6-4d17-8b45-1b48dfffb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-af2b82ff-b932-4563-8120-23fa915ce880,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1d4967ab-de7f-4dcb-b58b-46b81de85529,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-65428ed9-70e7-4988-b8ba-ab1c7f2097ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6ab56473-9583-4a05-ad2c-0ce5a41fc8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-85cea719-ea5d-4c80-b10c-c8f953d53ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361704014-172.17.0.18-1597358694846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-42e38093-cf99-42cf-ad02-91b2ddd8300e,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-7d30621a-a5ad-48e8-9f54-644057792176,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-4f67866b-dbb6-4d17-8b45-1b48dfffb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-af2b82ff-b932-4563-8120-23fa915ce880,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1d4967ab-de7f-4dcb-b58b-46b81de85529,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-65428ed9-70e7-4988-b8ba-ab1c7f2097ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6ab56473-9583-4a05-ad2c-0ce5a41fc8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-85cea719-ea5d-4c80-b10c-c8f953d53ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6924
