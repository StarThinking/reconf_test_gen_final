reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304128345-172.17.0.17-1597739078592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-2def5818-ad0b-4044-af25-2c88a5fbe163,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-90c78516-6201-49bd-9290-0c664c2b66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-36e0e116-0301-49f1-94fb-84f404e682b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-0f93d8f8-e525-4f85-b99a-fb3b7edde87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f6606376-e3d4-4662-81c5-2bb23abcfa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a8b9325a-6c0e-420f-9766-49299d273c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-7ac30594-f206-49ae-a6da-297a72dbf205,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-92f98c37-2b21-4fdd-9c82-6e7e456081d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304128345-172.17.0.17-1597739078592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-2def5818-ad0b-4044-af25-2c88a5fbe163,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-90c78516-6201-49bd-9290-0c664c2b66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-36e0e116-0301-49f1-94fb-84f404e682b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-0f93d8f8-e525-4f85-b99a-fb3b7edde87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f6606376-e3d4-4662-81c5-2bb23abcfa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a8b9325a-6c0e-420f-9766-49299d273c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-7ac30594-f206-49ae-a6da-297a72dbf205,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-92f98c37-2b21-4fdd-9c82-6e7e456081d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839603757-172.17.0.17-1597740027633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-bdcbea60-d3d8-4e5a-9a2e-7061c8fe0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-34d517d0-3d93-40c5-b6f7-0c2600ec7265,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-063e6078-c152-4790-a5e8-8d2d781405d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9dc911f3-7ef7-4312-b5a0-addf27203bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-059bc587-4fa0-4fdd-b4bc-3600830eb90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-8b36c9d3-1588-465a-8bc2-16df88fc6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-defc704e-ea04-470f-88de-c2661853a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-d4c89dab-6d11-4a6e-acca-19c001d86791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839603757-172.17.0.17-1597740027633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-bdcbea60-d3d8-4e5a-9a2e-7061c8fe0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-34d517d0-3d93-40c5-b6f7-0c2600ec7265,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-063e6078-c152-4790-a5e8-8d2d781405d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9dc911f3-7ef7-4312-b5a0-addf27203bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-059bc587-4fa0-4fdd-b4bc-3600830eb90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-8b36c9d3-1588-465a-8bc2-16df88fc6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-defc704e-ea04-470f-88de-c2661853a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-d4c89dab-6d11-4a6e-acca-19c001d86791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146275117-172.17.0.17-1597740231662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-1490cb9a-efc3-4445-b125-41346a49ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-89cba985-2f12-48cb-ab01-98c6ccddccff,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-0b7d3c9c-bb59-4ed3-8328-11991a1f9812,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ed588272-025a-4f54-ab85-4885a8916037,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-d82d75c0-2eba-4622-b89e-7ebebe229a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-46b75ecc-d995-4bc0-8e5d-26ccdfacbd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-f07bf41b-1760-4657-809f-81eb91814e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-cb58f245-c1b1-401b-87e4-d485bedb09b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146275117-172.17.0.17-1597740231662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-1490cb9a-efc3-4445-b125-41346a49ccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-89cba985-2f12-48cb-ab01-98c6ccddccff,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-0b7d3c9c-bb59-4ed3-8328-11991a1f9812,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ed588272-025a-4f54-ab85-4885a8916037,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-d82d75c0-2eba-4622-b89e-7ebebe229a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-46b75ecc-d995-4bc0-8e5d-26ccdfacbd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-f07bf41b-1760-4657-809f-81eb91814e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-cb58f245-c1b1-401b-87e4-d485bedb09b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391455075-172.17.0.17-1597740306519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-79ca809f-6335-4b9d-8ac0-d651c3e62190,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-11f7f857-20f5-4556-bb92-f43d434c1ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-77d6a290-4ce9-4021-847c-8b6496349a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e9b0da71-8c0c-48cc-910c-5cd07f102492,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e85e161d-aea1-4d87-b6b3-342150894e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-db6bf756-74df-4324-af22-6d95897857e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-96b78d57-69a8-4679-bb4d-2f0a8ee25f83,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e00d2f9c-45ce-4bba-a43c-cea7d86a76cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391455075-172.17.0.17-1597740306519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-79ca809f-6335-4b9d-8ac0-d651c3e62190,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-11f7f857-20f5-4556-bb92-f43d434c1ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-77d6a290-4ce9-4021-847c-8b6496349a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e9b0da71-8c0c-48cc-910c-5cd07f102492,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e85e161d-aea1-4d87-b6b3-342150894e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-db6bf756-74df-4324-af22-6d95897857e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-96b78d57-69a8-4679-bb4d-2f0a8ee25f83,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e00d2f9c-45ce-4bba-a43c-cea7d86a76cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458127207-172.17.0.17-1597740343634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46037,DS-fb7b76ed-5c35-44d3-8fdb-a7cab874c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-7ab7d0a4-e36d-49f3-ae17-8c33295fa088,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c08ee1c4-b340-4fc1-b866-56e3f0a3afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-a1f0fc1a-9b26-4511-b41a-22ec50e7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-4d5844ed-529a-4001-92b7-686c12b0455a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-5e09ebd3-f0d7-4ed0-adbe-214f9cfcbcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-d24cfd91-2f4a-4847-85ff-dbc57d455636,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-96513a21-1dcc-4eed-ba87-5dde5541e2ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458127207-172.17.0.17-1597740343634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46037,DS-fb7b76ed-5c35-44d3-8fdb-a7cab874c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-7ab7d0a4-e36d-49f3-ae17-8c33295fa088,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c08ee1c4-b340-4fc1-b866-56e3f0a3afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-a1f0fc1a-9b26-4511-b41a-22ec50e7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-4d5844ed-529a-4001-92b7-686c12b0455a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-5e09ebd3-f0d7-4ed0-adbe-214f9cfcbcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-d24cfd91-2f4a-4847-85ff-dbc57d455636,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-96513a21-1dcc-4eed-ba87-5dde5541e2ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213354925-172.17.0.17-1597740533786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34580,DS-40bb3bf0-c7cd-4f75-b81e-24edf897b906,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-585ae6eb-48f0-45a5-9cf8-6b7055fdcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d0f9c667-6fd7-430f-aa3a-139e71b89d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-f45fca1f-f6fb-4a32-aa76-ae4e3b96060d,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-c4620ea1-a25d-46b0-b461-96cc5a95b916,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-40fd867d-8121-4589-8f51-ca211205309c,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-653fa944-13b3-4207-9583-de752a45f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-68444631-41e2-4d0c-91c9-31bf15296537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213354925-172.17.0.17-1597740533786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34580,DS-40bb3bf0-c7cd-4f75-b81e-24edf897b906,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-585ae6eb-48f0-45a5-9cf8-6b7055fdcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d0f9c667-6fd7-430f-aa3a-139e71b89d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-f45fca1f-f6fb-4a32-aa76-ae4e3b96060d,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-c4620ea1-a25d-46b0-b461-96cc5a95b916,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-40fd867d-8121-4589-8f51-ca211205309c,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-653fa944-13b3-4207-9583-de752a45f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-68444631-41e2-4d0c-91c9-31bf15296537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071703227-172.17.0.17-1597741541969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-a9e61dd3-ceac-4a86-83c3-50beb1d3a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-ee119865-fe53-4027-82bc-b079d0da1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-c99808b5-d625-498e-8a75-9493f0ce799d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-535e283a-37d9-4238-9719-55171f1cfc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-43952281-b38c-44ec-9bdc-4ad759435bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-bc73f198-7067-4ab8-9ec2-7688f47f30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-310d2210-0143-411c-a561-04da35273cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-7f714706-d266-44b5-90d2-b70c92cca62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071703227-172.17.0.17-1597741541969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-a9e61dd3-ceac-4a86-83c3-50beb1d3a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-ee119865-fe53-4027-82bc-b079d0da1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-c99808b5-d625-498e-8a75-9493f0ce799d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-535e283a-37d9-4238-9719-55171f1cfc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-43952281-b38c-44ec-9bdc-4ad759435bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-bc73f198-7067-4ab8-9ec2-7688f47f30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-310d2210-0143-411c-a561-04da35273cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-7f714706-d266-44b5-90d2-b70c92cca62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935577632-172.17.0.17-1597741690405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-c041f1b8-0f12-4313-82e0-189647114038,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-deef352d-bdfc-4080-b0fe-f8f761241648,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9bba9b2c-3f61-4cc4-affd-c2fde9641023,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-09181dcf-021c-4aa2-a0c5-5e268c58d350,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-26557706-58e1-44c8-bae0-b84bab2e1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-d7d7e1be-cb11-4067-b906-21b5aa8f8aee,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-a418c3dd-d190-4ae5-a8bb-c204d4bf344b,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-d96b4234-9e4f-418a-91db-e5d01ea5b1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935577632-172.17.0.17-1597741690405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-c041f1b8-0f12-4313-82e0-189647114038,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-deef352d-bdfc-4080-b0fe-f8f761241648,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9bba9b2c-3f61-4cc4-affd-c2fde9641023,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-09181dcf-021c-4aa2-a0c5-5e268c58d350,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-26557706-58e1-44c8-bae0-b84bab2e1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-d7d7e1be-cb11-4067-b906-21b5aa8f8aee,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-a418c3dd-d190-4ae5-a8bb-c204d4bf344b,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-d96b4234-9e4f-418a-91db-e5d01ea5b1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377494458-172.17.0.17-1597741764871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-3b9c4156-ddfa-40e1-aa7f-f199b2e38393,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-cdf1e93a-a61a-4e69-a65a-d56f022c0c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-202cc45d-7b08-4756-be85-47cf7c9d85b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-f8488327-b39d-46ad-b042-74226548770a,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e0abbae2-fc54-44b4-8cde-233970392754,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-a27094c5-1df8-4046-a44a-8f7f3c2b18dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-e2355caa-ecd2-4e1e-9e1d-36bffa69b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-31bbfb06-4d2b-4376-96d0-0ff81ffef9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377494458-172.17.0.17-1597741764871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-3b9c4156-ddfa-40e1-aa7f-f199b2e38393,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-cdf1e93a-a61a-4e69-a65a-d56f022c0c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-202cc45d-7b08-4756-be85-47cf7c9d85b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-f8488327-b39d-46ad-b042-74226548770a,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e0abbae2-fc54-44b4-8cde-233970392754,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-a27094c5-1df8-4046-a44a-8f7f3c2b18dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-e2355caa-ecd2-4e1e-9e1d-36bffa69b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-31bbfb06-4d2b-4376-96d0-0ff81ffef9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464364399-172.17.0.17-1597742246129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-fe3ca50a-5a92-4353-974e-55c306ca42a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-ef1cfe78-c174-4b4d-ad6b-f1b225f5c927,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4e7c3e74-c37c-4bff-98df-cde6e1c05063,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1664ffd7-aad9-4615-aaf3-46103e7b05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-db824145-e565-4a26-bdd8-d9089618d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-0d5d58ca-82be-4e0b-8eee-a842e87ebb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-7cb0c6ce-d536-4071-8e7f-2c146318a6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-4f4ab575-fd98-48fc-8c7b-fe3592dc9680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464364399-172.17.0.17-1597742246129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-fe3ca50a-5a92-4353-974e-55c306ca42a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-ef1cfe78-c174-4b4d-ad6b-f1b225f5c927,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4e7c3e74-c37c-4bff-98df-cde6e1c05063,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1664ffd7-aad9-4615-aaf3-46103e7b05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-db824145-e565-4a26-bdd8-d9089618d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-0d5d58ca-82be-4e0b-8eee-a842e87ebb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-7cb0c6ce-d536-4071-8e7f-2c146318a6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-4f4ab575-fd98-48fc-8c7b-fe3592dc9680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989847001-172.17.0.17-1597742428025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-7d7c6442-3459-4bf5-977e-66b3eac5124c,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-4a8f00d4-9a03-47ef-9b7f-98d20d5e6d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-9af608c0-0f02-4d1e-a7e9-1e3cd40a44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-20a57545-7dc3-4c75-a727-7d3e7895a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-b8b44a3c-28ef-4789-8f4c-0c256f8710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6d3b445e-d5a9-4fb3-bb3f-5d7c53a07557,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-9cc92c87-1c91-4637-8aef-08e18807b667,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-d51a6d3e-eb49-404c-b5c4-6cce46de9fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989847001-172.17.0.17-1597742428025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-7d7c6442-3459-4bf5-977e-66b3eac5124c,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-4a8f00d4-9a03-47ef-9b7f-98d20d5e6d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-9af608c0-0f02-4d1e-a7e9-1e3cd40a44e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-20a57545-7dc3-4c75-a727-7d3e7895a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-b8b44a3c-28ef-4789-8f4c-0c256f8710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6d3b445e-d5a9-4fb3-bb3f-5d7c53a07557,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-9cc92c87-1c91-4637-8aef-08e18807b667,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-d51a6d3e-eb49-404c-b5c4-6cce46de9fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719745880-172.17.0.17-1597743385854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-32d9c5eb-ddd7-4791-a64d-1283048649f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-6a2a7e84-c51d-445b-8a4a-895b585b2b76,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-1ddd1a93-c2b9-4e33-a022-02db06341e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-62789d4f-6607-45e8-a35e-cb69fba1d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-99204e54-943e-4916-b297-866c73b1483b,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-55dbf09f-0124-4925-9224-38de5b10fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-ee83e3fe-1d1e-46b3-820a-2dce315eefe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-9dbd3f26-19db-4f96-afba-d535bc2e41e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719745880-172.17.0.17-1597743385854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-32d9c5eb-ddd7-4791-a64d-1283048649f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-6a2a7e84-c51d-445b-8a4a-895b585b2b76,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-1ddd1a93-c2b9-4e33-a022-02db06341e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-62789d4f-6607-45e8-a35e-cb69fba1d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-99204e54-943e-4916-b297-866c73b1483b,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-55dbf09f-0124-4925-9224-38de5b10fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-ee83e3fe-1d1e-46b3-820a-2dce315eefe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-9dbd3f26-19db-4f96-afba-d535bc2e41e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233664542-172.17.0.17-1597743460794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-d1656290-3e75-4084-bb57-290aace25366,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-69465942-b24c-4064-a006-625953d04a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-8fb10f7e-0459-4fe6-9b95-8399fa1a8f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d6a5bb51-4772-4461-9c65-5bb57f40635a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-535a73fe-ef78-40b9-bdca-6195977bf529,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-f32d5bf6-6eb6-4c99-a2c4-a2923bca1374,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-fac11abe-8a9b-4bf8-b4ad-40179fae20ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-015b6e68-cf14-406e-97ba-c9d919818058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233664542-172.17.0.17-1597743460794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-d1656290-3e75-4084-bb57-290aace25366,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-69465942-b24c-4064-a006-625953d04a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-8fb10f7e-0459-4fe6-9b95-8399fa1a8f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d6a5bb51-4772-4461-9c65-5bb57f40635a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-535a73fe-ef78-40b9-bdca-6195977bf529,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-f32d5bf6-6eb6-4c99-a2c4-a2923bca1374,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-fac11abe-8a9b-4bf8-b4ad-40179fae20ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-015b6e68-cf14-406e-97ba-c9d919818058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896929263-172.17.0.17-1597743642777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-5411fff6-9a8e-4c67-8fe4-a7b7bd95de05,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-606e25af-9241-48ce-b95d-02da443fdce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-e1684114-bd45-4e99-91c5-fd8c0b8ac619,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-9229433d-d12e-4f80-9e28-8f42ed093408,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-d1bd2e00-9d54-4af4-ad4b-3e8405b8148f,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-cb394aaf-9472-4a43-a920-accad32639ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-6485ac99-07fd-4fbb-b624-ba1f679e0f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-f1936177-48ed-4f23-a2b7-05daa0d20e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896929263-172.17.0.17-1597743642777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-5411fff6-9a8e-4c67-8fe4-a7b7bd95de05,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-606e25af-9241-48ce-b95d-02da443fdce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-e1684114-bd45-4e99-91c5-fd8c0b8ac619,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-9229433d-d12e-4f80-9e28-8f42ed093408,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-d1bd2e00-9d54-4af4-ad4b-3e8405b8148f,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-cb394aaf-9472-4a43-a920-accad32639ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-6485ac99-07fd-4fbb-b624-ba1f679e0f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-f1936177-48ed-4f23-a2b7-05daa0d20e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741855982-172.17.0.17-1597743722824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-4ae945af-fd16-4cd8-8369-710b4f2699ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-b4fbddfe-9992-482f-9ebe-1a2b5425b533,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-0eed578c-1928-4d11-a8ce-c972b0c73af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-6089f9f0-03a8-4d4e-bbb1-e1ddcc4ff669,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-bc0ea77c-7672-44c0-a54c-f947bdf5c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-36093505-800d-42db-a6f2-76392b59d150,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-b60a28ef-bccb-4c50-8fc2-5c42c3b57ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-f6c67081-cd94-49ce-9ffc-af17004579a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741855982-172.17.0.17-1597743722824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-4ae945af-fd16-4cd8-8369-710b4f2699ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-b4fbddfe-9992-482f-9ebe-1a2b5425b533,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-0eed578c-1928-4d11-a8ce-c972b0c73af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-6089f9f0-03a8-4d4e-bbb1-e1ddcc4ff669,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-bc0ea77c-7672-44c0-a54c-f947bdf5c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-36093505-800d-42db-a6f2-76392b59d150,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-b60a28ef-bccb-4c50-8fc2-5c42c3b57ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-f6c67081-cd94-49ce-9ffc-af17004579a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482190061-172.17.0.17-1597744070590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-14f70bce-9532-4a6a-8256-8cd4ccbcfbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-61fb40f9-7278-4a39-9f3d-07d82d5366f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-1e61e7cb-bbf2-432b-afea-b4949c34c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-3f88190c-796f-4e87-9b87-809017a09246,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-e8150a8b-ec6b-4c5e-8283-c8bde7f92927,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-1c85a8ed-4ca8-40ec-9898-93d0dd296714,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-4fcbf4a5-fcb1-4371-aba1-46d092ef0367,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-1d155322-73bc-4756-abde-dd4f8a49fba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482190061-172.17.0.17-1597744070590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-14f70bce-9532-4a6a-8256-8cd4ccbcfbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-61fb40f9-7278-4a39-9f3d-07d82d5366f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-1e61e7cb-bbf2-432b-afea-b4949c34c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-3f88190c-796f-4e87-9b87-809017a09246,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-e8150a8b-ec6b-4c5e-8283-c8bde7f92927,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-1c85a8ed-4ca8-40ec-9898-93d0dd296714,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-4fcbf4a5-fcb1-4371-aba1-46d092ef0367,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-1d155322-73bc-4756-abde-dd4f8a49fba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012891671-172.17.0.17-1597744223605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-1258dc1b-2ec8-4fd8-bc5a-d54ecb84d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-537716e8-0747-4096-bdb2-2e24348893b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-591c69bd-54ea-4714-88f5-58bc2820e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-986f687b-6c84-45d5-8530-4d2d0b98da93,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-e41740f6-a3cb-42ea-8794-7c67ea0c019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-24e24251-6d7c-4580-9f2f-e7790c41b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-f709351a-ec43-4d8c-b29f-7c3afd500e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-4ea4a5db-2f75-41d2-90a9-11894173ca90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012891671-172.17.0.17-1597744223605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-1258dc1b-2ec8-4fd8-bc5a-d54ecb84d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-537716e8-0747-4096-bdb2-2e24348893b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-591c69bd-54ea-4714-88f5-58bc2820e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-986f687b-6c84-45d5-8530-4d2d0b98da93,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-e41740f6-a3cb-42ea-8794-7c67ea0c019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-24e24251-6d7c-4580-9f2f-e7790c41b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-f709351a-ec43-4d8c-b29f-7c3afd500e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-4ea4a5db-2f75-41d2-90a9-11894173ca90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5747
