reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786395431-172.17.0.10-1597498481090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-c329bdaa-c07c-4625-8d1f-c41ff719bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-483f3eff-3a5a-4836-baa2-0a4ec35e47e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-01ae8fa3-8a91-47f7-be22-26f227f57e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-09dcfe70-6828-4ffa-aea8-1ac8938f0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-2a423ba9-ff1c-4dcd-9368-4cca4aa7ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-d675dc56-14c9-4880-91cd-0e2ea9a11eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a6280f2f-f55c-40c6-abae-6678f81ba139,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-ce1653ec-50da-42d2-a257-a5fec1ad4fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786395431-172.17.0.10-1597498481090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-c329bdaa-c07c-4625-8d1f-c41ff719bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-483f3eff-3a5a-4836-baa2-0a4ec35e47e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-01ae8fa3-8a91-47f7-be22-26f227f57e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-09dcfe70-6828-4ffa-aea8-1ac8938f0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-2a423ba9-ff1c-4dcd-9368-4cca4aa7ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-d675dc56-14c9-4880-91cd-0e2ea9a11eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a6280f2f-f55c-40c6-abae-6678f81ba139,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-ce1653ec-50da-42d2-a257-a5fec1ad4fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281163615-172.17.0.10-1597498594734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35812,DS-83205764-abbb-4f05-9b6e-881e79c9e905,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-a80239da-a62e-4217-8a30-d4c8e7c29e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-1195bf87-d6ea-452b-9997-06616b8f74fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-e010dba8-3ac5-435b-a1ab-7cc38570c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-469c51b2-0b40-4f33-8a12-7a3778a6382d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-107c2a13-a557-4f0f-8de1-ecd53b6d4484,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-9c624ca4-377d-4ee6-b187-5248d9d02608,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-df417237-1162-423a-8c0c-9081777d1737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281163615-172.17.0.10-1597498594734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35812,DS-83205764-abbb-4f05-9b6e-881e79c9e905,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-a80239da-a62e-4217-8a30-d4c8e7c29e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-1195bf87-d6ea-452b-9997-06616b8f74fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-e010dba8-3ac5-435b-a1ab-7cc38570c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-469c51b2-0b40-4f33-8a12-7a3778a6382d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-107c2a13-a557-4f0f-8de1-ecd53b6d4484,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-9c624ca4-377d-4ee6-b187-5248d9d02608,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-df417237-1162-423a-8c0c-9081777d1737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519767195-172.17.0.10-1597498897811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-7005163f-6103-41ce-ba06-2ab2d512275d,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-6f71e878-e209-4782-8256-1e41c063bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ace3dfdc-e00b-4121-9dce-5ed64f39cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-917a4946-3cb4-4b40-9d17-059a13738056,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c296e445-23a9-44c5-9ff9-593e890ead07,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-a6d9ad4a-829d-4371-b2bd-f786211794a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f213fc5b-ef17-4ac0-8110-89a4adea2502,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-aef811a7-03a5-4c34-8f20-c1cae29ca4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519767195-172.17.0.10-1597498897811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-7005163f-6103-41ce-ba06-2ab2d512275d,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-6f71e878-e209-4782-8256-1e41c063bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ace3dfdc-e00b-4121-9dce-5ed64f39cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-917a4946-3cb4-4b40-9d17-059a13738056,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c296e445-23a9-44c5-9ff9-593e890ead07,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-a6d9ad4a-829d-4371-b2bd-f786211794a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f213fc5b-ef17-4ac0-8110-89a4adea2502,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-aef811a7-03a5-4c34-8f20-c1cae29ca4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712453333-172.17.0.10-1597499318551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-1f56b9f3-572a-4fab-a2ed-038f03f1d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3f74733c-2863-4cd9-bd6c-2f97c1ebf7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-b8ca47c1-66a5-4483-8f72-0013d345e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-6025f974-6c7a-4cc7-88b3-8762fed2441e,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-7bbeac2b-b981-46ee-9ddf-a2fa2eb94912,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-9f65ac77-0936-4dd1-92ae-80ec24be9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-cdab7310-12a4-43cf-8b61-80fc8a1b2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-42dbf8ec-a873-4248-b96b-3f46f0edec76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712453333-172.17.0.10-1597499318551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-1f56b9f3-572a-4fab-a2ed-038f03f1d7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3f74733c-2863-4cd9-bd6c-2f97c1ebf7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-b8ca47c1-66a5-4483-8f72-0013d345e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-6025f974-6c7a-4cc7-88b3-8762fed2441e,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-7bbeac2b-b981-46ee-9ddf-a2fa2eb94912,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-9f65ac77-0936-4dd1-92ae-80ec24be9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-cdab7310-12a4-43cf-8b61-80fc8a1b2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-42dbf8ec-a873-4248-b96b-3f46f0edec76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100336419-172.17.0.10-1597499491088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-09375faf-0455-4ef7-9207-25a762feb5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-773793de-49ba-4a15-a998-9de0fff06676,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-70083cc4-e5b9-42ff-93c0-09c0345ff6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-51c4f327-08b6-4d2d-9733-6fee48ba99d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-77e2cabf-3f08-48b1-be87-fdad559f5f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-f78bd012-224c-44f3-b0ee-8f9e190a4a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-8d129a1e-06af-4ace-9ff4-cb2ab605fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-fbbee369-a51c-4b70-8ebb-46520493ac9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100336419-172.17.0.10-1597499491088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-09375faf-0455-4ef7-9207-25a762feb5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-773793de-49ba-4a15-a998-9de0fff06676,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-70083cc4-e5b9-42ff-93c0-09c0345ff6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-51c4f327-08b6-4d2d-9733-6fee48ba99d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-77e2cabf-3f08-48b1-be87-fdad559f5f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-f78bd012-224c-44f3-b0ee-8f9e190a4a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-8d129a1e-06af-4ace-9ff4-cb2ab605fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-fbbee369-a51c-4b70-8ebb-46520493ac9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130053875-172.17.0.10-1597499635792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-0567a803-317f-4ec5-b7f1-ab19805dc74c,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-75377b76-ecab-4ce7-af27-a62180b34930,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-3727cadc-6136-4d66-8f18-a90ea414860f,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-74825003-6abf-4f97-a413-655fbf318c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-903ed1b1-8eb2-429a-b7d3-3176543f11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-2ebb8759-6e16-4f30-9327-5f13a64aab64,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-cedc5526-b913-477a-b6ae-760d6ff5c774,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-be11e490-5371-4874-80d0-fa5314921e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130053875-172.17.0.10-1597499635792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-0567a803-317f-4ec5-b7f1-ab19805dc74c,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-75377b76-ecab-4ce7-af27-a62180b34930,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-3727cadc-6136-4d66-8f18-a90ea414860f,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-74825003-6abf-4f97-a413-655fbf318c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-903ed1b1-8eb2-429a-b7d3-3176543f11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-2ebb8759-6e16-4f30-9327-5f13a64aab64,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-cedc5526-b913-477a-b6ae-760d6ff5c774,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-be11e490-5371-4874-80d0-fa5314921e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514471816-172.17.0.10-1597499673778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-930718ac-b324-42e1-b7c8-44e5cf54532d,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-dc10d20b-2d6d-4dce-9d9b-ff0f3d8696a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-49f6e9a4-4a70-41c5-8639-0b56664f7069,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ad1cac92-6cf6-415b-a28c-be627199d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-a6ba8914-3bd3-4882-8f09-1ce788673a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-b07575d4-7378-4dbf-9870-57b8a5f2662a,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5c85d255-ed67-4b38-830e-5ce5cd293ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-85eeafac-ba5b-49b2-8529-b392a8770751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514471816-172.17.0.10-1597499673778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-930718ac-b324-42e1-b7c8-44e5cf54532d,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-dc10d20b-2d6d-4dce-9d9b-ff0f3d8696a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-49f6e9a4-4a70-41c5-8639-0b56664f7069,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ad1cac92-6cf6-415b-a28c-be627199d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-a6ba8914-3bd3-4882-8f09-1ce788673a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-b07575d4-7378-4dbf-9870-57b8a5f2662a,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5c85d255-ed67-4b38-830e-5ce5cd293ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-85eeafac-ba5b-49b2-8529-b392a8770751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743050360-172.17.0.10-1597499894660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45595,DS-54ca5a7a-5085-431e-8385-984fd2d7e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-0d58a713-5b90-4d8e-ba8f-f03e30bc68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5d2de4d4-76cf-4654-bcb2-6900ea3c4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-57454894-192c-4ebe-96ca-4b42b792ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-b6923c11-fa15-4775-be2c-c6f9f457e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-75ebb642-fe1f-4fe3-9916-a0c0a57c2493,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-4ba0f191-8d3d-4f0e-add9-1e2aa593d100,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f6b84be0-0d20-40c9-9b4d-db5362171d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743050360-172.17.0.10-1597499894660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45595,DS-54ca5a7a-5085-431e-8385-984fd2d7e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-0d58a713-5b90-4d8e-ba8f-f03e30bc68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5d2de4d4-76cf-4654-bcb2-6900ea3c4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-57454894-192c-4ebe-96ca-4b42b792ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-b6923c11-fa15-4775-be2c-c6f9f457e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-75ebb642-fe1f-4fe3-9916-a0c0a57c2493,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-4ba0f191-8d3d-4f0e-add9-1e2aa593d100,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f6b84be0-0d20-40c9-9b4d-db5362171d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089769567-172.17.0.10-1597500005217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-98dc579c-a0be-4d5f-a225-73587724fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-30e81c42-2441-4752-844c-3b8018229dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-590acda9-dc6f-4c2d-a690-ee0af3d7aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-c508d561-27f7-42a5-b3c8-26ca4ad4a18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-31fdd06f-e117-4a5f-8d89-dc59722e5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-05c778cc-d143-48ce-b4fc-5249f30a73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-df5ab355-d45a-4fac-b3ea-56c290e3bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-3c161ae6-5279-4093-b983-5a262ceac634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089769567-172.17.0.10-1597500005217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-98dc579c-a0be-4d5f-a225-73587724fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-30e81c42-2441-4752-844c-3b8018229dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-590acda9-dc6f-4c2d-a690-ee0af3d7aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-c508d561-27f7-42a5-b3c8-26ca4ad4a18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-31fdd06f-e117-4a5f-8d89-dc59722e5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-05c778cc-d143-48ce-b4fc-5249f30a73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-df5ab355-d45a-4fac-b3ea-56c290e3bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-3c161ae6-5279-4093-b983-5a262ceac634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831304359-172.17.0.10-1597500229916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-ce5e9cb1-18a7-4d3c-8080-86bddee82f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-a1ac0bf8-8557-43c6-9c0d-e9d31bf1bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-6d39cc7b-05a0-487b-93b0-ff1df66c6521,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-7bca2ca2-4096-4bc8-80eb-0f73025ab3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-d8ddfe98-3fee-4bbb-985e-3e3fc5c1dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-99dc98df-39e7-45c9-99b5-3a141bad885b,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-271438e8-c473-43db-a60c-37482b9adc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-bbaf3890-9523-498d-ace1-e7873f6c484f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831304359-172.17.0.10-1597500229916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-ce5e9cb1-18a7-4d3c-8080-86bddee82f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-a1ac0bf8-8557-43c6-9c0d-e9d31bf1bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-6d39cc7b-05a0-487b-93b0-ff1df66c6521,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-7bca2ca2-4096-4bc8-80eb-0f73025ab3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-d8ddfe98-3fee-4bbb-985e-3e3fc5c1dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-99dc98df-39e7-45c9-99b5-3a141bad885b,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-271438e8-c473-43db-a60c-37482b9adc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-bbaf3890-9523-498d-ace1-e7873f6c484f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449705912-172.17.0.10-1597500308602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-ab12f695-f09b-4f81-b770-5e2635e84773,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-2c87f700-5a5a-4c92-ac98-75d79b7f951c,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-9bb88e15-4a3d-4144-8b25-7cf50ce581d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-4e0d4447-d3dc-43a5-a264-ee241dd3cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-8f4dc735-362f-4f1b-b0eb-de04b1745b39,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-ef5e9267-0cda-4ecf-8b5d-36998fd68cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-fe74c412-9701-4998-8314-64bc343fac40,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-290d4a4a-e334-45af-bd4d-30f0a7ae083d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449705912-172.17.0.10-1597500308602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-ab12f695-f09b-4f81-b770-5e2635e84773,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-2c87f700-5a5a-4c92-ac98-75d79b7f951c,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-9bb88e15-4a3d-4144-8b25-7cf50ce581d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-4e0d4447-d3dc-43a5-a264-ee241dd3cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-8f4dc735-362f-4f1b-b0eb-de04b1745b39,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-ef5e9267-0cda-4ecf-8b5d-36998fd68cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-fe74c412-9701-4998-8314-64bc343fac40,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-290d4a4a-e334-45af-bd4d-30f0a7ae083d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904909047-172.17.0.10-1597500725351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-60fa53c6-aa0e-4240-8fb5-e9f7d81a11c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-8b12d74c-e354-47cd-998e-414b2396aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-629ca04f-a855-49aa-b26e-26f9cf017a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-43d9491f-5113-45d1-a96d-37cab0dab4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-aee061cf-9f8b-4730-bec0-3cf836765dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-6986e175-295e-49c8-8c76-4bb0632b49bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-516dcda5-1527-43a0-ac92-6a62e65e4d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-f4e84997-7126-4189-958f-bc22cf4828fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904909047-172.17.0.10-1597500725351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-60fa53c6-aa0e-4240-8fb5-e9f7d81a11c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-8b12d74c-e354-47cd-998e-414b2396aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-629ca04f-a855-49aa-b26e-26f9cf017a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-43d9491f-5113-45d1-a96d-37cab0dab4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-aee061cf-9f8b-4730-bec0-3cf836765dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-6986e175-295e-49c8-8c76-4bb0632b49bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-516dcda5-1527-43a0-ac92-6a62e65e4d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-f4e84997-7126-4189-958f-bc22cf4828fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319377199-172.17.0.10-1597500797123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-53500a9c-0f62-446c-a5e3-78dbb25438e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7cf1dee5-7163-45b3-b680-65a6116a0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-095128f8-6498-4617-be52-7193e12ead76,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-f5f8c020-ae37-40b7-8a97-5c758bc6e697,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-6efde3a4-733c-4933-badc-80cb9499ff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-fe51ab90-34f1-4704-a2ed-4ade41eee16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-1fbdb2b1-1a07-4b1b-a58f-99003f85e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-92fb7d1e-bbbf-40d8-9e06-679a0590d3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319377199-172.17.0.10-1597500797123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-53500a9c-0f62-446c-a5e3-78dbb25438e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7cf1dee5-7163-45b3-b680-65a6116a0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-095128f8-6498-4617-be52-7193e12ead76,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-f5f8c020-ae37-40b7-8a97-5c758bc6e697,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-6efde3a4-733c-4933-badc-80cb9499ff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-fe51ab90-34f1-4704-a2ed-4ade41eee16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-1fbdb2b1-1a07-4b1b-a58f-99003f85e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-92fb7d1e-bbbf-40d8-9e06-679a0590d3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294157712-172.17.0.10-1597500869420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38682,DS-ceebaf60-6c9a-4736-8f7c-ad302775f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-41e0228a-7ca6-4095-95bc-269fd5993ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-ad7b6cd8-334c-48db-bde2-ad0d9cb12258,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-ea02c522-82ab-4ae8-8b65-e172f1f06e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-e73478a3-c486-446f-a291-cd12a72eaa78,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-4c77e95b-42b8-4de5-ba1a-8b1cd4e7c778,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-7f622351-b910-40d5-9bdc-1215543b2156,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-985f7656-2560-402b-83e0-ad4dfa985ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294157712-172.17.0.10-1597500869420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38682,DS-ceebaf60-6c9a-4736-8f7c-ad302775f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-41e0228a-7ca6-4095-95bc-269fd5993ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-ad7b6cd8-334c-48db-bde2-ad0d9cb12258,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-ea02c522-82ab-4ae8-8b65-e172f1f06e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-e73478a3-c486-446f-a291-cd12a72eaa78,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-4c77e95b-42b8-4de5-ba1a-8b1cd4e7c778,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-7f622351-b910-40d5-9bdc-1215543b2156,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-985f7656-2560-402b-83e0-ad4dfa985ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051509473-172.17.0.10-1597501794354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-11d4efd0-3f05-45d4-ba7b-c8308afd31a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-722b82e6-5700-4c95-ac41-b07fbd90920c,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-c9a1ce63-870f-4d52-8e59-05e37e22d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-55fe7e85-c35e-4e11-b65c-83e5be4a3601,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-efe004a2-6665-48a9-9740-f6f904ae11cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-f566c3c8-6925-463f-957a-911a73197696,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-66e2e53c-d64d-4d26-978a-f8e941d47b74,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-8aed0816-9e8c-4245-9c64-a76d2aa66e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051509473-172.17.0.10-1597501794354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-11d4efd0-3f05-45d4-ba7b-c8308afd31a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-722b82e6-5700-4c95-ac41-b07fbd90920c,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-c9a1ce63-870f-4d52-8e59-05e37e22d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-55fe7e85-c35e-4e11-b65c-83e5be4a3601,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-efe004a2-6665-48a9-9740-f6f904ae11cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-f566c3c8-6925-463f-957a-911a73197696,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-66e2e53c-d64d-4d26-978a-f8e941d47b74,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-8aed0816-9e8c-4245-9c64-a76d2aa66e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088762841-172.17.0.10-1597502283407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-c3422c2f-7789-4a2e-a0a1-c4e8cf7e8032,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-6749f273-4bf5-4a05-9398-d9cf67f174e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c2938c3f-c913-4e7b-b35e-3645efe8f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-73c70c4a-8113-46eb-b48c-86206271c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-03c9cb68-27b9-4f8f-afa6-0338c07a544b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-9837d926-791f-43b8-ba1b-1541cc2156b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-27b9f2bd-c921-45c2-8812-ba99ff63725b,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-2359f7f7-5bcf-48f1-bfff-48a0b7d9e0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088762841-172.17.0.10-1597502283407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-c3422c2f-7789-4a2e-a0a1-c4e8cf7e8032,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-6749f273-4bf5-4a05-9398-d9cf67f174e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c2938c3f-c913-4e7b-b35e-3645efe8f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-73c70c4a-8113-46eb-b48c-86206271c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-03c9cb68-27b9-4f8f-afa6-0338c07a544b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-9837d926-791f-43b8-ba1b-1541cc2156b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-27b9f2bd-c921-45c2-8812-ba99ff63725b,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-2359f7f7-5bcf-48f1-bfff-48a0b7d9e0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254601873-172.17.0.10-1597502318630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45069,DS-c36bba71-8adc-4e25-94c8-80cf11c80fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-8afdcac7-5a34-415b-9182-a6493a3a4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-e51c93cd-d844-4c31-afc1-0e186262d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-4ccfd272-2be8-4c51-8068-7b32a1037946,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-85bfc904-ef67-4aad-8247-dffddf01ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-e4d3c131-6cc5-4d10-be86-08061ef5e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-304fe2ac-8d8e-40d5-8a50-b03a644198cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-b7079847-4fb8-45d9-872e-8dfb6db86dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254601873-172.17.0.10-1597502318630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45069,DS-c36bba71-8adc-4e25-94c8-80cf11c80fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-8afdcac7-5a34-415b-9182-a6493a3a4f31,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-e51c93cd-d844-4c31-afc1-0e186262d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-4ccfd272-2be8-4c51-8068-7b32a1037946,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-85bfc904-ef67-4aad-8247-dffddf01ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-e4d3c131-6cc5-4d10-be86-08061ef5e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-304fe2ac-8d8e-40d5-8a50-b03a644198cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-b7079847-4fb8-45d9-872e-8dfb6db86dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022624109-172.17.0.10-1597502746908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45398,DS-4844f570-b44c-42c6-99de-b9cd2ed4a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-8069e5cc-e4b2-4279-abc6-2574e7615575,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a582beec-5abc-424c-9f55-9362d878a222,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c03995a7-4682-4079-9972-5ab33c7ba27a,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-fac8a755-fb44-4196-985b-01354cf26212,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-d0fb429f-5e40-4502-8677-3c842878d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-23c0e664-2718-4520-8401-6dca5bddad42,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-a3a3d7cb-9b82-4996-a4b4-207ba3761b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022624109-172.17.0.10-1597502746908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45398,DS-4844f570-b44c-42c6-99de-b9cd2ed4a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-8069e5cc-e4b2-4279-abc6-2574e7615575,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a582beec-5abc-424c-9f55-9362d878a222,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c03995a7-4682-4079-9972-5ab33c7ba27a,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-fac8a755-fb44-4196-985b-01354cf26212,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-d0fb429f-5e40-4502-8677-3c842878d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-23c0e664-2718-4520-8401-6dca5bddad42,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-a3a3d7cb-9b82-4996-a4b4-207ba3761b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365804948-172.17.0.10-1597502860101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-24bb1676-bb79-4da0-b9fd-3804ae1c35bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-b6a13d7d-ffca-4787-a3cc-805ed845c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-ff458b16-6a05-45aa-83d6-6aace84634a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-596c01ff-7859-403c-9c3a-ccac746c2696,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-87361766-db13-4e84-9771-68021625c778,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-1c2758eb-efa2-42c9-994b-628646f545e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-c6f7e408-0a82-421e-bfca-1818b6570df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-939c1c56-74be-4b70-90b6-78d2bf30dc2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365804948-172.17.0.10-1597502860101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-24bb1676-bb79-4da0-b9fd-3804ae1c35bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-b6a13d7d-ffca-4787-a3cc-805ed845c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-ff458b16-6a05-45aa-83d6-6aace84634a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-596c01ff-7859-403c-9c3a-ccac746c2696,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-87361766-db13-4e84-9771-68021625c778,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-1c2758eb-efa2-42c9-994b-628646f545e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-c6f7e408-0a82-421e-bfca-1818b6570df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-939c1c56-74be-4b70-90b6-78d2bf30dc2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524675736-172.17.0.10-1597503545310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-fd7a251e-8c08-4e79-8e0e-b231de8fe852,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-811213b6-6ac7-4a31-86b6-986850f7332d,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-42fc4d8c-f0c8-4847-b560-eacdce511243,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-e80fa1b8-7f90-4231-8c73-be4768d95df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-165d9dc2-ec8c-4273-a38f-c740b245e04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-3e36f08f-85e2-434a-b2b3-460e4794cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-922e486c-ba16-49c8-8e94-0d36e3290d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-30766e88-cfea-44dd-b878-c17d559dfacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524675736-172.17.0.10-1597503545310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-fd7a251e-8c08-4e79-8e0e-b231de8fe852,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-811213b6-6ac7-4a31-86b6-986850f7332d,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-42fc4d8c-f0c8-4847-b560-eacdce511243,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-e80fa1b8-7f90-4231-8c73-be4768d95df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-165d9dc2-ec8c-4273-a38f-c740b245e04d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-3e36f08f-85e2-434a-b2b3-460e4794cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-922e486c-ba16-49c8-8e94-0d36e3290d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-30766e88-cfea-44dd-b878-c17d559dfacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5454
