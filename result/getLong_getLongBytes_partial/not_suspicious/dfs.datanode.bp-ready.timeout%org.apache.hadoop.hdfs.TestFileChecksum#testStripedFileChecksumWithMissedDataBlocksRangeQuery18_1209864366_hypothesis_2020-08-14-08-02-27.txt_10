reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382521510-172.17.0.12-1597392224843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-11f00a13-1057-4618-9dc5-9dde0470e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-16583cab-a3fe-468d-ad56-344db2e89a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-dc288107-1df6-46eb-afdc-bf9880450e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3a4610d4-73c6-4a79-b927-6a81e9f70b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-28796cf6-3105-490c-8095-264648bbc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-cf1938a9-0468-462e-a2d4-1c24cf30f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-c7c7f8ee-afde-4f98-b079-3a772b6f932e,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-fc669f00-b185-4bc2-b014-b0657a345078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382521510-172.17.0.12-1597392224843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-11f00a13-1057-4618-9dc5-9dde0470e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-16583cab-a3fe-468d-ad56-344db2e89a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-dc288107-1df6-46eb-afdc-bf9880450e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3a4610d4-73c6-4a79-b927-6a81e9f70b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-28796cf6-3105-490c-8095-264648bbc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-cf1938a9-0468-462e-a2d4-1c24cf30f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-c7c7f8ee-afde-4f98-b079-3a772b6f932e,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-fc669f00-b185-4bc2-b014-b0657a345078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924103782-172.17.0.12-1597392552142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-04ba3632-989e-42f2-a893-f25bcc2d746d,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-08b2a4c2-7d52-4a7b-a865-f6986ef8ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-8d5dd1a3-5af0-43ce-aa78-457ceb86210d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-27806354-4ab9-4ee7-b7d1-f59bf6717cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0bb19c2c-39e0-4c0d-856d-fdca89deccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-9b15af42-322a-4b78-9ec2-7ca0a083868a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-a197f810-733a-4e32-8f75-1604c8ce02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-0fa96f78-0d75-4bbd-a229-81f1f4a6370c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924103782-172.17.0.12-1597392552142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-04ba3632-989e-42f2-a893-f25bcc2d746d,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-08b2a4c2-7d52-4a7b-a865-f6986ef8ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-8d5dd1a3-5af0-43ce-aa78-457ceb86210d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-27806354-4ab9-4ee7-b7d1-f59bf6717cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0bb19c2c-39e0-4c0d-856d-fdca89deccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-9b15af42-322a-4b78-9ec2-7ca0a083868a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-a197f810-733a-4e32-8f75-1604c8ce02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-0fa96f78-0d75-4bbd-a229-81f1f4a6370c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583047232-172.17.0.12-1597392701181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-791d0cd1-cc6e-480a-8df2-da25060e4c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7d0b6fa3-9070-4038-99f8-28b502c0a980,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-b65ef2be-4cbc-4a61-bfa5-4eac6d9d9c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-dbdd53fb-c4fb-440b-9e81-b2fa9115176f,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-9ff2050a-48a3-4a7e-b88d-0c020e6e2291,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-15a98273-3a76-4b5e-b1ba-2881f19d2f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-d62d127f-73b0-48e1-a669-ea262b367bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-f9ca786b-90d1-47eb-a240-830bf2ddd9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583047232-172.17.0.12-1597392701181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-791d0cd1-cc6e-480a-8df2-da25060e4c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7d0b6fa3-9070-4038-99f8-28b502c0a980,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-b65ef2be-4cbc-4a61-bfa5-4eac6d9d9c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-dbdd53fb-c4fb-440b-9e81-b2fa9115176f,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-9ff2050a-48a3-4a7e-b88d-0c020e6e2291,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-15a98273-3a76-4b5e-b1ba-2881f19d2f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-d62d127f-73b0-48e1-a669-ea262b367bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-f9ca786b-90d1-47eb-a240-830bf2ddd9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323970063-172.17.0.12-1597393114949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-de4b76bb-7c49-4e83-9022-9d25147c6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-38544754-fb0d-4aba-b67b-bdcef1e5bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-41fe58f3-40ca-40d2-8319-0d28c5303e16,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-b9172bc7-2808-4620-966a-3829bf4c0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-9cd00cb6-71bf-4094-b090-483699e52aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-28b21ea8-5aa9-4692-9875-7bf21d42ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-08206794-3645-487b-95ef-684f8fcafb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-c6f53ef8-5a51-4147-95af-e42f65e7e9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323970063-172.17.0.12-1597393114949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-de4b76bb-7c49-4e83-9022-9d25147c6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-38544754-fb0d-4aba-b67b-bdcef1e5bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-41fe58f3-40ca-40d2-8319-0d28c5303e16,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-b9172bc7-2808-4620-966a-3829bf4c0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-9cd00cb6-71bf-4094-b090-483699e52aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-28b21ea8-5aa9-4692-9875-7bf21d42ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-08206794-3645-487b-95ef-684f8fcafb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-c6f53ef8-5a51-4147-95af-e42f65e7e9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356048011-172.17.0.12-1597394107808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-61c6aea0-b6c1-4c84-853f-c95482b0e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-23c14d7d-40e8-41dc-80e3-c6878f5cda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-eff7a58d-5391-4b2c-bda7-8d62b7e76374,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-80a0ad11-1fae-4b74-9f65-622d60535b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-9612b3cf-89d9-41e3-b1a9-ac739c6a7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-db3d0962-23e6-4b68-8a09-a23324d07c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-36a4972d-3e6f-402f-ac31-d941264f9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6a327ca1-59a1-4675-a56f-bc29aff7399b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356048011-172.17.0.12-1597394107808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-61c6aea0-b6c1-4c84-853f-c95482b0e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-23c14d7d-40e8-41dc-80e3-c6878f5cda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-eff7a58d-5391-4b2c-bda7-8d62b7e76374,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-80a0ad11-1fae-4b74-9f65-622d60535b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-9612b3cf-89d9-41e3-b1a9-ac739c6a7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-db3d0962-23e6-4b68-8a09-a23324d07c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-36a4972d-3e6f-402f-ac31-d941264f9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6a327ca1-59a1-4675-a56f-bc29aff7399b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779111544-172.17.0.12-1597394542093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37915,DS-cde0e4ed-4bf1-4386-ba50-94c2e09b432a,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-d2a3b8d7-2dbd-404b-9e9c-163c3eed75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-279b9872-9f8e-42db-b55f-57d8efbd7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-1c1dfa15-acb4-434f-934c-84c40218d4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-6a80e425-a593-4282-ba6f-760ec8856951,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-c4ea84a1-e371-4072-972e-bc3e13f391b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-92fa3f1e-6af0-441e-b184-5a412bac639b,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-cc57f629-fc9e-4777-89b3-264d89bbe19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779111544-172.17.0.12-1597394542093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37915,DS-cde0e4ed-4bf1-4386-ba50-94c2e09b432a,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-d2a3b8d7-2dbd-404b-9e9c-163c3eed75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-279b9872-9f8e-42db-b55f-57d8efbd7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-1c1dfa15-acb4-434f-934c-84c40218d4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-6a80e425-a593-4282-ba6f-760ec8856951,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-c4ea84a1-e371-4072-972e-bc3e13f391b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-92fa3f1e-6af0-441e-b184-5a412bac639b,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-cc57f629-fc9e-4777-89b3-264d89bbe19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909482255-172.17.0.12-1597394820051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36318,DS-77f8e37b-8f90-49a8-a8f9-e5895718feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ea6657bf-8b4e-4cf5-bb0a-09a0554aae87,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-e9bc09e7-31d4-4eb2-9bc0-08a99e18b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-d8978f7a-3c63-4a2e-8491-7542ec32d988,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-4fb79147-f8a2-4596-8e58-680f3cbd66f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-485c6b0f-d8d0-4393-97a9-b0a884208c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-94779337-64d8-4144-a4e3-c7e02a05ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-d5b05ed6-36d9-402b-a766-e355a84c18b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909482255-172.17.0.12-1597394820051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36318,DS-77f8e37b-8f90-49a8-a8f9-e5895718feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ea6657bf-8b4e-4cf5-bb0a-09a0554aae87,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-e9bc09e7-31d4-4eb2-9bc0-08a99e18b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-d8978f7a-3c63-4a2e-8491-7542ec32d988,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-4fb79147-f8a2-4596-8e58-680f3cbd66f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-485c6b0f-d8d0-4393-97a9-b0a884208c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-94779337-64d8-4144-a4e3-c7e02a05ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-d5b05ed6-36d9-402b-a766-e355a84c18b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80478243-172.17.0.12-1597394913471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-a7935b0f-ec31-4727-aae9-2d372d5e0731,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-991952d7-1de2-4626-b951-c9e363c35a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-6c2e668a-9bfa-489c-a4ab-740a28143aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-f1765f12-726a-4d17-9843-3aa96d347f72,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-5535a10f-6faf-42e5-a724-a761415ddcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-706b9718-ee40-4758-9a20-90b6c5512882,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-95cbadbc-8bbe-4e7d-8d88-cf0f7de20d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-6774dae5-3b93-4a2d-89f5-264a511c631c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80478243-172.17.0.12-1597394913471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-a7935b0f-ec31-4727-aae9-2d372d5e0731,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-991952d7-1de2-4626-b951-c9e363c35a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-6c2e668a-9bfa-489c-a4ab-740a28143aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-f1765f12-726a-4d17-9843-3aa96d347f72,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-5535a10f-6faf-42e5-a724-a761415ddcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-706b9718-ee40-4758-9a20-90b6c5512882,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-95cbadbc-8bbe-4e7d-8d88-cf0f7de20d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-6774dae5-3b93-4a2d-89f5-264a511c631c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892333581-172.17.0.12-1597394955514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-4253b036-021e-4ad0-afcf-8858a8fefe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-347f6924-c674-4483-b0a6-2b49ca04786e,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-d63d928a-826e-44ca-be09-6363e8c3d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-fd552042-e667-4d49-a3e9-7e6a345f39b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-25dd62f6-5fe3-438d-ad52-4a45be7a4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-635cb394-6e5e-46b4-8ef8-172a658d2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-55f42893-beec-47b8-a16f-604f1c936871,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-72cce7f8-bc60-485a-96ab-ea51e5949b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892333581-172.17.0.12-1597394955514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-4253b036-021e-4ad0-afcf-8858a8fefe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-347f6924-c674-4483-b0a6-2b49ca04786e,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-d63d928a-826e-44ca-be09-6363e8c3d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-fd552042-e667-4d49-a3e9-7e6a345f39b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-25dd62f6-5fe3-438d-ad52-4a45be7a4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-635cb394-6e5e-46b4-8ef8-172a658d2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-55f42893-beec-47b8-a16f-604f1c936871,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-72cce7f8-bc60-485a-96ab-ea51e5949b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838075093-172.17.0.12-1597395043794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-63eb97af-f098-4beb-a05d-429c0928cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8f074562-0f6f-4256-b290-cc6c1c3fab81,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-99b9b0eb-1921-4f29-8920-acc1cff25ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-3812c781-35ca-4ded-a977-535c03c01887,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-20edbb55-faac-4fd2-b265-5e147537c127,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-de1f135a-ba14-44ec-86eb-e5508e4df48a,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-88b8ddb0-c703-4a53-8ad2-104fa50b9df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-bbd4d1b8-8b53-45c0-aabf-8f5eeb88fdd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838075093-172.17.0.12-1597395043794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-63eb97af-f098-4beb-a05d-429c0928cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8f074562-0f6f-4256-b290-cc6c1c3fab81,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-99b9b0eb-1921-4f29-8920-acc1cff25ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-3812c781-35ca-4ded-a977-535c03c01887,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-20edbb55-faac-4fd2-b265-5e147537c127,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-de1f135a-ba14-44ec-86eb-e5508e4df48a,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-88b8ddb0-c703-4a53-8ad2-104fa50b9df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-bbd4d1b8-8b53-45c0-aabf-8f5eeb88fdd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929824208-172.17.0.12-1597395134147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-1e4555b5-c46a-47c6-ac51-4477ccbd187f,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-11a98b3f-5d4c-408e-a2c9-5ae44e1176cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-2b4a6862-6389-48fb-b908-94e03d004083,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-93a87d6a-7036-49dc-a4f8-445d63a65199,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-97f6f77f-0943-40b1-a7c6-7bb33a568f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-7ef1aa28-8a71-4070-be03-6bde26150101,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-dd857746-258a-47b5-adcf-af8e57b5ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-ec53b0c3-662a-47ab-bce2-c5172826a023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929824208-172.17.0.12-1597395134147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-1e4555b5-c46a-47c6-ac51-4477ccbd187f,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-11a98b3f-5d4c-408e-a2c9-5ae44e1176cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-2b4a6862-6389-48fb-b908-94e03d004083,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-93a87d6a-7036-49dc-a4f8-445d63a65199,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-97f6f77f-0943-40b1-a7c6-7bb33a568f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-7ef1aa28-8a71-4070-be03-6bde26150101,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-dd857746-258a-47b5-adcf-af8e57b5ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-ec53b0c3-662a-47ab-bce2-c5172826a023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648925736-172.17.0.12-1597396230121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-1b98752c-eb3a-4f4f-9960-4ffbb99f49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-559fb00a-8542-454c-bd3c-e4d3a49f9564,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-5a131375-ddc3-4473-81c4-ec248d0403c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-1201ec55-be2d-4ab3-b7b9-98009de99efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-16eebf4a-83de-48d3-a4c5-a409ba6fe1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-3425fdd7-246c-491b-a6cd-b94647b51d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-115bc0a5-b8f6-4c36-b07d-2b4a68e122cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-022e1710-fc3e-440d-a992-c292e64f6d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648925736-172.17.0.12-1597396230121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-1b98752c-eb3a-4f4f-9960-4ffbb99f49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-559fb00a-8542-454c-bd3c-e4d3a49f9564,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-5a131375-ddc3-4473-81c4-ec248d0403c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-1201ec55-be2d-4ab3-b7b9-98009de99efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-16eebf4a-83de-48d3-a4c5-a409ba6fe1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-3425fdd7-246c-491b-a6cd-b94647b51d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-115bc0a5-b8f6-4c36-b07d-2b4a68e122cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-022e1710-fc3e-440d-a992-c292e64f6d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103146062-172.17.0.12-1597396460317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-f564029c-a606-4761-8a26-5cc72491c661,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b476bcf7-8d71-49ad-a60d-8926dc4e00f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-b4da15c2-c6bd-40e3-a1f5-30a498302c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-a91abb15-8bb5-456f-acd8-8c9fab87b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-acbd259f-2e0d-4a02-a897-4fa17d6823b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-645fe6d8-a75d-474a-a42c-88920769ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8ea1b280-4aef-41e3-b88c-273920f223d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-09f9feda-b825-4403-8013-5eb3f4481f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103146062-172.17.0.12-1597396460317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-f564029c-a606-4761-8a26-5cc72491c661,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b476bcf7-8d71-49ad-a60d-8926dc4e00f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-b4da15c2-c6bd-40e3-a1f5-30a498302c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-a91abb15-8bb5-456f-acd8-8c9fab87b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-acbd259f-2e0d-4a02-a897-4fa17d6823b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-645fe6d8-a75d-474a-a42c-88920769ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8ea1b280-4aef-41e3-b88c-273920f223d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-09f9feda-b825-4403-8013-5eb3f4481f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236435300-172.17.0.12-1597396638842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-0b899072-3342-4263-b4cd-118f2e25ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-d498cd06-2d88-4962-bdd8-6ed3ba217afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-4991a6c0-76fe-4a07-b72a-c9b8583d10e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-62db1116-b27f-4906-a2ab-c09999715010,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f0d9cf51-4343-4941-b967-97866cdbb93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-beff8203-3030-443b-b38d-ab9d7877cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-87abc76d-60f0-4b5b-aaff-3ef1aabeeac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-dec4ea3b-3f15-4c2f-9ec3-ce5cf67939c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236435300-172.17.0.12-1597396638842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-0b899072-3342-4263-b4cd-118f2e25ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-d498cd06-2d88-4962-bdd8-6ed3ba217afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-4991a6c0-76fe-4a07-b72a-c9b8583d10e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-62db1116-b27f-4906-a2ab-c09999715010,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f0d9cf51-4343-4941-b967-97866cdbb93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-beff8203-3030-443b-b38d-ab9d7877cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-87abc76d-60f0-4b5b-aaff-3ef1aabeeac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-dec4ea3b-3f15-4c2f-9ec3-ce5cf67939c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044807600-172.17.0.12-1597397205152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-dc714f02-e458-406f-8e53-d759e51f61b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-0735f3ec-8c68-40f6-8116-0bec5d99d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-61b223f9-77f8-490a-bdb0-1bc3dacf03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-e59c3e1b-365f-4854-a11b-03921f384713,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-7981de59-b27e-4853-af38-e5386e2b9526,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d7e0ee6b-24a6-463c-86c5-7aa8e97b2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-4ff7d99b-b056-4f5c-8abc-0a93d8efd5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-13f131d1-60aa-4be1-857c-a75e57ee68bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044807600-172.17.0.12-1597397205152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-dc714f02-e458-406f-8e53-d759e51f61b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-0735f3ec-8c68-40f6-8116-0bec5d99d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-61b223f9-77f8-490a-bdb0-1bc3dacf03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-e59c3e1b-365f-4854-a11b-03921f384713,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-7981de59-b27e-4853-af38-e5386e2b9526,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d7e0ee6b-24a6-463c-86c5-7aa8e97b2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-4ff7d99b-b056-4f5c-8abc-0a93d8efd5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-13f131d1-60aa-4be1-857c-a75e57ee68bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993348872-172.17.0.12-1597397521021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-f463bebe-6ba9-4307-9f73-2909366b8225,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-05a6b8ec-67b0-4f9c-96dc-5efa19942919,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-1221235e-0ae6-4647-a52b-bede0682881f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-274517ca-e613-46db-9d05-6ad77d862063,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-2b2e652a-b99c-4ccc-9833-b663bd3b4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-3134383b-0497-4fa4-80b7-da0501cb8627,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-076a1981-1431-46ce-a9c8-9ba159d27e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-dd3ba88f-dc08-48f2-a7b0-146712e814fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993348872-172.17.0.12-1597397521021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-f463bebe-6ba9-4307-9f73-2909366b8225,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-05a6b8ec-67b0-4f9c-96dc-5efa19942919,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-1221235e-0ae6-4647-a52b-bede0682881f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-274517ca-e613-46db-9d05-6ad77d862063,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-2b2e652a-b99c-4ccc-9833-b663bd3b4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-3134383b-0497-4fa4-80b7-da0501cb8627,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-076a1981-1431-46ce-a9c8-9ba159d27e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-dd3ba88f-dc08-48f2-a7b0-146712e814fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085844579-172.17.0.12-1597397705483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-b1a7401b-38a9-414e-a73f-61715235d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-3a718132-dfa4-460e-ae40-d26015036e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-52f3bc0d-1b45-4b1d-8c12-096e275a9116,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-aa7d95a7-a1c0-4944-86db-98b8a1b612c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-829bff51-83be-4ae9-ac3b-03919fce8985,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-f4010127-4a80-4e82-8ee9-462cdd8e1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-7a178fcf-4d9b-4c34-8612-657c5eacdc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-2f7c12a1-c78e-4c91-8e5e-2545f2f37619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085844579-172.17.0.12-1597397705483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-b1a7401b-38a9-414e-a73f-61715235d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-3a718132-dfa4-460e-ae40-d26015036e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-52f3bc0d-1b45-4b1d-8c12-096e275a9116,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-aa7d95a7-a1c0-4944-86db-98b8a1b612c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-829bff51-83be-4ae9-ac3b-03919fce8985,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-f4010127-4a80-4e82-8ee9-462cdd8e1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-7a178fcf-4d9b-4c34-8612-657c5eacdc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-2f7c12a1-c78e-4c91-8e5e-2545f2f37619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703044580-172.17.0.12-1597398123108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-3fc781bb-a55e-4bcb-a363-04230f3888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-219d2367-6fee-46c2-8e0e-bd3eda975a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-a77b38b7-b987-419d-946c-4578b20b843d,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-805f7ffe-14b4-43ec-833b-2da1c8cf5019,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8ab0fefd-24f5-4407-9310-d4433c08edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-38274a02-bec6-4d4e-bcbe-d420215e5501,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-dc64efec-2409-4693-bc81-3dd486cded0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b5bc3a6f-ef0a-443d-a758-db495f7b277d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703044580-172.17.0.12-1597398123108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-3fc781bb-a55e-4bcb-a363-04230f3888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-219d2367-6fee-46c2-8e0e-bd3eda975a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-a77b38b7-b987-419d-946c-4578b20b843d,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-805f7ffe-14b4-43ec-833b-2da1c8cf5019,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8ab0fefd-24f5-4407-9310-d4433c08edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-38274a02-bec6-4d4e-bcbe-d420215e5501,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-dc64efec-2409-4693-bc81-3dd486cded0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b5bc3a6f-ef0a-443d-a758-db495f7b277d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6774
