reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053184243-172.17.0.16-1597708619288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-0926ddc6-53de-4496-840d-78226ea76416,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-0a8b0eac-dc55-4c8e-b606-eb2ef4de80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-f7fa866a-4515-45e0-988a-8c6748b086b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-4996b172-4b30-412e-afd2-fe75d2fecce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-04accefb-e381-41db-b8f4-23c1f6bf11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-9b05e1a2-b6f8-48ad-ac1b-74f08b9815e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-e4659c75-5301-4437-9ed3-36eb8a2698b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-124b7d6e-0186-4091-8d29-922abf0cf630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053184243-172.17.0.16-1597708619288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-0926ddc6-53de-4496-840d-78226ea76416,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-0a8b0eac-dc55-4c8e-b606-eb2ef4de80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-f7fa866a-4515-45e0-988a-8c6748b086b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-4996b172-4b30-412e-afd2-fe75d2fecce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-04accefb-e381-41db-b8f4-23c1f6bf11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-9b05e1a2-b6f8-48ad-ac1b-74f08b9815e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-e4659c75-5301-4437-9ed3-36eb8a2698b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-124b7d6e-0186-4091-8d29-922abf0cf630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148352666-172.17.0.16-1597708981129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45112,DS-2b3a01eb-1a0b-4b70-aa15-7f063751bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-f81034a7-f27e-4b29-8113-3da6efda7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-4fbb11f0-6d7b-44f0-bdd6-c2249d8d2237,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-fb0679d0-3822-4a48-83e1-c1316c9ad510,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-e55509fe-0967-4866-b629-153bfdf64ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-bb03ddba-3019-4bbc-8f9d-7c825a709e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-d6ba4718-85cf-411d-9d01-21d654386b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-4623cec0-78ec-4c92-97c4-4310fce7901b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148352666-172.17.0.16-1597708981129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45112,DS-2b3a01eb-1a0b-4b70-aa15-7f063751bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-f81034a7-f27e-4b29-8113-3da6efda7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-4fbb11f0-6d7b-44f0-bdd6-c2249d8d2237,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-fb0679d0-3822-4a48-83e1-c1316c9ad510,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-e55509fe-0967-4866-b629-153bfdf64ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-bb03ddba-3019-4bbc-8f9d-7c825a709e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-d6ba4718-85cf-411d-9d01-21d654386b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-4623cec0-78ec-4c92-97c4-4310fce7901b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490351317-172.17.0.16-1597709242597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-158a2ddc-df92-4d92-8261-1ffdf3efbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-a0c9f407-0d76-4142-92da-ac35fb6c6802,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-eebcfca6-3a76-4d07-96ec-281d8c727f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-fa9eb841-efad-4284-bb78-ec8c55d823dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-ee58ba97-3928-4b88-8558-f5780e02af94,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-acd5f5dd-353a-4870-9a49-ca252cb47609,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-d1014f5a-2914-4399-9d13-f1c2fc8c56e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-59875666-0995-42aa-8a3a-b371cc83f840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490351317-172.17.0.16-1597709242597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-158a2ddc-df92-4d92-8261-1ffdf3efbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-a0c9f407-0d76-4142-92da-ac35fb6c6802,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-eebcfca6-3a76-4d07-96ec-281d8c727f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-fa9eb841-efad-4284-bb78-ec8c55d823dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-ee58ba97-3928-4b88-8558-f5780e02af94,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-acd5f5dd-353a-4870-9a49-ca252cb47609,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-d1014f5a-2914-4399-9d13-f1c2fc8c56e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-59875666-0995-42aa-8a3a-b371cc83f840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859701707-172.17.0.16-1597709354765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-9661fd3b-0a08-4efc-a95e-c717930cb1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-e630a665-2524-473f-87e9-0a7ca28d7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-09a6a26b-09cc-4692-bc24-fe66869195d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-ca61fe53-fe48-407b-901d-fdd36b1f846d,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a2ba6bf6-ca2c-4518-a93f-e0fab01995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-22630cfe-fa08-461f-a96f-e7f32eacfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-b40c7b45-5240-4966-8697-f7d8f8f58214,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-4f5940fd-53fe-41f7-8f65-7dbabbc39bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859701707-172.17.0.16-1597709354765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-9661fd3b-0a08-4efc-a95e-c717930cb1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-e630a665-2524-473f-87e9-0a7ca28d7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-09a6a26b-09cc-4692-bc24-fe66869195d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-ca61fe53-fe48-407b-901d-fdd36b1f846d,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a2ba6bf6-ca2c-4518-a93f-e0fab01995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-22630cfe-fa08-461f-a96f-e7f32eacfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-b40c7b45-5240-4966-8697-f7d8f8f58214,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-4f5940fd-53fe-41f7-8f65-7dbabbc39bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434958926-172.17.0.16-1597710248495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-fccc44fb-ec2b-4f16-9de2-e060efd947f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-690488eb-dc67-4630-aafa-e2e2e3c84760,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-3f735a24-d4eb-47bc-b503-1510ab87d611,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-59571751-da19-4741-9c62-a2a8c4efe172,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-ef66b009-be4f-414e-8ce4-24559a27742b,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-690107c6-1cfd-44a0-bc9d-9b54361fae48,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-6a67dda5-8356-4ccc-bbee-1c6fe5c8cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e7b98c5b-264a-4160-8203-0a310f8f5836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434958926-172.17.0.16-1597710248495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-fccc44fb-ec2b-4f16-9de2-e060efd947f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-690488eb-dc67-4630-aafa-e2e2e3c84760,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-3f735a24-d4eb-47bc-b503-1510ab87d611,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-59571751-da19-4741-9c62-a2a8c4efe172,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-ef66b009-be4f-414e-8ce4-24559a27742b,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-690107c6-1cfd-44a0-bc9d-9b54361fae48,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-6a67dda5-8356-4ccc-bbee-1c6fe5c8cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e7b98c5b-264a-4160-8203-0a310f8f5836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878624450-172.17.0.16-1597710356230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-3a67c71f-0327-48c3-83c5-2eb2ad51e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-7fff63ed-ea94-4237-b2e7-c047e33f8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-29bea7c0-11f4-4350-b447-b295ac180a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-3cb3c268-a224-4bf4-b132-f7a7afd92fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-1843a4d3-bccb-492c-81d9-f299dbbe51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-49ccd61c-0a7f-41e1-9da9-dfe682a29a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-001caeb1-5fbf-40fe-9030-a80903c7f988,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-5aebd4e2-4cd5-48d2-acf6-fcd691c3ad34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878624450-172.17.0.16-1597710356230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-3a67c71f-0327-48c3-83c5-2eb2ad51e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-7fff63ed-ea94-4237-b2e7-c047e33f8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-29bea7c0-11f4-4350-b447-b295ac180a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-3cb3c268-a224-4bf4-b132-f7a7afd92fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-1843a4d3-bccb-492c-81d9-f299dbbe51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-49ccd61c-0a7f-41e1-9da9-dfe682a29a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-001caeb1-5fbf-40fe-9030-a80903c7f988,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-5aebd4e2-4cd5-48d2-acf6-fcd691c3ad34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490963270-172.17.0.16-1597710601823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-9eb11a77-555e-4dba-91c4-04cf6c78c195,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-66284f68-2b1b-43a6-96e4-dea8bb856b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-4cdbc036-967a-48a9-84fe-ae6a8d8e0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-9ad0154e-fbfa-4c17-acec-c088285b451e,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-c6980b90-6dff-4608-b8da-37c75486f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-634cd63f-2b2c-4cae-a2c1-4e9cb76a4541,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-561c7977-af24-422d-b15f-9f34303e2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9a616c5f-2b72-4502-8dda-5a40d5e472be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490963270-172.17.0.16-1597710601823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-9eb11a77-555e-4dba-91c4-04cf6c78c195,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-66284f68-2b1b-43a6-96e4-dea8bb856b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-4cdbc036-967a-48a9-84fe-ae6a8d8e0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-9ad0154e-fbfa-4c17-acec-c088285b451e,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-c6980b90-6dff-4608-b8da-37c75486f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-634cd63f-2b2c-4cae-a2c1-4e9cb76a4541,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-561c7977-af24-422d-b15f-9f34303e2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9a616c5f-2b72-4502-8dda-5a40d5e472be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236403813-172.17.0.16-1597710638972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-02ecf976-6717-4989-a134-e666574420c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-884e5690-cd48-458e-8b22-817823a9240f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-43aafd21-a4fb-4c46-84b4-1a028f7228ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-0873a31f-2dec-4131-b7df-ec41f7394102,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7bb3cf1f-cf0e-494a-b6bc-5f5bbf5546cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-101a4353-e945-49ee-b054-74667c20c008,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-9505681d-5dae-4abc-bdfb-b1733368f557,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-f5f12b7d-1bdb-4a1e-bc04-8fcc52653583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236403813-172.17.0.16-1597710638972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-02ecf976-6717-4989-a134-e666574420c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-884e5690-cd48-458e-8b22-817823a9240f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-43aafd21-a4fb-4c46-84b4-1a028f7228ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-0873a31f-2dec-4131-b7df-ec41f7394102,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-7bb3cf1f-cf0e-494a-b6bc-5f5bbf5546cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-101a4353-e945-49ee-b054-74667c20c008,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-9505681d-5dae-4abc-bdfb-b1733368f557,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-f5f12b7d-1bdb-4a1e-bc04-8fcc52653583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180110469-172.17.0.16-1597710930467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-d9af4c86-c57c-4d1b-b05c-c50917a59243,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-4edc6182-4bc3-4594-9a75-f303504b4f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-9437aea3-c22a-4401-8fa6-61f8a42e1055,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-4a275658-25ef-48e3-91d1-981321c7b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-a1e10874-5977-4cdf-b17f-85fec25e0438,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2cfb4f8b-bc23-4e8c-b531-1a561520d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-aa2c2707-7eed-456c-8ba6-10739b607d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-dc444d7e-78b7-407a-8e02-9a489372e7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180110469-172.17.0.16-1597710930467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-d9af4c86-c57c-4d1b-b05c-c50917a59243,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-4edc6182-4bc3-4594-9a75-f303504b4f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-9437aea3-c22a-4401-8fa6-61f8a42e1055,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-4a275658-25ef-48e3-91d1-981321c7b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-a1e10874-5977-4cdf-b17f-85fec25e0438,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2cfb4f8b-bc23-4e8c-b531-1a561520d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-aa2c2707-7eed-456c-8ba6-10739b607d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-dc444d7e-78b7-407a-8e02-9a489372e7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295272824-172.17.0.16-1597711313948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-a8c425a8-2aed-4191-a248-9b8f875060c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-2d704ab3-96d1-48f3-84a3-b039674216a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-f8b76a1a-9f68-4450-a6b0-8f768b31af47,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0cdfc874-aede-4a1c-b694-00440644000a,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-4eb73eed-1275-4338-b0f2-462d4fdc6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-eb67f4a3-0671-4bb1-90f9-7a0c457ebfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-9cb06674-53fa-455d-9c8b-42bbeac30220,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-09dcb05e-63e3-4ef1-8eaf-740767f1e13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295272824-172.17.0.16-1597711313948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-a8c425a8-2aed-4191-a248-9b8f875060c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-2d704ab3-96d1-48f3-84a3-b039674216a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-f8b76a1a-9f68-4450-a6b0-8f768b31af47,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0cdfc874-aede-4a1c-b694-00440644000a,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-4eb73eed-1275-4338-b0f2-462d4fdc6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-eb67f4a3-0671-4bb1-90f9-7a0c457ebfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-9cb06674-53fa-455d-9c8b-42bbeac30220,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-09dcb05e-63e3-4ef1-8eaf-740767f1e13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750235484-172.17.0.16-1597711391940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-fe64bd08-c663-41bc-8f15-804238c5774a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-e7f04ce5-220d-4220-be78-4e65081e54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-77fcb1c5-f612-4315-ada2-084952929469,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-f6e9925f-37a8-4c03-a97b-ea017c2aaefe,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-c34dd827-4bed-4a4c-a879-fe423d1f8153,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-3ccdaefa-bbe3-4f05-9119-d9269c4dd552,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-c641bc1f-c85c-45a1-9500-3759f29073be,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-46529761-7282-449b-aa22-fae17e3e4ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750235484-172.17.0.16-1597711391940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-fe64bd08-c663-41bc-8f15-804238c5774a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-e7f04ce5-220d-4220-be78-4e65081e54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-77fcb1c5-f612-4315-ada2-084952929469,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-f6e9925f-37a8-4c03-a97b-ea017c2aaefe,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-c34dd827-4bed-4a4c-a879-fe423d1f8153,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-3ccdaefa-bbe3-4f05-9119-d9269c4dd552,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-c641bc1f-c85c-45a1-9500-3759f29073be,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-46529761-7282-449b-aa22-fae17e3e4ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60702916-172.17.0.16-1597711497726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-59588176-6ffc-44ef-864e-3868b7903d73,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-056f2ce4-4923-4809-ac31-1ee7cf8d5538,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-f9124129-e304-4af1-84ae-47df19b06865,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-00557150-af51-43f5-a71b-b3b915db8728,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-0f99f707-3132-49ce-b289-77f07c335f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-f866a1bd-2653-43b1-aeb4-b95e988a5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-63ee2a2c-98a0-4634-b020-11dc2dedfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a59d7358-703c-4596-a586-a1053fd667f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60702916-172.17.0.16-1597711497726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-59588176-6ffc-44ef-864e-3868b7903d73,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-056f2ce4-4923-4809-ac31-1ee7cf8d5538,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-f9124129-e304-4af1-84ae-47df19b06865,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-00557150-af51-43f5-a71b-b3b915db8728,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-0f99f707-3132-49ce-b289-77f07c335f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-f866a1bd-2653-43b1-aeb4-b95e988a5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-63ee2a2c-98a0-4634-b020-11dc2dedfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a59d7358-703c-4596-a586-a1053fd667f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060015484-172.17.0.16-1597711678854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-75137007-a30c-4c84-8fdc-55642fd5602a,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-04e3bb3f-1856-42ed-9304-6c73dc252027,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-749bfa66-3f79-487b-b7f2-0aa8e91f5083,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-16a1806c-ca3f-4750-abba-9dc3e2cb5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-66d0663f-25cc-4018-aefc-46b68eed1951,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-d7585c7e-eec8-433b-b0e0-609f7d09c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-bc6a9a29-cf66-441e-bad6-32bfb9e5a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-a93dfd00-c213-421d-ba68-858869e89570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060015484-172.17.0.16-1597711678854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-75137007-a30c-4c84-8fdc-55642fd5602a,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-04e3bb3f-1856-42ed-9304-6c73dc252027,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-749bfa66-3f79-487b-b7f2-0aa8e91f5083,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-16a1806c-ca3f-4750-abba-9dc3e2cb5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-66d0663f-25cc-4018-aefc-46b68eed1951,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-d7585c7e-eec8-433b-b0e0-609f7d09c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-bc6a9a29-cf66-441e-bad6-32bfb9e5a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-a93dfd00-c213-421d-ba68-858869e89570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134484113-172.17.0.16-1597711919462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-e9cbd881-e13e-4e06-a6ad-1d8e4d9ba5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-b276203e-6767-4e85-ac64-cd347c327b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1b7027c5-b9bd-4779-ad28-2c596dc711ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-b1317d1d-ac40-4b14-b750-44ae55b8e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-5b6c9623-ad8f-4dcf-9965-88fed83c9f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-6b8c8d5b-d21a-4e2d-a490-8d241cd00d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-8cb389bf-ef2e-431e-a9d3-575d6c68b05a,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-b6f8b737-857c-4b30-a2e2-6d4b26aaf42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134484113-172.17.0.16-1597711919462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-e9cbd881-e13e-4e06-a6ad-1d8e4d9ba5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-b276203e-6767-4e85-ac64-cd347c327b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1b7027c5-b9bd-4779-ad28-2c596dc711ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-b1317d1d-ac40-4b14-b750-44ae55b8e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-5b6c9623-ad8f-4dcf-9965-88fed83c9f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-6b8c8d5b-d21a-4e2d-a490-8d241cd00d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-8cb389bf-ef2e-431e-a9d3-575d6c68b05a,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-b6f8b737-857c-4b30-a2e2-6d4b26aaf42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441908180-172.17.0.16-1597712570279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-547d91cb-a1e0-4991-832e-92384c0b3365,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e28194e5-56e2-414a-9504-060469e97144,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-b4d4c881-2e1a-4b60-b9b0-a32e73654d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5fd76310-b161-4fd9-8a24-745de57e60e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-772baec1-f5a4-4415-b012-b6807b2ec4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f3a4cb95-d1ad-4b63-ad79-abeeb243e676,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-07b83411-c192-45ba-938c-3b68a6444262,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-56154932-e132-4dda-acef-a7a8d69499c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441908180-172.17.0.16-1597712570279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-547d91cb-a1e0-4991-832e-92384c0b3365,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e28194e5-56e2-414a-9504-060469e97144,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-b4d4c881-2e1a-4b60-b9b0-a32e73654d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5fd76310-b161-4fd9-8a24-745de57e60e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-772baec1-f5a4-4415-b012-b6807b2ec4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f3a4cb95-d1ad-4b63-ad79-abeeb243e676,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-07b83411-c192-45ba-938c-3b68a6444262,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-56154932-e132-4dda-acef-a7a8d69499c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194122347-172.17.0.16-1597712648992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-f067f6ce-0028-429d-9089-3d698e9ffa17,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-29725db0-44c9-4eb0-b613-f93ce5e45642,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-3d0cde01-3c66-44b1-a569-3e11c074560c,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-a70038f5-682b-4a64-a9ee-929bbd2b5276,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-463de887-70c3-45fb-8e35-f1ad1646dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-d7a81b18-7b73-4d9b-b7cf-25785d0df5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-94ffb91e-8687-4496-b341-36b4a91fc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-6b7702fa-5afd-42b5-9414-af42e9b6dbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194122347-172.17.0.16-1597712648992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-f067f6ce-0028-429d-9089-3d698e9ffa17,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-29725db0-44c9-4eb0-b613-f93ce5e45642,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-3d0cde01-3c66-44b1-a569-3e11c074560c,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-a70038f5-682b-4a64-a9ee-929bbd2b5276,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-463de887-70c3-45fb-8e35-f1ad1646dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-d7a81b18-7b73-4d9b-b7cf-25785d0df5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-94ffb91e-8687-4496-b341-36b4a91fc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-6b7702fa-5afd-42b5-9414-af42e9b6dbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981959161-172.17.0.16-1597712724862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-a0aa814c-0f6a-41a5-bc36-4c72c2f044b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-f62ff574-1ea2-4185-a9ce-421c0afb94e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-c6b003d4-6635-45e9-9faf-8451e844b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-8fb8d62c-a323-42ea-bd7e-1c1760356b49,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-402b60cc-ecfd-4f42-8e72-a694c6836faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c8bfa905-29f7-43d0-926c-663fa0da9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-11879308-0114-442f-ba55-06c5289770d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-5af33db5-5741-4028-8ce9-d50180ea3d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981959161-172.17.0.16-1597712724862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-a0aa814c-0f6a-41a5-bc36-4c72c2f044b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-f62ff574-1ea2-4185-a9ce-421c0afb94e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-c6b003d4-6635-45e9-9faf-8451e844b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-8fb8d62c-a323-42ea-bd7e-1c1760356b49,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-402b60cc-ecfd-4f42-8e72-a694c6836faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c8bfa905-29f7-43d0-926c-663fa0da9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-11879308-0114-442f-ba55-06c5289770d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-5af33db5-5741-4028-8ce9-d50180ea3d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620587844-172.17.0.16-1597713469860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-8da74533-30ae-464d-9470-8fbacd00f834,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-7d011937-ae39-4c0c-91e8-58bfc16ecd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-ec20ce94-e96f-498e-afbb-1595010db4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-f2f5e0c7-b679-478a-91d7-5f00b9d0ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-7968295e-aa2d-4ffb-b6b0-5871a8af3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9f24acc2-0f4b-47c8-9e58-39344e61149f,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-6383f530-8003-4f19-b7f4-93a443fff1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-1019f4d1-e443-41d2-b024-884fa5ed974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620587844-172.17.0.16-1597713469860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-8da74533-30ae-464d-9470-8fbacd00f834,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-7d011937-ae39-4c0c-91e8-58bfc16ecd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-ec20ce94-e96f-498e-afbb-1595010db4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-f2f5e0c7-b679-478a-91d7-5f00b9d0ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-7968295e-aa2d-4ffb-b6b0-5871a8af3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9f24acc2-0f4b-47c8-9e58-39344e61149f,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-6383f530-8003-4f19-b7f4-93a443fff1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-1019f4d1-e443-41d2-b024-884fa5ed974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5369
