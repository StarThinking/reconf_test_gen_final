reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013851293-172.17.0.16-1597759426783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-a129f868-540d-4348-8217-3b07b505963f,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8f50eb96-7e0b-40d9-b31d-2219ccdec95f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-8b845551-bc22-4149-9ba4-e20753b23308,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-ce2479e8-c8a1-4532-8eb1-d14fa1a951fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-fe4af350-cd5f-424f-825d-b1040353287c,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-1182122a-cd1f-487f-bf54-d207167bd762,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c6597c62-8db0-4193-801c-a39ffdb54811,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-415f6932-c281-465b-9883-746001cbdedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013851293-172.17.0.16-1597759426783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-a129f868-540d-4348-8217-3b07b505963f,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8f50eb96-7e0b-40d9-b31d-2219ccdec95f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-8b845551-bc22-4149-9ba4-e20753b23308,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-ce2479e8-c8a1-4532-8eb1-d14fa1a951fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-fe4af350-cd5f-424f-825d-b1040353287c,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-1182122a-cd1f-487f-bf54-d207167bd762,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c6597c62-8db0-4193-801c-a39ffdb54811,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-415f6932-c281-465b-9883-746001cbdedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448346957-172.17.0.16-1597759657093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-4bc3c658-9201-4336-bd2d-c62af0f10877,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-3e6f694f-4f1c-4a79-8671-3370b1620aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-3c767d2b-efd5-4f35-8f20-3624e8b9e300,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-29d43570-d0fa-4888-9c48-146909b09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-e0990fe3-e7ac-46eb-b0da-9b70f0d50026,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-c39ad07e-71dd-460e-9205-aff2bd52d387,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-b16c5031-e900-4129-a9c6-142db807cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-1054600e-5db2-4bf9-9b2f-21bb0c422885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448346957-172.17.0.16-1597759657093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44018,DS-4bc3c658-9201-4336-bd2d-c62af0f10877,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-3e6f694f-4f1c-4a79-8671-3370b1620aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-3c767d2b-efd5-4f35-8f20-3624e8b9e300,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-29d43570-d0fa-4888-9c48-146909b09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-e0990fe3-e7ac-46eb-b0da-9b70f0d50026,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-c39ad07e-71dd-460e-9205-aff2bd52d387,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-b16c5031-e900-4129-a9c6-142db807cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-1054600e-5db2-4bf9-9b2f-21bb0c422885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003614252-172.17.0.16-1597759795658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-9ae528fb-1db1-4d14-ada5-8a009efad82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8176ea96-5185-4882-9de4-994e98ddc7db,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-921a128b-39e8-4dbe-a9e6-3132652d0360,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-395f990b-0b35-484b-a02a-125af0420cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-7e469513-24e5-48ec-bb54-e3889c66df12,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-f3588c84-c396-46a3-8343-48242a8eba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-496ba21a-898e-4f60-acb3-9665704f829c,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-0e9fefce-ea90-4c75-8ba3-a6e5f6eaf2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003614252-172.17.0.16-1597759795658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-9ae528fb-1db1-4d14-ada5-8a009efad82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8176ea96-5185-4882-9de4-994e98ddc7db,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-921a128b-39e8-4dbe-a9e6-3132652d0360,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-395f990b-0b35-484b-a02a-125af0420cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-7e469513-24e5-48ec-bb54-e3889c66df12,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-f3588c84-c396-46a3-8343-48242a8eba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-496ba21a-898e-4f60-acb3-9665704f829c,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-0e9fefce-ea90-4c75-8ba3-a6e5f6eaf2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651571818-172.17.0.16-1597759950376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-25bd8acb-70d8-49c8-af30-847fe2d03e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-29aa7b25-9efb-4816-989a-56539ad95d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-7ef04e03-1e8f-40e9-acb1-988205e46d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-03dd837d-a652-40ed-90e9-aa0593aab34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-aa4d91a6-0106-4343-adee-540d4a4236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-895b974f-aa36-4420-9f8a-6754c04b0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-d644afa4-03c7-4ca0-adfb-ecf7d3eb11d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-a7f8b6de-0117-415f-8787-966704d4f945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651571818-172.17.0.16-1597759950376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-25bd8acb-70d8-49c8-af30-847fe2d03e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-29aa7b25-9efb-4816-989a-56539ad95d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-7ef04e03-1e8f-40e9-acb1-988205e46d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-03dd837d-a652-40ed-90e9-aa0593aab34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-aa4d91a6-0106-4343-adee-540d4a4236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-895b974f-aa36-4420-9f8a-6754c04b0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-d644afa4-03c7-4ca0-adfb-ecf7d3eb11d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-a7f8b6de-0117-415f-8787-966704d4f945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602000647-172.17.0.16-1597760271422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-8881254d-f1dc-4eb0-9d67-cfbbd89f240a,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c2dd795c-080d-407a-b0a0-3a627ce1359e,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-732c8e81-0206-4bc2-ad5f-922130e77142,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-e400abea-0707-4b02-8249-bd71f86e434f,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2553dabd-403f-44ee-a1a4-ddc2c6a99ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c9f578f3-6cc3-4f00-9205-9006e3cc14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5ead7ad5-ec28-4f9e-aef3-f39cfb0d698f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-b5d120a6-1bf2-4b9c-9178-12774d651410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602000647-172.17.0.16-1597760271422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-8881254d-f1dc-4eb0-9d67-cfbbd89f240a,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c2dd795c-080d-407a-b0a0-3a627ce1359e,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-732c8e81-0206-4bc2-ad5f-922130e77142,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-e400abea-0707-4b02-8249-bd71f86e434f,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2553dabd-403f-44ee-a1a4-ddc2c6a99ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c9f578f3-6cc3-4f00-9205-9006e3cc14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5ead7ad5-ec28-4f9e-aef3-f39cfb0d698f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-b5d120a6-1bf2-4b9c-9178-12774d651410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433409198-172.17.0.16-1597760826998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37735,DS-f0945924-39a8-434e-8f62-8494a508f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-59783aaf-7eec-4032-a3d1-9995b9ea174e,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-386fb1bb-bc8e-4f9f-963c-58eda7b459d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-938d6016-4800-4a4c-b6f2-afea508f43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-6d0a06b7-f091-4f22-a56e-ac8fceecde39,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-680ed7d8-7100-4222-b2e9-f2c1af60114a,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3df5d32a-7a62-482b-94a5-5ba756a5aa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-30b0151a-5f62-439a-8ae9-cf353835668f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433409198-172.17.0.16-1597760826998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37735,DS-f0945924-39a8-434e-8f62-8494a508f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-59783aaf-7eec-4032-a3d1-9995b9ea174e,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-386fb1bb-bc8e-4f9f-963c-58eda7b459d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-938d6016-4800-4a4c-b6f2-afea508f43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-6d0a06b7-f091-4f22-a56e-ac8fceecde39,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-680ed7d8-7100-4222-b2e9-f2c1af60114a,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3df5d32a-7a62-482b-94a5-5ba756a5aa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-30b0151a-5f62-439a-8ae9-cf353835668f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516837625-172.17.0.16-1597760865171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-f0b9d5ba-a84a-4184-8d7c-cf5cbfa0c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-bbce02fd-4d35-4b70-a55d-8971ccc94828,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5082f064-3933-4685-ae75-17f97d4f1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c252efd8-b895-4869-918d-823eae0554e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-701b91d8-0645-437d-9f1e-222ff9809343,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-576b8db1-1506-48a4-a159-8a1e201eb6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-fd122ae2-9361-44c7-8102-80f1a2efe3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-68f04a55-cc9f-4bc8-979f-a2a795e2e7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516837625-172.17.0.16-1597760865171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-f0b9d5ba-a84a-4184-8d7c-cf5cbfa0c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-bbce02fd-4d35-4b70-a55d-8971ccc94828,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5082f064-3933-4685-ae75-17f97d4f1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c252efd8-b895-4869-918d-823eae0554e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-701b91d8-0645-437d-9f1e-222ff9809343,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-576b8db1-1506-48a4-a159-8a1e201eb6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-fd122ae2-9361-44c7-8102-80f1a2efe3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-68f04a55-cc9f-4bc8-979f-a2a795e2e7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197911863-172.17.0.16-1597760908321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-54008093-e534-4ab1-8d05-bd4ddda82726,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-7ecae933-3202-4b07-b702-48ce81bd9012,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-1c4fff1b-20da-4486-bfb2-22b6ac35771c,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f0afafb8-4ca2-48f3-ab88-80cd0fc317e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-1bd8c514-7ac5-4081-8018-156e939adbec,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-818b2f80-66c6-4ee2-9c1c-39eea4297066,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-8112c505-7e8f-4bcd-8e5e-aa60460e624b,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-d6e9b0a8-e456-445c-9508-661f9e5cc7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197911863-172.17.0.16-1597760908321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-54008093-e534-4ab1-8d05-bd4ddda82726,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-7ecae933-3202-4b07-b702-48ce81bd9012,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-1c4fff1b-20da-4486-bfb2-22b6ac35771c,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-f0afafb8-4ca2-48f3-ab88-80cd0fc317e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-1bd8c514-7ac5-4081-8018-156e939adbec,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-818b2f80-66c6-4ee2-9c1c-39eea4297066,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-8112c505-7e8f-4bcd-8e5e-aa60460e624b,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-d6e9b0a8-e456-445c-9508-661f9e5cc7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870536983-172.17.0.16-1597761171191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-67b02122-8412-4180-a7b4-36d95a845b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-ab6600df-ca97-4314-a606-41993e5689e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-7645be70-dc6f-4fed-83b3-6a0e001f6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-ce7e1fc3-bd0e-40df-9a1c-565990db3091,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-0d6721f4-f356-4ed9-bc02-66bb731adcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-f5985531-5396-4e8d-9735-dbf43e9981ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-0f22b446-08c1-4006-8bd5-22d0938c3006,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4ac475b1-5a65-4ccb-a269-827ad78cf47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870536983-172.17.0.16-1597761171191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-67b02122-8412-4180-a7b4-36d95a845b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-ab6600df-ca97-4314-a606-41993e5689e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-7645be70-dc6f-4fed-83b3-6a0e001f6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-ce7e1fc3-bd0e-40df-9a1c-565990db3091,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-0d6721f4-f356-4ed9-bc02-66bb731adcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-f5985531-5396-4e8d-9735-dbf43e9981ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-0f22b446-08c1-4006-8bd5-22d0938c3006,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4ac475b1-5a65-4ccb-a269-827ad78cf47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458349274-172.17.0.16-1597761645284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-efd3949f-7ac0-45b9-9a41-494e1dbc44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-cf178dd6-71ab-498e-8942-681cc02d4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-675e03a9-54be-45b1-8fb2-ad1ce447044a,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-6881bee5-2e9a-4306-bd40-f8a642461ced,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-34d0575c-4235-4142-b468-1777cda2d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-48c34bec-2530-478f-8d5a-7bce813a48de,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-060b8d13-c5de-479c-9060-496d15189203,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-bcc8f094-ae8f-4f6a-ac7d-3a909cdcd8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458349274-172.17.0.16-1597761645284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-efd3949f-7ac0-45b9-9a41-494e1dbc44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-cf178dd6-71ab-498e-8942-681cc02d4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-675e03a9-54be-45b1-8fb2-ad1ce447044a,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-6881bee5-2e9a-4306-bd40-f8a642461ced,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-34d0575c-4235-4142-b468-1777cda2d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-48c34bec-2530-478f-8d5a-7bce813a48de,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-060b8d13-c5de-479c-9060-496d15189203,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-bcc8f094-ae8f-4f6a-ac7d-3a909cdcd8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793916587-172.17.0.16-1597761740058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-5782c0d6-a456-42b2-a16b-067e9630d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-c6b627d3-8571-436f-b576-c04bb43cedb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-e3bb20f4-3ee6-41c8-8121-05df699b6df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-c61c507f-7668-4d2f-a872-d173375ce2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a6c57a1d-f676-4b96-9295-a72e1fc3a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-d635abfc-48ea-437a-9c72-fd4f669816df,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-18f484a1-7ad7-4ecb-8c64-02ea172e9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-28fbf133-8b17-43e5-9596-4f3ea9d3ebfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793916587-172.17.0.16-1597761740058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-5782c0d6-a456-42b2-a16b-067e9630d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-c6b627d3-8571-436f-b576-c04bb43cedb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-e3bb20f4-3ee6-41c8-8121-05df699b6df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-c61c507f-7668-4d2f-a872-d173375ce2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a6c57a1d-f676-4b96-9295-a72e1fc3a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-d635abfc-48ea-437a-9c72-fd4f669816df,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-18f484a1-7ad7-4ecb-8c64-02ea172e9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-28fbf133-8b17-43e5-9596-4f3ea9d3ebfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124327779-172.17.0.16-1597761835279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-ccabf682-e073-4bb2-9456-51e11435188d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8fc3df19-bca2-49fb-a921-fdb274759384,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b535056c-5928-4be3-9136-2ab553456e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-fef9bebe-ecfa-482d-828f-ed2a2a7b2f91,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-9049330d-428b-45f8-a258-d96092f6f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-b15615e5-3710-48ab-b419-527edcda11a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-1c30941c-b5ae-44f5-a4cd-b16feae915b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d4d996ba-41b4-4f4a-a488-f2e3d4eb242e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124327779-172.17.0.16-1597761835279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-ccabf682-e073-4bb2-9456-51e11435188d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-8fc3df19-bca2-49fb-a921-fdb274759384,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b535056c-5928-4be3-9136-2ab553456e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-fef9bebe-ecfa-482d-828f-ed2a2a7b2f91,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-9049330d-428b-45f8-a258-d96092f6f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-b15615e5-3710-48ab-b419-527edcda11a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-1c30941c-b5ae-44f5-a4cd-b16feae915b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d4d996ba-41b4-4f4a-a488-f2e3d4eb242e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135246538-172.17.0.16-1597761867124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-d9c5e444-e6e5-46fc-8fd5-bc80448767ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-c6ef9b21-9987-465b-bae0-ecdd3278a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-79e641a8-69e1-4e05-a3a8-56459bb57369,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-e839bbc7-76d3-497a-a57e-45d89c1c6e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-a232fbb3-4aaf-4bf6-abd3-773fdb3adebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-38137343-78c5-4f06-957f-9e6e92256b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-014ab619-60df-409d-8566-b085f783b949,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-911ebb06-af71-4310-9260-f271c4e5940f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135246538-172.17.0.16-1597761867124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-d9c5e444-e6e5-46fc-8fd5-bc80448767ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-c6ef9b21-9987-465b-bae0-ecdd3278a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-79e641a8-69e1-4e05-a3a8-56459bb57369,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-e839bbc7-76d3-497a-a57e-45d89c1c6e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-a232fbb3-4aaf-4bf6-abd3-773fdb3adebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-38137343-78c5-4f06-957f-9e6e92256b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-014ab619-60df-409d-8566-b085f783b949,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-911ebb06-af71-4310-9260-f271c4e5940f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722511002-172.17.0.16-1597761883124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-1b29eb94-db64-4ee5-aa46-117ae8065868,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-fa295971-44e0-45d8-8e7f-a3b1adba07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-6e3a6417-3c8b-41b1-b40d-c55da0a1ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-7746dc58-f65e-418e-b865-bac028aec0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-3515fbaf-64fa-434a-bab1-489e912df46b,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3cabff90-a975-4d7f-89b7-136040a4f598,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-e1067335-cbaa-454a-8857-9e3099c30180,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-d372a29c-3330-421f-bbff-fc7d2e6896e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722511002-172.17.0.16-1597761883124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-1b29eb94-db64-4ee5-aa46-117ae8065868,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-fa295971-44e0-45d8-8e7f-a3b1adba07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-6e3a6417-3c8b-41b1-b40d-c55da0a1ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-7746dc58-f65e-418e-b865-bac028aec0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-3515fbaf-64fa-434a-bab1-489e912df46b,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3cabff90-a975-4d7f-89b7-136040a4f598,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-e1067335-cbaa-454a-8857-9e3099c30180,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-d372a29c-3330-421f-bbff-fc7d2e6896e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958107412-172.17.0.16-1597761978283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46428,DS-0d05573e-3625-4088-a1c0-414eeb0ea123,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-63d9077a-0093-4fc2-9372-3a865bff1756,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-660ddb6a-4ea0-4bd2-b685-b5354220adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-32caba20-f748-4583-9fc9-af61f76ddb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-3882e08a-f38f-49ed-9d05-4b0dd206b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-391f54f6-8406-4ce7-b05e-6e750054316e,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-fc6a28ac-9ecc-4633-aa36-5a8259154190,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-11a7df24-f181-4618-9a35-5d2c5ded1e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958107412-172.17.0.16-1597761978283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46428,DS-0d05573e-3625-4088-a1c0-414eeb0ea123,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-63d9077a-0093-4fc2-9372-3a865bff1756,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-660ddb6a-4ea0-4bd2-b685-b5354220adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-32caba20-f748-4583-9fc9-af61f76ddb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-3882e08a-f38f-49ed-9d05-4b0dd206b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-391f54f6-8406-4ce7-b05e-6e750054316e,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-fc6a28ac-9ecc-4633-aa36-5a8259154190,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-11a7df24-f181-4618-9a35-5d2c5ded1e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702841536-172.17.0.16-1597762041719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-7b183fde-53a6-47d0-8d57-31e17455be44,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-1a27cb59-6297-4fd8-872f-fa5692795cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-4fad179c-e52a-415e-a577-4abee056351e,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6ab1e537-de91-452a-9c47-4763c11af39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-cc039e5c-7256-4618-85f8-f2abe70eb4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-92ad1aee-d5fd-4b0d-ac78-aad48187c233,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-4ad7209e-5522-45bd-b41d-e6ec4c7697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-390e4dda-c0f4-4ee5-9f99-c0b0f4f4a219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702841536-172.17.0.16-1597762041719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-7b183fde-53a6-47d0-8d57-31e17455be44,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-1a27cb59-6297-4fd8-872f-fa5692795cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-4fad179c-e52a-415e-a577-4abee056351e,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6ab1e537-de91-452a-9c47-4763c11af39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-cc039e5c-7256-4618-85f8-f2abe70eb4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-92ad1aee-d5fd-4b0d-ac78-aad48187c233,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-4ad7209e-5522-45bd-b41d-e6ec4c7697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-390e4dda-c0f4-4ee5-9f99-c0b0f4f4a219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151134703-172.17.0.16-1597762247412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-55f83302-0b9b-4212-8a77-623796fa1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-a80b2bf7-1083-493c-864a-e2d15a528c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d97141b5-b191-4e4d-a599-5ec88ef77a27,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-2d6045db-f768-4b2a-adfa-469b90a1ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9fb689b1-6667-4ea3-a9a8-4426fe937387,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-aed71ed0-d445-4ba9-98ce-d936b44798a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c005db8e-0ac6-4d29-a09a-85dce2dbc61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-340147e9-8d98-4f36-bc68-97eab75118c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151134703-172.17.0.16-1597762247412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-55f83302-0b9b-4212-8a77-623796fa1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-a80b2bf7-1083-493c-864a-e2d15a528c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d97141b5-b191-4e4d-a599-5ec88ef77a27,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-2d6045db-f768-4b2a-adfa-469b90a1ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9fb689b1-6667-4ea3-a9a8-4426fe937387,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-aed71ed0-d445-4ba9-98ce-d936b44798a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c005db8e-0ac6-4d29-a09a-85dce2dbc61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-340147e9-8d98-4f36-bc68-97eab75118c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126695956-172.17.0.16-1597762358989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-c7e92df0-cd26-493c-9639-3b290243a4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-ab17e71b-e012-402f-b266-a0ebbb68913f,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-e3f685ac-c18c-42e4-a323-2caacb9c9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-a9514901-6a39-4fae-bbcf-18e2b381ddba,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e0146b4d-13a2-4536-a6cf-faa4ad155e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-3be2a601-c0ee-4db6-ac60-1e4a9c8496a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-c86fb7e6-ec4b-4c7f-a4bc-d52979422690,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-fbc534a9-f63e-4783-81bd-a9ebdce41c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126695956-172.17.0.16-1597762358989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-c7e92df0-cd26-493c-9639-3b290243a4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-ab17e71b-e012-402f-b266-a0ebbb68913f,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-e3f685ac-c18c-42e4-a323-2caacb9c9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-a9514901-6a39-4fae-bbcf-18e2b381ddba,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e0146b4d-13a2-4536-a6cf-faa4ad155e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-3be2a601-c0ee-4db6-ac60-1e4a9c8496a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-c86fb7e6-ec4b-4c7f-a4bc-d52979422690,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-fbc534a9-f63e-4783-81bd-a9ebdce41c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755908958-172.17.0.16-1597762581559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-e4cec38d-1706-46d3-b9e3-74c41f12d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-0e07f341-e707-4b8d-8180-5e7161b959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-3f17976d-755b-47b7-998b-483d1d33e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6a5e2e52-82ed-4f10-aff4-62cbbb0c8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-196bf75b-4ad3-4bd4-9ff4-825b8014ded1,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-ec88479c-973d-43b1-b45d-aea816bc0428,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-3bf31987-a7d5-4f05-8ee5-eb1998b48fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-aeed7591-9af4-4946-b0f6-9537ccdefdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755908958-172.17.0.16-1597762581559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-e4cec38d-1706-46d3-b9e3-74c41f12d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-0e07f341-e707-4b8d-8180-5e7161b959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-3f17976d-755b-47b7-998b-483d1d33e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6a5e2e52-82ed-4f10-aff4-62cbbb0c8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-196bf75b-4ad3-4bd4-9ff4-825b8014ded1,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-ec88479c-973d-43b1-b45d-aea816bc0428,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-3bf31987-a7d5-4f05-8ee5-eb1998b48fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-aeed7591-9af4-4946-b0f6-9537ccdefdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377162103-172.17.0.16-1597762692110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-3c47b4a1-294a-4c67-beab-8ecb80da2132,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-02fac52a-08c9-445a-bb07-f71a3847d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-b4337520-5fda-4856-9cbe-bc2ff94e002e,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4a6b2d32-f5d5-4960-b569-2145216d45c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-551f59b7-2a0a-45e1-9106-1decc7f706ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-39b5f3d8-bb8d-43dd-bc0f-09ad47ec2404,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-2cebdc6b-0676-4593-a878-7e24b50f7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-736d3747-d9a3-47e7-a5a4-c31300ae7a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377162103-172.17.0.16-1597762692110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-3c47b4a1-294a-4c67-beab-8ecb80da2132,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-02fac52a-08c9-445a-bb07-f71a3847d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-b4337520-5fda-4856-9cbe-bc2ff94e002e,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4a6b2d32-f5d5-4960-b569-2145216d45c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-551f59b7-2a0a-45e1-9106-1decc7f706ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-39b5f3d8-bb8d-43dd-bc0f-09ad47ec2404,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-2cebdc6b-0676-4593-a878-7e24b50f7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-736d3747-d9a3-47e7-a5a4-c31300ae7a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776910283-172.17.0.16-1597762708238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-eccdf1c1-da27-4fbe-bc3f-09e2281bbec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-90e183e8-e728-4f40-8f36-86facb96a942,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-01c793d2-2b61-4460-a5bb-0f69b0d38a46,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-35574f48-451d-46be-bdf4-a6c8aabc1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-4f1a7f10-6ad7-4a1a-9368-c5653c7e34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-89a586e0-6cf0-434e-ba72-f75c61ff822d,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-edf65855-3b11-4a94-9101-ec01d7e91f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-d167489f-5986-4f6d-9a29-9e5477db9c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776910283-172.17.0.16-1597762708238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-eccdf1c1-da27-4fbe-bc3f-09e2281bbec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-90e183e8-e728-4f40-8f36-86facb96a942,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-01c793d2-2b61-4460-a5bb-0f69b0d38a46,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-35574f48-451d-46be-bdf4-a6c8aabc1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-4f1a7f10-6ad7-4a1a-9368-c5653c7e34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-89a586e0-6cf0-434e-ba72-f75c61ff822d,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-edf65855-3b11-4a94-9101-ec01d7e91f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-d167489f-5986-4f6d-9a29-9e5477db9c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781389926-172.17.0.16-1597762914650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-efdcfd9b-94d9-4ccf-bb47-fda9a1388975,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-afc51839-93d5-4a65-a2c5-ba2e2f34a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-d91056b4-18e3-475d-9fd2-ac1f60c3ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-6f5ee8b2-39a8-4adc-b7c0-b2856cfc8247,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-52e55e90-2b75-4bb3-9be6-a7b6e71a3688,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1cf112dc-8de6-4a57-8bb2-5799057f510f,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-90f68434-c77a-481c-9513-53db3955c180,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-22d6adb3-f07a-479b-9694-4498097abc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781389926-172.17.0.16-1597762914650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-efdcfd9b-94d9-4ccf-bb47-fda9a1388975,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-afc51839-93d5-4a65-a2c5-ba2e2f34a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-d91056b4-18e3-475d-9fd2-ac1f60c3ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-6f5ee8b2-39a8-4adc-b7c0-b2856cfc8247,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-52e55e90-2b75-4bb3-9be6-a7b6e71a3688,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1cf112dc-8de6-4a57-8bb2-5799057f510f,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-90f68434-c77a-481c-9513-53db3955c180,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-22d6adb3-f07a-479b-9694-4498097abc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208941458-172.17.0.16-1597762977606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-6ad394d2-7adf-486a-888b-2c660d3fbd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-a14a230a-5273-4abf-819f-a6a994be4a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-97ed6cac-921f-4275-85b4-354b47ef70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-d2bb2dfe-6486-474c-8dfe-aa5519e68118,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-03da1bca-b3cc-4d62-a2f6-095f407bce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-cac64495-9b61-47ab-ad10-9b15020b2141,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-93145961-9513-472c-aa98-2d73a52040f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-ef526f84-a90d-47de-ba92-43dc7b8a869a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208941458-172.17.0.16-1597762977606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-6ad394d2-7adf-486a-888b-2c660d3fbd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-a14a230a-5273-4abf-819f-a6a994be4a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-97ed6cac-921f-4275-85b4-354b47ef70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-d2bb2dfe-6486-474c-8dfe-aa5519e68118,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-03da1bca-b3cc-4d62-a2f6-095f407bce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-cac64495-9b61-47ab-ad10-9b15020b2141,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-93145961-9513-472c-aa98-2d73a52040f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-ef526f84-a90d-47de-ba92-43dc7b8a869a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 3651
