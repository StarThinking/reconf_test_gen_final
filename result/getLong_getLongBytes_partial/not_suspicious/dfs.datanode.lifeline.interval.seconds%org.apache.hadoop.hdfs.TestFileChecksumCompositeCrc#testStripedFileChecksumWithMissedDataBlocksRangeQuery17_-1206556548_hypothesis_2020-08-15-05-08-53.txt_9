reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171110629-172.17.0.10-1597468186456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-e10e74ec-751d-4718-baaa-efc8bb4ee3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-49eadca9-c481-489e-a7fc-5f59ec6bdab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-89a4b975-3d50-42d3-a3a7-7bf1e17e9541,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-96b1b9b2-6bab-4dc8-9873-37adc28eb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-cdf1b1f0-4651-4485-90fc-741e78c6532b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-1311f71f-f623-45c1-8684-646d797bf0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-806e1b11-2691-4e40-b224-40e6caaec2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-b8d389bf-0c98-427a-8e63-b6346e16b9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171110629-172.17.0.10-1597468186456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-e10e74ec-751d-4718-baaa-efc8bb4ee3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-49eadca9-c481-489e-a7fc-5f59ec6bdab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-89a4b975-3d50-42d3-a3a7-7bf1e17e9541,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-96b1b9b2-6bab-4dc8-9873-37adc28eb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-cdf1b1f0-4651-4485-90fc-741e78c6532b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-1311f71f-f623-45c1-8684-646d797bf0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-806e1b11-2691-4e40-b224-40e6caaec2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-b8d389bf-0c98-427a-8e63-b6346e16b9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912230005-172.17.0.10-1597468423620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-7181ea3e-d37f-4740-8a4b-d0c6fc2786c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-4cfbb831-6eeb-49e4-91b0-3973a7746acc,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-73e9707b-47a3-4c84-88e7-4ed951639c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-4ab587a9-60da-4543-8673-151000c6f734,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-88c9ddc3-c9b7-4dc7-8041-97ba4ce5c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-2d74bd96-7fd3-4903-a295-3333e94c5ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-45d9ed1a-bcd7-4900-a08a-e6e92e845efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a6f20681-a13d-4687-b040-370c67a760e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912230005-172.17.0.10-1597468423620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-7181ea3e-d37f-4740-8a4b-d0c6fc2786c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-4cfbb831-6eeb-49e4-91b0-3973a7746acc,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-73e9707b-47a3-4c84-88e7-4ed951639c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-4ab587a9-60da-4543-8673-151000c6f734,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-88c9ddc3-c9b7-4dc7-8041-97ba4ce5c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-2d74bd96-7fd3-4903-a295-3333e94c5ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-45d9ed1a-bcd7-4900-a08a-e6e92e845efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a6f20681-a13d-4687-b040-370c67a760e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403037713-172.17.0.10-1597468695300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-40a7c2bf-69e4-4c69-b941-7c28788b998a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-7a89031e-58ff-41e2-9e09-72e8fcbbe56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-e3abece2-9ea4-45b0-86d4-2530aa5356b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-e13ba51b-930e-4e64-aec2-ae6354cd6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-e26174df-686f-4338-aab8-4a17d281a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-fbe8e1b3-3a70-43bb-bcf0-97ff1e676184,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-699b16a8-0cf3-4db8-b6de-1c2cdb1bf731,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-267da330-458d-46a5-b49f-ce7ac7915c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403037713-172.17.0.10-1597468695300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-40a7c2bf-69e4-4c69-b941-7c28788b998a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-7a89031e-58ff-41e2-9e09-72e8fcbbe56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-e3abece2-9ea4-45b0-86d4-2530aa5356b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-e13ba51b-930e-4e64-aec2-ae6354cd6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-e26174df-686f-4338-aab8-4a17d281a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-fbe8e1b3-3a70-43bb-bcf0-97ff1e676184,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-699b16a8-0cf3-4db8-b6de-1c2cdb1bf731,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-267da330-458d-46a5-b49f-ce7ac7915c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107908313-172.17.0.10-1597468977327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-d153ffd4-c6a1-4dc8-af38-8c9bac110f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7968cbdc-c666-4867-a021-b99339139ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-eaa5ecb8-0041-48c3-a76c-33a6c692b155,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-929a1041-1bd4-43ac-b3ac-2bb7b86cafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-1aec19ae-3b05-4847-9470-6e76b9754758,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-9990bb94-c0b3-4757-9911-2b373812e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-0aced2f3-45a5-43f4-b9e6-e64023fcddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-08ae49db-bc20-4e27-ab8a-89f68ccacdb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107908313-172.17.0.10-1597468977327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-d153ffd4-c6a1-4dc8-af38-8c9bac110f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7968cbdc-c666-4867-a021-b99339139ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-eaa5ecb8-0041-48c3-a76c-33a6c692b155,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-929a1041-1bd4-43ac-b3ac-2bb7b86cafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-1aec19ae-3b05-4847-9470-6e76b9754758,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-9990bb94-c0b3-4757-9911-2b373812e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-0aced2f3-45a5-43f4-b9e6-e64023fcddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-08ae49db-bc20-4e27-ab8a-89f68ccacdb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426777568-172.17.0.10-1597469222424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-5c06b260-503c-4ec5-b3da-49e91baaaacd,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-a0174aa1-5779-4134-9b07-cc593f15c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-476690f3-4332-485b-9df9-ac34f2820e17,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-8cbfe335-ffd4-49e8-b834-a40867b5667c,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-07edce21-b3d8-49ba-aa3b-109d97e51c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c639f18c-c013-4338-b809-865fd7cadf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-b29effbd-0a7d-4066-aaf1-1011cf85f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-69528d56-18eb-4f11-bbb3-33125492f07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426777568-172.17.0.10-1597469222424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-5c06b260-503c-4ec5-b3da-49e91baaaacd,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-a0174aa1-5779-4134-9b07-cc593f15c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-476690f3-4332-485b-9df9-ac34f2820e17,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-8cbfe335-ffd4-49e8-b834-a40867b5667c,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-07edce21-b3d8-49ba-aa3b-109d97e51c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c639f18c-c013-4338-b809-865fd7cadf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-b29effbd-0a7d-4066-aaf1-1011cf85f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-69528d56-18eb-4f11-bbb3-33125492f07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874311168-172.17.0.10-1597469807187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37484,DS-2d83029b-c32a-4065-8826-d89c1d011997,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-2e8d852f-26e9-4970-b1c0-f9b6858c1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-4513b591-3ea1-4214-923a-06e6d6c930ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-e6ad19c1-a790-4323-b8ae-c18f610e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-23d36706-6376-4eb5-8c3b-ec8281a03f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-d8a57fce-afc9-450b-a560-7e31673ab788,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-608e6894-65ae-4deb-874d-3611977427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d85011c4-936b-46a0-a6a7-534b9e0f1454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874311168-172.17.0.10-1597469807187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37484,DS-2d83029b-c32a-4065-8826-d89c1d011997,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-2e8d852f-26e9-4970-b1c0-f9b6858c1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-4513b591-3ea1-4214-923a-06e6d6c930ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-e6ad19c1-a790-4323-b8ae-c18f610e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-23d36706-6376-4eb5-8c3b-ec8281a03f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-d8a57fce-afc9-450b-a560-7e31673ab788,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-608e6894-65ae-4deb-874d-3611977427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d85011c4-936b-46a0-a6a7-534b9e0f1454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066216894-172.17.0.10-1597470031205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-64f3cb1c-f8cf-48e1-bd1c-0f63b37e0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-dfeda8f7-a135-4c76-82c8-b8183be2d11b,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-7a2d3ba9-e5e2-4c49-a0b0-cbc6fcecb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-4fca1643-951d-4e97-aa1e-74afeba555b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-f3bd7c4d-1feb-4005-a3eb-2a529c15c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-4d38ffeb-4f20-4823-b684-bb3f0a6dba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-6e9d97aa-8689-473b-bfbe-85e7df9867c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-81e8df56-f046-4036-888d-21cb3a9071ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066216894-172.17.0.10-1597470031205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-64f3cb1c-f8cf-48e1-bd1c-0f63b37e0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-dfeda8f7-a135-4c76-82c8-b8183be2d11b,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-7a2d3ba9-e5e2-4c49-a0b0-cbc6fcecb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-4fca1643-951d-4e97-aa1e-74afeba555b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-f3bd7c4d-1feb-4005-a3eb-2a529c15c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-4d38ffeb-4f20-4823-b684-bb3f0a6dba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-6e9d97aa-8689-473b-bfbe-85e7df9867c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-81e8df56-f046-4036-888d-21cb3a9071ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335264516-172.17.0.10-1597470414720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-49080e54-65ee-4d71-86a0-fe95395175e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-95732b00-7324-4ebe-bba0-28dc1382a569,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8b5d8e45-16bc-418c-aa35-5d160e5a24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-b08d24a3-0f1a-46b9-b801-2ece60dd0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-752cd018-2796-4c30-acda-7bd3ad35830c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a777a10e-c350-4cad-9cca-922bf174906b,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-a8249558-0dc5-4ed0-9f72-0ca0336f8bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-dd374b56-678f-4d7a-893d-8612a6df44ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335264516-172.17.0.10-1597470414720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-49080e54-65ee-4d71-86a0-fe95395175e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-95732b00-7324-4ebe-bba0-28dc1382a569,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8b5d8e45-16bc-418c-aa35-5d160e5a24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-b08d24a3-0f1a-46b9-b801-2ece60dd0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-752cd018-2796-4c30-acda-7bd3ad35830c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a777a10e-c350-4cad-9cca-922bf174906b,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-a8249558-0dc5-4ed0-9f72-0ca0336f8bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-dd374b56-678f-4d7a-893d-8612a6df44ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441595559-172.17.0.10-1597470495118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-0bbae45b-6c95-48db-a3f4-aee5cd049453,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4af910f1-5f37-47e0-9fd5-6e30c6b5bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-5a39ed8b-4b63-4f1b-9be9-c107b254fbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-b0870815-c355-4841-97c8-ff3cac00432f,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-ab2ea4d8-ae37-4ac0-9aab-84ffec1184b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-13f92915-da7d-4663-9eb3-f87f36070c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-efef5baa-b73a-467e-bd24-5e39daed5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-9ebfa5be-1221-4e0d-ac19-12f0365dfd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441595559-172.17.0.10-1597470495118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-0bbae45b-6c95-48db-a3f4-aee5cd049453,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4af910f1-5f37-47e0-9fd5-6e30c6b5bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-5a39ed8b-4b63-4f1b-9be9-c107b254fbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-b0870815-c355-4841-97c8-ff3cac00432f,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-ab2ea4d8-ae37-4ac0-9aab-84ffec1184b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-13f92915-da7d-4663-9eb3-f87f36070c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-efef5baa-b73a-467e-bd24-5e39daed5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-9ebfa5be-1221-4e0d-ac19-12f0365dfd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191973102-172.17.0.10-1597470576129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-e9a03e3f-2393-43ba-bcf4-188cbacad5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-d20aaed1-d698-47c7-958c-d3bfa7b50065,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-63ad049c-1684-45af-87c1-424e7a773cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-cc85ce63-a275-49ba-a1ad-d9fc134f126d,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-fc411867-6330-46fc-b57c-e824c9623523,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-8e2486ea-3525-419d-9abb-a7b2eb9143c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-a84dc3cc-3c93-44e2-8738-1ab254e28b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-85ed662f-9e58-47eb-b138-f039dec84ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191973102-172.17.0.10-1597470576129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-e9a03e3f-2393-43ba-bcf4-188cbacad5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-d20aaed1-d698-47c7-958c-d3bfa7b50065,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-63ad049c-1684-45af-87c1-424e7a773cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-cc85ce63-a275-49ba-a1ad-d9fc134f126d,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-fc411867-6330-46fc-b57c-e824c9623523,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-8e2486ea-3525-419d-9abb-a7b2eb9143c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-a84dc3cc-3c93-44e2-8738-1ab254e28b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-85ed662f-9e58-47eb-b138-f039dec84ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655546005-172.17.0.10-1597470844383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-f3b2ba43-271c-4d8c-b528-a3d5b65d14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-dc2c4536-3cc2-441c-9713-d2b4e2810d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-dd292b80-aeca-4d9f-99da-59865550efc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-bb00c9fa-e3d6-4c50-ab15-0bf94d145f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fc6edc8d-2b5f-422c-9742-c9284c9bc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-d27448e1-5885-4b36-b9ee-4b4ac9aad2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-fe0445ba-50d8-4c43-9717-44cfa19fa2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-c9e762b5-db81-42f0-9456-a1d75ea93091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655546005-172.17.0.10-1597470844383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-f3b2ba43-271c-4d8c-b528-a3d5b65d14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-dc2c4536-3cc2-441c-9713-d2b4e2810d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-dd292b80-aeca-4d9f-99da-59865550efc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-bb00c9fa-e3d6-4c50-ab15-0bf94d145f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fc6edc8d-2b5f-422c-9742-c9284c9bc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-d27448e1-5885-4b36-b9ee-4b4ac9aad2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-fe0445ba-50d8-4c43-9717-44cfa19fa2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-c9e762b5-db81-42f0-9456-a1d75ea93091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470325118-172.17.0.10-1597471089304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-5e7b2cee-8631-4b0f-810a-37490f2b948c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5e935711-b9b4-457a-b5ea-edae01d0a1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-9903ca5b-e08c-428f-9800-381eee7bb752,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9940911a-9c14-4c04-8717-c47f6505e0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-ae3de10e-6745-412b-b32a-8cc042a60a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-c6b2aef8-9d45-4e85-8d44-fe057f81068c,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-81280f9f-5c1a-440f-b6b2-778598f22982,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-e370d384-35d2-4840-bba2-2193f7aa947b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470325118-172.17.0.10-1597471089304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-5e7b2cee-8631-4b0f-810a-37490f2b948c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5e935711-b9b4-457a-b5ea-edae01d0a1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-9903ca5b-e08c-428f-9800-381eee7bb752,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9940911a-9c14-4c04-8717-c47f6505e0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-ae3de10e-6745-412b-b32a-8cc042a60a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-c6b2aef8-9d45-4e85-8d44-fe057f81068c,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-81280f9f-5c1a-440f-b6b2-778598f22982,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-e370d384-35d2-4840-bba2-2193f7aa947b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749957805-172.17.0.10-1597471992570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-2d56c069-cd1d-4069-b16c-24b6ced2b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-37143137-5fb7-47ab-81ed-a2e48abb83d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-686a63a1-71ff-4190-989f-346f9ac4f091,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6efbea68-4c51-4e23-aa10-d41a930053bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d8690de6-6147-4f0b-be0d-0328c82ba781,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-b3491c4c-922e-4198-9c19-86c95f7364bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-155a1e4f-a491-4f6f-af18-4f32b06e48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-7653a8e7-89ec-44ac-81f4-8593e45a2cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749957805-172.17.0.10-1597471992570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-2d56c069-cd1d-4069-b16c-24b6ced2b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-37143137-5fb7-47ab-81ed-a2e48abb83d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-686a63a1-71ff-4190-989f-346f9ac4f091,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6efbea68-4c51-4e23-aa10-d41a930053bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d8690de6-6147-4f0b-be0d-0328c82ba781,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-b3491c4c-922e-4198-9c19-86c95f7364bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-155a1e4f-a491-4f6f-af18-4f32b06e48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-7653a8e7-89ec-44ac-81f4-8593e45a2cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738707705-172.17.0.10-1597472248003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-3e4438ad-15cb-4c0b-be6d-fb87cfac05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-7b607a6b-b50a-410d-8766-0e2a51547e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-95b4f148-50b1-4ebe-b73d-729d992547aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6dbce9a3-21d4-45b4-9818-8696ede93d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-60d10313-1b39-4e98-8250-a1bb2e7a8aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7aec21e1-bdbc-4bae-ba4f-bfbdc7d01166,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-acb3539e-1c3a-42ef-941d-2385532cbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-48d31162-c698-4c9b-bb3d-b783412a58cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738707705-172.17.0.10-1597472248003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-3e4438ad-15cb-4c0b-be6d-fb87cfac05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-7b607a6b-b50a-410d-8766-0e2a51547e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-95b4f148-50b1-4ebe-b73d-729d992547aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6dbce9a3-21d4-45b4-9818-8696ede93d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-60d10313-1b39-4e98-8250-a1bb2e7a8aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7aec21e1-bdbc-4bae-ba4f-bfbdc7d01166,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-acb3539e-1c3a-42ef-941d-2385532cbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-48d31162-c698-4c9b-bb3d-b783412a58cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764170389-172.17.0.10-1597472696934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-145bdb25-a9ed-4d0e-a3f5-773b4300b305,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b3d34c64-e17e-407d-8ad0-52ab19f24e58,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-9f15b86e-8d70-438c-9bc1-368b23098db5,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-f88c9bce-40ca-40d9-b251-6236a2b90608,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-a8e5fb29-f05b-41ee-bf7d-5f19d53935c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-3dcb9da7-a8b2-4e28-aa1d-a53e3d744bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-cc801bc6-8a8f-4203-8a42-c4c749df561b,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-0e65450f-4fdc-41a9-ade6-a9cc21b919ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764170389-172.17.0.10-1597472696934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-145bdb25-a9ed-4d0e-a3f5-773b4300b305,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b3d34c64-e17e-407d-8ad0-52ab19f24e58,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-9f15b86e-8d70-438c-9bc1-368b23098db5,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-f88c9bce-40ca-40d9-b251-6236a2b90608,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-a8e5fb29-f05b-41ee-bf7d-5f19d53935c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-3dcb9da7-a8b2-4e28-aa1d-a53e3d744bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-cc801bc6-8a8f-4203-8a42-c4c749df561b,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-0e65450f-4fdc-41a9-ade6-a9cc21b919ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1296007038-172.17.0.10-1597472803470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-a28204d8-6558-4e9c-a7d1-7e4a3906ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7e076aba-acb2-47ab-ab48-65ed9367d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4579ba3e-f78b-42f1-ac34-fe616c16c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-13c3244a-da65-41a5-b6bf-cad6d8c9039c,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-79c865fa-ceb8-47d2-9e43-a3e21f8dac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-e6b22c85-faf1-481e-829e-59084604453e,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-97fca818-7777-4cdf-b9e1-2f398c72f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-23c5484d-6ee4-4c6b-9a7d-bd29171eb0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1296007038-172.17.0.10-1597472803470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-a28204d8-6558-4e9c-a7d1-7e4a3906ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7e076aba-acb2-47ab-ab48-65ed9367d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4579ba3e-f78b-42f1-ac34-fe616c16c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-13c3244a-da65-41a5-b6bf-cad6d8c9039c,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-79c865fa-ceb8-47d2-9e43-a3e21f8dac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-e6b22c85-faf1-481e-829e-59084604453e,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-97fca818-7777-4cdf-b9e1-2f398c72f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-23c5484d-6ee4-4c6b-9a7d-bd29171eb0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38756876-172.17.0.10-1597472993417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-6e43cd25-2741-4649-8c69-b84ae7660ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-152dff90-1756-4114-8e78-a720cbe19dca,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ebcecbc6-f79d-4eaa-ae48-48014c3b3ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1d716325-05bf-4467-91f4-d84234055d00,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c5c17050-842a-40cc-a7c7-6c670e43931e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-548bebd8-6aec-43a8-9cf4-605848b4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-d56c8ca5-096f-4494-8b5f-1c426dc3c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-f388b3d2-669d-4866-8e0a-f3cf2416e996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38756876-172.17.0.10-1597472993417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-6e43cd25-2741-4649-8c69-b84ae7660ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-152dff90-1756-4114-8e78-a720cbe19dca,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ebcecbc6-f79d-4eaa-ae48-48014c3b3ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1d716325-05bf-4467-91f4-d84234055d00,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c5c17050-842a-40cc-a7c7-6c670e43931e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-548bebd8-6aec-43a8-9cf4-605848b4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-d56c8ca5-096f-4494-8b5f-1c426dc3c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-f388b3d2-669d-4866-8e0a-f3cf2416e996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970272954-172.17.0.10-1597473067151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-35876dce-a367-47a9-adb2-e9731d9dd8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-c708dcf6-190a-4ac5-a6d7-4b0ee6f78953,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-11c7e3ab-f1cd-49a3-a745-6b1d076885e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-fc526c51-7ddd-49e9-a431-9b164cfcf78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-077c47a1-e4ad-4fed-a3de-f2d8799b6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-88a911d4-0cf6-4051-a862-7c6ba55b12e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-c625fe6c-2d4b-4237-908b-fd0ad3303840,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-a3db8549-cc9f-45de-9268-59575eca6bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970272954-172.17.0.10-1597473067151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-35876dce-a367-47a9-adb2-e9731d9dd8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-c708dcf6-190a-4ac5-a6d7-4b0ee6f78953,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-11c7e3ab-f1cd-49a3-a745-6b1d076885e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-fc526c51-7ddd-49e9-a431-9b164cfcf78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-077c47a1-e4ad-4fed-a3de-f2d8799b6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-88a911d4-0cf6-4051-a862-7c6ba55b12e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-c625fe6c-2d4b-4237-908b-fd0ad3303840,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-a3db8549-cc9f-45de-9268-59575eca6bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323644023-172.17.0.10-1597473327317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-9dabb7de-1623-418a-8b5d-ecd73e89b530,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-8efadd50-dd91-48f9-85bc-a4457b8724f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-ada6d05e-9bdc-4574-aa26-5f00d3024937,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-a1af73c1-4ede-4d28-8a1b-e14061d6ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-92c74e6b-35c7-489e-ab0e-2d87ef7a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-611fd968-2eca-489d-8337-a7bfa33449c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-d6c32e7a-d6b8-4bed-af8b-460a0edb332d,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-21a9c9a1-fec9-4d9d-8044-4f966a9bfcdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323644023-172.17.0.10-1597473327317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-9dabb7de-1623-418a-8b5d-ecd73e89b530,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-8efadd50-dd91-48f9-85bc-a4457b8724f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-ada6d05e-9bdc-4574-aa26-5f00d3024937,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-a1af73c1-4ede-4d28-8a1b-e14061d6ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-92c74e6b-35c7-489e-ab0e-2d87ef7a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-611fd968-2eca-489d-8337-a7bfa33449c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-d6c32e7a-d6b8-4bed-af8b-460a0edb332d,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-21a9c9a1-fec9-4d9d-8044-4f966a9bfcdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516283666-172.17.0.10-1597473363274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-28c5af71-2a68-4af7-b951-3b12687841d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-f4ccd6f8-8446-4fd1-8268-73a726f9b0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-465c20f8-5c5f-4b59-9611-8a4f5e78cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-ef11b580-3954-4b67-8c6f-403ddfc3e59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-aa8f795c-9e8c-4759-8439-2599c259ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-5aebc05f-67ef-4a60-82da-d912e6f0cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-82b7b558-059f-4535-943d-9510be40c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-86564f59-689b-4834-a7de-a64d596d0f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516283666-172.17.0.10-1597473363274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-28c5af71-2a68-4af7-b951-3b12687841d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-f4ccd6f8-8446-4fd1-8268-73a726f9b0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-465c20f8-5c5f-4b59-9611-8a4f5e78cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-ef11b580-3954-4b67-8c6f-403ddfc3e59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-aa8f795c-9e8c-4759-8439-2599c259ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-5aebc05f-67ef-4a60-82da-d912e6f0cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-82b7b558-059f-4535-943d-9510be40c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-86564f59-689b-4834-a7de-a64d596d0f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5716
