reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079049361-172.17.0.17-1597407842873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-42dbd410-9acc-4280-8ce0-514256a79820,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-194f15d4-6d58-4593-9d58-fd87b99efd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-33a19951-8bc8-46a7-8b38-c3ac0bc18a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f282f76c-b10e-4f21-9194-5d33f621935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-92348325-883d-4d12-9c5b-7dbd30218b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-3aa552ab-1d67-4d5d-9e53-2bcddef3f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-bb1a3ad9-e96b-475f-bf1a-bcd9e0f21511,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-b41acb16-88b1-4db1-92c0-a98c70b3a14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079049361-172.17.0.17-1597407842873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-42dbd410-9acc-4280-8ce0-514256a79820,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-194f15d4-6d58-4593-9d58-fd87b99efd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-33a19951-8bc8-46a7-8b38-c3ac0bc18a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f282f76c-b10e-4f21-9194-5d33f621935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-92348325-883d-4d12-9c5b-7dbd30218b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-3aa552ab-1d67-4d5d-9e53-2bcddef3f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-bb1a3ad9-e96b-475f-bf1a-bcd9e0f21511,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-b41acb16-88b1-4db1-92c0-a98c70b3a14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004926599-172.17.0.17-1597407927562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-bcf9dd3a-5dca-41e5-9021-10a07a30e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-0faf44eb-d399-4e44-ba84-37a13a53cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-8c0a3b51-bccd-424d-915b-4bb8228a597a,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-212df9fb-a995-4df5-8037-dba9a4c0e564,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-89b51c57-949f-4dd1-985d-bca323f08237,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ca65618b-4c1e-4304-b15c-b9e1d9878aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-08aa7a7b-8a88-4c2e-91cf-c3bb980701eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-90901b6c-275e-4c3a-81c5-1417bfb81718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004926599-172.17.0.17-1597407927562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-bcf9dd3a-5dca-41e5-9021-10a07a30e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-0faf44eb-d399-4e44-ba84-37a13a53cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-8c0a3b51-bccd-424d-915b-4bb8228a597a,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-212df9fb-a995-4df5-8037-dba9a4c0e564,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-89b51c57-949f-4dd1-985d-bca323f08237,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ca65618b-4c1e-4304-b15c-b9e1d9878aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-08aa7a7b-8a88-4c2e-91cf-c3bb980701eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-90901b6c-275e-4c3a-81c5-1417bfb81718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238448589-172.17.0.17-1597408242986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-fbc4c106-2d78-4172-a93e-17f47dcd401a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-5ac9eb77-1f81-47a5-9a8e-97d967d0bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-5364f269-f740-4c9b-ad52-48323bf7f911,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5e82fc73-72e3-43e9-ad52-e82ad49aec40,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-722ad2e5-ec71-4e19-9b00-8bf62d4b45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-bf1993c5-50ab-4f19-9154-7df558adc069,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-f45600b0-c4ae-4be0-bdb5-fb35bfb89633,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-cc02fb57-1169-4d2c-8e66-6f5d2ce6daae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238448589-172.17.0.17-1597408242986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-fbc4c106-2d78-4172-a93e-17f47dcd401a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-5ac9eb77-1f81-47a5-9a8e-97d967d0bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-5364f269-f740-4c9b-ad52-48323bf7f911,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-5e82fc73-72e3-43e9-ad52-e82ad49aec40,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-722ad2e5-ec71-4e19-9b00-8bf62d4b45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-bf1993c5-50ab-4f19-9154-7df558adc069,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-f45600b0-c4ae-4be0-bdb5-fb35bfb89633,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-cc02fb57-1169-4d2c-8e66-6f5d2ce6daae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80723765-172.17.0.17-1597408323330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-cccc370c-eeda-4424-a67c-867471744129,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6bfeb40b-a799-48dc-99ed-953bb226c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-f680a314-b5b3-47c3-9997-de1f27ec4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-618678ca-d7ec-449d-95c3-0e40fcdc9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-f8170fe3-c435-4bae-b448-e205981c3174,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-eb4911da-1beb-4bb7-8312-da45dfc29d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-86b4a4a6-aa71-47dd-89de-c811a9e00c20,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b78c7a7d-ec77-41fe-9392-b527c848ef1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80723765-172.17.0.17-1597408323330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-cccc370c-eeda-4424-a67c-867471744129,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6bfeb40b-a799-48dc-99ed-953bb226c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-f680a314-b5b3-47c3-9997-de1f27ec4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-618678ca-d7ec-449d-95c3-0e40fcdc9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-f8170fe3-c435-4bae-b448-e205981c3174,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-eb4911da-1beb-4bb7-8312-da45dfc29d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-86b4a4a6-aa71-47dd-89de-c811a9e00c20,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b78c7a7d-ec77-41fe-9392-b527c848ef1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130066124-172.17.0.17-1597408774820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-9e9e9338-132d-44d3-a074-432a389fdd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-446b5d97-ad61-4bee-9cec-9aac2e7e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-bd553780-16bd-48dd-8730-c267a9fb17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-e924ea36-e611-407e-a5d0-41ee41461b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-845fc0db-3add-4658-bda2-2254ab3f939b,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-87260c07-415a-44e2-a3d7-88568446568d,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-76390e31-ef52-4e21-a256-8e2b5b0860fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-f2bfe16f-1f66-4464-bf98-ef2490913e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130066124-172.17.0.17-1597408774820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-9e9e9338-132d-44d3-a074-432a389fdd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-446b5d97-ad61-4bee-9cec-9aac2e7e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-bd553780-16bd-48dd-8730-c267a9fb17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-e924ea36-e611-407e-a5d0-41ee41461b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-845fc0db-3add-4658-bda2-2254ab3f939b,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-87260c07-415a-44e2-a3d7-88568446568d,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-76390e31-ef52-4e21-a256-8e2b5b0860fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-f2bfe16f-1f66-4464-bf98-ef2490913e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101348450-172.17.0.17-1597408882695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-b1df4d78-7bcc-4ac7-b8f3-b490b0e23099,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-41b6ae43-56b3-415b-ba02-3d385056b517,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-9c7817fa-5b0c-4a68-9731-340db5b087f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-5bd0c7b8-aaba-42bb-8db6-638a7159a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-d38aea4c-1e1f-445e-9c50-02c968267a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-272b7ae5-9e73-41d4-b8ee-0feea08d618b,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-a2ca5668-794f-4bf5-8849-4f1548282ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cedddf9c-b6e6-493b-a51d-3cc323e3aab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101348450-172.17.0.17-1597408882695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-b1df4d78-7bcc-4ac7-b8f3-b490b0e23099,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-41b6ae43-56b3-415b-ba02-3d385056b517,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-9c7817fa-5b0c-4a68-9731-340db5b087f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-5bd0c7b8-aaba-42bb-8db6-638a7159a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-d38aea4c-1e1f-445e-9c50-02c968267a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-272b7ae5-9e73-41d4-b8ee-0feea08d618b,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-a2ca5668-794f-4bf5-8849-4f1548282ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cedddf9c-b6e6-493b-a51d-3cc323e3aab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801282425-172.17.0.17-1597409037088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-e08fd550-eaf9-4f2a-8e83-b7176003f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-ea0fe667-d6cb-40f0-8abe-e1c5d97ed20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-02ceeb24-e410-4b6d-b1ae-13ba28faf538,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-64757bb5-890b-4926-a520-0e44e592b637,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-019820c3-ae93-4e40-bb28-afb0492ab897,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-7f226e93-f02d-4cf9-b8c9-ab3c68538fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-ff78ba10-19b2-4fbe-8955-133ca7e8f635,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-bf811693-f4bf-4d71-8ec9-ed27e2cb4f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801282425-172.17.0.17-1597409037088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-e08fd550-eaf9-4f2a-8e83-b7176003f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-ea0fe667-d6cb-40f0-8abe-e1c5d97ed20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-02ceeb24-e410-4b6d-b1ae-13ba28faf538,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-64757bb5-890b-4926-a520-0e44e592b637,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-019820c3-ae93-4e40-bb28-afb0492ab897,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-7f226e93-f02d-4cf9-b8c9-ab3c68538fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-ff78ba10-19b2-4fbe-8955-133ca7e8f635,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-bf811693-f4bf-4d71-8ec9-ed27e2cb4f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064777007-172.17.0.17-1597409082381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37950,DS-2c1c80e2-02f3-4712-92d8-023602fa34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8f1e5e0a-35c6-4628-aff1-a264dda0ccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-b9dfb391-469b-49eb-9ebf-de0c17491878,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-4f0573f7-80d9-4cb7-9b21-a4192e2bc329,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b29f5074-3da3-4b88-bec4-1e5c3bef860f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-1ce5760d-9683-4ed7-bbec-402e57dd93fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-ffa928cc-eb55-44c3-a609-74f615617db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-cbae7447-3a06-4a02-83e6-5c44cef3185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064777007-172.17.0.17-1597409082381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37950,DS-2c1c80e2-02f3-4712-92d8-023602fa34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8f1e5e0a-35c6-4628-aff1-a264dda0ccb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-b9dfb391-469b-49eb-9ebf-de0c17491878,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-4f0573f7-80d9-4cb7-9b21-a4192e2bc329,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b29f5074-3da3-4b88-bec4-1e5c3bef860f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-1ce5760d-9683-4ed7-bbec-402e57dd93fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-ffa928cc-eb55-44c3-a609-74f615617db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-cbae7447-3a06-4a02-83e6-5c44cef3185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120135790-172.17.0.17-1597409271495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-81c97d17-9e64-4569-865a-ff5ba7cb2c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c4804141-3d3a-4768-bb85-38e32d4b5b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-54782303-6467-4387-b4d8-fe54f7c83a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-13dcad99-e9c4-4bcd-8638-9e8574ae8188,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-adf7afc6-c8d3-4b31-a488-fd7d7ba998ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-d168886e-7547-43d0-b2bb-0714ea8b6571,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-3eaafb06-17a8-44d8-8fe5-bcfa0dbd444d,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-01ede680-a2f5-4538-b689-7f9d25fc095b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120135790-172.17.0.17-1597409271495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-81c97d17-9e64-4569-865a-ff5ba7cb2c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c4804141-3d3a-4768-bb85-38e32d4b5b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-54782303-6467-4387-b4d8-fe54f7c83a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-13dcad99-e9c4-4bcd-8638-9e8574ae8188,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-adf7afc6-c8d3-4b31-a488-fd7d7ba998ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-d168886e-7547-43d0-b2bb-0714ea8b6571,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-3eaafb06-17a8-44d8-8fe5-bcfa0dbd444d,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-01ede680-a2f5-4538-b689-7f9d25fc095b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588347999-172.17.0.17-1597409385462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-8e2135c9-e968-4d57-9a5b-13db67913418,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-fa32f199-bb01-4cff-868d-b61c8e52a941,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-052c6d88-5eda-4159-a805-5bcc253f02be,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-de2b80e3-f230-4d8b-bde7-f4ca1d237a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-b5297f3e-ae86-49f0-a576-153a58f85c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3b47acfe-d09a-4208-a6fc-fb1106bed80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-3c63e6d6-8326-4a1a-9a09-5cc638d9872b,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-94d3be18-bc36-42b5-b39a-3a99b303a25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588347999-172.17.0.17-1597409385462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-8e2135c9-e968-4d57-9a5b-13db67913418,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-fa32f199-bb01-4cff-868d-b61c8e52a941,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-052c6d88-5eda-4159-a805-5bcc253f02be,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-de2b80e3-f230-4d8b-bde7-f4ca1d237a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-b5297f3e-ae86-49f0-a576-153a58f85c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3b47acfe-d09a-4208-a6fc-fb1106bed80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-3c63e6d6-8326-4a1a-9a09-5cc638d9872b,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-94d3be18-bc36-42b5-b39a-3a99b303a25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234950099-172.17.0.17-1597409423895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-7a80b9ba-1015-4236-9300-7100be4c7b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4a867259-901e-45ef-9fda-97a8ef376e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-e7a84aa2-8e4c-44e2-8c54-e4bf7a7ccba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-47f51dba-7abf-4e82-b4e1-0e3abb82dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-72f9b2a2-c7ea-4fef-ab44-8412a3294058,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5ec4d3be-f845-40ef-be5b-6459334963c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-e3d3af6c-9c2f-44c5-a355-5bd49f9ed43c,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f82e388e-02e9-4485-b31e-a8fd5a9a0d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234950099-172.17.0.17-1597409423895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-7a80b9ba-1015-4236-9300-7100be4c7b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4a867259-901e-45ef-9fda-97a8ef376e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-e7a84aa2-8e4c-44e2-8c54-e4bf7a7ccba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-47f51dba-7abf-4e82-b4e1-0e3abb82dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-72f9b2a2-c7ea-4fef-ab44-8412a3294058,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5ec4d3be-f845-40ef-be5b-6459334963c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-e3d3af6c-9c2f-44c5-a355-5bd49f9ed43c,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f82e388e-02e9-4485-b31e-a8fd5a9a0d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651661589-172.17.0.17-1597409537983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-e7146809-b406-4087-bfdc-cfccb0e9e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-59d964f4-fdbd-4860-88e7-7e2fff131dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-372d34fb-a466-4b8f-8f7f-201018fc1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-11900d69-3ebc-404e-ba8f-c2e5393288bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-1d299868-f87a-42e8-868e-2c7ded0bdcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-dac27175-b5de-4a2d-99ee-e3447aa95b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-2facff35-0790-4296-ab2a-b07aa73b1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-07650b04-ca25-4ed7-9059-8d6e25c2a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651661589-172.17.0.17-1597409537983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-e7146809-b406-4087-bfdc-cfccb0e9e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-59d964f4-fdbd-4860-88e7-7e2fff131dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-372d34fb-a466-4b8f-8f7f-201018fc1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-11900d69-3ebc-404e-ba8f-c2e5393288bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-1d299868-f87a-42e8-868e-2c7ded0bdcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-dac27175-b5de-4a2d-99ee-e3447aa95b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-2facff35-0790-4296-ab2a-b07aa73b1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-07650b04-ca25-4ed7-9059-8d6e25c2a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521317204-172.17.0.17-1597410102857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-be09b23c-7319-4f74-aa80-7fb5aba82491,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-6a074288-dbe5-49a4-b628-ea83b4c72b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-f0fe6ecb-79b6-4009-9265-9ffbb9ba3301,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-f0eeb8ea-609e-4c20-9da1-afad74af9085,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-7653b10c-62b7-41a4-be6a-f16c6bc99e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-20435eff-9f5a-466e-9a2d-d42ce40022eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-9a8363f4-b677-4580-becf-fc61623c4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-03ae1cc8-cf8c-4589-a278-3f410f04a8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521317204-172.17.0.17-1597410102857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-be09b23c-7319-4f74-aa80-7fb5aba82491,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-6a074288-dbe5-49a4-b628-ea83b4c72b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-f0fe6ecb-79b6-4009-9265-9ffbb9ba3301,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-f0eeb8ea-609e-4c20-9da1-afad74af9085,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-7653b10c-62b7-41a4-be6a-f16c6bc99e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-20435eff-9f5a-466e-9a2d-d42ce40022eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-9a8363f4-b677-4580-becf-fc61623c4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-03ae1cc8-cf8c-4589-a278-3f410f04a8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017784682-172.17.0.17-1597410185607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-220b3379-b4cc-456b-9da6-6f263124824c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-083151b4-d117-4bb9-bd41-1811f71aee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-0b5ccf65-6700-4d82-911a-04f02d99577b,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-387c14af-4fc2-40a4-8a44-5c28139db1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d7622883-2310-49a2-85ce-f7209fe97f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-2be2737b-be63-4ba2-945c-894999c27bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-1de49085-a80a-4568-8d32-27e6beafea15,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-b5af4a0a-0b3d-43bc-8fab-4b70cb0a9fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017784682-172.17.0.17-1597410185607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-220b3379-b4cc-456b-9da6-6f263124824c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-083151b4-d117-4bb9-bd41-1811f71aee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-0b5ccf65-6700-4d82-911a-04f02d99577b,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-387c14af-4fc2-40a4-8a44-5c28139db1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d7622883-2310-49a2-85ce-f7209fe97f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-2be2737b-be63-4ba2-945c-894999c27bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-1de49085-a80a-4568-8d32-27e6beafea15,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-b5af4a0a-0b3d-43bc-8fab-4b70cb0a9fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732935295-172.17.0.17-1597410464909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46672,DS-b40e5853-dcd2-4344-8605-d56744e89465,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-3a940f50-f571-4b8f-b8cf-a60d5aac7951,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-3cd156dd-b6e3-4873-a25c-a2b1bc787ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-7053dada-65b0-4a2e-b9d5-18873b2699b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-e00ee919-ab4f-41ce-b7b8-98e2d3e3794a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-ec4222d0-d9a2-417c-afb2-d536ad277973,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8d3bedff-1f4f-4442-9876-cd4041b88e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-3ab8308b-e616-4617-aa12-f0466df18e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732935295-172.17.0.17-1597410464909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46672,DS-b40e5853-dcd2-4344-8605-d56744e89465,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-3a940f50-f571-4b8f-b8cf-a60d5aac7951,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-3cd156dd-b6e3-4873-a25c-a2b1bc787ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-7053dada-65b0-4a2e-b9d5-18873b2699b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-e00ee919-ab4f-41ce-b7b8-98e2d3e3794a,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-ec4222d0-d9a2-417c-afb2-d536ad277973,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8d3bedff-1f4f-4442-9876-cd4041b88e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-3ab8308b-e616-4617-aa12-f0466df18e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306169372-172.17.0.17-1597410724652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-1a592e77-e5c5-4c69-bb6f-ffbafadc1753,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-19912579-05f0-494b-b135-14b1fdd67b48,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-73b51b0b-93c3-44d9-82d2-6f5690348b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-618bd9a0-ca07-4a01-b49c-e12def54524b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6c8a4252-9ed6-4e91-8f86-1ee2e8936dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-10cf3c6f-d5a1-4e04-bcfd-8858cdcd7564,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-19212c73-a401-459f-bb9b-14719d5dc248,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-1ce84ccc-2c47-44c7-b0dd-bba1de05911a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306169372-172.17.0.17-1597410724652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-1a592e77-e5c5-4c69-bb6f-ffbafadc1753,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-19912579-05f0-494b-b135-14b1fdd67b48,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-73b51b0b-93c3-44d9-82d2-6f5690348b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-618bd9a0-ca07-4a01-b49c-e12def54524b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6c8a4252-9ed6-4e91-8f86-1ee2e8936dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-10cf3c6f-d5a1-4e04-bcfd-8858cdcd7564,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-19212c73-a401-459f-bb9b-14719d5dc248,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-1ce84ccc-2c47-44c7-b0dd-bba1de05911a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721245039-172.17.0.17-1597411337896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-81a17508-8108-4b64-a516-165d75c61e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-18d0a37c-12e3-4456-b4bb-103235f53d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-f9849bbe-d713-41df-9266-50f5d06c617c,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-d8257746-0edb-4f53-a573-e59ed20b7d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f635bca0-e8bc-4971-9bfc-aec529a8514f,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-079c632d-b23a-4879-9404-969ed987d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-0f4d4bb6-77ce-41c9-aba1-e6792f7d8752,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-dbb36745-7a3e-4fa0-acd1-9b66bdfbeb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721245039-172.17.0.17-1597411337896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-81a17508-8108-4b64-a516-165d75c61e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-18d0a37c-12e3-4456-b4bb-103235f53d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-f9849bbe-d713-41df-9266-50f5d06c617c,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-d8257746-0edb-4f53-a573-e59ed20b7d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f635bca0-e8bc-4971-9bfc-aec529a8514f,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-079c632d-b23a-4879-9404-969ed987d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-0f4d4bb6-77ce-41c9-aba1-e6792f7d8752,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-dbb36745-7a3e-4fa0-acd1-9b66bdfbeb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510758157-172.17.0.17-1597411734514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45184,DS-61d2cb93-7dcf-4f7a-83c4-28a3a9e3c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-0f109b3e-e22d-4d9f-b424-5fa3ef9f84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-4a1f27fc-f085-4fb1-b3c4-aa78cf3db2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-964c3d90-a4a5-4301-a6ef-45e48de9bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-055c9135-c92e-420e-8bef-72cac364b858,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-508509fe-658e-41ef-92bf-536ad2c768ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-ef32ff41-8ad2-47d9-b159-803161a08b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3e8f6867-93f1-4c88-b36a-559814f2952c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510758157-172.17.0.17-1597411734514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45184,DS-61d2cb93-7dcf-4f7a-83c4-28a3a9e3c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-0f109b3e-e22d-4d9f-b424-5fa3ef9f84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-4a1f27fc-f085-4fb1-b3c4-aa78cf3db2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-964c3d90-a4a5-4301-a6ef-45e48de9bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-055c9135-c92e-420e-8bef-72cac364b858,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-508509fe-658e-41ef-92bf-536ad2c768ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-ef32ff41-8ad2-47d9-b159-803161a08b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3e8f6867-93f1-4c88-b36a-559814f2952c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574466256-172.17.0.17-1597412037075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-b9173f33-b950-4c5c-b1a0-7800107c0718,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-46e03feb-cff3-4af9-8bf1-4855348ca5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-41f947c1-2ab6-42d6-9013-5d015cb40def,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-979a33b8-f1aa-4cf1-a19f-bec569201ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-13b1b05e-9750-4816-ad3a-85be1ac5c6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-a305c2f1-c6d5-4e14-a29c-d09e0702a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-53945463-8130-472b-859e-0e445d38310e,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-213bd288-a71e-42d6-ad93-1048c396a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574466256-172.17.0.17-1597412037075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-b9173f33-b950-4c5c-b1a0-7800107c0718,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-46e03feb-cff3-4af9-8bf1-4855348ca5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-41f947c1-2ab6-42d6-9013-5d015cb40def,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-979a33b8-f1aa-4cf1-a19f-bec569201ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-13b1b05e-9750-4816-ad3a-85be1ac5c6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-a305c2f1-c6d5-4e14-a29c-d09e0702a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-53945463-8130-472b-859e-0e445d38310e,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-213bd288-a71e-42d6-ad93-1048c396a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189154631-172.17.0.17-1597412221477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-7f5aa174-6a0a-4bb0-b306-67dede911d45,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-6e4ef83d-80ac-4d0a-9d07-1596894b5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-81fe61a2-4c8b-4aee-aec3-bf5768148162,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-7ad78e40-ea50-4286-8e1a-7fb15e0ba860,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-2008910a-e3af-4b56-83de-fa18d3010d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-d1258140-1b2d-417c-b4ed-31096e50cdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-3129af66-bc5c-4dc3-af6f-fc686bf3026a,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-2083814f-f534-4396-a093-857f9a34c200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189154631-172.17.0.17-1597412221477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-7f5aa174-6a0a-4bb0-b306-67dede911d45,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-6e4ef83d-80ac-4d0a-9d07-1596894b5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-81fe61a2-4c8b-4aee-aec3-bf5768148162,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-7ad78e40-ea50-4286-8e1a-7fb15e0ba860,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-2008910a-e3af-4b56-83de-fa18d3010d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-d1258140-1b2d-417c-b4ed-31096e50cdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-3129af66-bc5c-4dc3-af6f-fc686bf3026a,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-2083814f-f534-4396-a093-857f9a34c200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56695445-172.17.0.17-1597412260249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-d8706a92-1ae0-4057-9aef-d8c1cbc969a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-35a61026-6151-4bd3-8182-c86119b9c99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-924b9780-eacd-4d28-9cc5-d5a5806e05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-f9c67c52-11d0-47bf-8324-be2e2785f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-2000e1b6-2cde-44fd-b2d8-51f02de5e964,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-f182ab9f-ca22-4eb0-a719-61b4346ba0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-ffa558ee-7e21-4764-8b8c-40a27bd72d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-d8ed783c-f6e5-4966-915d-43419447f6e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56695445-172.17.0.17-1597412260249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-d8706a92-1ae0-4057-9aef-d8c1cbc969a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-35a61026-6151-4bd3-8182-c86119b9c99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-924b9780-eacd-4d28-9cc5-d5a5806e05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-f9c67c52-11d0-47bf-8324-be2e2785f2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-2000e1b6-2cde-44fd-b2d8-51f02de5e964,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-f182ab9f-ca22-4eb0-a719-61b4346ba0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-ffa558ee-7e21-4764-8b8c-40a27bd72d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-d8ed783c-f6e5-4966-915d-43419447f6e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396575450-172.17.0.17-1597412295430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33055,DS-7d072565-2d9b-4967-a7a6-3c3276ca5528,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c807fb6a-732a-4078-ada6-13963b194320,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-d73e1ab5-a200-4854-9a97-7b87e4e873e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-de0e4f9c-2eec-4554-ad67-a4a8cf6ee2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-364bad81-54bf-46fb-bde8-367be5911e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-0e9983b0-80a1-4ebd-a011-dacd22913169,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-bd7d562d-f4bf-4c65-87f1-63c5e01d19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-e6726e00-0d37-4a0a-94f3-ba742866f6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396575450-172.17.0.17-1597412295430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33055,DS-7d072565-2d9b-4967-a7a6-3c3276ca5528,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c807fb6a-732a-4078-ada6-13963b194320,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-d73e1ab5-a200-4854-9a97-7b87e4e873e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-de0e4f9c-2eec-4554-ad67-a4a8cf6ee2da,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-364bad81-54bf-46fb-bde8-367be5911e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-0e9983b0-80a1-4ebd-a011-dacd22913169,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-bd7d562d-f4bf-4c65-87f1-63c5e01d19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-e6726e00-0d37-4a0a-94f3-ba742866f6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701134853-172.17.0.17-1597412559835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-3b9b2a1d-58ac-4423-9621-7d7e8cf2011e,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-57923764-ce72-4d77-82d4-24d7ca1650c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-1039f17f-eb78-459a-beed-c02f17c3dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-ec8d9882-ce3d-4841-9cff-a68dfdc2f262,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-3a38142a-912e-4a50-b14a-fd236251f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3f338fd0-a8be-48da-9e84-52c352efe592,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-67ead756-9df5-4ea1-bec4-854da086a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e61dc8cb-b6f5-44f0-aee6-57bb3ab49775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701134853-172.17.0.17-1597412559835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-3b9b2a1d-58ac-4423-9621-7d7e8cf2011e,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-57923764-ce72-4d77-82d4-24d7ca1650c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-1039f17f-eb78-459a-beed-c02f17c3dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-ec8d9882-ce3d-4841-9cff-a68dfdc2f262,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-3a38142a-912e-4a50-b14a-fd236251f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3f338fd0-a8be-48da-9e84-52c352efe592,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-67ead756-9df5-4ea1-bec4-854da086a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e61dc8cb-b6f5-44f0-aee6-57bb3ab49775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860487892-172.17.0.17-1597412598637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37448,DS-68634da8-b371-434a-979c-705771453521,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-913f5320-fe16-42d7-a4c5-7ba602a81e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-e06e14f2-5d1e-44f5-8db7-6c03f2fa3158,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-a21f0b06-4966-48be-b624-5b272622f72c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-281f76d4-ed8a-4272-9744-5d455ec87573,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-fa7b0b16-b1d1-4959-963f-555d45f1ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-bc2772e6-bc13-4cea-a06e-51c53dcb0ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-79e25b5e-19bd-4f05-9f0e-0b8b41474746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860487892-172.17.0.17-1597412598637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37448,DS-68634da8-b371-434a-979c-705771453521,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-913f5320-fe16-42d7-a4c5-7ba602a81e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-e06e14f2-5d1e-44f5-8db7-6c03f2fa3158,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-a21f0b06-4966-48be-b624-5b272622f72c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-281f76d4-ed8a-4272-9744-5d455ec87573,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-fa7b0b16-b1d1-4959-963f-555d45f1ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-bc2772e6-bc13-4cea-a06e-51c53dcb0ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-79e25b5e-19bd-4f05-9f0e-0b8b41474746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132628573-172.17.0.17-1597412672743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-04a23e10-0948-4fb0-8624-a8cc0c6aa660,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-794749fa-16fc-4ca8-a518-4a8f5f90bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-c3e2302f-ad2e-4d66-9232-bb970aa1c3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8e4845e2-bc5c-4fbc-a9e3-0e302b93ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-4681cf46-bf4e-44cb-8c8b-0533e0b3e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-01583f5c-b939-4879-8613-3e44cd880b36,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-023d5926-dc91-4cc5-8a26-829086822e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-5028e83e-e330-484e-891f-07a6e88eb137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132628573-172.17.0.17-1597412672743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-04a23e10-0948-4fb0-8624-a8cc0c6aa660,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-794749fa-16fc-4ca8-a518-4a8f5f90bfef,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-c3e2302f-ad2e-4d66-9232-bb970aa1c3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8e4845e2-bc5c-4fbc-a9e3-0e302b93ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-4681cf46-bf4e-44cb-8c8b-0533e0b3e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-01583f5c-b939-4879-8613-3e44cd880b36,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-023d5926-dc91-4cc5-8a26-829086822e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-5028e83e-e330-484e-891f-07a6e88eb137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104052501-172.17.0.17-1597412807528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-132d1c6b-c444-4d3a-b08e-e3f94e870304,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-da39f5c8-57dd-4166-8f1e-79f6897cb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-b83a2f4a-380d-4afc-9cfc-6372e1fa0891,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-e9b60fe1-c321-4744-aa87-e7d518f9424f,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-722f8394-1712-45ef-9827-b6db79ded6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-8a220a63-f871-4580-a443-55576a660371,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-785e4c62-0d66-4f68-9ed8-b4533168d20c,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-b4c71dda-c726-4532-b3c7-b28b6bb3c464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104052501-172.17.0.17-1597412807528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-132d1c6b-c444-4d3a-b08e-e3f94e870304,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-da39f5c8-57dd-4166-8f1e-79f6897cb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-b83a2f4a-380d-4afc-9cfc-6372e1fa0891,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-e9b60fe1-c321-4744-aa87-e7d518f9424f,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-722f8394-1712-45ef-9827-b6db79ded6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-8a220a63-f871-4580-a443-55576a660371,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-785e4c62-0d66-4f68-9ed8-b4533168d20c,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-b4c71dda-c726-4532-b3c7-b28b6bb3c464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5714
