reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141974078-172.17.0.17-1597735128757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-93e58da0-3c9f-4848-a0c8-6cd1b3c93475,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-728dab9e-3a5d-46ca-a574-0b1918672aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-2ba32c64-1aef-4b07-8fdc-1e321a2a8128,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-7886b012-a7e1-4294-816d-87e4d685f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-12e7825d-911f-4712-98a4-a79eec99779c,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-47fc61c8-8da6-4a5a-b24d-485c5490a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-144cd3c9-ef47-4f5e-970f-96039ad41141,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-19490e36-1a5c-400b-9226-3f1cfa2ac369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141974078-172.17.0.17-1597735128757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-93e58da0-3c9f-4848-a0c8-6cd1b3c93475,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-728dab9e-3a5d-46ca-a574-0b1918672aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-2ba32c64-1aef-4b07-8fdc-1e321a2a8128,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-7886b012-a7e1-4294-816d-87e4d685f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-12e7825d-911f-4712-98a4-a79eec99779c,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-47fc61c8-8da6-4a5a-b24d-485c5490a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-144cd3c9-ef47-4f5e-970f-96039ad41141,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-19490e36-1a5c-400b-9226-3f1cfa2ac369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485025668-172.17.0.17-1597735208545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-02f55409-d8fc-44d3-be05-7fc21848eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-f7ded3f9-0faf-4d04-b489-4010203aa969,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-0adab440-2de0-4a48-a95a-e1e000b24a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7436b7af-18ae-4cd5-a1a6-9a3ec6286c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-be157130-cee4-44b0-aa51-628b14816807,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-2e6000b4-44d6-4e32-8f2a-5325bf41bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-397f5b83-0531-4cd6-b5e9-6a5d8f4435e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-acdd29fe-8187-4aa2-9f06-77e1fc2bbb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485025668-172.17.0.17-1597735208545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-02f55409-d8fc-44d3-be05-7fc21848eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-f7ded3f9-0faf-4d04-b489-4010203aa969,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-0adab440-2de0-4a48-a95a-e1e000b24a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7436b7af-18ae-4cd5-a1a6-9a3ec6286c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-be157130-cee4-44b0-aa51-628b14816807,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-2e6000b4-44d6-4e32-8f2a-5325bf41bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-397f5b83-0531-4cd6-b5e9-6a5d8f4435e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-acdd29fe-8187-4aa2-9f06-77e1fc2bbb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230775174-172.17.0.17-1597735243252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-9ccca581-836d-4292-8e64-cc9dfa3ff3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-856eba9b-3f93-40af-a624-e1b24ee32ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-cf53139e-0079-47d6-878b-a3981f566412,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-8b5dc8b9-8fa6-4571-8d5c-9d0c26ce2575,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-28097432-e8e7-45fb-ab99-ec1628c2610f,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-b7532664-aed5-46f9-b6cb-55be31f0c160,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f6419b74-a336-4d4b-9fb2-7053b02e4619,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-bf990767-b968-4b86-8fdc-58e895bb40c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230775174-172.17.0.17-1597735243252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-9ccca581-836d-4292-8e64-cc9dfa3ff3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-856eba9b-3f93-40af-a624-e1b24ee32ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-cf53139e-0079-47d6-878b-a3981f566412,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-8b5dc8b9-8fa6-4571-8d5c-9d0c26ce2575,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-28097432-e8e7-45fb-ab99-ec1628c2610f,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-b7532664-aed5-46f9-b6cb-55be31f0c160,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-f6419b74-a336-4d4b-9fb2-7053b02e4619,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-bf990767-b968-4b86-8fdc-58e895bb40c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792630879-172.17.0.17-1597736332995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-1e9f5d74-46e7-4c08-9f77-9c1665bd140a,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-2909365c-2601-40ed-acb9-cd8ab5da5e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-4982dd41-1aca-4f5a-abc7-08ec53c6ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ddf80073-45bd-452c-bdfc-03eee1f1a119,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-d16a90f9-ce91-4f9c-ac2f-d510fdef20ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-6a7c4736-2a5a-41c5-9eb2-5c36dc34cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-1663836e-c24c-4e43-8ea3-0f384e1a7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-d41b4976-0767-44c9-bed9-b644a93d972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792630879-172.17.0.17-1597736332995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-1e9f5d74-46e7-4c08-9f77-9c1665bd140a,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-2909365c-2601-40ed-acb9-cd8ab5da5e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-4982dd41-1aca-4f5a-abc7-08ec53c6ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ddf80073-45bd-452c-bdfc-03eee1f1a119,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-d16a90f9-ce91-4f9c-ac2f-d510fdef20ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-6a7c4736-2a5a-41c5-9eb2-5c36dc34cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-1663836e-c24c-4e43-8ea3-0f384e1a7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-d41b4976-0767-44c9-bed9-b644a93d972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343387548-172.17.0.17-1597736371461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-b7a64bda-632b-45c4-b24b-3f2d7d53a317,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-400516b9-a063-4d80-a859-a04a82c1e12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-c019a153-6dbe-4ae8-afb2-e6951171422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-cebd0ecd-8270-4f93-a5b3-5702d30b56de,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-081e29cf-bb67-4670-b38f-78439ad5cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-ff236988-71e1-4741-ba58-2953bdada196,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-07bcf64a-df70-480e-8baf-278027be4483,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-0cea9054-594d-43d5-8f42-97e39e3d411e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343387548-172.17.0.17-1597736371461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-b7a64bda-632b-45c4-b24b-3f2d7d53a317,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-400516b9-a063-4d80-a859-a04a82c1e12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-c019a153-6dbe-4ae8-afb2-e6951171422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-cebd0ecd-8270-4f93-a5b3-5702d30b56de,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-081e29cf-bb67-4670-b38f-78439ad5cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-ff236988-71e1-4741-ba58-2953bdada196,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-07bcf64a-df70-480e-8baf-278027be4483,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-0cea9054-594d-43d5-8f42-97e39e3d411e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890508628-172.17.0.17-1597736413389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-36d5bd36-db2d-4ff4-aa17-eca989e85744,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-bc4cf829-3028-4228-87eb-f2e3edb9d8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-10ebb165-5fd2-49be-a279-04da1c60b580,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-2650733e-aee5-4b56-a1b7-e7aa3a4f9cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7dc80dd9-cf73-4637-b07b-c4cd0b0a0dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-70c4bbf7-b6bd-4429-b499-387f5587e987,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7876515d-4e9c-4d8c-9716-e3f2b3c5fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-3b2de09e-0769-4e59-b9bd-75a6615da0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890508628-172.17.0.17-1597736413389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-36d5bd36-db2d-4ff4-aa17-eca989e85744,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-bc4cf829-3028-4228-87eb-f2e3edb9d8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-10ebb165-5fd2-49be-a279-04da1c60b580,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-2650733e-aee5-4b56-a1b7-e7aa3a4f9cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7dc80dd9-cf73-4637-b07b-c4cd0b0a0dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-70c4bbf7-b6bd-4429-b499-387f5587e987,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7876515d-4e9c-4d8c-9716-e3f2b3c5fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-3b2de09e-0769-4e59-b9bd-75a6615da0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114701293-172.17.0.17-1597736723041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33679,DS-932a285d-c77f-449d-b162-4b26a4f39b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f75affe3-b202-4649-a1f2-4be934b93a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1b77f451-90ff-4b23-a6a4-85ad8907d945,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-466f2ecd-e9bd-40c6-a601-387601665990,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-ebc1a6d6-e78f-4c07-b6a8-29942760158e,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-b2be6df4-7d16-420b-82fc-4db4a3ab2aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-d553bac8-d7eb-4d64-bfd4-4f2472ebbabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-eee376ca-51a7-4439-935d-f1d641d58942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114701293-172.17.0.17-1597736723041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33679,DS-932a285d-c77f-449d-b162-4b26a4f39b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f75affe3-b202-4649-a1f2-4be934b93a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1b77f451-90ff-4b23-a6a4-85ad8907d945,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-466f2ecd-e9bd-40c6-a601-387601665990,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-ebc1a6d6-e78f-4c07-b6a8-29942760158e,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-b2be6df4-7d16-420b-82fc-4db4a3ab2aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-d553bac8-d7eb-4d64-bfd4-4f2472ebbabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-eee376ca-51a7-4439-935d-f1d641d58942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087064067-172.17.0.17-1597736843016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-059db7c4-a975-41b3-ab40-3e9fbd50a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-7b1bd51c-bdca-41b3-b05b-abe94bede3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aea0e708-ed9f-4c6a-8f61-f5d9ff71c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-3c5a39ee-71aa-45ce-a9a8-a682a99d0881,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-83224794-34cd-4640-b13a-8cc63ed2928b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2ae812fd-03fc-4c7c-b5c5-c263358d2674,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-5f9678c2-b1c7-43c0-8b8a-ab65463f5621,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-05aa706a-5275-4307-8d51-f012dd6e50b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087064067-172.17.0.17-1597736843016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-059db7c4-a975-41b3-ab40-3e9fbd50a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-7b1bd51c-bdca-41b3-b05b-abe94bede3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aea0e708-ed9f-4c6a-8f61-f5d9ff71c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-3c5a39ee-71aa-45ce-a9a8-a682a99d0881,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-83224794-34cd-4640-b13a-8cc63ed2928b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2ae812fd-03fc-4c7c-b5c5-c263358d2674,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-5f9678c2-b1c7-43c0-8b8a-ab65463f5621,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-05aa706a-5275-4307-8d51-f012dd6e50b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206919061-172.17.0.17-1597738121663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-8338b8eb-4799-490e-beaf-24ad0bf9d667,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-2eb589bd-95f2-49ac-85fd-460fe88e61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-97540fd9-4a7c-44ac-b3ab-b1b382994de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-6bb6eae5-a5cf-4bfe-bf20-c35b6112a846,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-cd2d6032-8bfd-4d5d-a5f3-42d2052069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-b5e248e7-bf7f-44ec-ae9b-f6a8cf8e03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-d9536b1c-1e97-4b15-abd3-b9b1366d7397,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-241cbbb7-079f-42b4-bc96-790ffb361c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206919061-172.17.0.17-1597738121663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-8338b8eb-4799-490e-beaf-24ad0bf9d667,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-2eb589bd-95f2-49ac-85fd-460fe88e61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-97540fd9-4a7c-44ac-b3ab-b1b382994de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-6bb6eae5-a5cf-4bfe-bf20-c35b6112a846,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-cd2d6032-8bfd-4d5d-a5f3-42d2052069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-b5e248e7-bf7f-44ec-ae9b-f6a8cf8e03b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-d9536b1c-1e97-4b15-abd3-b9b1366d7397,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-241cbbb7-079f-42b4-bc96-790ffb361c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999400816-172.17.0.17-1597738741948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-7eda3a95-1b84-400e-9318-9135764467c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-52258e58-ae8c-4adf-a6d2-c4c7e8152cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-cc6f5f3e-3bf7-4d1e-b89f-1380fba1ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-0e6d99a7-47af-4deb-99fa-930d5ed16b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-e25fed71-a148-439b-bab2-682df8359288,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-994d14ce-32fe-4493-8d36-db76b53a7603,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-3494901c-1096-4f3d-8fd5-b40d91a75ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-42c347b9-7832-4da8-ba53-f28b7b24415a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999400816-172.17.0.17-1597738741948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-7eda3a95-1b84-400e-9318-9135764467c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-52258e58-ae8c-4adf-a6d2-c4c7e8152cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-cc6f5f3e-3bf7-4d1e-b89f-1380fba1ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-0e6d99a7-47af-4deb-99fa-930d5ed16b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-e25fed71-a148-439b-bab2-682df8359288,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-994d14ce-32fe-4493-8d36-db76b53a7603,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-3494901c-1096-4f3d-8fd5-b40d91a75ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-42c347b9-7832-4da8-ba53-f28b7b24415a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714616420-172.17.0.17-1597739168280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-6240a001-c622-465e-bdb9-2c77bdfc24ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f8386423-64e4-428c-a9b6-c08b881f3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-1140d696-8737-48ea-a546-8519c65df7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-16bb1a4b-ef36-47d6-941a-45472c738478,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-6eb4490e-0f1c-47c5-9bc8-8f04b06a3113,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-878cf6c0-0dfb-4bbe-8163-d9bb11c82703,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-13929bf8-3f97-4433-beb8-a64e9a928929,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-9239f543-f2fe-4550-818e-d97b96d644f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714616420-172.17.0.17-1597739168280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-6240a001-c622-465e-bdb9-2c77bdfc24ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f8386423-64e4-428c-a9b6-c08b881f3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-1140d696-8737-48ea-a546-8519c65df7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-16bb1a4b-ef36-47d6-941a-45472c738478,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-6eb4490e-0f1c-47c5-9bc8-8f04b06a3113,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-878cf6c0-0dfb-4bbe-8163-d9bb11c82703,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-13929bf8-3f97-4433-beb8-a64e9a928929,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-9239f543-f2fe-4550-818e-d97b96d644f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084569314-172.17.0.17-1597739460819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-28ef4ce2-ab24-4ecb-bc68-1aa2d2028362,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-c796f009-5305-493b-8467-3ff8d3cea923,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-4c0f2e47-c226-4cb2-aaf8-fbab5d82681a,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-581c55e2-30e7-4c8a-96a1-e131b10cda00,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-7b316bd3-7e12-4102-a464-dc8943160091,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d1b1b1c2-0258-417e-aca7-f2a1952079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-a3e6a8c4-1572-43b9-9098-e6d925cac173,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-dc71b324-911d-4ccd-95c9-f27e817b0489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084569314-172.17.0.17-1597739460819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-28ef4ce2-ab24-4ecb-bc68-1aa2d2028362,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-c796f009-5305-493b-8467-3ff8d3cea923,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-4c0f2e47-c226-4cb2-aaf8-fbab5d82681a,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-581c55e2-30e7-4c8a-96a1-e131b10cda00,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-7b316bd3-7e12-4102-a464-dc8943160091,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d1b1b1c2-0258-417e-aca7-f2a1952079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-a3e6a8c4-1572-43b9-9098-e6d925cac173,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-dc71b324-911d-4ccd-95c9-f27e817b0489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069496390-172.17.0.17-1597739575475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-4a858ab6-befb-40c8-82ff-39301e206c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ba146406-c529-4a1a-a061-3945b09be23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-1dd1c7b8-a443-4738-8b20-a8fb9912045d,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-eec9ce52-28ee-4bef-84b4-7d2281d6fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-a8d6665a-fe3b-4944-ad34-b29542a97359,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-8f830de5-f443-45a9-8107-a6bb6ad4e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-16f47d03-db90-48c7-8b69-1b4fbdd0b993,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-db0411f2-a103-4f0d-b348-8e197ab2b068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069496390-172.17.0.17-1597739575475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-4a858ab6-befb-40c8-82ff-39301e206c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ba146406-c529-4a1a-a061-3945b09be23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-1dd1c7b8-a443-4738-8b20-a8fb9912045d,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-eec9ce52-28ee-4bef-84b4-7d2281d6fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-a8d6665a-fe3b-4944-ad34-b29542a97359,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-8f830de5-f443-45a9-8107-a6bb6ad4e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-16f47d03-db90-48c7-8b69-1b4fbdd0b993,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-db0411f2-a103-4f0d-b348-8e197ab2b068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563533221-172.17.0.17-1597739716492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-5c85c5ed-4306-4d62-a2c2-ce49d86d5a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-53c708bc-ed68-4ece-aa68-e5ae78a4becb,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-2818deb8-4d65-4a07-ba62-11291a7a925a,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-5c1627f4-1524-45d3-bead-91b79597c411,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-26c1e7bd-3a22-4af0-9b8d-69d46627e456,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-e0e6fd1e-61e2-4d1e-a6b8-a195247e0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-19381eb8-1a2a-48a5-9dd8-d901b5951b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e69d5833-6605-412c-92b2-2271223b254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563533221-172.17.0.17-1597739716492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-5c85c5ed-4306-4d62-a2c2-ce49d86d5a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-53c708bc-ed68-4ece-aa68-e5ae78a4becb,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-2818deb8-4d65-4a07-ba62-11291a7a925a,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-5c1627f4-1524-45d3-bead-91b79597c411,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-26c1e7bd-3a22-4af0-9b8d-69d46627e456,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-e0e6fd1e-61e2-4d1e-a6b8-a195247e0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-19381eb8-1a2a-48a5-9dd8-d901b5951b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e69d5833-6605-412c-92b2-2271223b254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702491408-172.17.0.17-1597739757878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-9ebbac10-8c99-4e9b-8ab8-c99db9379405,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-5c5006cc-82c9-43d6-b103-03224fea183b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-30e71670-8603-4667-b499-bf52441d5ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-542e8aca-4246-41d4-96e5-5b22cdb61cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-72df1e5d-0141-4c8f-b4ad-2f0d87586097,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-ccc73077-153a-48ae-a4b9-6e1d067b06db,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-612520e3-6c45-431c-b3fe-89b08c9837a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-774a64ff-e315-4fe3-84c5-d4512088105e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702491408-172.17.0.17-1597739757878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-9ebbac10-8c99-4e9b-8ab8-c99db9379405,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-5c5006cc-82c9-43d6-b103-03224fea183b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-30e71670-8603-4667-b499-bf52441d5ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-542e8aca-4246-41d4-96e5-5b22cdb61cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-72df1e5d-0141-4c8f-b4ad-2f0d87586097,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-ccc73077-153a-48ae-a4b9-6e1d067b06db,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-612520e3-6c45-431c-b3fe-89b08c9837a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-774a64ff-e315-4fe3-84c5-d4512088105e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541002070-172.17.0.17-1597740073489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-b551f9ba-faa5-4777-933c-89ad35273fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ede3282f-aa38-4a2c-bad5-298577d356ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-c837a3c1-b01e-4118-b244-289d6f54d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-7b739d0d-e084-413d-9506-cec248aa44b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-cbaadcfe-120e-4203-b0b0-6ce0a96f4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-7603c9ed-7aab-48d3-8b45-c25a94e51d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-669d9b40-6ed4-4451-8721-efa1c21fc67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-1f5b728a-6531-4349-a312-a1c55374ca83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541002070-172.17.0.17-1597740073489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-b551f9ba-faa5-4777-933c-89ad35273fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ede3282f-aa38-4a2c-bad5-298577d356ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-c837a3c1-b01e-4118-b244-289d6f54d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-7b739d0d-e084-413d-9506-cec248aa44b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-cbaadcfe-120e-4203-b0b0-6ce0a96f4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-7603c9ed-7aab-48d3-8b45-c25a94e51d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-669d9b40-6ed4-4451-8721-efa1c21fc67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-1f5b728a-6531-4349-a312-a1c55374ca83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335062776-172.17.0.17-1597740229690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-35fd6051-d20d-4d43-851b-c1045707519d,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-45041369-e782-4207-893b-d03d1f85aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-86fd5abd-b546-42c7-874b-34fb541ebf04,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-82a32d41-e3c5-4a3e-b5fb-e730bfd8046a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-ed6c8fa3-0f90-4187-b9cf-8d8fbd495241,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c5e8b268-7fd6-4776-83ee-c92947c51121,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-06429338-30b9-4df1-ba6f-3b62c18a08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-2fc7f486-274b-44a0-8f28-f914a27540bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335062776-172.17.0.17-1597740229690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-35fd6051-d20d-4d43-851b-c1045707519d,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-45041369-e782-4207-893b-d03d1f85aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-86fd5abd-b546-42c7-874b-34fb541ebf04,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-82a32d41-e3c5-4a3e-b5fb-e730bfd8046a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-ed6c8fa3-0f90-4187-b9cf-8d8fbd495241,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c5e8b268-7fd6-4776-83ee-c92947c51121,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-06429338-30b9-4df1-ba6f-3b62c18a08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-2fc7f486-274b-44a0-8f28-f914a27540bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5619
