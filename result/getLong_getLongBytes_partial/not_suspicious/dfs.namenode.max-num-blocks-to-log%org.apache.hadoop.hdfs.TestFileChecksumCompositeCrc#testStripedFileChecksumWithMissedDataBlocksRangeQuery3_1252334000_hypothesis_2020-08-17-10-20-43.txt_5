reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320838040-172.17.0.3-1597659829447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-7d7c98e9-a321-45e0-a050-94292e49443e,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-e4034f1e-fdc9-4040-a8f8-2cf5c73d1d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-2a894b5a-4ccf-40d9-aa26-118d1bb7be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-43a815f3-691a-4554-b193-08ad3b4abcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1b0e6a74-fb85-40f0-ad0a-1b097224d954,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-d859d6bf-aa02-473a-89e7-5cb710d275af,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-9023814f-77b7-485c-bf03-0367e35b78d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-196386bb-715d-4895-871b-49fa308ea2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320838040-172.17.0.3-1597659829447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-7d7c98e9-a321-45e0-a050-94292e49443e,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-e4034f1e-fdc9-4040-a8f8-2cf5c73d1d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-2a894b5a-4ccf-40d9-aa26-118d1bb7be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-43a815f3-691a-4554-b193-08ad3b4abcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1b0e6a74-fb85-40f0-ad0a-1b097224d954,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-d859d6bf-aa02-473a-89e7-5cb710d275af,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-9023814f-77b7-485c-bf03-0367e35b78d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-196386bb-715d-4895-871b-49fa308ea2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703430502-172.17.0.3-1597660307773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33639,DS-9b967a2a-5cd4-440f-8ed2-a2e51a276b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-729e6ff1-1d9e-4d92-bdca-b3ab538fec97,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-aa87cb2f-c4c7-438e-9753-54511dca2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-01e145b9-2dc6-4c55-be16-3cf51751526b,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-84d9f32a-cac9-4017-83cf-faaff51878fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d4b5bdf6-6f87-4159-b639-e7dc37fc9b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-3a5dd378-a211-4d77-bd84-ee9f0f0a4391,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-7d1e203a-48e3-4a07-9933-c85bb02a9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703430502-172.17.0.3-1597660307773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33639,DS-9b967a2a-5cd4-440f-8ed2-a2e51a276b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-729e6ff1-1d9e-4d92-bdca-b3ab538fec97,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-aa87cb2f-c4c7-438e-9753-54511dca2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-01e145b9-2dc6-4c55-be16-3cf51751526b,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-84d9f32a-cac9-4017-83cf-faaff51878fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d4b5bdf6-6f87-4159-b639-e7dc37fc9b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-3a5dd378-a211-4d77-bd84-ee9f0f0a4391,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-7d1e203a-48e3-4a07-9933-c85bb02a9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059979095-172.17.0.3-1597661734937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-22f3a9a8-f436-46c4-9c07-45251a755324,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-3ed9b5d6-5c1b-4b16-8b4f-2ac87199c623,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-81479f9d-6670-418a-a936-b8af25a28836,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0c09e7d0-d8b4-4f03-b633-f57b3e75fbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-64408913-52e4-464c-9c3f-117991e5ba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-0cdc7351-6cd1-4fc2-a456-2e977d16a88b,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-1cb3fe9a-6cb4-41ff-95fe-c0eca01021f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-63b539b0-57dc-480f-83e5-9621e1fbcd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059979095-172.17.0.3-1597661734937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-22f3a9a8-f436-46c4-9c07-45251a755324,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-3ed9b5d6-5c1b-4b16-8b4f-2ac87199c623,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-81479f9d-6670-418a-a936-b8af25a28836,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0c09e7d0-d8b4-4f03-b633-f57b3e75fbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-64408913-52e4-464c-9c3f-117991e5ba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-0cdc7351-6cd1-4fc2-a456-2e977d16a88b,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-1cb3fe9a-6cb4-41ff-95fe-c0eca01021f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-63b539b0-57dc-480f-83e5-9621e1fbcd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272437612-172.17.0.3-1597661910715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43508,DS-4840b48c-a56a-4e37-b86d-04b523a1be31,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1fd62d30-c1e8-4493-9d03-1dc0ef009820,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-fb7b1df5-910a-4138-b40b-a9ffe4865ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-80c0c07d-d32d-4628-b930-2a1d46e0445f,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-726148e9-041b-4a96-b316-7fa4c5404856,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-83bd312b-25e9-472a-81cf-a6ef15f2e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-480e3eb5-dcd8-461c-a671-a4628f981972,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f7a51ae6-4801-44ab-9fcd-a647e930d890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272437612-172.17.0.3-1597661910715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43508,DS-4840b48c-a56a-4e37-b86d-04b523a1be31,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1fd62d30-c1e8-4493-9d03-1dc0ef009820,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-fb7b1df5-910a-4138-b40b-a9ffe4865ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-80c0c07d-d32d-4628-b930-2a1d46e0445f,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-726148e9-041b-4a96-b316-7fa4c5404856,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-83bd312b-25e9-472a-81cf-a6ef15f2e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-480e3eb5-dcd8-461c-a671-a4628f981972,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f7a51ae6-4801-44ab-9fcd-a647e930d890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9398756-172.17.0.3-1597662534871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-b4bad2e4-c609-49c2-8751-a1400dd03c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-361caa4e-4b55-43b6-bb26-4b2717e23026,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e2c6c0bd-d6a4-4f67-929c-4ea3e3eec8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-166f4cfc-9cd9-4129-8506-b05361cdb772,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c6d599a0-396e-4c4d-862e-3d670c5edbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-7d829c8a-9f58-43a1-bf19-84b46296520c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-895a1be8-56af-4777-bc26-adcfa067e359,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-91dd4339-3973-4ca9-bdc9-4ab2a80ca089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9398756-172.17.0.3-1597662534871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-b4bad2e4-c609-49c2-8751-a1400dd03c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-361caa4e-4b55-43b6-bb26-4b2717e23026,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e2c6c0bd-d6a4-4f67-929c-4ea3e3eec8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-166f4cfc-9cd9-4129-8506-b05361cdb772,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c6d599a0-396e-4c4d-862e-3d670c5edbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-7d829c8a-9f58-43a1-bf19-84b46296520c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-895a1be8-56af-4777-bc26-adcfa067e359,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-91dd4339-3973-4ca9-bdc9-4ab2a80ca089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404187680-172.17.0.3-1597662571288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-c0cbfd1c-5d78-42d0-9e2f-060c209548fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c33434a5-648d-4cad-a0da-aa0fa93751a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-045603ac-3ef8-4f57-8d86-7a37d4ab5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-2ff865a4-f0e3-4f68-87a4-c39280c2e298,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-ad81b4d1-d7e8-435f-b943-be70c8671532,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-c462a848-53fd-4a0a-ba2c-10083b26fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-a4b6208d-668b-456c-bb73-5a8d3986cede,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-ee714e45-545d-477d-8309-f42749eab391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404187680-172.17.0.3-1597662571288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-c0cbfd1c-5d78-42d0-9e2f-060c209548fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c33434a5-648d-4cad-a0da-aa0fa93751a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-045603ac-3ef8-4f57-8d86-7a37d4ab5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-2ff865a4-f0e3-4f68-87a4-c39280c2e298,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-ad81b4d1-d7e8-435f-b943-be70c8671532,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-c462a848-53fd-4a0a-ba2c-10083b26fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-a4b6208d-668b-456c-bb73-5a8d3986cede,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-ee714e45-545d-477d-8309-f42749eab391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243227602-172.17.0.3-1597662878333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-1bee518a-8e26-4b7a-a864-f62bc9447de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-8c5555d4-bafc-4ef2-ba08-af1f2ab86a60,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-4766a42c-7097-472f-a58a-668a4a31f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-ddf5d6f5-64d8-4561-9008-76f5aae564dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-87d0ca22-0da7-4a68-b751-07bb9b9a95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-158dbbd6-046a-4163-9184-cd683a6526eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-e7703df1-6510-4eb1-9a81-0762d90401f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-0778abab-bad5-479d-8810-8920540d57ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243227602-172.17.0.3-1597662878333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-1bee518a-8e26-4b7a-a864-f62bc9447de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-8c5555d4-bafc-4ef2-ba08-af1f2ab86a60,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-4766a42c-7097-472f-a58a-668a4a31f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-ddf5d6f5-64d8-4561-9008-76f5aae564dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-87d0ca22-0da7-4a68-b751-07bb9b9a95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-158dbbd6-046a-4163-9184-cd683a6526eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-e7703df1-6510-4eb1-9a81-0762d90401f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-0778abab-bad5-479d-8810-8920540d57ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899807061-172.17.0.3-1597663135561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-9a04261a-800d-44af-8f68-c08025df3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-db7c8de6-994b-49c1-b48c-2bfc91571a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-815bb9d8-e97d-4395-b3f0-79560edf110f,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-f5078d10-de0f-4b2b-93fa-ca8814362756,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4f8bfe1d-8b25-494e-a843-74d7174f4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-efa57aab-6d52-416b-9348-4296ed752fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-bfd37904-039a-4c4a-829b-f6c224c6e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-e4a66181-b7a6-4f0c-b843-666819c40ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899807061-172.17.0.3-1597663135561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-9a04261a-800d-44af-8f68-c08025df3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-db7c8de6-994b-49c1-b48c-2bfc91571a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-815bb9d8-e97d-4395-b3f0-79560edf110f,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-f5078d10-de0f-4b2b-93fa-ca8814362756,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-4f8bfe1d-8b25-494e-a843-74d7174f4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-efa57aab-6d52-416b-9348-4296ed752fad,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-bfd37904-039a-4c4a-829b-f6c224c6e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-e4a66181-b7a6-4f0c-b843-666819c40ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559859692-172.17.0.3-1597663480549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-138d3f1b-06c2-40f6-9342-325469659165,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-322a058a-c36a-4355-bfb9-66a5900c61db,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d781a589-a036-4a3d-b48d-dc7039cdf745,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-9273de94-5b54-4ecd-bcc3-9ef85957f075,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-fd2817d1-d6be-466e-9502-74d5ff45d925,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d020c1f9-eb2a-4a0b-9030-f1bb1b8478a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-1ed4d439-9a4a-4b97-83b3-8c8b7fb8cc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-13d8dda3-2800-4bae-8760-81fc299410a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559859692-172.17.0.3-1597663480549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-138d3f1b-06c2-40f6-9342-325469659165,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-322a058a-c36a-4355-bfb9-66a5900c61db,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d781a589-a036-4a3d-b48d-dc7039cdf745,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-9273de94-5b54-4ecd-bcc3-9ef85957f075,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-fd2817d1-d6be-466e-9502-74d5ff45d925,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d020c1f9-eb2a-4a0b-9030-f1bb1b8478a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-1ed4d439-9a4a-4b97-83b3-8c8b7fb8cc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-13d8dda3-2800-4bae-8760-81fc299410a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778055923-172.17.0.3-1597663763757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40131,DS-dce7a0db-f3c1-4fe6-ad18-144ff0258a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-aca42e94-e144-4447-859d-4495dec64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-3339b94a-134e-4373-a74a-61dbca2b28bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-40f0b401-8773-43e7-8c0b-d974e1ac06f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-4900baf1-df15-46ae-938b-966fb9db2824,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-449d530e-6cfb-4d16-a2c1-493c3f8a2c86,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-af4ebeeb-61e3-4e7a-8b63-080cec60776b,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-2c36e38b-da9e-4094-987b-be461ef653a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778055923-172.17.0.3-1597663763757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40131,DS-dce7a0db-f3c1-4fe6-ad18-144ff0258a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-aca42e94-e144-4447-859d-4495dec64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-3339b94a-134e-4373-a74a-61dbca2b28bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-40f0b401-8773-43e7-8c0b-d974e1ac06f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-4900baf1-df15-46ae-938b-966fb9db2824,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-449d530e-6cfb-4d16-a2c1-493c3f8a2c86,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-af4ebeeb-61e3-4e7a-8b63-080cec60776b,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-2c36e38b-da9e-4094-987b-be461ef653a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497924774-172.17.0.3-1597663801392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-8345115a-272c-4660-a83a-a6afb8c2efb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-2efc9e43-c6ce-4469-9114-6dc4b2e43cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c48c9489-a10d-4e32-b392-a06870e807b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-9034061f-34f2-4f69-9225-701da956eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-6bce8abd-fa7f-4f95-8179-8249dd61ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-bd6f1292-84a7-4054-9618-aa367c7c9b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-a754784a-f715-4500-9d11-a137979b96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-7432e4d7-96ca-4491-aedb-92ffca6060d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497924774-172.17.0.3-1597663801392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-8345115a-272c-4660-a83a-a6afb8c2efb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-2efc9e43-c6ce-4469-9114-6dc4b2e43cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c48c9489-a10d-4e32-b392-a06870e807b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-9034061f-34f2-4f69-9225-701da956eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-6bce8abd-fa7f-4f95-8179-8249dd61ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-bd6f1292-84a7-4054-9618-aa367c7c9b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-a754784a-f715-4500-9d11-a137979b96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-7432e4d7-96ca-4491-aedb-92ffca6060d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197549167-172.17.0.3-1597663845118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37121,DS-df0d87ff-dff6-4679-945e-3f69fbedc605,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-2fd748a5-7770-41af-aa10-865facbe7a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-0c680de8-470b-4ecc-ba7b-bd29a7d285c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-7216d22a-c9bb-4493-b472-ffde3b2410ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-6392b97a-e024-446b-a30c-4d6c2f3b6484,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-542afe77-8a69-4aed-9021-c947371b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-83319ded-5a4f-40b9-9557-b17f3ac816e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-16ee1936-c7c1-4a0a-aee3-c3ba666fe747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197549167-172.17.0.3-1597663845118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37121,DS-df0d87ff-dff6-4679-945e-3f69fbedc605,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-2fd748a5-7770-41af-aa10-865facbe7a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-0c680de8-470b-4ecc-ba7b-bd29a7d285c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-7216d22a-c9bb-4493-b472-ffde3b2410ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-6392b97a-e024-446b-a30c-4d6c2f3b6484,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-542afe77-8a69-4aed-9021-c947371b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-83319ded-5a4f-40b9-9557-b17f3ac816e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-16ee1936-c7c1-4a0a-aee3-c3ba666fe747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153444833-172.17.0.3-1597663918256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-d4841b66-2634-4c22-99ec-4668acfa7f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-b60081eb-bbbb-4c2f-924a-e7f69a0dc193,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-36f498cd-8b60-42eb-9698-e2783a2cbc10,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-d0e918be-0f7c-4e3e-a311-65b54f30306a,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-48f09397-8198-4535-af18-0adfc78f199c,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-fdca77bd-4e9e-4c3d-9f29-4e2abdee58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-98922f6f-6ce6-483a-8cc6-d2296972b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1f889e99-dda8-4706-ab52-25e91bc8e149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153444833-172.17.0.3-1597663918256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-d4841b66-2634-4c22-99ec-4668acfa7f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-b60081eb-bbbb-4c2f-924a-e7f69a0dc193,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-36f498cd-8b60-42eb-9698-e2783a2cbc10,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-d0e918be-0f7c-4e3e-a311-65b54f30306a,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-48f09397-8198-4535-af18-0adfc78f199c,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-fdca77bd-4e9e-4c3d-9f29-4e2abdee58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-98922f6f-6ce6-483a-8cc6-d2296972b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1f889e99-dda8-4706-ab52-25e91bc8e149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077958884-172.17.0.3-1597663993372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-dc7d0037-af0a-4989-8782-9c823368c25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-c1d03fa5-59ed-4cdc-9067-278bce8b8a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-124a87b2-9964-4a2b-b5d6-df92b490efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-5637edb3-209c-4a98-a9fa-33d236f21599,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-b85bcf15-dc93-40c4-8eb5-e01bd97abaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-9090ab79-3362-4ac8-a06d-3a76b89d969c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-eb853a90-fec7-48ba-a716-3398af5ae89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-28bb09e6-fc6e-4035-b493-ff4197748f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077958884-172.17.0.3-1597663993372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-dc7d0037-af0a-4989-8782-9c823368c25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-c1d03fa5-59ed-4cdc-9067-278bce8b8a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-124a87b2-9964-4a2b-b5d6-df92b490efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-5637edb3-209c-4a98-a9fa-33d236f21599,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-b85bcf15-dc93-40c4-8eb5-e01bd97abaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-9090ab79-3362-4ac8-a06d-3a76b89d969c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-eb853a90-fec7-48ba-a716-3398af5ae89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-28bb09e6-fc6e-4035-b493-ff4197748f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516940689-172.17.0.3-1597664067621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-6792d91d-e6a2-42da-b6f6-1e8760e8746e,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-00230807-b38e-477c-b63b-81b2598a6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-ecb3fb81-502e-48d9-aaa5-fb5593ac342c,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-34bebfb7-b811-4409-b433-15f572587638,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e90097ef-eabb-4f01-82c4-51cc7b91b933,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-44b7020f-a4f2-4b4f-8231-b68157a26bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-b918b1ea-75e5-44ae-a8f5-01364307dc02,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-8c0be976-4d1b-450a-97ce-4e4e4be84c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516940689-172.17.0.3-1597664067621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-6792d91d-e6a2-42da-b6f6-1e8760e8746e,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-00230807-b38e-477c-b63b-81b2598a6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-ecb3fb81-502e-48d9-aaa5-fb5593ac342c,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-34bebfb7-b811-4409-b433-15f572587638,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e90097ef-eabb-4f01-82c4-51cc7b91b933,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-44b7020f-a4f2-4b4f-8231-b68157a26bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-b918b1ea-75e5-44ae-a8f5-01364307dc02,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-8c0be976-4d1b-450a-97ce-4e4e4be84c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679114729-172.17.0.3-1597664151526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-b1f955f4-c856-4d84-bc0b-cd3870089eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-2136d48a-b15a-4761-a7ca-9379175c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-021d639a-9ad3-40ff-90a9-383e27a2bd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-2cfae3a8-3b67-41c6-ba96-d7acb895251b,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-fcd071ca-b082-4062-928e-d55aea5680f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-40eea213-1289-4043-b24b-ec11ce9bc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-1898369d-4620-4588-b1ab-118e756838d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8168901c-db76-4fdf-b7cf-e52ff6f08753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679114729-172.17.0.3-1597664151526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-b1f955f4-c856-4d84-bc0b-cd3870089eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-2136d48a-b15a-4761-a7ca-9379175c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-021d639a-9ad3-40ff-90a9-383e27a2bd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-2cfae3a8-3b67-41c6-ba96-d7acb895251b,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-fcd071ca-b082-4062-928e-d55aea5680f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-40eea213-1289-4043-b24b-ec11ce9bc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-1898369d-4620-4588-b1ab-118e756838d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8168901c-db76-4fdf-b7cf-e52ff6f08753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221928069-172.17.0.3-1597664429143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-4cfd7993-6cef-4c77-b5ae-7a90473562c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5698dd5a-9674-4b52-829c-a44ea73c0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-79c8ef10-3606-4a7d-a3db-283a7e548240,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-c8546d1d-1468-4a56-bf37-af35ed0affb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-3210037f-a56c-47c0-b45f-10629f41c51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-946af350-7e0e-48aa-bd54-2752879497bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-37128848-13d8-4eca-8969-a1ba0427c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-b4298166-9425-4469-aed0-f61610baf536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221928069-172.17.0.3-1597664429143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-4cfd7993-6cef-4c77-b5ae-7a90473562c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5698dd5a-9674-4b52-829c-a44ea73c0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-79c8ef10-3606-4a7d-a3db-283a7e548240,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-c8546d1d-1468-4a56-bf37-af35ed0affb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-3210037f-a56c-47c0-b45f-10629f41c51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-946af350-7e0e-48aa-bd54-2752879497bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-37128848-13d8-4eca-8969-a1ba0427c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-b4298166-9425-4469-aed0-f61610baf536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031695272-172.17.0.3-1597664500919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-393bfdf8-6c77-455c-9d12-cb4b9dbc3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-72ff1213-be2d-47e8-9783-c273f0fb7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-0216fc87-be88-4cd3-8163-d4a3731cd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-1951c59a-edbb-425a-9530-9b5529b15f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-2ed8985f-d714-4ac9-983b-76533a29f368,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-f6484c7d-caf0-45dc-9284-e3349234d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-db250c0c-6c9e-4654-896c-5e8c9bb7346a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-43dafe63-5ffe-4728-a765-5368bc8d9e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031695272-172.17.0.3-1597664500919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-393bfdf8-6c77-455c-9d12-cb4b9dbc3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-72ff1213-be2d-47e8-9783-c273f0fb7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-0216fc87-be88-4cd3-8163-d4a3731cd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-1951c59a-edbb-425a-9530-9b5529b15f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-2ed8985f-d714-4ac9-983b-76533a29f368,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-f6484c7d-caf0-45dc-9284-e3349234d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-db250c0c-6c9e-4654-896c-5e8c9bb7346a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-43dafe63-5ffe-4728-a765-5368bc8d9e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834954031-172.17.0.3-1597665166226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-6506954d-af00-4c48-9342-7b5884f58a13,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-dc1354e2-89ac-481e-a644-f38c64cdfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-e6ca5ca7-45f4-48c1-9fea-a2f484d75491,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-705cbe7a-cb17-4a45-803f-104fb0dd3660,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-d65937d6-0eea-4e25-87ec-a0a5f9a1d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-eeb4c478-2708-4838-aa66-301f6765684f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-ea615ada-fed8-4e5a-a12a-4b2e27afba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-f2e2b4fa-e20f-48f3-9212-2e28c4200a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834954031-172.17.0.3-1597665166226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-6506954d-af00-4c48-9342-7b5884f58a13,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-dc1354e2-89ac-481e-a644-f38c64cdfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-e6ca5ca7-45f4-48c1-9fea-a2f484d75491,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-705cbe7a-cb17-4a45-803f-104fb0dd3660,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-d65937d6-0eea-4e25-87ec-a0a5f9a1d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-eeb4c478-2708-4838-aa66-301f6765684f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-ea615ada-fed8-4e5a-a12a-4b2e27afba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-f2e2b4fa-e20f-48f3-9212-2e28c4200a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5692
