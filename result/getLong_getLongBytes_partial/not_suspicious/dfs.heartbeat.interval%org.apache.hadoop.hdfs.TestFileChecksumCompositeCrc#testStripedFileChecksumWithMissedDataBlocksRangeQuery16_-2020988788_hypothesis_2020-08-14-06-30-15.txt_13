reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044223115-172.17.0.17-1597386632308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-eba32eff-bbe5-4e10-9e06-59889f164546,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-21ea77f2-5324-489f-a590-6885edd327ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-f57553fa-85f6-46dd-9bc4-6cc830da176d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-c7476837-ea49-4df8-acae-48df9b8ed72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-d2688005-15e0-4a48-b6d4-d7ef789024dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-1401a4e3-b7dd-4b19-a555-9e2c2f61ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-47b9f6d8-e38a-49dc-a033-9f16079e59e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-3442a7df-2973-4b12-8c7a-c4383f13ef6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044223115-172.17.0.17-1597386632308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-eba32eff-bbe5-4e10-9e06-59889f164546,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-21ea77f2-5324-489f-a590-6885edd327ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-f57553fa-85f6-46dd-9bc4-6cc830da176d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-c7476837-ea49-4df8-acae-48df9b8ed72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-d2688005-15e0-4a48-b6d4-d7ef789024dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-1401a4e3-b7dd-4b19-a555-9e2c2f61ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-47b9f6d8-e38a-49dc-a033-9f16079e59e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-3442a7df-2973-4b12-8c7a-c4383f13ef6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238788946-172.17.0.17-1597387119266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43993,DS-718e18d2-04e4-4308-9356-e1a13d1ba3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-ebf05b2a-59c2-4afd-ba56-35b387e1ccba,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a1271f96-fc20-4723-9845-ca0a3e4756b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-84bf1959-bd2a-48be-b42d-2147c1830b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ca64a7f9-d686-48fb-a716-f7676fba4206,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-90d12b72-5a47-4563-83bd-8c417e89ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-d667ff62-1f49-480a-980c-bd2b348144bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-8df35fee-bac0-4c36-b7af-097780a87da1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238788946-172.17.0.17-1597387119266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43993,DS-718e18d2-04e4-4308-9356-e1a13d1ba3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-ebf05b2a-59c2-4afd-ba56-35b387e1ccba,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a1271f96-fc20-4723-9845-ca0a3e4756b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-84bf1959-bd2a-48be-b42d-2147c1830b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ca64a7f9-d686-48fb-a716-f7676fba4206,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-90d12b72-5a47-4563-83bd-8c417e89ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-d667ff62-1f49-480a-980c-bd2b348144bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-8df35fee-bac0-4c36-b7af-097780a87da1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104261845-172.17.0.17-1597387415994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-25a61ba2-104e-4b88-96c1-bee4bb6d70b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-e973d15a-e665-4257-9f6d-6d2676f50745,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-07b9a6af-e090-4773-bcea-6da01c8798fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-3dfad469-cb50-4cc5-bb58-9748f329372f,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-429ad596-b748-4008-b451-ad18b5d6b4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-b3acc182-63e1-4255-820d-575481554bea,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-c236f13d-702d-4642-8c01-796b78030503,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-2b16b4fe-81a5-4309-8e07-2a5ed97f3697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104261845-172.17.0.17-1597387415994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-25a61ba2-104e-4b88-96c1-bee4bb6d70b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-e973d15a-e665-4257-9f6d-6d2676f50745,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-07b9a6af-e090-4773-bcea-6da01c8798fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-3dfad469-cb50-4cc5-bb58-9748f329372f,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-429ad596-b748-4008-b451-ad18b5d6b4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-b3acc182-63e1-4255-820d-575481554bea,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-c236f13d-702d-4642-8c01-796b78030503,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-2b16b4fe-81a5-4309-8e07-2a5ed97f3697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39712065-172.17.0.17-1597387932557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-99ce177f-fae7-4d2a-8c50-a578fcb23d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-6af33174-199c-4371-b3d5-80c4d2459346,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-0587aa51-42d3-4365-ad34-81f000a049ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-2ae68ba1-134c-429f-a0e0-754947af0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-0922148f-5de1-4e12-b8cf-cd7477b4966b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-75d6ca55-0744-41ca-a5b2-0dbb157f4766,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-debe6a24-b821-47ec-8608-01b206687f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-c0c31752-c65b-42f2-b009-7e13a8968afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39712065-172.17.0.17-1597387932557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-99ce177f-fae7-4d2a-8c50-a578fcb23d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-6af33174-199c-4371-b3d5-80c4d2459346,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-0587aa51-42d3-4365-ad34-81f000a049ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-2ae68ba1-134c-429f-a0e0-754947af0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-0922148f-5de1-4e12-b8cf-cd7477b4966b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-75d6ca55-0744-41ca-a5b2-0dbb157f4766,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-debe6a24-b821-47ec-8608-01b206687f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-c0c31752-c65b-42f2-b009-7e13a8968afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331112495-172.17.0.17-1597388070485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-22424ca5-558f-49c5-ad28-1837100e2031,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-1c0cb8d4-eb77-4127-b47d-bdd7e2848ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-fa06f01b-12bb-4a86-9bfa-a5397ce4dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-1e810420-6917-41d3-92e7-f951c1b5d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-b921f1ef-edaf-4b35-bfd1-5eacd29f152d,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-cbc6c402-aedf-4424-90cf-a6e9e4ecb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-e12476e0-f6b3-4ea1-8c5c-f768514c6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-94c5f7e6-dc3c-4674-8a2c-9812b3cad25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331112495-172.17.0.17-1597388070485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-22424ca5-558f-49c5-ad28-1837100e2031,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-1c0cb8d4-eb77-4127-b47d-bdd7e2848ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-fa06f01b-12bb-4a86-9bfa-a5397ce4dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-1e810420-6917-41d3-92e7-f951c1b5d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-b921f1ef-edaf-4b35-bfd1-5eacd29f152d,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-cbc6c402-aedf-4424-90cf-a6e9e4ecb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-e12476e0-f6b3-4ea1-8c5c-f768514c6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-94c5f7e6-dc3c-4674-8a2c-9812b3cad25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130023943-172.17.0.17-1597388101338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f521f364-d24e-46c2-a2b4-75e9441d09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-b60ad2bd-70b7-4e0e-a824-df864c5745ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-07093382-b8ac-4dd7-993e-a942060faa38,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e446f5b4-5731-4487-bbfa-a3e32fdd5b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-0d176e18-f5a4-4f01-a847-542d61d693b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-6fa55b18-5814-4056-9a18-63892b662c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9f31cc54-59dc-42ca-8ad2-7b2bae15970c,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-db60eca9-1919-4be2-87c8-871c231734f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130023943-172.17.0.17-1597388101338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f521f364-d24e-46c2-a2b4-75e9441d09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-b60ad2bd-70b7-4e0e-a824-df864c5745ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-07093382-b8ac-4dd7-993e-a942060faa38,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e446f5b4-5731-4487-bbfa-a3e32fdd5b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-0d176e18-f5a4-4f01-a847-542d61d693b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-6fa55b18-5814-4056-9a18-63892b662c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9f31cc54-59dc-42ca-8ad2-7b2bae15970c,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-db60eca9-1919-4be2-87c8-871c231734f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190347463-172.17.0.17-1597388751897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-d4aeec9c-be85-4408-be8c-e9fdf2fd4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-34286418-b224-4da8-8011-01a2125c6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-073b53d8-1287-4cf6-adc4-f19270bb8d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-076dbb40-9554-4585-a8d9-d27aa3b762ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-0a2eb6a6-96ef-4d19-ba65-174bb91b914b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-dc21845e-5778-44b5-aead-b357d605a4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-4e203135-7724-4af2-81a9-1b23cdc2e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-1342e2e4-8164-4a55-971b-6aaf8ae12bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190347463-172.17.0.17-1597388751897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-d4aeec9c-be85-4408-be8c-e9fdf2fd4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-34286418-b224-4da8-8011-01a2125c6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-073b53d8-1287-4cf6-adc4-f19270bb8d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-076dbb40-9554-4585-a8d9-d27aa3b762ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-0a2eb6a6-96ef-4d19-ba65-174bb91b914b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-dc21845e-5778-44b5-aead-b357d605a4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-4e203135-7724-4af2-81a9-1b23cdc2e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-1342e2e4-8164-4a55-971b-6aaf8ae12bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711042100-172.17.0.17-1597389512253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-58cc510a-2d8e-4a47-9055-f79bce5170b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-9789bbe9-7a88-4375-b70c-3d03b3983348,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-0b3d1065-9f02-4f88-8606-f3966611fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-b6a8ed62-c479-42b2-be04-b5b771e42d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c6317a18-7a44-4999-8f71-478cf3f549d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-2eaef8be-5180-4015-bf6e-c703fdf95d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-ebbd1b5e-113d-4b47-85dc-7f490e9210c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-55957ece-dfd7-4d98-8e9a-3f62b066b783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711042100-172.17.0.17-1597389512253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-58cc510a-2d8e-4a47-9055-f79bce5170b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-9789bbe9-7a88-4375-b70c-3d03b3983348,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-0b3d1065-9f02-4f88-8606-f3966611fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-b6a8ed62-c479-42b2-be04-b5b771e42d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c6317a18-7a44-4999-8f71-478cf3f549d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-2eaef8be-5180-4015-bf6e-c703fdf95d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-ebbd1b5e-113d-4b47-85dc-7f490e9210c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-55957ece-dfd7-4d98-8e9a-3f62b066b783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471553850-172.17.0.17-1597389621465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-4120302d-1928-4295-a726-fa1f3496bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-9bd4ad09-d007-4564-93d9-1c1abf027b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-611574be-2f5c-4e34-8629-76892cc7c41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c0cdf294-384a-481c-9a35-c9cbdbf41ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-01585d4f-9d65-4215-9f6e-5c63fa69a697,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-1cc97211-5435-4660-8709-fceb81606a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e350c198-2f78-4abe-b9ce-e8f488770a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-f1c95721-8f43-43f1-aa7a-1c45756784de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471553850-172.17.0.17-1597389621465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-4120302d-1928-4295-a726-fa1f3496bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-9bd4ad09-d007-4564-93d9-1c1abf027b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-611574be-2f5c-4e34-8629-76892cc7c41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c0cdf294-384a-481c-9a35-c9cbdbf41ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-01585d4f-9d65-4215-9f6e-5c63fa69a697,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-1cc97211-5435-4660-8709-fceb81606a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e350c198-2f78-4abe-b9ce-e8f488770a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-f1c95721-8f43-43f1-aa7a-1c45756784de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375162708-172.17.0.17-1597390110771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-db9d5177-f55f-4c6a-b77f-3585aa1579d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-03e5f568-9f3a-4b0b-90bd-f1c264db2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-da8f99fd-b156-4773-a34f-ff6501ce88fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-d5c42da4-e3f2-4b3e-a2b3-a0af7d55f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-5b6ff18f-3d62-472a-b373-cd5cc3f5ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-cfd7c2fa-4657-4375-9173-fe3156b3f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-089c7dc9-0546-4237-b78e-61d951783a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-046323c9-df85-4fcc-b94f-28b6f7f05bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375162708-172.17.0.17-1597390110771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-db9d5177-f55f-4c6a-b77f-3585aa1579d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-03e5f568-9f3a-4b0b-90bd-f1c264db2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-da8f99fd-b156-4773-a34f-ff6501ce88fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-d5c42da4-e3f2-4b3e-a2b3-a0af7d55f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-5b6ff18f-3d62-472a-b373-cd5cc3f5ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-cfd7c2fa-4657-4375-9173-fe3156b3f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-089c7dc9-0546-4237-b78e-61d951783a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-046323c9-df85-4fcc-b94f-28b6f7f05bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186225357-172.17.0.17-1597390317172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41200,DS-ffa57691-0ae9-49ef-a3d3-25d994a54b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-b8519b17-bd2c-44b3-8b7f-2d8b3f825cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9501b316-9768-4533-84ae-aa128b6c4564,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-aa7931d8-e027-4d8f-87f3-3e10f82b8fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-e5130583-f98c-4528-bda5-4e078ef4df81,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-683bc898-0906-40a8-b315-8e2af74bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-c8a77cae-9c80-4754-b9cf-c6a28c25d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-f135faa5-0e59-46b4-b45b-b9924f329892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186225357-172.17.0.17-1597390317172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41200,DS-ffa57691-0ae9-49ef-a3d3-25d994a54b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-b8519b17-bd2c-44b3-8b7f-2d8b3f825cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9501b316-9768-4533-84ae-aa128b6c4564,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-aa7931d8-e027-4d8f-87f3-3e10f82b8fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-e5130583-f98c-4528-bda5-4e078ef4df81,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-683bc898-0906-40a8-b315-8e2af74bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-c8a77cae-9c80-4754-b9cf-c6a28c25d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-f135faa5-0e59-46b4-b45b-b9924f329892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2699989-172.17.0.17-1597390615658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-0086113c-ec94-481a-baa4-2e43f9c1c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-ef766046-a9b5-4a3a-b03a-9ca0d0e001b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-ceae07a0-a584-48f0-a3a1-370b5d07896b,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ee45c166-3649-4239-b71f-62bb9b69b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-6d6e47bf-0b96-4145-b674-bd6bcec99a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-c8e62831-a185-442f-b475-3a5c45d6bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-16fd37bb-03a5-4b0c-a6fa-90dccb039703,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9e1d7823-e077-4d4a-a6cc-780fea42f184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2699989-172.17.0.17-1597390615658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-0086113c-ec94-481a-baa4-2e43f9c1c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-ef766046-a9b5-4a3a-b03a-9ca0d0e001b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-ceae07a0-a584-48f0-a3a1-370b5d07896b,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ee45c166-3649-4239-b71f-62bb9b69b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-6d6e47bf-0b96-4145-b674-bd6bcec99a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-c8e62831-a185-442f-b475-3a5c45d6bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-16fd37bb-03a5-4b0c-a6fa-90dccb039703,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9e1d7823-e077-4d4a-a6cc-780fea42f184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720895429-172.17.0.17-1597391528626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-f38a8455-5338-40f5-8d1d-f4018efd7646,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-eb523605-c5ff-4260-ad40-78a21219c4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-7d30c466-af36-4547-89bd-56838a1f49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-de15a03b-e686-4dc4-8855-1c1d7bd8e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-9508b1bb-fefc-4751-85fe-dde89a806279,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-226a8d7d-ac2e-4509-b47e-4aab9ea27b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-9c4b9cd4-5502-4366-a1be-0ee3c6b49ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-73a2ef9d-4c2a-4837-8e83-ae463a0ebd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720895429-172.17.0.17-1597391528626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-f38a8455-5338-40f5-8d1d-f4018efd7646,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-eb523605-c5ff-4260-ad40-78a21219c4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-7d30c466-af36-4547-89bd-56838a1f49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-de15a03b-e686-4dc4-8855-1c1d7bd8e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-9508b1bb-fefc-4751-85fe-dde89a806279,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-226a8d7d-ac2e-4509-b47e-4aab9ea27b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-9c4b9cd4-5502-4366-a1be-0ee3c6b49ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-73a2ef9d-4c2a-4837-8e83-ae463a0ebd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398493712-172.17.0.17-1597391599750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-fedaa1d4-70b2-46d8-a28c-9db0d366ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-23d4e949-d05d-4aac-bffb-7c3e4bc19a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-3f298e88-da14-4d20-be32-ddac83e89572,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-c7c445b6-df7e-4100-a5b2-e4b006103811,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-47746ed8-a74f-4bea-809f-a3c210bb2671,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-ffe38e97-6728-40b4-923f-2347f613b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-4aeed0c0-c159-4604-a35f-dcf571e1ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-7cc74f5b-8f6b-4330-b2ae-01a1bb294ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398493712-172.17.0.17-1597391599750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-fedaa1d4-70b2-46d8-a28c-9db0d366ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-23d4e949-d05d-4aac-bffb-7c3e4bc19a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-3f298e88-da14-4d20-be32-ddac83e89572,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-c7c445b6-df7e-4100-a5b2-e4b006103811,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-47746ed8-a74f-4bea-809f-a3c210bb2671,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-ffe38e97-6728-40b4-923f-2347f613b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-4aeed0c0-c159-4604-a35f-dcf571e1ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-7cc74f5b-8f6b-4330-b2ae-01a1bb294ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323596225-172.17.0.17-1597391636289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-c1c6b251-063e-40ee-a3ac-6c0ae37b6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-86464826-356c-41bf-9083-6b3bc7f6883a,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3e7f391d-de9a-4083-8a11-aaf19dda5d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-0be99920-14b5-4afb-b3a3-269dbdeb5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-af552296-28ae-46f9-bcba-7ea5255c9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-147b0a60-3e1e-44ff-9762-6762b0e6c205,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-d4636da7-03d9-4507-9a82-cdd38f35e925,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-dee1c22f-74c9-420c-99ed-031015c7f1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323596225-172.17.0.17-1597391636289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-c1c6b251-063e-40ee-a3ac-6c0ae37b6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-86464826-356c-41bf-9083-6b3bc7f6883a,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3e7f391d-de9a-4083-8a11-aaf19dda5d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-0be99920-14b5-4afb-b3a3-269dbdeb5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-af552296-28ae-46f9-bcba-7ea5255c9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-147b0a60-3e1e-44ff-9762-6762b0e6c205,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-d4636da7-03d9-4507-9a82-cdd38f35e925,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-dee1c22f-74c9-420c-99ed-031015c7f1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5435
